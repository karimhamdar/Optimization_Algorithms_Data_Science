{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybKCScz9Y7gB"
      },
      "source": [
        "# Optimization for data science\n",
        "\n",
        "Members: Karim Hamdar (2092041), Davide Christian Mancosu Bustos (2089208), Luca Tusini (2092227)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxCb6_De2UrU"
      },
      "source": [
        "#**TOY Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K42SP5Fiv5f8"
      },
      "source": [
        "# **Preliminary steps**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iueURCUJ3H_R"
      },
      "outputs": [],
      "source": [
        "#!conda install --yes xlrd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MGfv40oyuoec"
      },
      "outputs": [],
      "source": [
        "# libraries\n",
        "import xlrd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kFKz4HvEHyt2"
      },
      "outputs": [],
      "source": [
        "# set the seed to replicate the results\n",
        "np.random.seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KXvbJZDQInwC"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "m, d, k = 1000, 1000, 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLKgOJrhvx8S"
      },
      "source": [
        "# **First point**\n",
        "\n",
        "Randomly generate a 1000x1000 matrix with entries from a N(0,1) distribution\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItyhYR9OuvNY",
        "outputId": "0ad27f15-91da-45d2-b21c-3702b562036c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-1.0856306   0.99734545  0.2829785  ... -0.90932702  0.47026375\n",
            "  -1.11143045]\n",
            " [-0.74882747  0.56759473  0.71815054 ... -0.35929672 -1.60969508\n",
            "   0.01357006]\n",
            " [-1.77422355 -1.20137731  1.09625679 ...  2.04043199  1.01591697\n",
            "  -1.63378817]\n",
            " ...\n",
            " [-0.58293176 -0.39992967 -0.66714316 ... -0.84152302 -0.7138398\n",
            "   0.24183884]\n",
            " [ 0.31359983 -0.2658506   0.32559755 ... -0.89330319  0.89285981\n",
            "   1.21151471]\n",
            " [ 0.31397752  0.3933895  -0.81198728 ... -0.84768045 -0.73819061\n",
            "  -1.29277267]]\n"
          ]
        }
      ],
      "source": [
        "# randomly generate a 1000x1000 matrix with entries from a N(0,1) distribution\n",
        "A = np.random.randn(m, d)\n",
        "print(A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hoWc2wju4aP"
      },
      "source": [
        "# **Second point**\n",
        "\n",
        "Generate $b_i\\in{1,2,...,k},\\ (k=50)$ by computing $AX+E$ with $X,E$ sampled from normal distribution $X\\in R^{dxk}\\ ,\\ \\ E\\in R^{mxk}$ considering max index in the row as a class label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rG1lTVU8uzTg",
        "outputId": "f0cb9b2c-e8f2-4d3a-90df-4e53f17908e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class labels shape: (1000,)\n",
            "Class labels: [ 1  6 32 10 26 45 27  4 23 37]\n"
          ]
        }
      ],
      "source": [
        "# Generate random matrices\n",
        "X = np.random.randn(m, k)\n",
        "\n",
        "# Generate random matrices\n",
        "W = np.random.randn(d, k)\n",
        "E = np.random.randn(m, k)\n",
        "\n",
        "# Compute AX + E\n",
        "AX_plus_E = np.dot(A, X) + E\n",
        "\n",
        "# Find max index in each row\n",
        "B = np.argmax(AX_plus_E, axis=1) # <-- range from 0 to 49\n",
        "\n",
        "print(\"Class labels shape:\", B.shape)\n",
        "print(\"Class labels:\", B[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkQ16o_ulxef"
      },
      "source": [
        "We want to minimize the function:\n",
        "\n",
        "$$f(x)= \\underset{x\\epsilon R^{dxk}}{min}{\\sum_{i=1}^{m}\\left[{-x}{b_i}^Ta_i+\\log{\\left(\\sum_{c=1}^{k}e^{\\left(x_c^Ta_i\\right)}\\right)}\\right]}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zmb6wc0-FWgy"
      },
      "outputs": [],
      "source": [
        "# Convert a vector of random numbers into a one-hot encoding version.\n",
        "def one_hot_encode(vector):\n",
        "    unique_values = np.unique(vector)\n",
        "    num_unique = len(unique_values)\n",
        "    num_elements = len(vector)\n",
        "\n",
        "    one_hot = np.zeros((num_elements, num_unique))\n",
        "\n",
        "    for i, value in enumerate(vector):\n",
        "        index = np.where(unique_values == value)[0][0]\n",
        "        one_hot[i, index] = 1\n",
        "\n",
        "    return one_hot\n",
        "\n",
        "# Function to compute negative log-likelihood\n",
        "def loss(A, B, X):\n",
        "    # NOTICE: B must be in one-hot encoding for\n",
        "    loss = (np.trace(A @ X @ B.T) + np.sum(np.log(np.sum(np.exp(- np.dot(A, X)), axis=1))))\n",
        "    return np.round(loss,2)\n",
        "\n",
        "# Function to compute softmax row-wise of an input matrix\n",
        "def softmax(matrix):\n",
        "    return np.array([np.exp(row) / sum(np.exp(row)) for row in matrix]).reshape(matrix.shape)\n",
        "\n",
        "# Function to compute the gradient\n",
        "def gradient(A, B, X):\n",
        "    # NOTICE: B must be in one-hot encoding for\n",
        "    P = softmax(- np.dot(A, X))\n",
        "    gd = (A.T @ (B - P))\n",
        "    return gd\n",
        "\n",
        "# Function to compute the gradient of just one column of the parameters\n",
        "def gradient_col(A, B, X, index):\n",
        "    # NOTICE: B must be in one-hot encoding for\n",
        "    P = softmax(- np.dot(A, X))\n",
        "    gd = (A.T @ (B[:,index] - P[:,index]))\n",
        "    return gd\n",
        "\n",
        "# Function to compute the score accuracy\n",
        "def accuracy(A, X, B):\n",
        "    acc = np.sum(np.argmax(softmax(-np.dot(A, X)), axis=1) == B )/A.shape[0]*100\n",
        "    return np.round(acc,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8ByFRyYaV6A"
      },
      "source": [
        "# **Third point**\n",
        "\n",
        "Solve the problem with:\n",
        "1.   Gradient Descent\n",
        "2.   BCGD with randomized rule\n",
        "3.   BCGD with gauss-southwell rule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IIVY53ZlgjH"
      },
      "source": [
        "The partial derivative of $f(x)$ is:\n",
        "\n",
        "$$\\frac{\\partial f(x)}{\\partial X_{j_c}}=-\\sum_{i=1}^{m}{a_{ij}\\left[I\\left(b_i=c\\right)-\\frac{e^{{x_c}^T}a_i}{\\sum_{c'=1}^{k}{e^{{x_{c'}}^T}a_i}}\\right]}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtZY5Pf8Fst9"
      },
      "outputs": [],
      "source": [
        "def gradient_descent(A, B, alpha, max_iter, threshold):\n",
        "\n",
        "    B_onehot = one_hot_encode(B)\n",
        "\n",
        "    # different ways to initialize the parameters\n",
        "    X = np.zeros((A.shape[1], B_onehot.shape[1]))\n",
        "    # X = np.random.rand(A.shape[1], B_onehot.shape[1])\n",
        "    # X = np.random.normal(1, 1, (A.shape[1], B_onehot.shape[1]))\n",
        "\n",
        "    step = 0\n",
        "    step_lst = []\n",
        "    loss_lst = []\n",
        "    acc_lst = []\n",
        "\n",
        "    init_time = time.time()\n",
        "    ticks_gd = [] # CPU time\n",
        "\n",
        "    # print(f\"Initial accuracy: {accuracy(A,X,B)}%\\n\")\n",
        "\n",
        "    while step < max_iter:\n",
        "        step += 1\n",
        "        step_lst.append(step)\n",
        "\n",
        "        X -= alpha * gradient(A, B_onehot, X)\n",
        "\n",
        "        loss_lst.append(loss(A, B_onehot, X))\n",
        "\n",
        "        acc_lst.append(accuracy(A, X, B))\n",
        "\n",
        "        print(f\"Step: {step} ------------ Loss: {loss_lst[-1]} ------------ Accuracy: {acc_lst[-1]}%\")\n",
        "        ticks_gd.append(time.time() - init_time)\n",
        "\n",
        "        # Stopping condition over accuracy\n",
        "        if acc_lst[-1] >= threshold:\n",
        "            print(f\"\\nStopping Condition reached at iteration {step}: accuracy = {acc_lst[-1]}%\")\n",
        "            break\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'step': step_lst,\n",
        "        'loss': loss_lst,\n",
        "        'accuracy': acc_lst,\n",
        "        'CPU': ticks_gd\n",
        "    })\n",
        "\n",
        "    return df, X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5eZWQ1o9Pbw"
      },
      "outputs": [],
      "source": [
        "def R_bcgd(A, B, alpha, max_iter, threshold, block_size=1):\n",
        "\n",
        "    B_onehot = one_hot_encode(B)\n",
        "\n",
        "    # different ways to initialize the parameters\n",
        "    X = np.zeros((A.shape[1], B_onehot.shape[1]))\n",
        "    # X = np.random.rand(A.shape[1], B_onehot.shape[1])\n",
        "    # X = np.random.normal(1, 1, (A.shape[1], B_onehot.shape[1]))\n",
        "\n",
        "    step = 0\n",
        "    step_lst = []\n",
        "    loss_lst = []\n",
        "    acc_lst = []\n",
        "\n",
        "    init_time = time.time()\n",
        "    ticks_gd = [] # CPU time\n",
        "\n",
        "    # print(f\"Initial accuracy: {accuracy(A,X,B)}%\\n\")\n",
        "\n",
        "    while step < max_iter:\n",
        "        step += 1\n",
        "        step_lst.append(step)\n",
        "\n",
        "        # Choose block at random\n",
        "        block_index = np.random.choice(X.shape[0], block_size, replace=False)\n",
        "        # block_index = np.random.choice(X.shape[1], block_size, replace=False)\n",
        "\n",
        "        X[block_index] -= alpha * gradient(A, B_onehot, X)[block_index]\n",
        "        # X[:,block_index] -= alpha * gradient_col(A, B_onehot, X, block_index)\n",
        "\n",
        "        loss_lst.append(loss(A, B_onehot, X))\n",
        "\n",
        "        # predict to check accuracy\n",
        "        acc_lst.append(accuracy(A,X,B))\n",
        "\n",
        "        print(f\"Step: {step} ------------ Loss: {loss_lst[-1]} ------------ Accuracy: {acc_lst[-1]}%\")\n",
        "        ticks_gd.append(time.time() - init_time)\n",
        "\n",
        "        if acc_lst[-1] >= threshold:\n",
        "            print(f\"\\nStopping Condition reached at iteration {step}: accuracy = {acc_lst[-1]}%\")\n",
        "            break\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'step': step_lst,\n",
        "        'loss': loss_lst,\n",
        "        'accuracy': acc_lst,\n",
        "        'CPU': ticks_gd\n",
        "    })\n",
        "\n",
        "    return df, X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7vY1pd79PCQ"
      },
      "outputs": [],
      "source": [
        "def GS_bcgd(A, B, alpha, max_iter, threshold, block_size=1):\n",
        "\n",
        "    B_onehot = one_hot_encode(B)\n",
        "\n",
        "    # different ways to initialize the parameters\n",
        "    X = np.zeros((A.shape[1], B_onehot.shape[1]))\n",
        "    # X = np.random.rand(A.shape[1], B_onehot.shape[1])\n",
        "    # X = np.random.normal(1, 1, (A.shape[1], B_onehot.shape[1]))\n",
        "\n",
        "    step = 0\n",
        "    step_lst = []\n",
        "    loss_lst = []\n",
        "    acc_lst = []\n",
        "\n",
        "    init_time = time.time()\n",
        "    ticks_gd = [] # CPU time\n",
        "\n",
        "    # print(f\"Initial accuracy: {accuracy(A,X,B)}%\\n\")\n",
        "\n",
        "    while step < max_iter:\n",
        "        step += 1\n",
        "        step_lst.append(step)\n",
        "\n",
        "        norm = []\n",
        "\n",
        "        # compute norm of each row (block)\n",
        "        for block in gradient(A, B_onehot, X):\n",
        "            norm.append(np.linalg.norm(block))\n",
        "\n",
        "        # take max norm index\n",
        "        block_index = np.argmax(norm)\n",
        "\n",
        "        X[block_index] -= alpha * gradient(A, B_onehot, X)[block_index]\n",
        "\n",
        "        loss_lst.append(loss(A, B_onehot, X))\n",
        "\n",
        "        acc_lst.append(accuracy(A,X,B))\n",
        "\n",
        "        print(f\"Step: {step} ------------ Loss: {loss_lst[-1]} ------------ Accuracy: {acc_lst[-1]}%\")\n",
        "        ticks_gd.append(time.time() - init_time)\n",
        "\n",
        "        if acc_lst[-1] >= threshold:\n",
        "            print(f\"\\nStopping Condition reached at iteration {step}: accuracy = {acc_lst[-1]}%\")\n",
        "            break\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'step': step_lst,\n",
        "        'loss': loss_lst,\n",
        "        'accuracy': acc_lst,\n",
        "        'CPU': ticks_gd\n",
        "    })\n",
        "\n",
        "\n",
        "    return df, X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "US7rhsbMF0L5"
      },
      "outputs": [],
      "source": [
        "class Multiclass:\n",
        "\n",
        "    def fit(self, A, B, type, alpha, max_iter, threshold):\n",
        "        if type==\"GD\":\n",
        "            self.loss_steps, self.X = gradient_descent(A, B, alpha, max_iter, threshold)\n",
        "\n",
        "        elif type==\"BCGD_R\":\n",
        "            self.loss_steps, self.X = R_bcgd(A, B, alpha, max_iter, threshold)\n",
        "\n",
        "        elif type==\"BCGD_GS\":\n",
        "            self.loss_steps, self.X = GS_bcgd(A, B, alpha, max_iter, threshold)\n",
        "\n",
        "    def plot(self, w):\n",
        "        if w == \"Loss\":\n",
        "            return self.loss_steps.plot(\n",
        "                x='step',\n",
        "                y='loss',\n",
        "                xlabel='Step',\n",
        "                ylabel='Loss',\n",
        "                color='orange',\n",
        "                title='Iterations VS Loss')\n",
        "\n",
        "        elif w == \"Accuracy\":\n",
        "            return self.loss_steps.plot(\n",
        "                x='step',\n",
        "                y='accuracy',\n",
        "                xlabel='Step',\n",
        "                ylabel='Accuracy',\n",
        "                color='orange',\n",
        "                title='Iterations VS Accuracy')\n",
        "\n",
        "        elif w == \"CPU\":\n",
        "            return self.loss_steps.plot(\n",
        "                x='CPU',\n",
        "                y='accuracy',\n",
        "                xlabel='CPU time',\n",
        "                ylabel='Accuracy',\n",
        "                title='CPU time VS Accuracy',\n",
        "                color='orange',\n",
        "                legend=False)\n",
        "\n",
        "    def backup(self):\n",
        "      return self.loss_steps\n",
        "\n",
        "    def predict(self, H):\n",
        "        Z = - H @ self.X\n",
        "        P = softmax(Z)\n",
        "        return np.argmax(P, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JsMqP0A_DcP"
      },
      "outputs": [],
      "source": [
        "# Initialize the model\n",
        "model = Multiclass()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkRTsqHxb6gk"
      },
      "source": [
        "**Perform classic Gradient Descent algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "0KeYlW9T7xeC",
        "outputId": "aaafa496-2359-4257-ac2a-fac5549d33ed"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'B' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-810f116060ad>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"GD\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'B' is not defined"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "# fit model\n",
        "model.fit(A, B, \"GD\", 0.01, 2000, 100)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"\\n Time taken: {np.round(end_time - start_time,2)} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bX0pZSNSHqkP"
      },
      "outputs": [],
      "source": [
        "# check how many matches comparing predicted value and actual value\n",
        "np.sum(model.predict(A) == B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xismagzyHmr-"
      },
      "outputs": [],
      "source": [
        "# Produce plots\n",
        "args = [\"Loss\", \"Accuracy\", \"CPU\"]\n",
        "for a in args: model.plot(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1mKfopxppdn"
      },
      "outputs": [],
      "source": [
        "# save the data for later comparison\n",
        "df_gd = model.backup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbrl0AcBsxnJ"
      },
      "source": [
        "**Perform BCGD Randomized**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwfTGjOr-77n",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "# fit model\n",
        "model.fit(A, B, \"BCGD_R\", 0.01, 2000, 100)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"\\n Time taken: {np.round(end_time - start_time,2)} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Qfjdyue_Zpo"
      },
      "outputs": [],
      "source": [
        "# check how many matches comparing predicted value and actual value\n",
        "np.sum(model.predict(A) == B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Iy1qk5x_ZAU",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Produce plots\n",
        "args = [\"Loss\", \"Accuracy\", \"CPU\"]\n",
        "for a in args: model.plot(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynqL1o6NqwW0"
      },
      "outputs": [],
      "source": [
        "# save the data for later comparison\n",
        "df_random = model.backup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thhcgXZI0cAB"
      },
      "source": [
        "**Perform BCGD with GS rule**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TT5lEbqT_OYQ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "# fit model\n",
        "model.fit(A, B, \"BCGD_GS\", 0.01, 2000, 100)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"\\n Time taken: {np.round(end_time - start_time,2)} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "locPusdN_d1Y"
      },
      "outputs": [],
      "source": [
        "# check how many matches comparing predicted value and actual value\n",
        "np.sum(model.predict(A) == B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ue8n8SVE_dwM"
      },
      "outputs": [],
      "source": [
        "# Produce plots\n",
        "args = [\"Loss\", \"Accuracy\", \"CPU\"]\n",
        "for a in args: model.plot(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tm1iJ9drq2Qd"
      },
      "outputs": [],
      "source": [
        "# save the data for later comparison\n",
        "df_gs = model.backup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2lELzoCT1LA"
      },
      "source": [
        "# **1Â° Real dataset**\n",
        "\n",
        "(https://archive.ics.uci.edu/dataset/602/dry+bean+dataset)\n",
        "\n",
        "The dataset contains 13,611 observations, each with 17 features about dry beans, which are to be classified into one of seven classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "megRV2ODO7Wu"
      },
      "source": [
        "## 1) Data Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "ytqWwCsjT4xB",
        "outputId": "bb56294f-a629-45af-d90e-7c0615806252"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
              "13606  42097    759.696       288.721612       185.944705      1.552728   \n",
              "13607  42101    757.499       281.576392       190.713136      1.476439   \n",
              "13608  42139    759.321       281.539928       191.187979      1.472582   \n",
              "13609  42147    763.779       283.382636       190.275731      1.489326   \n",
              "13610  42159    772.237       295.142741       182.204716      1.619841   \n",
              "\n",
              "       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
              "13606      0.765002       42508     231.515799  0.714574  0.990331   0.916603   \n",
              "13607      0.735702       42494     231.526798  0.799943  0.990752   0.922015   \n",
              "13608      0.734065       42569     231.631261  0.729932  0.989899   0.918424   \n",
              "13609      0.741055       42667     231.653248  0.705389  0.987813   0.907906   \n",
              "13610      0.786693       42600     231.686223  0.788962  0.989648   0.888380   \n",
              "\n",
              "       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \\\n",
              "13606     0.801865      0.006858      0.001749      0.642988      0.998385   \n",
              "13607     0.822252      0.006688      0.001886      0.676099      0.998219   \n",
              "13608     0.822730      0.006681      0.001888      0.676884      0.996767   \n",
              "13609     0.817457      0.006724      0.001852      0.668237      0.995222   \n",
              "13610     0.784997      0.007001      0.001640      0.616221      0.998180   \n",
              "\n",
              "          Class  \n",
              "13606  DERMASON  \n",
              "13607  DERMASON  \n",
              "13608  DERMASON  \n",
              "13609  DERMASON  \n",
              "13610  DERMASON  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc4f2ad8-691e-4eb9-9fe5-340f41fbe67d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Area</th>\n",
              "      <th>Perimeter</th>\n",
              "      <th>MajorAxisLength</th>\n",
              "      <th>MinorAxisLength</th>\n",
              "      <th>AspectRation</th>\n",
              "      <th>Eccentricity</th>\n",
              "      <th>ConvexArea</th>\n",
              "      <th>EquivDiameter</th>\n",
              "      <th>Extent</th>\n",
              "      <th>Solidity</th>\n",
              "      <th>roundness</th>\n",
              "      <th>Compactness</th>\n",
              "      <th>ShapeFactor1</th>\n",
              "      <th>ShapeFactor2</th>\n",
              "      <th>ShapeFactor3</th>\n",
              "      <th>ShapeFactor4</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13606</th>\n",
              "      <td>42097</td>\n",
              "      <td>759.696</td>\n",
              "      <td>288.721612</td>\n",
              "      <td>185.944705</td>\n",
              "      <td>1.552728</td>\n",
              "      <td>0.765002</td>\n",
              "      <td>42508</td>\n",
              "      <td>231.515799</td>\n",
              "      <td>0.714574</td>\n",
              "      <td>0.990331</td>\n",
              "      <td>0.916603</td>\n",
              "      <td>0.801865</td>\n",
              "      <td>0.006858</td>\n",
              "      <td>0.001749</td>\n",
              "      <td>0.642988</td>\n",
              "      <td>0.998385</td>\n",
              "      <td>DERMASON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13607</th>\n",
              "      <td>42101</td>\n",
              "      <td>757.499</td>\n",
              "      <td>281.576392</td>\n",
              "      <td>190.713136</td>\n",
              "      <td>1.476439</td>\n",
              "      <td>0.735702</td>\n",
              "      <td>42494</td>\n",
              "      <td>231.526798</td>\n",
              "      <td>0.799943</td>\n",
              "      <td>0.990752</td>\n",
              "      <td>0.922015</td>\n",
              "      <td>0.822252</td>\n",
              "      <td>0.006688</td>\n",
              "      <td>0.001886</td>\n",
              "      <td>0.676099</td>\n",
              "      <td>0.998219</td>\n",
              "      <td>DERMASON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13608</th>\n",
              "      <td>42139</td>\n",
              "      <td>759.321</td>\n",
              "      <td>281.539928</td>\n",
              "      <td>191.187979</td>\n",
              "      <td>1.472582</td>\n",
              "      <td>0.734065</td>\n",
              "      <td>42569</td>\n",
              "      <td>231.631261</td>\n",
              "      <td>0.729932</td>\n",
              "      <td>0.989899</td>\n",
              "      <td>0.918424</td>\n",
              "      <td>0.822730</td>\n",
              "      <td>0.006681</td>\n",
              "      <td>0.001888</td>\n",
              "      <td>0.676884</td>\n",
              "      <td>0.996767</td>\n",
              "      <td>DERMASON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13609</th>\n",
              "      <td>42147</td>\n",
              "      <td>763.779</td>\n",
              "      <td>283.382636</td>\n",
              "      <td>190.275731</td>\n",
              "      <td>1.489326</td>\n",
              "      <td>0.741055</td>\n",
              "      <td>42667</td>\n",
              "      <td>231.653248</td>\n",
              "      <td>0.705389</td>\n",
              "      <td>0.987813</td>\n",
              "      <td>0.907906</td>\n",
              "      <td>0.817457</td>\n",
              "      <td>0.006724</td>\n",
              "      <td>0.001852</td>\n",
              "      <td>0.668237</td>\n",
              "      <td>0.995222</td>\n",
              "      <td>DERMASON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13610</th>\n",
              "      <td>42159</td>\n",
              "      <td>772.237</td>\n",
              "      <td>295.142741</td>\n",
              "      <td>182.204716</td>\n",
              "      <td>1.619841</td>\n",
              "      <td>0.786693</td>\n",
              "      <td>42600</td>\n",
              "      <td>231.686223</td>\n",
              "      <td>0.788962</td>\n",
              "      <td>0.989648</td>\n",
              "      <td>0.888380</td>\n",
              "      <td>0.784997</td>\n",
              "      <td>0.007001</td>\n",
              "      <td>0.001640</td>\n",
              "      <td>0.616221</td>\n",
              "      <td>0.998180</td>\n",
              "      <td>DERMASON</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc4f2ad8-691e-4eb9-9fe5-340f41fbe67d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc4f2ad8-691e-4eb9-9fe5-340f41fbe67d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc4f2ad8-691e-4eb9-9fe5-340f41fbe67d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-17aa0649-296d-49bc-9726-6200ffefd4af\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-17aa0649-296d-49bc-9726-6200ffefd4af')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-17aa0649-296d-49bc-9726-6200ffefd4af button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Area\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27,\n        \"min\": 42097,\n        \"max\": 42159,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          42101,\n          42159,\n          42139\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Perimeter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.903881418185824,\n        \"min\": 757.499,\n        \"max\": 772.237,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          757.499,\n          772.237,\n          759.321\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MajorAxisLength\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.8583621051616115,\n        \"min\": 281.53992791425856,\n        \"max\": 295.1427409885261,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          281.57639233416154,\n          295.1427409885261,\n          281.53992791425856\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MinorAxisLength\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.8888151442155374,\n        \"min\": 182.20471589551335,\n        \"max\": 191.18797890118992,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          190.71313645035534,\n          182.20471589551335,\n          191.18797890118992\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AspectRation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06344782532739073,\n        \"min\": 1.4725817466785633,\n        \"max\": 1.619841393994313,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.4764394187783645,\n          1.619841393994313,\n          1.4725817466785633\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Eccentricity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.022795191425363633,\n        \"min\": 0.7340647812005844,\n        \"max\": 0.7866930164023944,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7357022182714947,\n          0.7866930164023944,\n          0.7340647812005844\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ConvexArea\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 70,\n        \"min\": 42494,\n        \"max\": 42667,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          42494,\n          42600,\n          42569\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EquivDiameter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07690880864502898,\n        \"min\": 231.51579884473574,\n        \"max\": 231.68622308305197,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          231.5267977424969,\n          231.68622308305197,\n          231.63126122264893\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Extent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04368957594452771,\n        \"min\": 0.7053891213389122,\n        \"max\": 0.7999429982899487,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7999429982899487,\n          0.7889624971929037,\n          0.7299324441364975\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.001130070302611255,\n        \"min\": 0.9878125952140999,\n        \"max\": 0.9907516355250153,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9907516355250153,\n          0.9896478873239437,\n          0.9898987526134041\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roundness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013495456756684954,\n        \"min\": 0.8883803685666437,\n        \"max\": 0.92201534243912,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.92201534243912,\n          0.8883803685666437,\n          0.9184240911067681\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Compactness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01627108658909681,\n        \"min\": 0.7849971925687949,\n        \"max\": 0.8227297028121389,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8222521633409233,\n          0.7849971925687949,\n          0.8227297028121389\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ShapeFactor1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0001375668572222549,\n        \"min\": 0.006681219960470314,\n        \"max\": 0.007000705448149294,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.006688116489730922,\n          0.007000705448149294,\n          0.006681219960470314\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ShapeFactor2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00010732246023172789,\n        \"min\": 0.0016398117055199317,\n        \"max\": 0.0018882706374543654,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.001885834995309918,\n          0.0016398117055199317,\n          0.0018882706374543654\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ShapeFactor3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.026179779347149882,\n        \"min\": 0.6162205923408897,\n        \"max\": 0.6768841638893502,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6760986201188287,\n          0.6162205923408897,\n          0.6768841638893502\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ShapeFactor4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.001358366974602117,\n        \"min\": 0.9952224197261494,\n        \"max\": 0.9983852479466693,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9982186537250977,\n          0.9981796233054678,\n          0.9967672643592382\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"DERMASON\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# load the dataset\n",
        "df = pd.read_excel(\"/content/Dry_Bean_Dataset.xlsx\") #(13611, 17)\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5p6MO1RWVI4",
        "outputId": "57983789-5153-4ee2-aff7-ef16ec840e89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength',\n",
              "       'AspectRation', 'Eccentricity', 'ConvexArea', 'EquivDiameter', 'Extent',\n",
              "       'Solidity', 'roundness', 'Compactness', 'ShapeFactor1', 'ShapeFactor2',\n",
              "       'ShapeFactor3', 'ShapeFactor4', 'Class'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4THvBmHWfeh",
        "outputId": "38a6c4f0-444c-4316-cd38-590f3f54558c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q: is there any missing value?  A: False\n"
          ]
        }
      ],
      "source": [
        "# checking for missing values\n",
        "print(f'Q: is there any missing value?  A: {df.isnull().any().any()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooHWVQV7XLky",
        "outputId": "d6977bff-131d-4e84-dd87-72ef372e10e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['SEKER', 'BARBUNYA', 'BOMBAY', 'CALI', 'HOROZ', 'SIRA', 'DERMASON']"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# labels (#7)\n",
        "labels = df['Class'].unique().tolist()\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJXat21fMLtV",
        "outputId": "44a6fd40-eaa9-473a-be8c-95dc2335cc8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Class\n",
              "DERMASON    3546\n",
              "SIRA        2636\n",
              "SEKER       2027\n",
              "HOROZ       1928\n",
              "CALI        1630\n",
              "BARBUNYA    1322\n",
              "BOMBAY       522\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check if dataset is balanced\n",
        "df['Class'].value_counts() # frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDbpiiO2XLvu",
        "outputId": "c52b26d2-8ea5-4412-f040-f46671fff5b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0           SEKER\n",
              "1           SEKER\n",
              "2           SEKER\n",
              "3           SEKER\n",
              "4           SEKER\n",
              "           ...   \n",
              "13606    DERMASON\n",
              "13607    DERMASON\n",
              "13608    DERMASON\n",
              "13609    DERMASON\n",
              "13610    DERMASON\n",
              "Name: Class, Length: 13611, dtype: object"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# NOTICE: class are divided into block\n",
        "df['Class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4TfEp8zLEuK",
        "outputId": "48136b7a-5426-4206-c2c8-0276c0f40f76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0           HOROZ\n",
              "1            CALI\n",
              "2        BARBUNYA\n",
              "3           SEKER\n",
              "4            SIRA\n",
              "           ...   \n",
              "13606       SEKER\n",
              "13607    DERMASON\n",
              "13608       SEKER\n",
              "13609    DERMASON\n",
              "13610        SIRA\n",
              "Name: Class, Length: 13611, dtype: object"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# shuffle rows to prevent imbalanced splitting\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df['Class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KumZse34LGy8"
      },
      "outputs": [],
      "source": [
        "# reduce the dataset\n",
        "df = df[:9000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-7IyJLdXENe",
        "outputId": "a78a9efd-1b30-4eff-c1b4-52d893a12ed6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4 3 1 0 5 4 0 5 5 4 2 5]\n"
          ]
        }
      ],
      "source": [
        "# make labels as numbers\n",
        "Y = df[\"Class\"]\n",
        "\n",
        "# Step 1: Create a mapping of each unique word to a unique number\n",
        "word_to_number = {word: index for index, word in enumerate(labels)}\n",
        "\n",
        "# Step 2: Replace each word in the original list with its corresponding number\n",
        "Y_as_number = [word_to_number[word] for word in Y]\n",
        "\n",
        "Y = np.asarray(Y_as_number)\n",
        "print(Y[:12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSMN6ugAXtml",
        "outputId": "79f044c7-8614-4540-bb02-8e8c4a5534b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'SEKER': 0,\n",
              " 'BARBUNYA': 1,\n",
              " 'BOMBAY': 2,\n",
              " 'CALI': 3,\n",
              " 'HOROZ': 4,\n",
              " 'SIRA': 5,\n",
              " 'DERMASON': 6}"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# codex list\n",
        "word_to_number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "bbj1qlgcYGog",
        "outputId": "adb1eef2-796e-4aad-b75b-af295042526c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Area\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18224,\n        \"min\": 31608,\n        \"max\": 80946,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          31608,\n          61348,\n          80946\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Perimeter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 160.83383025501814,\n        \"min\": 664.008,\n        \"max\": 1093.51,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          664.008,\n          949.0609999999999,\n          1093.51\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MajorAxisLength\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 68.84526002564813,\n        \"min\": 240.69309504958682,\n        \"max\": 422.83780951816544,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          240.69309504958682,\n          356.93935562443517,\n          422.83780951816544\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MinorAxisLength\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29.51291186684457,\n        \"min\": 167.7228089559975,\n        \"max\": 245.39768518042038,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          167.7228089559975,\n          219.2460921673,\n          245.39768518042038\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AspectRation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12968221094796492,\n        \"min\": 1.4350647747184657,\n        \"max\": 1.7747585243709407,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.4350647747184657,\n          1.6280306394335442,\n          1.7230717119735184\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Eccentricity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04231167541010005,\n        \"min\": 0.7172337471664271,\n        \"max\": 0.8261454360174783,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7172337471664271,\n          0.7891200063532787,\n          0.8143608226511527\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ConvexArea\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18433,\n        \"min\": 31977,\n        \"max\": 81704,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          31977,\n          62159,\n          81704\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EquivDiameter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45.267029716441186,\n        \"min\": 200.61045718005084,\n        \"max\": 321.0352756133389,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          200.61045718005084,\n          279.4829146663759,\n          321.0352756133389\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Extent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.045415968822950556,\n        \"min\": 0.6782805429864254,\n        \"max\": 0.7916006927263731,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.69929203539823,\n          0.7399884203416,\n          0.6782805429864254\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0031502461533674288,\n        \"min\": 0.9822384428223845,\n        \"max\": 0.9907226084402232,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.988460455952716,\n          0.9869528145562187,\n          0.9907226084402232\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roundness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.021927980803347572,\n        \"min\": 0.8495081286252752,\n        \"max\": 0.9008661260689276,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9008661260689276,\n          0.8558980137759908,\n          0.8506673002237689\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Compactness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.032764474504078864,\n        \"min\": 0.7484406714561835,\n        \"max\": 0.8334699304054474,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8334699304054474,\n          0.7829983168357667,\n          0.7592397566792025\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ShapeFactor1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0009304088092660192,\n        \"min\": 0.005223702338820515,\n        \"max\": 0.007614942263021602,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.007614942263021602,\n          0.005818272080987729,\n          0.005223702338820515\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ShapeFactor2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0004852670974344817,\n        \"min\": 0.0010707151548126337,\n        \"max\": 0.0022667630367196674,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0022667630367196674,\n          0.001349016007436091,\n          0.0010707151548126337\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ShapeFactor3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.051957384446599045,\n        \"min\": 0.560163438689783,\n        \"max\": 0.6946721248900614,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6946721248900614,\n          0.6130863641676438,\n          0.5764450081222947\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ShapeFactor4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0032782851425384096,\n        \"min\": 0.9897614104859574,\n        \"max\": 0.9981233854838358,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9968994964085539,\n          0.9981233854838358,\n          0.993256087003871\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9c9db2f9-00a4-48fa-9afa-35e5f6f1b04a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Area</th>\n",
              "      <th>Perimeter</th>\n",
              "      <th>MajorAxisLength</th>\n",
              "      <th>MinorAxisLength</th>\n",
              "      <th>AspectRation</th>\n",
              "      <th>Eccentricity</th>\n",
              "      <th>ConvexArea</th>\n",
              "      <th>EquivDiameter</th>\n",
              "      <th>Extent</th>\n",
              "      <th>Solidity</th>\n",
              "      <th>roundness</th>\n",
              "      <th>Compactness</th>\n",
              "      <th>ShapeFactor1</th>\n",
              "      <th>ShapeFactor2</th>\n",
              "      <th>ShapeFactor3</th>\n",
              "      <th>ShapeFactor4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8995</th>\n",
              "      <td>68629</td>\n",
              "      <td>992.208</td>\n",
              "      <td>379.468285</td>\n",
              "      <td>232.654677</td>\n",
              "      <td>1.631037</td>\n",
              "      <td>0.790000</td>\n",
              "      <td>69870</td>\n",
              "      <td>295.603039</td>\n",
              "      <td>0.758264</td>\n",
              "      <td>0.982238</td>\n",
              "      <td>0.876016</td>\n",
              "      <td>0.778993</td>\n",
              "      <td>0.005529</td>\n",
              "      <td>0.001256</td>\n",
              "      <td>0.606830</td>\n",
              "      <td>0.989761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8996</th>\n",
              "      <td>31608</td>\n",
              "      <td>664.008</td>\n",
              "      <td>240.693095</td>\n",
              "      <td>167.722809</td>\n",
              "      <td>1.435065</td>\n",
              "      <td>0.717234</td>\n",
              "      <td>31977</td>\n",
              "      <td>200.610457</td>\n",
              "      <td>0.699292</td>\n",
              "      <td>0.988460</td>\n",
              "      <td>0.900866</td>\n",
              "      <td>0.833470</td>\n",
              "      <td>0.007615</td>\n",
              "      <td>0.002267</td>\n",
              "      <td>0.694672</td>\n",
              "      <td>0.996899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8997</th>\n",
              "      <td>80946</td>\n",
              "      <td>1093.510</td>\n",
              "      <td>422.837810</td>\n",
              "      <td>245.397685</td>\n",
              "      <td>1.723072</td>\n",
              "      <td>0.814361</td>\n",
              "      <td>81704</td>\n",
              "      <td>321.035276</td>\n",
              "      <td>0.678281</td>\n",
              "      <td>0.990723</td>\n",
              "      <td>0.850667</td>\n",
              "      <td>0.759240</td>\n",
              "      <td>0.005224</td>\n",
              "      <td>0.001071</td>\n",
              "      <td>0.576445</td>\n",
              "      <td>0.993256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8998</th>\n",
              "      <td>63993</td>\n",
              "      <td>972.943</td>\n",
              "      <td>381.385269</td>\n",
              "      <td>214.894175</td>\n",
              "      <td>1.774759</td>\n",
              "      <td>0.826145</td>\n",
              "      <td>64754</td>\n",
              "      <td>285.444247</td>\n",
              "      <td>0.791601</td>\n",
              "      <td>0.988248</td>\n",
              "      <td>0.849508</td>\n",
              "      <td>0.748441</td>\n",
              "      <td>0.005960</td>\n",
              "      <td>0.001154</td>\n",
              "      <td>0.560163</td>\n",
              "      <td>0.994155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8999</th>\n",
              "      <td>61348</td>\n",
              "      <td>949.061</td>\n",
              "      <td>356.939356</td>\n",
              "      <td>219.246092</td>\n",
              "      <td>1.628031</td>\n",
              "      <td>0.789120</td>\n",
              "      <td>62159</td>\n",
              "      <td>279.482915</td>\n",
              "      <td>0.739988</td>\n",
              "      <td>0.986953</td>\n",
              "      <td>0.855898</td>\n",
              "      <td>0.782998</td>\n",
              "      <td>0.005818</td>\n",
              "      <td>0.001349</td>\n",
              "      <td>0.613086</td>\n",
              "      <td>0.998123</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c9db2f9-00a4-48fa-9afa-35e5f6f1b04a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c9db2f9-00a4-48fa-9afa-35e5f6f1b04a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c9db2f9-00a4-48fa-9afa-35e5f6f1b04a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-525b0c41-83ff-435f-ac86-10c8aedd2e46\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-525b0c41-83ff-435f-ac86-10c8aedd2e46')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-525b0c41-83ff-435f-ac86-10c8aedd2e46 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
              "8995  68629    992.208       379.468285       232.654677      1.631037   \n",
              "8996  31608    664.008       240.693095       167.722809      1.435065   \n",
              "8997  80946   1093.510       422.837810       245.397685      1.723072   \n",
              "8998  63993    972.943       381.385269       214.894175      1.774759   \n",
              "8999  61348    949.061       356.939356       219.246092      1.628031   \n",
              "\n",
              "      Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
              "8995      0.790000       69870     295.603039  0.758264  0.982238   0.876016   \n",
              "8996      0.717234       31977     200.610457  0.699292  0.988460   0.900866   \n",
              "8997      0.814361       81704     321.035276  0.678281  0.990723   0.850667   \n",
              "8998      0.826145       64754     285.444247  0.791601  0.988248   0.849508   \n",
              "8999      0.789120       62159     279.482915  0.739988  0.986953   0.855898   \n",
              "\n",
              "      Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \n",
              "8995     0.778993      0.005529      0.001256      0.606830      0.989761  \n",
              "8996     0.833470      0.007615      0.002267      0.694672      0.996899  \n",
              "8997     0.759240      0.005224      0.001071      0.576445      0.993256  \n",
              "8998     0.748441      0.005960      0.001154      0.560163      0.994155  \n",
              "8999     0.782998      0.005818      0.001349      0.613086      0.998123  "
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# takes al columns but last one (class)\n",
        "X = df.iloc[:, :-1]\n",
        "\n",
        "X.tail() #(9000, 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tre0ikbTYGr9",
        "outputId": "bf60ac89-2c74-457a-8963-3a8e5c7ca044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Area               float64\n",
            "Perimeter          float64\n",
            "MajorAxisLength    float64\n",
            "MinorAxisLength    float64\n",
            "AspectRation       float64\n",
            "Eccentricity       float64\n",
            "ConvexArea         float64\n",
            "EquivDiameter      float64\n",
            "Extent             float64\n",
            "Solidity           float64\n",
            "roundness          float64\n",
            "Compactness        float64\n",
            "ShapeFactor1       float64\n",
            "ShapeFactor2       float64\n",
            "ShapeFactor3       float64\n",
            "ShapeFactor4       float64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# min-max scaler to avoid overflow issues\n",
        "X = (X-X.min())/(X.max()-X.min())\n",
        "print(X.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "dwvCv0eraxtx",
        "outputId": "41f6d353-3c80-46fb-a590-cc9d0aa854e7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Area\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07781786233249668,\n        \"min\": 0.04777195169857726,\n        \"max\": 0.2584416471673299,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.04777195169857726,\n          0.1747596030675161,\n          0.2584416471673299\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Perimeter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11012711957304464,\n        \"min\": 0.0952289655569083,\n        \"max\": 0.3893201902442966,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0952289655569083,\n          0.2904121914110698,\n          0.3893201902442966\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MajorAxisLength\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12398765522797231,\n        \"min\": 0.10282036172387912,\n        \"max\": 0.43085595997296827,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.10282036172387912,\n          0.31217538881399054,\n          0.43085595997296827\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MinorAxisLength\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08739753959388613,\n        \"min\": 0.13388229442229488,\n        \"max\": 0.36390341537785376,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.13388229442229488,\n          0.2864598579234279,\n          0.36390341537785376\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AspectRation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0922716850163412,\n        \"min\": 0.2918641237411387,\n        \"max\": 0.5335635398817987,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.2918641237411387,\n          0.4291634908458529,\n          0.4967872600962287\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Eccentricity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.061102388873935966,\n        \"min\": 0.7195708938468672,\n        \"max\": 0.8768505170381888,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7195708938468672,\n          0.8233820079413723,\n          0.8598323294656325\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ConvexArea\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07598907672141163,\n        \"min\": 0.046554289978027595,\n        \"max\": 0.2515489926909806,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.046554289978027595,\n          0.17097663834576238,\n          0.2515489926909806\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EquivDiameter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11091310078468647,\n        \"min\": 0.0964561185023876,\n        \"max\": 0.3915205419367716,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0964561185023876,\n          0.2897091081753407,\n          0.3915205419367716\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Extent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15901986127051487,\n        \"min\": 0.3907967217229832,\n        \"max\": 0.787576862229292,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.46436654077577383,\n          0.6068612107262213,\n          0.3907967217229832\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06162670429122983,\n        \"min\": 0.7566608900767445,\n        \"max\": 0.9226324174538888,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8783790494241385,\n          0.848885807945266,\n          0.9226324174538888\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roundness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.050534666198415186,\n        \"min\": 0.6746464561282374,\n        \"max\": 0.7930047892875686,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7930047892875686,\n          0.6893724227383653,\n          0.677317853477674\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Compactness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09449667640122017,\n        \"min\": 0.31109246790019746,\n        \"max\": 0.5563270547257503,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5563270547257503,\n          0.4107608642975228,\n          0.342238325637723\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ShapeFactor1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12125502592721406,\n        \"min\": 0.31873318636401937,\n        \"max\": 0.6303702389365631,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6303702389365631,\n          0.39622016712347335,\n          0.31873318636401937\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ShapeFactor2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15668288009758943,\n        \"min\": 0.1623672183917016,\n        \"max\": 0.5485467633527472,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5485467633527472,\n          0.25222490574200745,\n          0.1623672183917016\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ShapeFactor3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09205307328818599,\n        \"min\": 0.26544520019703893,\n        \"max\": 0.5037546932666485,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5037546932666485,\n          0.35920892578730224,\n          0.29429131168207906\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ShapeFactor4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0676374369949889,\n        \"min\": 0.7947960940651688,\n        \"max\": 0.967319999851697,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9420687734882275,\n          0.967319999851697,\n          0.866898108539487\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7057c2fb-bb20-4c8b-8a25-f1b146e65606\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Area</th>\n",
              "      <th>Perimeter</th>\n",
              "      <th>MajorAxisLength</th>\n",
              "      <th>MinorAxisLength</th>\n",
              "      <th>AspectRation</th>\n",
              "      <th>Eccentricity</th>\n",
              "      <th>ConvexArea</th>\n",
              "      <th>EquivDiameter</th>\n",
              "      <th>Extent</th>\n",
              "      <th>Solidity</th>\n",
              "      <th>roundness</th>\n",
              "      <th>Compactness</th>\n",
              "      <th>ShapeFactor1</th>\n",
              "      <th>ShapeFactor2</th>\n",
              "      <th>ShapeFactor3</th>\n",
              "      <th>ShapeFactor4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8995</th>\n",
              "      <td>0.205849</td>\n",
              "      <td>0.319956</td>\n",
              "      <td>0.352749</td>\n",
              "      <td>0.326167</td>\n",
              "      <td>0.431302</td>\n",
              "      <td>0.824653</td>\n",
              "      <td>0.202764</td>\n",
              "      <td>0.329207</td>\n",
              "      <td>0.670853</td>\n",
              "      <td>0.756661</td>\n",
              "      <td>0.735736</td>\n",
              "      <td>0.399208</td>\n",
              "      <td>0.358556</td>\n",
              "      <td>0.222184</td>\n",
              "      <td>0.348124</td>\n",
              "      <td>0.794796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8996</th>\n",
              "      <td>0.047772</td>\n",
              "      <td>0.095229</td>\n",
              "      <td>0.102820</td>\n",
              "      <td>0.133882</td>\n",
              "      <td>0.291864</td>\n",
              "      <td>0.719571</td>\n",
              "      <td>0.046554</td>\n",
              "      <td>0.096456</td>\n",
              "      <td>0.464367</td>\n",
              "      <td>0.878379</td>\n",
              "      <td>0.793005</td>\n",
              "      <td>0.556327</td>\n",
              "      <td>0.630370</td>\n",
              "      <td>0.548547</td>\n",
              "      <td>0.503755</td>\n",
              "      <td>0.942069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8997</th>\n",
              "      <td>0.258442</td>\n",
              "      <td>0.389320</td>\n",
              "      <td>0.430856</td>\n",
              "      <td>0.363903</td>\n",
              "      <td>0.496787</td>\n",
              "      <td>0.859832</td>\n",
              "      <td>0.251549</td>\n",
              "      <td>0.391521</td>\n",
              "      <td>0.390797</td>\n",
              "      <td>0.922632</td>\n",
              "      <td>0.677318</td>\n",
              "      <td>0.342238</td>\n",
              "      <td>0.318733</td>\n",
              "      <td>0.162367</td>\n",
              "      <td>0.294291</td>\n",
              "      <td>0.866898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8998</th>\n",
              "      <td>0.186054</td>\n",
              "      <td>0.306765</td>\n",
              "      <td>0.356202</td>\n",
              "      <td>0.273572</td>\n",
              "      <td>0.533564</td>\n",
              "      <td>0.876851</td>\n",
              "      <td>0.181674</td>\n",
              "      <td>0.304316</td>\n",
              "      <td>0.787577</td>\n",
              "      <td>0.874220</td>\n",
              "      <td>0.674646</td>\n",
              "      <td>0.311092</td>\n",
              "      <td>0.414664</td>\n",
              "      <td>0.189117</td>\n",
              "      <td>0.265445</td>\n",
              "      <td>0.885441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8999</th>\n",
              "      <td>0.174760</td>\n",
              "      <td>0.290412</td>\n",
              "      <td>0.312175</td>\n",
              "      <td>0.286460</td>\n",
              "      <td>0.429163</td>\n",
              "      <td>0.823382</td>\n",
              "      <td>0.170977</td>\n",
              "      <td>0.289709</td>\n",
              "      <td>0.606861</td>\n",
              "      <td>0.848886</td>\n",
              "      <td>0.689372</td>\n",
              "      <td>0.410761</td>\n",
              "      <td>0.396220</td>\n",
              "      <td>0.252225</td>\n",
              "      <td>0.359209</td>\n",
              "      <td>0.967320</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7057c2fb-bb20-4c8b-8a25-f1b146e65606')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7057c2fb-bb20-4c8b-8a25-f1b146e65606 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7057c2fb-bb20-4c8b-8a25-f1b146e65606');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5db98d7e-8f72-42a0-86de-3cc3932d6f49\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5db98d7e-8f72-42a0-86de-3cc3932d6f49')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5db98d7e-8f72-42a0-86de-3cc3932d6f49 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
              "8995  0.205849   0.319956         0.352749         0.326167      0.431302   \n",
              "8996  0.047772   0.095229         0.102820         0.133882      0.291864   \n",
              "8997  0.258442   0.389320         0.430856         0.363903      0.496787   \n",
              "8998  0.186054   0.306765         0.356202         0.273572      0.533564   \n",
              "8999  0.174760   0.290412         0.312175         0.286460      0.429163   \n",
              "\n",
              "      Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
              "8995      0.824653    0.202764       0.329207  0.670853  0.756661   0.735736   \n",
              "8996      0.719571    0.046554       0.096456  0.464367  0.878379   0.793005   \n",
              "8997      0.859832    0.251549       0.391521  0.390797  0.922632   0.677318   \n",
              "8998      0.876851    0.181674       0.304316  0.787577  0.874220   0.674646   \n",
              "8999      0.823382    0.170977       0.289709  0.606861  0.848886   0.689372   \n",
              "\n",
              "      Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \n",
              "8995     0.399208      0.358556      0.222184      0.348124      0.794796  \n",
              "8996     0.556327      0.630370      0.548547      0.503755      0.942069  \n",
              "8997     0.342238      0.318733      0.162367      0.294291      0.866898  \n",
              "8998     0.311092      0.414664      0.189117      0.265445      0.885441  \n",
              "8999     0.410761      0.396220      0.252225      0.359209      0.967320  "
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UAL6w--YT9W"
      },
      "outputs": [],
      "source": [
        "# split into train (70%) and test set (30%)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "     X, Y, test_size=0.30, random_state=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VCntHfalEGZ"
      },
      "outputs": [],
      "source": [
        "# convert dataset into numpy array\n",
        "X_train = X_train.to_numpy()\n",
        "X_test = X_test.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7CiA1IIPDon"
      },
      "source": [
        "## 2) Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlHJ9wToXEQ8",
        "outputId": "13449667-040a-492b-d0fb-191192df7f0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mOutput streaming troncato alle ultime 5000 righe.\u001b[0m\n",
            "Step: 3 ------------ Loss: 11222.37 ------------ Accuracy: 26.2%\n",
            "Step: 4 ------------ Loss: 11078.39 ------------ Accuracy: 26.2%\n",
            "Step: 5 ------------ Loss: 10950.74 ------------ Accuracy: 26.2%\n",
            "Step: 6 ------------ Loss: 10832.48 ------------ Accuracy: 26.2%\n",
            "Step: 7 ------------ Loss: 10720.69 ------------ Accuracy: 26.3%\n",
            "Step: 8 ------------ Loss: 10613.94 ------------ Accuracy: 26.3%\n",
            "Step: 9 ------------ Loss: 10511.37 ------------ Accuracy: 26.4%\n",
            "Step: 10 ------------ Loss: 10412.46 ------------ Accuracy: 26.7%\n",
            "Step: 11 ------------ Loss: 10316.83 ------------ Accuracy: 27.7%\n",
            "Step: 12 ------------ Loss: 10224.21 ------------ Accuracy: 28.7%\n",
            "Step: 13 ------------ Loss: 10134.38 ------------ Accuracy: 29.7%\n",
            "Step: 14 ------------ Loss: 10047.16 ------------ Accuracy: 31.0%\n",
            "Step: 15 ------------ Loss: 9962.4 ------------ Accuracy: 32.4%\n",
            "Step: 16 ------------ Loss: 9879.96 ------------ Accuracy: 33.7%\n",
            "Step: 17 ------------ Loss: 9799.73 ------------ Accuracy: 34.5%\n",
            "Step: 18 ------------ Loss: 9721.6 ------------ Accuracy: 35.2%\n",
            "Step: 19 ------------ Loss: 9645.48 ------------ Accuracy: 36.0%\n",
            "Step: 20 ------------ Loss: 9571.27 ------------ Accuracy: 36.7%\n",
            "Step: 21 ------------ Loss: 9498.91 ------------ Accuracy: 37.4%\n",
            "Step: 22 ------------ Loss: 9428.3 ------------ Accuracy: 38.1%\n",
            "Step: 23 ------------ Loss: 9359.38 ------------ Accuracy: 38.7%\n",
            "Step: 24 ------------ Loss: 9292.08 ------------ Accuracy: 39.3%\n",
            "Step: 25 ------------ Loss: 9226.34 ------------ Accuracy: 39.8%\n",
            "Step: 26 ------------ Loss: 9162.1 ------------ Accuracy: 40.2%\n",
            "Step: 27 ------------ Loss: 9099.31 ------------ Accuracy: 40.8%\n",
            "Step: 28 ------------ Loss: 9037.9 ------------ Accuracy: 41.2%\n",
            "Step: 29 ------------ Loss: 8977.83 ------------ Accuracy: 41.8%\n",
            "Step: 30 ------------ Loss: 8919.06 ------------ Accuracy: 42.4%\n",
            "Step: 31 ------------ Loss: 8861.53 ------------ Accuracy: 43.1%\n",
            "Step: 32 ------------ Loss: 8805.2 ------------ Accuracy: 43.5%\n",
            "Step: 33 ------------ Loss: 8750.03 ------------ Accuracy: 44.2%\n",
            "Step: 34 ------------ Loss: 8695.99 ------------ Accuracy: 44.9%\n",
            "Step: 35 ------------ Loss: 8643.03 ------------ Accuracy: 45.5%\n",
            "Step: 36 ------------ Loss: 8591.12 ------------ Accuracy: 46.2%\n",
            "Step: 37 ------------ Loss: 8540.23 ------------ Accuracy: 46.8%\n",
            "Step: 38 ------------ Loss: 8490.32 ------------ Accuracy: 47.6%\n",
            "Step: 39 ------------ Loss: 8441.36 ------------ Accuracy: 48.1%\n",
            "Step: 40 ------------ Loss: 8393.32 ------------ Accuracy: 48.8%\n",
            "Step: 41 ------------ Loss: 8346.18 ------------ Accuracy: 49.4%\n",
            "Step: 42 ------------ Loss: 8299.9 ------------ Accuracy: 50.0%\n",
            "Step: 43 ------------ Loss: 8254.46 ------------ Accuracy: 50.6%\n",
            "Step: 44 ------------ Loss: 8209.84 ------------ Accuracy: 51.2%\n",
            "Step: 45 ------------ Loss: 8166.0 ------------ Accuracy: 51.6%\n",
            "Step: 46 ------------ Loss: 8122.94 ------------ Accuracy: 52.0%\n",
            "Step: 47 ------------ Loss: 8080.62 ------------ Accuracy: 52.5%\n",
            "Step: 48 ------------ Loss: 8039.03 ------------ Accuracy: 52.8%\n",
            "Step: 49 ------------ Loss: 7998.14 ------------ Accuracy: 53.2%\n",
            "Step: 50 ------------ Loss: 7957.93 ------------ Accuracy: 53.7%\n",
            "Step: 51 ------------ Loss: 7918.4 ------------ Accuracy: 54.0%\n",
            "Step: 52 ------------ Loss: 7879.5 ------------ Accuracy: 54.5%\n",
            "Step: 53 ------------ Loss: 7841.24 ------------ Accuracy: 55.1%\n",
            "Step: 54 ------------ Loss: 7803.59 ------------ Accuracy: 55.6%\n",
            "Step: 55 ------------ Loss: 7766.54 ------------ Accuracy: 55.8%\n",
            "Step: 56 ------------ Loss: 7730.07 ------------ Accuracy: 56.1%\n",
            "Step: 57 ------------ Loss: 7694.17 ------------ Accuracy: 56.6%\n",
            "Step: 58 ------------ Loss: 7658.82 ------------ Accuracy: 56.9%\n",
            "Step: 59 ------------ Loss: 7624.01 ------------ Accuracy: 57.2%\n",
            "Step: 60 ------------ Loss: 7589.72 ------------ Accuracy: 57.5%\n",
            "Step: 61 ------------ Loss: 7555.94 ------------ Accuracy: 57.9%\n",
            "Step: 62 ------------ Loss: 7522.67 ------------ Accuracy: 58.3%\n",
            "Step: 63 ------------ Loss: 7489.88 ------------ Accuracy: 58.7%\n",
            "Step: 64 ------------ Loss: 7457.56 ------------ Accuracy: 58.9%\n",
            "Step: 65 ------------ Loss: 7425.71 ------------ Accuracy: 59.2%\n",
            "Step: 66 ------------ Loss: 7394.31 ------------ Accuracy: 59.4%\n",
            "Step: 67 ------------ Loss: 7363.35 ------------ Accuracy: 59.9%\n",
            "Step: 68 ------------ Loss: 7332.83 ------------ Accuracy: 60.3%\n",
            "Step: 69 ------------ Loss: 7302.72 ------------ Accuracy: 60.7%\n",
            "Step: 70 ------------ Loss: 7273.03 ------------ Accuracy: 61.1%\n",
            "Step: 71 ------------ Loss: 7243.74 ------------ Accuracy: 61.5%\n",
            "Step: 72 ------------ Loss: 7214.85 ------------ Accuracy: 61.9%\n",
            "Step: 73 ------------ Loss: 7186.34 ------------ Accuracy: 62.3%\n",
            "Step: 74 ------------ Loss: 7158.2 ------------ Accuracy: 62.6%\n",
            "Step: 75 ------------ Loss: 7130.44 ------------ Accuracy: 63.0%\n",
            "Step: 76 ------------ Loss: 7103.03 ------------ Accuracy: 63.3%\n",
            "Step: 77 ------------ Loss: 7075.98 ------------ Accuracy: 63.7%\n",
            "Step: 78 ------------ Loss: 7049.27 ------------ Accuracy: 64.1%\n",
            "Step: 79 ------------ Loss: 7022.9 ------------ Accuracy: 64.4%\n",
            "Step: 80 ------------ Loss: 6996.87 ------------ Accuracy: 64.8%\n",
            "Step: 81 ------------ Loss: 6971.15 ------------ Accuracy: 65.1%\n",
            "Step: 82 ------------ Loss: 6945.75 ------------ Accuracy: 65.4%\n",
            "Step: 83 ------------ Loss: 6920.66 ------------ Accuracy: 65.6%\n",
            "Step: 84 ------------ Loss: 6895.88 ------------ Accuracy: 66.0%\n",
            "Step: 85 ------------ Loss: 6871.4 ------------ Accuracy: 66.4%\n",
            "Step: 86 ------------ Loss: 6847.2 ------------ Accuracy: 66.8%\n",
            "Step: 87 ------------ Loss: 6823.3 ------------ Accuracy: 67.0%\n",
            "Step: 88 ------------ Loss: 6799.67 ------------ Accuracy: 67.3%\n",
            "Step: 89 ------------ Loss: 6776.32 ------------ Accuracy: 67.6%\n",
            "Step: 90 ------------ Loss: 6753.24 ------------ Accuracy: 68.0%\n",
            "Step: 91 ------------ Loss: 6730.42 ------------ Accuracy: 68.3%\n",
            "Step: 92 ------------ Loss: 6707.87 ------------ Accuracy: 68.6%\n",
            "Step: 93 ------------ Loss: 6685.56 ------------ Accuracy: 68.8%\n",
            "Step: 94 ------------ Loss: 6663.51 ------------ Accuracy: 68.9%\n",
            "Step: 95 ------------ Loss: 6641.71 ------------ Accuracy: 69.3%\n",
            "Step: 96 ------------ Loss: 6620.14 ------------ Accuracy: 69.7%\n",
            "Step: 97 ------------ Loss: 6598.81 ------------ Accuracy: 69.8%\n",
            "Step: 98 ------------ Loss: 6577.71 ------------ Accuracy: 70.1%\n",
            "Step: 99 ------------ Loss: 6556.84 ------------ Accuracy: 70.3%\n",
            "Step: 100 ------------ Loss: 6536.2 ------------ Accuracy: 70.5%\n",
            "Step: 101 ------------ Loss: 6515.77 ------------ Accuracy: 70.8%\n",
            "Step: 102 ------------ Loss: 6495.56 ------------ Accuracy: 71.0%\n",
            "Step: 103 ------------ Loss: 6475.56 ------------ Accuracy: 71.3%\n",
            "Step: 104 ------------ Loss: 6455.77 ------------ Accuracy: 71.5%\n",
            "Step: 105 ------------ Loss: 6436.18 ------------ Accuracy: 71.7%\n",
            "Step: 106 ------------ Loss: 6416.79 ------------ Accuracy: 71.9%\n",
            "Step: 107 ------------ Loss: 6397.61 ------------ Accuracy: 72.0%\n",
            "Step: 108 ------------ Loss: 6378.61 ------------ Accuracy: 72.3%\n",
            "Step: 109 ------------ Loss: 6359.81 ------------ Accuracy: 72.5%\n",
            "Step: 110 ------------ Loss: 6341.19 ------------ Accuracy: 72.7%\n",
            "Step: 111 ------------ Loss: 6322.76 ------------ Accuracy: 72.9%\n",
            "Step: 112 ------------ Loss: 6304.51 ------------ Accuracy: 73.1%\n",
            "Step: 113 ------------ Loss: 6286.44 ------------ Accuracy: 73.4%\n",
            "Step: 114 ------------ Loss: 6268.55 ------------ Accuracy: 73.6%\n",
            "Step: 115 ------------ Loss: 6250.82 ------------ Accuracy: 73.7%\n",
            "Step: 116 ------------ Loss: 6233.27 ------------ Accuracy: 73.9%\n",
            "Step: 117 ------------ Loss: 6215.88 ------------ Accuracy: 74.0%\n",
            "Step: 118 ------------ Loss: 6198.66 ------------ Accuracy: 74.2%\n",
            "Step: 119 ------------ Loss: 6181.6 ------------ Accuracy: 74.4%\n",
            "Step: 120 ------------ Loss: 6164.7 ------------ Accuracy: 74.6%\n",
            "Step: 121 ------------ Loss: 6147.96 ------------ Accuracy: 74.8%\n",
            "Step: 122 ------------ Loss: 6131.37 ------------ Accuracy: 75.0%\n",
            "Step: 123 ------------ Loss: 6114.93 ------------ Accuracy: 75.1%\n",
            "Step: 124 ------------ Loss: 6098.65 ------------ Accuracy: 75.2%\n",
            "Step: 125 ------------ Loss: 6082.51 ------------ Accuracy: 75.3%\n",
            "Step: 126 ------------ Loss: 6066.51 ------------ Accuracy: 75.5%\n",
            "Step: 127 ------------ Loss: 6050.66 ------------ Accuracy: 75.7%\n",
            "Step: 128 ------------ Loss: 6034.95 ------------ Accuracy: 75.8%\n",
            "Step: 129 ------------ Loss: 6019.37 ------------ Accuracy: 76.1%\n",
            "Step: 130 ------------ Loss: 6003.94 ------------ Accuracy: 76.3%\n",
            "Step: 131 ------------ Loss: 5988.63 ------------ Accuracy: 76.4%\n",
            "Step: 132 ------------ Loss: 5973.46 ------------ Accuracy: 76.6%\n",
            "Step: 133 ------------ Loss: 5958.43 ------------ Accuracy: 76.7%\n",
            "Step: 134 ------------ Loss: 5943.52 ------------ Accuracy: 76.8%\n",
            "Step: 135 ------------ Loss: 5928.73 ------------ Accuracy: 77.0%\n",
            "Step: 136 ------------ Loss: 5914.07 ------------ Accuracy: 77.1%\n",
            "Step: 137 ------------ Loss: 5899.54 ------------ Accuracy: 77.2%\n",
            "Step: 138 ------------ Loss: 5885.13 ------------ Accuracy: 77.3%\n",
            "Step: 139 ------------ Loss: 5870.83 ------------ Accuracy: 77.4%\n",
            "Step: 140 ------------ Loss: 5856.66 ------------ Accuracy: 77.5%\n",
            "Step: 141 ------------ Loss: 5842.6 ------------ Accuracy: 77.6%\n",
            "Step: 142 ------------ Loss: 5828.65 ------------ Accuracy: 77.8%\n",
            "Step: 143 ------------ Loss: 5814.82 ------------ Accuracy: 78.0%\n",
            "Step: 144 ------------ Loss: 5801.1 ------------ Accuracy: 78.1%\n",
            "Step: 145 ------------ Loss: 5787.49 ------------ Accuracy: 78.2%\n",
            "Step: 146 ------------ Loss: 5773.99 ------------ Accuracy: 78.3%\n",
            "Step: 147 ------------ Loss: 5760.6 ------------ Accuracy: 78.4%\n",
            "Step: 148 ------------ Loss: 5747.31 ------------ Accuracy: 78.5%\n",
            "Step: 149 ------------ Loss: 5734.13 ------------ Accuracy: 78.7%\n",
            "Step: 150 ------------ Loss: 5721.05 ------------ Accuracy: 78.8%\n",
            "Step: 151 ------------ Loss: 5708.07 ------------ Accuracy: 78.9%\n",
            "Step: 152 ------------ Loss: 5695.19 ------------ Accuracy: 79.1%\n",
            "Step: 153 ------------ Loss: 5682.41 ------------ Accuracy: 79.1%\n",
            "Step: 154 ------------ Loss: 5669.73 ------------ Accuracy: 79.3%\n",
            "Step: 155 ------------ Loss: 5657.15 ------------ Accuracy: 79.4%\n",
            "Step: 156 ------------ Loss: 5644.66 ------------ Accuracy: 79.4%\n",
            "Step: 157 ------------ Loss: 5632.26 ------------ Accuracy: 79.6%\n",
            "Step: 158 ------------ Loss: 5619.96 ------------ Accuracy: 79.7%\n",
            "Step: 159 ------------ Loss: 5607.75 ------------ Accuracy: 79.7%\n",
            "Step: 160 ------------ Loss: 5595.63 ------------ Accuracy: 79.9%\n",
            "Step: 161 ------------ Loss: 5583.6 ------------ Accuracy: 80.0%\n",
            "Step: 162 ------------ Loss: 5571.65 ------------ Accuracy: 80.1%\n",
            "Step: 163 ------------ Loss: 5559.8 ------------ Accuracy: 80.2%\n",
            "Step: 164 ------------ Loss: 5548.03 ------------ Accuracy: 80.3%\n",
            "Step: 165 ------------ Loss: 5536.34 ------------ Accuracy: 80.3%\n",
            "Step: 166 ------------ Loss: 5524.74 ------------ Accuracy: 80.5%\n",
            "Step: 167 ------------ Loss: 5513.22 ------------ Accuracy: 80.6%\n",
            "Step: 168 ------------ Loss: 5501.78 ------------ Accuracy: 80.6%\n",
            "Step: 169 ------------ Loss: 5490.43 ------------ Accuracy: 80.7%\n",
            "Step: 170 ------------ Loss: 5479.15 ------------ Accuracy: 80.8%\n",
            "Step: 171 ------------ Loss: 5467.96 ------------ Accuracy: 80.8%\n",
            "Step: 172 ------------ Loss: 5456.84 ------------ Accuracy: 80.9%\n",
            "Step: 173 ------------ Loss: 5445.8 ------------ Accuracy: 81.0%\n",
            "Step: 174 ------------ Loss: 5434.83 ------------ Accuracy: 81.0%\n",
            "Step: 175 ------------ Loss: 5423.94 ------------ Accuracy: 81.0%\n",
            "Step: 176 ------------ Loss: 5413.13 ------------ Accuracy: 81.1%\n",
            "Step: 177 ------------ Loss: 5402.38 ------------ Accuracy: 81.2%\n",
            "Step: 178 ------------ Loss: 5391.72 ------------ Accuracy: 81.2%\n",
            "Step: 179 ------------ Loss: 5381.12 ------------ Accuracy: 81.3%\n",
            "Step: 180 ------------ Loss: 5370.59 ------------ Accuracy: 81.4%\n",
            "Step: 181 ------------ Loss: 5360.14 ------------ Accuracy: 81.4%\n",
            "Step: 182 ------------ Loss: 5349.75 ------------ Accuracy: 81.5%\n",
            "Step: 183 ------------ Loss: 5339.43 ------------ Accuracy: 81.6%\n",
            "Step: 184 ------------ Loss: 5329.18 ------------ Accuracy: 81.7%\n",
            "Step: 185 ------------ Loss: 5319.0 ------------ Accuracy: 81.7%\n",
            "Step: 186 ------------ Loss: 5308.89 ------------ Accuracy: 81.9%\n",
            "Step: 187 ------------ Loss: 5298.84 ------------ Accuracy: 81.9%\n",
            "Step: 188 ------------ Loss: 5288.85 ------------ Accuracy: 82.0%\n",
            "Step: 189 ------------ Loss: 5278.93 ------------ Accuracy: 82.0%\n",
            "Step: 190 ------------ Loss: 5269.07 ------------ Accuracy: 82.1%\n",
            "Step: 191 ------------ Loss: 5259.28 ------------ Accuracy: 82.2%\n",
            "Step: 192 ------------ Loss: 5249.55 ------------ Accuracy: 82.3%\n",
            "Step: 193 ------------ Loss: 5239.88 ------------ Accuracy: 82.4%\n",
            "Step: 194 ------------ Loss: 5230.27 ------------ Accuracy: 82.4%\n",
            "Step: 195 ------------ Loss: 5220.72 ------------ Accuracy: 82.5%\n",
            "Step: 196 ------------ Loss: 5211.23 ------------ Accuracy: 82.6%\n",
            "Step: 197 ------------ Loss: 5201.8 ------------ Accuracy: 82.7%\n",
            "Step: 198 ------------ Loss: 5192.42 ------------ Accuracy: 82.7%\n",
            "Step: 199 ------------ Loss: 5183.11 ------------ Accuracy: 82.7%\n",
            "Step: 200 ------------ Loss: 5173.85 ------------ Accuracy: 82.8%\n",
            "Step: 201 ------------ Loss: 5164.65 ------------ Accuracy: 82.9%\n",
            "Step: 202 ------------ Loss: 5155.51 ------------ Accuracy: 82.9%\n",
            "Step: 203 ------------ Loss: 5146.42 ------------ Accuracy: 83.1%\n",
            "Step: 204 ------------ Loss: 5137.38 ------------ Accuracy: 83.1%\n",
            "Step: 205 ------------ Loss: 5128.4 ------------ Accuracy: 83.1%\n",
            "Step: 206 ------------ Loss: 5119.47 ------------ Accuracy: 83.2%\n",
            "Step: 207 ------------ Loss: 5110.6 ------------ Accuracy: 83.3%\n",
            "Step: 208 ------------ Loss: 5101.78 ------------ Accuracy: 83.3%\n",
            "Step: 209 ------------ Loss: 5093.01 ------------ Accuracy: 83.4%\n",
            "Step: 210 ------------ Loss: 5084.29 ------------ Accuracy: 83.5%\n",
            "Step: 211 ------------ Loss: 5075.63 ------------ Accuracy: 83.6%\n",
            "Step: 212 ------------ Loss: 5067.01 ------------ Accuracy: 83.5%\n",
            "Step: 213 ------------ Loss: 5058.44 ------------ Accuracy: 83.6%\n",
            "Step: 214 ------------ Loss: 5049.93 ------------ Accuracy: 83.7%\n",
            "Step: 215 ------------ Loss: 5041.46 ------------ Accuracy: 83.7%\n",
            "Step: 216 ------------ Loss: 5033.04 ------------ Accuracy: 83.7%\n",
            "Step: 217 ------------ Loss: 5024.67 ------------ Accuracy: 83.8%\n",
            "Step: 218 ------------ Loss: 5016.35 ------------ Accuracy: 83.8%\n",
            "Step: 219 ------------ Loss: 5008.07 ------------ Accuracy: 83.8%\n",
            "Step: 220 ------------ Loss: 4999.85 ------------ Accuracy: 83.9%\n",
            "Step: 221 ------------ Loss: 4991.66 ------------ Accuracy: 83.9%\n",
            "Step: 222 ------------ Loss: 4983.53 ------------ Accuracy: 84.0%\n",
            "Step: 223 ------------ Loss: 4975.44 ------------ Accuracy: 84.0%\n",
            "Step: 224 ------------ Loss: 4967.39 ------------ Accuracy: 84.1%\n",
            "Step: 225 ------------ Loss: 4959.39 ------------ Accuracy: 84.2%\n",
            "Step: 226 ------------ Loss: 4951.43 ------------ Accuracy: 84.2%\n",
            "Step: 227 ------------ Loss: 4943.52 ------------ Accuracy: 84.3%\n",
            "Step: 228 ------------ Loss: 4935.65 ------------ Accuracy: 84.3%\n",
            "Step: 229 ------------ Loss: 4927.82 ------------ Accuracy: 84.4%\n",
            "Step: 230 ------------ Loss: 4920.03 ------------ Accuracy: 84.4%\n",
            "Step: 231 ------------ Loss: 4912.29 ------------ Accuracy: 84.4%\n",
            "Step: 232 ------------ Loss: 4904.59 ------------ Accuracy: 84.5%\n",
            "Step: 233 ------------ Loss: 4896.93 ------------ Accuracy: 84.5%\n",
            "Step: 234 ------------ Loss: 4889.31 ------------ Accuracy: 84.6%\n",
            "Step: 235 ------------ Loss: 4881.74 ------------ Accuracy: 84.6%\n",
            "Step: 236 ------------ Loss: 4874.2 ------------ Accuracy: 84.6%\n",
            "Step: 237 ------------ Loss: 4866.7 ------------ Accuracy: 84.6%\n",
            "Step: 238 ------------ Loss: 4859.24 ------------ Accuracy: 84.7%\n",
            "Step: 239 ------------ Loss: 4851.83 ------------ Accuracy: 84.7%\n",
            "Step: 240 ------------ Loss: 4844.45 ------------ Accuracy: 84.7%\n",
            "Step: 241 ------------ Loss: 4837.11 ------------ Accuracy: 84.8%\n",
            "Step: 242 ------------ Loss: 4829.8 ------------ Accuracy: 84.8%\n",
            "Step: 243 ------------ Loss: 4822.54 ------------ Accuracy: 84.9%\n",
            "Step: 244 ------------ Loss: 4815.31 ------------ Accuracy: 85.0%\n",
            "Step: 245 ------------ Loss: 4808.12 ------------ Accuracy: 85.0%\n",
            "Step: 246 ------------ Loss: 4800.97 ------------ Accuracy: 85.0%\n",
            "Step: 247 ------------ Loss: 4793.85 ------------ Accuracy: 85.0%\n",
            "Step: 248 ------------ Loss: 4786.77 ------------ Accuracy: 85.0%\n",
            "Step: 249 ------------ Loss: 4779.72 ------------ Accuracy: 85.0%\n",
            "Step: 250 ------------ Loss: 4772.72 ------------ Accuracy: 85.0%\n",
            "Step: 251 ------------ Loss: 4765.74 ------------ Accuracy: 85.1%\n",
            "Step: 252 ------------ Loss: 4758.8 ------------ Accuracy: 85.1%\n",
            "Step: 253 ------------ Loss: 4751.9 ------------ Accuracy: 85.1%\n",
            "Step: 254 ------------ Loss: 4745.03 ------------ Accuracy: 85.1%\n",
            "Step: 255 ------------ Loss: 4738.19 ------------ Accuracy: 85.2%\n",
            "Step: 256 ------------ Loss: 4731.39 ------------ Accuracy: 85.2%\n",
            "Step: 257 ------------ Loss: 4724.62 ------------ Accuracy: 85.3%\n",
            "Step: 258 ------------ Loss: 4717.89 ------------ Accuracy: 85.3%\n",
            "Step: 259 ------------ Loss: 4711.19 ------------ Accuracy: 85.3%\n",
            "Step: 260 ------------ Loss: 4704.52 ------------ Accuracy: 85.3%\n",
            "Step: 261 ------------ Loss: 4697.88 ------------ Accuracy: 85.4%\n",
            "Step: 262 ------------ Loss: 4691.28 ------------ Accuracy: 85.4%\n",
            "Step: 263 ------------ Loss: 4684.71 ------------ Accuracy: 85.4%\n",
            "Step: 264 ------------ Loss: 4678.17 ------------ Accuracy: 85.4%\n",
            "Step: 265 ------------ Loss: 4671.66 ------------ Accuracy: 85.4%\n",
            "Step: 266 ------------ Loss: 4665.18 ------------ Accuracy: 85.4%\n",
            "Step: 267 ------------ Loss: 4658.73 ------------ Accuracy: 85.5%\n",
            "Step: 268 ------------ Loss: 4652.32 ------------ Accuracy: 85.5%\n",
            "Step: 269 ------------ Loss: 4645.93 ------------ Accuracy: 85.6%\n",
            "Step: 270 ------------ Loss: 4639.58 ------------ Accuracy: 85.6%\n",
            "Step: 271 ------------ Loss: 4633.25 ------------ Accuracy: 85.6%\n",
            "Step: 272 ------------ Loss: 4626.96 ------------ Accuracy: 85.6%\n",
            "Step: 273 ------------ Loss: 4620.69 ------------ Accuracy: 85.7%\n",
            "Step: 274 ------------ Loss: 4614.45 ------------ Accuracy: 85.7%\n",
            "Step: 275 ------------ Loss: 4608.24 ------------ Accuracy: 85.7%\n",
            "Step: 276 ------------ Loss: 4602.07 ------------ Accuracy: 85.7%\n",
            "Step: 277 ------------ Loss: 4595.92 ------------ Accuracy: 85.8%\n",
            "Step: 278 ------------ Loss: 4589.79 ------------ Accuracy: 85.8%\n",
            "Step: 279 ------------ Loss: 4583.7 ------------ Accuracy: 85.8%\n",
            "Step: 280 ------------ Loss: 4577.63 ------------ Accuracy: 85.8%\n",
            "Step: 281 ------------ Loss: 4571.59 ------------ Accuracy: 85.8%\n",
            "Step: 282 ------------ Loss: 4565.58 ------------ Accuracy: 85.9%\n",
            "Step: 283 ------------ Loss: 4559.6 ------------ Accuracy: 85.9%\n",
            "Step: 284 ------------ Loss: 4553.64 ------------ Accuracy: 85.9%\n",
            "Step: 285 ------------ Loss: 4547.71 ------------ Accuracy: 85.9%\n",
            "Step: 286 ------------ Loss: 4541.81 ------------ Accuracy: 85.9%\n",
            "Step: 287 ------------ Loss: 4535.94 ------------ Accuracy: 85.9%\n",
            "Step: 288 ------------ Loss: 4530.09 ------------ Accuracy: 85.9%\n",
            "Step: 289 ------------ Loss: 4524.26 ------------ Accuracy: 85.9%\n",
            "Step: 290 ------------ Loss: 4518.46 ------------ Accuracy: 86.0%\n",
            "Step: 291 ------------ Loss: 4512.69 ------------ Accuracy: 86.0%\n",
            "Step: 292 ------------ Loss: 4506.94 ------------ Accuracy: 86.1%\n",
            "Step: 293 ------------ Loss: 4501.22 ------------ Accuracy: 86.1%\n",
            "Step: 294 ------------ Loss: 4495.53 ------------ Accuracy: 86.1%\n",
            "Step: 295 ------------ Loss: 4489.86 ------------ Accuracy: 86.2%\n",
            "Step: 296 ------------ Loss: 4484.21 ------------ Accuracy: 86.2%\n",
            "Step: 297 ------------ Loss: 4478.59 ------------ Accuracy: 86.2%\n",
            "Step: 298 ------------ Loss: 4472.99 ------------ Accuracy: 86.2%\n",
            "Step: 299 ------------ Loss: 4467.42 ------------ Accuracy: 86.2%\n",
            "Step: 300 ------------ Loss: 4461.87 ------------ Accuracy: 86.3%\n",
            "Step: 301 ------------ Loss: 4456.34 ------------ Accuracy: 86.3%\n",
            "Step: 302 ------------ Loss: 4450.84 ------------ Accuracy: 86.3%\n",
            "Step: 303 ------------ Loss: 4445.36 ------------ Accuracy: 86.3%\n",
            "Step: 304 ------------ Loss: 4439.91 ------------ Accuracy: 86.4%\n",
            "Step: 305 ------------ Loss: 4434.47 ------------ Accuracy: 86.4%\n",
            "Step: 306 ------------ Loss: 4429.07 ------------ Accuracy: 86.4%\n",
            "Step: 307 ------------ Loss: 4423.68 ------------ Accuracy: 86.4%\n",
            "Step: 308 ------------ Loss: 4418.32 ------------ Accuracy: 86.5%\n",
            "Step: 309 ------------ Loss: 4412.98 ------------ Accuracy: 86.5%\n",
            "Step: 310 ------------ Loss: 4407.66 ------------ Accuracy: 86.5%\n",
            "Step: 311 ------------ Loss: 4402.36 ------------ Accuracy: 86.6%\n",
            "Step: 312 ------------ Loss: 4397.09 ------------ Accuracy: 86.6%\n",
            "Step: 313 ------------ Loss: 4391.84 ------------ Accuracy: 86.6%\n",
            "Step: 314 ------------ Loss: 4386.61 ------------ Accuracy: 86.7%\n",
            "Step: 315 ------------ Loss: 4381.4 ------------ Accuracy: 86.7%\n",
            "Step: 316 ------------ Loss: 4376.21 ------------ Accuracy: 86.7%\n",
            "Step: 317 ------------ Loss: 4371.05 ------------ Accuracy: 86.7%\n",
            "Step: 318 ------------ Loss: 4365.9 ------------ Accuracy: 86.8%\n",
            "Step: 319 ------------ Loss: 4360.78 ------------ Accuracy: 86.8%\n",
            "Step: 320 ------------ Loss: 4355.68 ------------ Accuracy: 86.8%\n",
            "Step: 321 ------------ Loss: 4350.6 ------------ Accuracy: 86.8%\n",
            "Step: 322 ------------ Loss: 4345.54 ------------ Accuracy: 86.8%\n",
            "Step: 323 ------------ Loss: 4340.49 ------------ Accuracy: 86.8%\n",
            "Step: 324 ------------ Loss: 4335.47 ------------ Accuracy: 86.8%\n",
            "Step: 325 ------------ Loss: 4330.47 ------------ Accuracy: 86.8%\n",
            "Step: 326 ------------ Loss: 4325.5 ------------ Accuracy: 86.9%\n",
            "Step: 327 ------------ Loss: 4320.54 ------------ Accuracy: 86.9%\n",
            "Step: 328 ------------ Loss: 4315.6 ------------ Accuracy: 86.9%\n",
            "Step: 329 ------------ Loss: 4310.68 ------------ Accuracy: 86.9%\n",
            "Step: 330 ------------ Loss: 4305.77 ------------ Accuracy: 86.9%\n",
            "Step: 331 ------------ Loss: 4300.89 ------------ Accuracy: 87.0%\n",
            "Step: 332 ------------ Loss: 4296.03 ------------ Accuracy: 87.0%\n",
            "Step: 333 ------------ Loss: 4291.19 ------------ Accuracy: 87.0%\n",
            "Step: 334 ------------ Loss: 4286.36 ------------ Accuracy: 87.0%\n",
            "Step: 335 ------------ Loss: 4281.56 ------------ Accuracy: 87.0%\n",
            "Step: 336 ------------ Loss: 4276.77 ------------ Accuracy: 87.1%\n",
            "Step: 337 ------------ Loss: 4272.01 ------------ Accuracy: 87.1%\n",
            "Step: 338 ------------ Loss: 4267.26 ------------ Accuracy: 87.1%\n",
            "Step: 339 ------------ Loss: 4262.53 ------------ Accuracy: 87.1%\n",
            "Step: 340 ------------ Loss: 4257.82 ------------ Accuracy: 87.1%\n",
            "Step: 341 ------------ Loss: 4253.12 ------------ Accuracy: 87.1%\n",
            "Step: 342 ------------ Loss: 4248.45 ------------ Accuracy: 87.1%\n",
            "Step: 343 ------------ Loss: 4243.79 ------------ Accuracy: 87.1%\n",
            "Step: 344 ------------ Loss: 4239.15 ------------ Accuracy: 87.1%\n",
            "Step: 345 ------------ Loss: 4234.53 ------------ Accuracy: 87.2%\n",
            "Step: 346 ------------ Loss: 4229.92 ------------ Accuracy: 87.2%\n",
            "Step: 347 ------------ Loss: 4225.33 ------------ Accuracy: 87.2%\n",
            "Step: 348 ------------ Loss: 4220.76 ------------ Accuracy: 87.2%\n",
            "Step: 349 ------------ Loss: 4216.21 ------------ Accuracy: 87.2%\n",
            "Step: 350 ------------ Loss: 4211.68 ------------ Accuracy: 87.3%\n",
            "Step: 351 ------------ Loss: 4207.16 ------------ Accuracy: 87.3%\n",
            "Step: 352 ------------ Loss: 4202.66 ------------ Accuracy: 87.3%\n",
            "Step: 353 ------------ Loss: 4198.17 ------------ Accuracy: 87.3%\n",
            "Step: 354 ------------ Loss: 4193.71 ------------ Accuracy: 87.3%\n",
            "Step: 355 ------------ Loss: 4189.26 ------------ Accuracy: 87.3%\n",
            "Step: 356 ------------ Loss: 4184.82 ------------ Accuracy: 87.4%\n",
            "Step: 357 ------------ Loss: 4180.4 ------------ Accuracy: 87.4%\n",
            "Step: 358 ------------ Loss: 4176.0 ------------ Accuracy: 87.4%\n",
            "Step: 359 ------------ Loss: 4171.62 ------------ Accuracy: 87.4%\n",
            "Step: 360 ------------ Loss: 4167.25 ------------ Accuracy: 87.5%\n",
            "Step: 361 ------------ Loss: 4162.9 ------------ Accuracy: 87.5%\n",
            "Step: 362 ------------ Loss: 4158.56 ------------ Accuracy: 87.5%\n",
            "Step: 363 ------------ Loss: 4154.24 ------------ Accuracy: 87.5%\n",
            "Step: 364 ------------ Loss: 4149.93 ------------ Accuracy: 87.5%\n",
            "Step: 365 ------------ Loss: 4145.64 ------------ Accuracy: 87.5%\n",
            "Step: 366 ------------ Loss: 4141.37 ------------ Accuracy: 87.5%\n",
            "Step: 367 ------------ Loss: 4137.11 ------------ Accuracy: 87.6%\n",
            "Step: 368 ------------ Loss: 4132.87 ------------ Accuracy: 87.6%\n",
            "Step: 369 ------------ Loss: 4128.64 ------------ Accuracy: 87.6%\n",
            "Step: 370 ------------ Loss: 4124.43 ------------ Accuracy: 87.6%\n",
            "Step: 371 ------------ Loss: 4120.23 ------------ Accuracy: 87.7%\n",
            "Step: 372 ------------ Loss: 4116.05 ------------ Accuracy: 87.7%\n",
            "Step: 373 ------------ Loss: 4111.88 ------------ Accuracy: 87.6%\n",
            "Step: 374 ------------ Loss: 4107.73 ------------ Accuracy: 87.6%\n",
            "Step: 375 ------------ Loss: 4103.59 ------------ Accuracy: 87.6%\n",
            "Step: 376 ------------ Loss: 4099.47 ------------ Accuracy: 87.7%\n",
            "Step: 377 ------------ Loss: 4095.36 ------------ Accuracy: 87.7%\n",
            "Step: 378 ------------ Loss: 4091.27 ------------ Accuracy: 87.7%\n",
            "Step: 379 ------------ Loss: 4087.19 ------------ Accuracy: 87.7%\n",
            "Step: 380 ------------ Loss: 4083.12 ------------ Accuracy: 87.7%\n",
            "Step: 381 ------------ Loss: 4079.07 ------------ Accuracy: 87.7%\n",
            "Step: 382 ------------ Loss: 4075.03 ------------ Accuracy: 87.7%\n",
            "Step: 383 ------------ Loss: 4071.01 ------------ Accuracy: 87.8%\n",
            "Step: 384 ------------ Loss: 4067.0 ------------ Accuracy: 87.8%\n",
            "Step: 385 ------------ Loss: 4063.01 ------------ Accuracy: 87.8%\n",
            "Step: 386 ------------ Loss: 4059.03 ------------ Accuracy: 87.8%\n",
            "Step: 387 ------------ Loss: 4055.06 ------------ Accuracy: 87.8%\n",
            "Step: 388 ------------ Loss: 4051.11 ------------ Accuracy: 87.8%\n",
            "Step: 389 ------------ Loss: 4047.17 ------------ Accuracy: 87.8%\n",
            "Step: 390 ------------ Loss: 4043.24 ------------ Accuracy: 87.9%\n",
            "Step: 391 ------------ Loss: 4039.33 ------------ Accuracy: 87.9%\n",
            "Step: 392 ------------ Loss: 4035.43 ------------ Accuracy: 88.0%\n",
            "Step: 393 ------------ Loss: 4031.54 ------------ Accuracy: 88.0%\n",
            "Step: 394 ------------ Loss: 4027.67 ------------ Accuracy: 88.0%\n",
            "Step: 395 ------------ Loss: 4023.81 ------------ Accuracy: 88.0%\n",
            "Step: 396 ------------ Loss: 4019.97 ------------ Accuracy: 88.0%\n",
            "Step: 397 ------------ Loss: 4016.13 ------------ Accuracy: 88.0%\n",
            "Step: 398 ------------ Loss: 4012.31 ------------ Accuracy: 88.0%\n",
            "Step: 399 ------------ Loss: 4008.5 ------------ Accuracy: 88.0%\n",
            "Step: 400 ------------ Loss: 4004.71 ------------ Accuracy: 88.0%\n",
            "Step: 401 ------------ Loss: 4000.93 ------------ Accuracy: 88.0%\n",
            "Step: 402 ------------ Loss: 3997.16 ------------ Accuracy: 88.0%\n",
            "Step: 403 ------------ Loss: 3993.4 ------------ Accuracy: 88.0%\n",
            "Step: 404 ------------ Loss: 3989.66 ------------ Accuracy: 88.0%\n",
            "Step: 405 ------------ Loss: 3985.93 ------------ Accuracy: 88.0%\n",
            "Step: 406 ------------ Loss: 3982.21 ------------ Accuracy: 88.0%\n",
            "Step: 407 ------------ Loss: 3978.5 ------------ Accuracy: 88.0%\n",
            "Step: 408 ------------ Loss: 3974.81 ------------ Accuracy: 88.0%\n",
            "Step: 409 ------------ Loss: 3971.12 ------------ Accuracy: 88.0%\n",
            "Step: 410 ------------ Loss: 3967.45 ------------ Accuracy: 88.1%\n",
            "Step: 411 ------------ Loss: 3963.79 ------------ Accuracy: 88.1%\n",
            "Step: 412 ------------ Loss: 3960.15 ------------ Accuracy: 88.1%\n",
            "Step: 413 ------------ Loss: 3956.51 ------------ Accuracy: 88.1%\n",
            "Step: 414 ------------ Loss: 3952.89 ------------ Accuracy: 88.1%\n",
            "Step: 415 ------------ Loss: 3949.28 ------------ Accuracy: 88.1%\n",
            "Step: 416 ------------ Loss: 3945.68 ------------ Accuracy: 88.1%\n",
            "Step: 417 ------------ Loss: 3942.1 ------------ Accuracy: 88.1%\n",
            "Step: 418 ------------ Loss: 3938.52 ------------ Accuracy: 88.1%\n",
            "Step: 419 ------------ Loss: 3934.96 ------------ Accuracy: 88.1%\n",
            "Step: 420 ------------ Loss: 3931.4 ------------ Accuracy: 88.1%\n",
            "Step: 421 ------------ Loss: 3927.86 ------------ Accuracy: 88.1%\n",
            "Step: 422 ------------ Loss: 3924.33 ------------ Accuracy: 88.1%\n",
            "Step: 423 ------------ Loss: 3920.82 ------------ Accuracy: 88.1%\n",
            "Step: 424 ------------ Loss: 3917.31 ------------ Accuracy: 88.2%\n",
            "Step: 425 ------------ Loss: 3913.81 ------------ Accuracy: 88.2%\n",
            "Step: 426 ------------ Loss: 3910.33 ------------ Accuracy: 88.2%\n",
            "Step: 427 ------------ Loss: 3906.85 ------------ Accuracy: 88.2%\n",
            "Step: 428 ------------ Loss: 3903.39 ------------ Accuracy: 88.2%\n",
            "Step: 429 ------------ Loss: 3899.94 ------------ Accuracy: 88.2%\n",
            "Step: 430 ------------ Loss: 3896.5 ------------ Accuracy: 88.2%\n",
            "Step: 431 ------------ Loss: 3893.07 ------------ Accuracy: 88.2%\n",
            "Step: 432 ------------ Loss: 3889.65 ------------ Accuracy: 88.3%\n",
            "Step: 433 ------------ Loss: 3886.24 ------------ Accuracy: 88.3%\n",
            "Step: 434 ------------ Loss: 3882.85 ------------ Accuracy: 88.3%\n",
            "Step: 435 ------------ Loss: 3879.46 ------------ Accuracy: 88.3%\n",
            "Step: 436 ------------ Loss: 3876.08 ------------ Accuracy: 88.3%\n",
            "Step: 437 ------------ Loss: 3872.72 ------------ Accuracy: 88.3%\n",
            "Step: 438 ------------ Loss: 3869.36 ------------ Accuracy: 88.3%\n",
            "Step: 439 ------------ Loss: 3866.02 ------------ Accuracy: 88.3%\n",
            "Step: 440 ------------ Loss: 3862.68 ------------ Accuracy: 88.3%\n",
            "Step: 441 ------------ Loss: 3859.36 ------------ Accuracy: 88.3%\n",
            "Step: 442 ------------ Loss: 3856.04 ------------ Accuracy: 88.3%\n",
            "Step: 443 ------------ Loss: 3852.74 ------------ Accuracy: 88.3%\n",
            "Step: 444 ------------ Loss: 3849.45 ------------ Accuracy: 88.4%\n",
            "Step: 445 ------------ Loss: 3846.16 ------------ Accuracy: 88.4%\n",
            "Step: 446 ------------ Loss: 3842.89 ------------ Accuracy: 88.4%\n",
            "Step: 447 ------------ Loss: 3839.63 ------------ Accuracy: 88.4%\n",
            "Step: 448 ------------ Loss: 3836.37 ------------ Accuracy: 88.4%\n",
            "Step: 449 ------------ Loss: 3833.13 ------------ Accuracy: 88.4%\n",
            "Step: 450 ------------ Loss: 3829.9 ------------ Accuracy: 88.4%\n",
            "Step: 451 ------------ Loss: 3826.67 ------------ Accuracy: 88.5%\n",
            "Step: 452 ------------ Loss: 3823.46 ------------ Accuracy: 88.5%\n",
            "Step: 453 ------------ Loss: 3820.25 ------------ Accuracy: 88.5%\n",
            "Step: 454 ------------ Loss: 3817.06 ------------ Accuracy: 88.5%\n",
            "Step: 455 ------------ Loss: 3813.88 ------------ Accuracy: 88.5%\n",
            "Step: 456 ------------ Loss: 3810.7 ------------ Accuracy: 88.5%\n",
            "Step: 457 ------------ Loss: 3807.53 ------------ Accuracy: 88.5%\n",
            "Step: 458 ------------ Loss: 3804.38 ------------ Accuracy: 88.6%\n",
            "Step: 459 ------------ Loss: 3801.23 ------------ Accuracy: 88.6%\n",
            "Step: 460 ------------ Loss: 3798.09 ------------ Accuracy: 88.6%\n",
            "Step: 461 ------------ Loss: 3794.97 ------------ Accuracy: 88.6%\n",
            "Step: 462 ------------ Loss: 3791.85 ------------ Accuracy: 88.6%\n",
            "Step: 463 ------------ Loss: 3788.74 ------------ Accuracy: 88.7%\n",
            "Step: 464 ------------ Loss: 3785.64 ------------ Accuracy: 88.7%\n",
            "Step: 465 ------------ Loss: 3782.55 ------------ Accuracy: 88.7%\n",
            "Step: 466 ------------ Loss: 3779.46 ------------ Accuracy: 88.7%\n",
            "Step: 467 ------------ Loss: 3776.39 ------------ Accuracy: 88.7%\n",
            "Step: 468 ------------ Loss: 3773.33 ------------ Accuracy: 88.7%\n",
            "Step: 469 ------------ Loss: 3770.27 ------------ Accuracy: 88.7%\n",
            "Step: 470 ------------ Loss: 3767.23 ------------ Accuracy: 88.7%\n",
            "Step: 471 ------------ Loss: 3764.19 ------------ Accuracy: 88.7%\n",
            "Step: 472 ------------ Loss: 3761.16 ------------ Accuracy: 88.7%\n",
            "Step: 473 ------------ Loss: 3758.14 ------------ Accuracy: 88.7%\n",
            "Step: 474 ------------ Loss: 3755.13 ------------ Accuracy: 88.8%\n",
            "Step: 475 ------------ Loss: 3752.13 ------------ Accuracy: 88.8%\n",
            "Step: 476 ------------ Loss: 3749.14 ------------ Accuracy: 88.8%\n",
            "Step: 477 ------------ Loss: 3746.15 ------------ Accuracy: 88.8%\n",
            "Step: 478 ------------ Loss: 3743.18 ------------ Accuracy: 88.8%\n",
            "Step: 479 ------------ Loss: 3740.21 ------------ Accuracy: 88.8%\n",
            "Step: 480 ------------ Loss: 3737.25 ------------ Accuracy: 88.8%\n",
            "Step: 481 ------------ Loss: 3734.3 ------------ Accuracy: 88.8%\n",
            "Step: 482 ------------ Loss: 3731.36 ------------ Accuracy: 88.8%\n",
            "Step: 483 ------------ Loss: 3728.42 ------------ Accuracy: 88.8%\n",
            "Step: 484 ------------ Loss: 3725.5 ------------ Accuracy: 88.9%\n",
            "Step: 485 ------------ Loss: 3722.58 ------------ Accuracy: 88.9%\n",
            "Step: 486 ------------ Loss: 3719.67 ------------ Accuracy: 88.9%\n",
            "Step: 487 ------------ Loss: 3716.77 ------------ Accuracy: 88.9%\n",
            "Step: 488 ------------ Loss: 3713.88 ------------ Accuracy: 88.9%\n",
            "Step: 489 ------------ Loss: 3711.0 ------------ Accuracy: 88.9%\n",
            "Step: 490 ------------ Loss: 3708.12 ------------ Accuracy: 88.9%\n",
            "Step: 491 ------------ Loss: 3705.26 ------------ Accuracy: 88.9%\n",
            "Step: 492 ------------ Loss: 3702.4 ------------ Accuracy: 88.9%\n",
            "Step: 493 ------------ Loss: 3699.55 ------------ Accuracy: 88.9%\n",
            "Step: 494 ------------ Loss: 3696.7 ------------ Accuracy: 89.0%\n",
            "Step: 495 ------------ Loss: 3693.87 ------------ Accuracy: 89.0%\n",
            "Step: 496 ------------ Loss: 3691.04 ------------ Accuracy: 89.0%\n",
            "Step: 497 ------------ Loss: 3688.22 ------------ Accuracy: 89.0%\n",
            "Step: 498 ------------ Loss: 3685.41 ------------ Accuracy: 89.0%\n",
            "Step: 499 ------------ Loss: 3682.61 ------------ Accuracy: 89.0%\n",
            "Step: 500 ------------ Loss: 3679.81 ------------ Accuracy: 89.0%\n",
            "Step: 501 ------------ Loss: 3677.02 ------------ Accuracy: 89.0%\n",
            "Step: 502 ------------ Loss: 3674.24 ------------ Accuracy: 89.0%\n",
            "Step: 503 ------------ Loss: 3671.47 ------------ Accuracy: 89.0%\n",
            "Step: 504 ------------ Loss: 3668.7 ------------ Accuracy: 89.0%\n",
            "Step: 505 ------------ Loss: 3665.95 ------------ Accuracy: 89.0%\n",
            "Step: 506 ------------ Loss: 3663.2 ------------ Accuracy: 89.0%\n",
            "Step: 507 ------------ Loss: 3660.45 ------------ Accuracy: 89.0%\n",
            "Step: 508 ------------ Loss: 3657.72 ------------ Accuracy: 89.0%\n",
            "Step: 509 ------------ Loss: 3654.99 ------------ Accuracy: 89.0%\n",
            "Step: 510 ------------ Loss: 3652.27 ------------ Accuracy: 89.0%\n",
            "Step: 511 ------------ Loss: 3649.56 ------------ Accuracy: 89.0%\n",
            "Step: 512 ------------ Loss: 3646.86 ------------ Accuracy: 89.0%\n",
            "Step: 513 ------------ Loss: 3644.16 ------------ Accuracy: 89.1%\n",
            "Step: 514 ------------ Loss: 3641.47 ------------ Accuracy: 89.1%\n",
            "Step: 515 ------------ Loss: 3638.78 ------------ Accuracy: 89.1%\n",
            "Step: 516 ------------ Loss: 3636.11 ------------ Accuracy: 89.1%\n",
            "Step: 517 ------------ Loss: 3633.44 ------------ Accuracy: 89.1%\n",
            "Step: 518 ------------ Loss: 3630.78 ------------ Accuracy: 89.2%\n",
            "Step: 519 ------------ Loss: 3628.12 ------------ Accuracy: 89.2%\n",
            "Step: 520 ------------ Loss: 3625.48 ------------ Accuracy: 89.2%\n",
            "Step: 521 ------------ Loss: 3622.84 ------------ Accuracy: 89.2%\n",
            "Step: 522 ------------ Loss: 3620.2 ------------ Accuracy: 89.2%\n",
            "Step: 523 ------------ Loss: 3617.58 ------------ Accuracy: 89.2%\n",
            "Step: 524 ------------ Loss: 3614.96 ------------ Accuracy: 89.2%\n",
            "Step: 525 ------------ Loss: 3612.35 ------------ Accuracy: 89.3%\n",
            "Step: 526 ------------ Loss: 3609.74 ------------ Accuracy: 89.3%\n",
            "Step: 527 ------------ Loss: 3607.15 ------------ Accuracy: 89.3%\n",
            "Step: 528 ------------ Loss: 3604.55 ------------ Accuracy: 89.3%\n",
            "Step: 529 ------------ Loss: 3601.97 ------------ Accuracy: 89.3%\n",
            "Step: 530 ------------ Loss: 3599.39 ------------ Accuracy: 89.3%\n",
            "Step: 531 ------------ Loss: 3596.82 ------------ Accuracy: 89.3%\n",
            "Step: 532 ------------ Loss: 3594.26 ------------ Accuracy: 89.3%\n",
            "Step: 533 ------------ Loss: 3591.7 ------------ Accuracy: 89.3%\n",
            "Step: 534 ------------ Loss: 3589.15 ------------ Accuracy: 89.3%\n",
            "Step: 535 ------------ Loss: 3586.61 ------------ Accuracy: 89.3%\n",
            "Step: 536 ------------ Loss: 3584.07 ------------ Accuracy: 89.3%\n",
            "Step: 537 ------------ Loss: 3581.54 ------------ Accuracy: 89.3%\n",
            "Step: 538 ------------ Loss: 3579.02 ------------ Accuracy: 89.3%\n",
            "Step: 539 ------------ Loss: 3576.5 ------------ Accuracy: 89.3%\n",
            "Step: 540 ------------ Loss: 3573.99 ------------ Accuracy: 89.3%\n",
            "Step: 541 ------------ Loss: 3571.48 ------------ Accuracy: 89.3%\n",
            "Step: 542 ------------ Loss: 3568.99 ------------ Accuracy: 89.3%\n",
            "Step: 543 ------------ Loss: 3566.5 ------------ Accuracy: 89.3%\n",
            "Step: 544 ------------ Loss: 3564.01 ------------ Accuracy: 89.3%\n",
            "Step: 545 ------------ Loss: 3561.53 ------------ Accuracy: 89.3%\n",
            "Step: 546 ------------ Loss: 3559.06 ------------ Accuracy: 89.3%\n",
            "Step: 547 ------------ Loss: 3556.6 ------------ Accuracy: 89.3%\n",
            "Step: 548 ------------ Loss: 3554.14 ------------ Accuracy: 89.3%\n",
            "Step: 549 ------------ Loss: 3551.68 ------------ Accuracy: 89.3%\n",
            "Step: 550 ------------ Loss: 3549.24 ------------ Accuracy: 89.3%\n",
            "Step: 551 ------------ Loss: 3546.8 ------------ Accuracy: 89.3%\n",
            "Step: 552 ------------ Loss: 3544.36 ------------ Accuracy: 89.3%\n",
            "Step: 553 ------------ Loss: 3541.94 ------------ Accuracy: 89.3%\n",
            "Step: 554 ------------ Loss: 3539.51 ------------ Accuracy: 89.3%\n",
            "Step: 555 ------------ Loss: 3537.1 ------------ Accuracy: 89.3%\n",
            "Step: 556 ------------ Loss: 3534.69 ------------ Accuracy: 89.3%\n",
            "Step: 557 ------------ Loss: 3532.29 ------------ Accuracy: 89.3%\n",
            "Step: 558 ------------ Loss: 3529.89 ------------ Accuracy: 89.3%\n",
            "Step: 559 ------------ Loss: 3527.5 ------------ Accuracy: 89.3%\n",
            "Step: 560 ------------ Loss: 3525.11 ------------ Accuracy: 89.3%\n",
            "Step: 561 ------------ Loss: 3522.73 ------------ Accuracy: 89.3%\n",
            "Step: 562 ------------ Loss: 3520.36 ------------ Accuracy: 89.3%\n",
            "Step: 563 ------------ Loss: 3517.99 ------------ Accuracy: 89.3%\n",
            "Step: 564 ------------ Loss: 3515.63 ------------ Accuracy: 89.3%\n",
            "Step: 565 ------------ Loss: 3513.28 ------------ Accuracy: 89.3%\n",
            "Step: 566 ------------ Loss: 3510.93 ------------ Accuracy: 89.3%\n",
            "Step: 567 ------------ Loss: 3508.58 ------------ Accuracy: 89.3%\n",
            "Step: 568 ------------ Loss: 3506.25 ------------ Accuracy: 89.3%\n",
            "Step: 569 ------------ Loss: 3503.91 ------------ Accuracy: 89.3%\n",
            "Step: 570 ------------ Loss: 3501.59 ------------ Accuracy: 89.3%\n",
            "Step: 571 ------------ Loss: 3499.27 ------------ Accuracy: 89.3%\n",
            "Step: 572 ------------ Loss: 3496.95 ------------ Accuracy: 89.3%\n",
            "Step: 573 ------------ Loss: 3494.65 ------------ Accuracy: 89.4%\n",
            "Step: 574 ------------ Loss: 3492.34 ------------ Accuracy: 89.4%\n",
            "Step: 575 ------------ Loss: 3490.04 ------------ Accuracy: 89.4%\n",
            "Step: 576 ------------ Loss: 3487.75 ------------ Accuracy: 89.4%\n",
            "Step: 577 ------------ Loss: 3485.47 ------------ Accuracy: 89.4%\n",
            "Step: 578 ------------ Loss: 3483.19 ------------ Accuracy: 89.4%\n",
            "Step: 579 ------------ Loss: 3480.91 ------------ Accuracy: 89.4%\n",
            "Step: 580 ------------ Loss: 3478.64 ------------ Accuracy: 89.4%\n",
            "Step: 581 ------------ Loss: 3476.38 ------------ Accuracy: 89.4%\n",
            "Step: 582 ------------ Loss: 3474.12 ------------ Accuracy: 89.4%\n",
            "Step: 583 ------------ Loss: 3471.87 ------------ Accuracy: 89.4%\n",
            "Step: 584 ------------ Loss: 3469.62 ------------ Accuracy: 89.4%\n",
            "Step: 585 ------------ Loss: 3467.38 ------------ Accuracy: 89.4%\n",
            "Step: 586 ------------ Loss: 3465.14 ------------ Accuracy: 89.4%\n",
            "Step: 587 ------------ Loss: 3462.91 ------------ Accuracy: 89.4%\n",
            "Step: 588 ------------ Loss: 3460.69 ------------ Accuracy: 89.4%\n",
            "Step: 589 ------------ Loss: 3458.47 ------------ Accuracy: 89.4%\n",
            "Step: 590 ------------ Loss: 3456.25 ------------ Accuracy: 89.4%\n",
            "Step: 591 ------------ Loss: 3454.04 ------------ Accuracy: 89.4%\n",
            "Step: 592 ------------ Loss: 3451.84 ------------ Accuracy: 89.4%\n",
            "Step: 593 ------------ Loss: 3449.64 ------------ Accuracy: 89.4%\n",
            "Step: 594 ------------ Loss: 3447.44 ------------ Accuracy: 89.4%\n",
            "Step: 595 ------------ Loss: 3445.26 ------------ Accuracy: 89.4%\n",
            "Step: 596 ------------ Loss: 3443.07 ------------ Accuracy: 89.5%\n",
            "Step: 597 ------------ Loss: 3440.9 ------------ Accuracy: 89.5%\n",
            "Step: 598 ------------ Loss: 3438.72 ------------ Accuracy: 89.5%\n",
            "Step: 599 ------------ Loss: 3436.56 ------------ Accuracy: 89.5%\n",
            "Step: 600 ------------ Loss: 3434.39 ------------ Accuracy: 89.5%\n",
            "Step: 601 ------------ Loss: 3432.24 ------------ Accuracy: 89.5%\n",
            "Step: 602 ------------ Loss: 3430.08 ------------ Accuracy: 89.5%\n",
            "Step: 603 ------------ Loss: 3427.94 ------------ Accuracy: 89.5%\n",
            "Step: 604 ------------ Loss: 3425.79 ------------ Accuracy: 89.5%\n",
            "Step: 605 ------------ Loss: 3423.66 ------------ Accuracy: 89.5%\n",
            "Step: 606 ------------ Loss: 3421.53 ------------ Accuracy: 89.5%\n",
            "Step: 607 ------------ Loss: 3419.4 ------------ Accuracy: 89.5%\n",
            "Step: 608 ------------ Loss: 3417.28 ------------ Accuracy: 89.5%\n",
            "Step: 609 ------------ Loss: 3415.16 ------------ Accuracy: 89.5%\n",
            "Step: 610 ------------ Loss: 3413.05 ------------ Accuracy: 89.5%\n",
            "Step: 611 ------------ Loss: 3410.94 ------------ Accuracy: 89.5%\n",
            "Step: 612 ------------ Loss: 3408.84 ------------ Accuracy: 89.5%\n",
            "Step: 613 ------------ Loss: 3406.74 ------------ Accuracy: 89.5%\n",
            "Step: 614 ------------ Loss: 3404.65 ------------ Accuracy: 89.5%\n",
            "Step: 615 ------------ Loss: 3402.56 ------------ Accuracy: 89.5%\n",
            "Step: 616 ------------ Loss: 3400.48 ------------ Accuracy: 89.5%\n",
            "Step: 617 ------------ Loss: 3398.4 ------------ Accuracy: 89.6%\n",
            "Step: 618 ------------ Loss: 3396.33 ------------ Accuracy: 89.6%\n",
            "Step: 619 ------------ Loss: 3394.26 ------------ Accuracy: 89.6%\n",
            "Step: 620 ------------ Loss: 3392.2 ------------ Accuracy: 89.6%\n",
            "Step: 621 ------------ Loss: 3390.14 ------------ Accuracy: 89.6%\n",
            "Step: 622 ------------ Loss: 3388.09 ------------ Accuracy: 89.6%\n",
            "Step: 623 ------------ Loss: 3386.04 ------------ Accuracy: 89.6%\n",
            "Step: 624 ------------ Loss: 3383.99 ------------ Accuracy: 89.6%\n",
            "Step: 625 ------------ Loss: 3381.96 ------------ Accuracy: 89.6%\n",
            "Step: 626 ------------ Loss: 3379.92 ------------ Accuracy: 89.6%\n",
            "Step: 627 ------------ Loss: 3377.89 ------------ Accuracy: 89.6%\n",
            "Step: 628 ------------ Loss: 3375.86 ------------ Accuracy: 89.6%\n",
            "Step: 629 ------------ Loss: 3373.84 ------------ Accuracy: 89.6%\n",
            "Step: 630 ------------ Loss: 3371.83 ------------ Accuracy: 89.6%\n",
            "Step: 631 ------------ Loss: 3369.82 ------------ Accuracy: 89.6%\n",
            "Step: 632 ------------ Loss: 3367.81 ------------ Accuracy: 89.6%\n",
            "Step: 633 ------------ Loss: 3365.81 ------------ Accuracy: 89.6%\n",
            "Step: 634 ------------ Loss: 3363.81 ------------ Accuracy: 89.6%\n",
            "Step: 635 ------------ Loss: 3361.81 ------------ Accuracy: 89.6%\n",
            "Step: 636 ------------ Loss: 3359.83 ------------ Accuracy: 89.6%\n",
            "Step: 637 ------------ Loss: 3357.84 ------------ Accuracy: 89.6%\n",
            "Step: 638 ------------ Loss: 3355.86 ------------ Accuracy: 89.6%\n",
            "Step: 639 ------------ Loss: 3353.89 ------------ Accuracy: 89.6%\n",
            "Step: 640 ------------ Loss: 3351.91 ------------ Accuracy: 89.6%\n",
            "Step: 641 ------------ Loss: 3349.95 ------------ Accuracy: 89.6%\n",
            "Step: 642 ------------ Loss: 3347.99 ------------ Accuracy: 89.6%\n",
            "Step: 643 ------------ Loss: 3346.03 ------------ Accuracy: 89.6%\n",
            "Step: 644 ------------ Loss: 3344.07 ------------ Accuracy: 89.6%\n",
            "Step: 645 ------------ Loss: 3342.13 ------------ Accuracy: 89.6%\n",
            "Step: 646 ------------ Loss: 3340.18 ------------ Accuracy: 89.6%\n",
            "Step: 647 ------------ Loss: 3338.24 ------------ Accuracy: 89.5%\n",
            "Step: 648 ------------ Loss: 3336.3 ------------ Accuracy: 89.6%\n",
            "Step: 649 ------------ Loss: 3334.37 ------------ Accuracy: 89.6%\n",
            "Step: 650 ------------ Loss: 3332.44 ------------ Accuracy: 89.6%\n",
            "Step: 651 ------------ Loss: 3330.52 ------------ Accuracy: 89.6%\n",
            "Step: 652 ------------ Loss: 3328.6 ------------ Accuracy: 89.6%\n",
            "Step: 653 ------------ Loss: 3326.69 ------------ Accuracy: 89.6%\n",
            "Step: 654 ------------ Loss: 3324.78 ------------ Accuracy: 89.6%\n",
            "Step: 655 ------------ Loss: 3322.87 ------------ Accuracy: 89.6%\n",
            "Step: 656 ------------ Loss: 3320.97 ------------ Accuracy: 89.6%\n",
            "Step: 657 ------------ Loss: 3319.07 ------------ Accuracy: 89.6%\n",
            "Step: 658 ------------ Loss: 3317.18 ------------ Accuracy: 89.6%\n",
            "Step: 659 ------------ Loss: 3315.29 ------------ Accuracy: 89.6%\n",
            "Step: 660 ------------ Loss: 3313.4 ------------ Accuracy: 89.6%\n",
            "Step: 661 ------------ Loss: 3311.52 ------------ Accuracy: 89.6%\n",
            "Step: 662 ------------ Loss: 3309.64 ------------ Accuracy: 89.6%\n",
            "Step: 663 ------------ Loss: 3307.77 ------------ Accuracy: 89.6%\n",
            "Step: 664 ------------ Loss: 3305.9 ------------ Accuracy: 89.6%\n",
            "Step: 665 ------------ Loss: 3304.04 ------------ Accuracy: 89.6%\n",
            "Step: 666 ------------ Loss: 3302.18 ------------ Accuracy: 89.6%\n",
            "Step: 667 ------------ Loss: 3300.32 ------------ Accuracy: 89.6%\n",
            "Step: 668 ------------ Loss: 3298.47 ------------ Accuracy: 89.6%\n",
            "Step: 669 ------------ Loss: 3296.62 ------------ Accuracy: 89.6%\n",
            "Step: 670 ------------ Loss: 3294.77 ------------ Accuracy: 89.6%\n",
            "Step: 671 ------------ Loss: 3292.93 ------------ Accuracy: 89.6%\n",
            "Step: 672 ------------ Loss: 3291.1 ------------ Accuracy: 89.7%\n",
            "Step: 673 ------------ Loss: 3289.26 ------------ Accuracy: 89.7%\n",
            "Step: 674 ------------ Loss: 3287.43 ------------ Accuracy: 89.7%\n",
            "Step: 675 ------------ Loss: 3285.61 ------------ Accuracy: 89.7%\n",
            "Step: 676 ------------ Loss: 3283.79 ------------ Accuracy: 89.7%\n",
            "Step: 677 ------------ Loss: 3281.97 ------------ Accuracy: 89.7%\n",
            "Step: 678 ------------ Loss: 3280.16 ------------ Accuracy: 89.7%\n",
            "Step: 679 ------------ Loss: 3278.35 ------------ Accuracy: 89.7%\n",
            "Step: 680 ------------ Loss: 3276.54 ------------ Accuracy: 89.7%\n",
            "Step: 681 ------------ Loss: 3274.74 ------------ Accuracy: 89.7%\n",
            "Step: 682 ------------ Loss: 3272.94 ------------ Accuracy: 89.7%\n",
            "Step: 683 ------------ Loss: 3271.15 ------------ Accuracy: 89.7%\n",
            "Step: 684 ------------ Loss: 3269.36 ------------ Accuracy: 89.7%\n",
            "Step: 685 ------------ Loss: 3267.57 ------------ Accuracy: 89.7%\n",
            "Step: 686 ------------ Loss: 3265.79 ------------ Accuracy: 89.7%\n",
            "Step: 687 ------------ Loss: 3264.01 ------------ Accuracy: 89.7%\n",
            "Step: 688 ------------ Loss: 3262.24 ------------ Accuracy: 89.7%\n",
            "Step: 689 ------------ Loss: 3260.47 ------------ Accuracy: 89.7%\n",
            "Step: 690 ------------ Loss: 3258.7 ------------ Accuracy: 89.7%\n",
            "Step: 691 ------------ Loss: 3256.94 ------------ Accuracy: 89.7%\n",
            "Step: 692 ------------ Loss: 3255.18 ------------ Accuracy: 89.7%\n",
            "Step: 693 ------------ Loss: 3253.42 ------------ Accuracy: 89.7%\n",
            "Step: 694 ------------ Loss: 3251.67 ------------ Accuracy: 89.7%\n",
            "Step: 695 ------------ Loss: 3249.92 ------------ Accuracy: 89.7%\n",
            "Step: 696 ------------ Loss: 3248.17 ------------ Accuracy: 89.7%\n",
            "Step: 697 ------------ Loss: 3246.43 ------------ Accuracy: 89.7%\n",
            "Step: 698 ------------ Loss: 3244.69 ------------ Accuracy: 89.7%\n",
            "Step: 699 ------------ Loss: 3242.96 ------------ Accuracy: 89.7%\n",
            "Step: 700 ------------ Loss: 3241.23 ------------ Accuracy: 89.7%\n",
            "Step: 701 ------------ Loss: 3239.5 ------------ Accuracy: 89.7%\n",
            "Step: 702 ------------ Loss: 3237.78 ------------ Accuracy: 89.7%\n",
            "Step: 703 ------------ Loss: 3236.06 ------------ Accuracy: 89.7%\n",
            "Step: 704 ------------ Loss: 3234.34 ------------ Accuracy: 89.7%\n",
            "Step: 705 ------------ Loss: 3232.63 ------------ Accuracy: 89.7%\n",
            "Step: 706 ------------ Loss: 3230.92 ------------ Accuracy: 89.8%\n",
            "Step: 707 ------------ Loss: 3229.21 ------------ Accuracy: 89.8%\n",
            "Step: 708 ------------ Loss: 3227.51 ------------ Accuracy: 89.8%\n",
            "Step: 709 ------------ Loss: 3225.81 ------------ Accuracy: 89.8%\n",
            "Step: 710 ------------ Loss: 3224.12 ------------ Accuracy: 89.7%\n",
            "Step: 711 ------------ Loss: 3222.42 ------------ Accuracy: 89.7%\n",
            "Step: 712 ------------ Loss: 3220.74 ------------ Accuracy: 89.7%\n",
            "Step: 713 ------------ Loss: 3219.05 ------------ Accuracy: 89.8%\n",
            "Step: 714 ------------ Loss: 3217.37 ------------ Accuracy: 89.8%\n",
            "Step: 715 ------------ Loss: 3215.69 ------------ Accuracy: 89.8%\n",
            "Step: 716 ------------ Loss: 3214.02 ------------ Accuracy: 89.8%\n",
            "Step: 717 ------------ Loss: 3212.35 ------------ Accuracy: 89.8%\n",
            "Step: 718 ------------ Loss: 3210.68 ------------ Accuracy: 89.8%\n",
            "Step: 719 ------------ Loss: 3209.01 ------------ Accuracy: 89.8%\n",
            "Step: 720 ------------ Loss: 3207.35 ------------ Accuracy: 89.8%\n",
            "Step: 721 ------------ Loss: 3205.7 ------------ Accuracy: 89.8%\n",
            "Step: 722 ------------ Loss: 3204.04 ------------ Accuracy: 89.8%\n",
            "Step: 723 ------------ Loss: 3202.39 ------------ Accuracy: 89.8%\n",
            "Step: 724 ------------ Loss: 3200.74 ------------ Accuracy: 89.8%\n",
            "Step: 725 ------------ Loss: 3199.1 ------------ Accuracy: 89.8%\n",
            "Step: 726 ------------ Loss: 3197.46 ------------ Accuracy: 89.8%\n",
            "Step: 727 ------------ Loss: 3195.82 ------------ Accuracy: 89.8%\n",
            "Step: 728 ------------ Loss: 3194.19 ------------ Accuracy: 89.8%\n",
            "Step: 729 ------------ Loss: 3192.56 ------------ Accuracy: 89.8%\n",
            "Step: 730 ------------ Loss: 3190.93 ------------ Accuracy: 89.8%\n",
            "Step: 731 ------------ Loss: 3189.3 ------------ Accuracy: 89.8%\n",
            "Step: 732 ------------ Loss: 3187.68 ------------ Accuracy: 89.8%\n",
            "Step: 733 ------------ Loss: 3186.06 ------------ Accuracy: 89.8%\n",
            "Step: 734 ------------ Loss: 3184.45 ------------ Accuracy: 89.8%\n",
            "Step: 735 ------------ Loss: 3182.84 ------------ Accuracy: 89.8%\n",
            "Step: 736 ------------ Loss: 3181.23 ------------ Accuracy: 89.8%\n",
            "Step: 737 ------------ Loss: 3179.63 ------------ Accuracy: 89.8%\n",
            "Step: 738 ------------ Loss: 3178.02 ------------ Accuracy: 89.8%\n",
            "Step: 739 ------------ Loss: 3176.43 ------------ Accuracy: 89.8%\n",
            "Step: 740 ------------ Loss: 3174.83 ------------ Accuracy: 89.8%\n",
            "Step: 741 ------------ Loss: 3173.24 ------------ Accuracy: 89.8%\n",
            "Step: 742 ------------ Loss: 3171.65 ------------ Accuracy: 89.8%\n",
            "Step: 743 ------------ Loss: 3170.06 ------------ Accuracy: 89.8%\n",
            "Step: 744 ------------ Loss: 3168.48 ------------ Accuracy: 89.8%\n",
            "Step: 745 ------------ Loss: 3166.9 ------------ Accuracy: 89.8%\n",
            "Step: 746 ------------ Loss: 3165.32 ------------ Accuracy: 89.8%\n",
            "Step: 747 ------------ Loss: 3163.75 ------------ Accuracy: 89.8%\n",
            "Step: 748 ------------ Loss: 3162.18 ------------ Accuracy: 89.8%\n",
            "Step: 749 ------------ Loss: 3160.61 ------------ Accuracy: 89.7%\n",
            "Step: 750 ------------ Loss: 3159.05 ------------ Accuracy: 89.7%\n",
            "Step: 751 ------------ Loss: 3157.49 ------------ Accuracy: 89.8%\n",
            "Step: 752 ------------ Loss: 3155.93 ------------ Accuracy: 89.8%\n",
            "Step: 753 ------------ Loss: 3154.37 ------------ Accuracy: 89.8%\n",
            "Step: 754 ------------ Loss: 3152.82 ------------ Accuracy: 89.8%\n",
            "Step: 755 ------------ Loss: 3151.27 ------------ Accuracy: 89.8%\n",
            "Step: 756 ------------ Loss: 3149.73 ------------ Accuracy: 89.8%\n",
            "Step: 757 ------------ Loss: 3148.19 ------------ Accuracy: 89.8%\n",
            "Step: 758 ------------ Loss: 3146.65 ------------ Accuracy: 89.8%\n",
            "Step: 759 ------------ Loss: 3145.11 ------------ Accuracy: 89.8%\n",
            "Step: 760 ------------ Loss: 3143.57 ------------ Accuracy: 89.7%\n",
            "Step: 761 ------------ Loss: 3142.04 ------------ Accuracy: 89.8%\n",
            "Step: 762 ------------ Loss: 3140.52 ------------ Accuracy: 89.8%\n",
            "Step: 763 ------------ Loss: 3138.99 ------------ Accuracy: 89.8%\n",
            "Step: 764 ------------ Loss: 3137.47 ------------ Accuracy: 89.8%\n",
            "Step: 765 ------------ Loss: 3135.95 ------------ Accuracy: 89.8%\n",
            "Step: 766 ------------ Loss: 3134.43 ------------ Accuracy: 89.9%\n",
            "Step: 767 ------------ Loss: 3132.92 ------------ Accuracy: 89.9%\n",
            "Step: 768 ------------ Loss: 3131.41 ------------ Accuracy: 89.9%\n",
            "Step: 769 ------------ Loss: 3129.9 ------------ Accuracy: 89.9%\n",
            "Step: 770 ------------ Loss: 3128.4 ------------ Accuracy: 89.9%\n",
            "Step: 771 ------------ Loss: 3126.9 ------------ Accuracy: 89.9%\n",
            "Step: 772 ------------ Loss: 3125.4 ------------ Accuracy: 89.9%\n",
            "Step: 773 ------------ Loss: 3123.9 ------------ Accuracy: 89.9%\n",
            "Step: 774 ------------ Loss: 3122.41 ------------ Accuracy: 89.9%\n",
            "Step: 775 ------------ Loss: 3120.92 ------------ Accuracy: 89.9%\n",
            "Step: 776 ------------ Loss: 3119.43 ------------ Accuracy: 89.9%\n",
            "Step: 777 ------------ Loss: 3117.95 ------------ Accuracy: 89.9%\n",
            "Step: 778 ------------ Loss: 3116.47 ------------ Accuracy: 89.9%\n",
            "Step: 779 ------------ Loss: 3114.99 ------------ Accuracy: 89.9%\n",
            "Step: 780 ------------ Loss: 3113.51 ------------ Accuracy: 89.9%\n",
            "Step: 781 ------------ Loss: 3112.04 ------------ Accuracy: 89.9%\n",
            "Step: 782 ------------ Loss: 3110.57 ------------ Accuracy: 89.9%\n",
            "Step: 783 ------------ Loss: 3109.1 ------------ Accuracy: 89.9%\n",
            "Step: 784 ------------ Loss: 3107.63 ------------ Accuracy: 89.9%\n",
            "Step: 785 ------------ Loss: 3106.17 ------------ Accuracy: 89.9%\n",
            "Step: 786 ------------ Loss: 3104.71 ------------ Accuracy: 89.9%\n",
            "Step: 787 ------------ Loss: 3103.26 ------------ Accuracy: 89.9%\n",
            "Step: 788 ------------ Loss: 3101.8 ------------ Accuracy: 89.9%\n",
            "Step: 789 ------------ Loss: 3100.35 ------------ Accuracy: 89.9%\n",
            "Step: 790 ------------ Loss: 3098.9 ------------ Accuracy: 89.9%\n",
            "Step: 791 ------------ Loss: 3097.46 ------------ Accuracy: 89.9%\n",
            "Step: 792 ------------ Loss: 3096.01 ------------ Accuracy: 89.9%\n",
            "Step: 793 ------------ Loss: 3094.57 ------------ Accuracy: 89.9%\n",
            "Step: 794 ------------ Loss: 3093.14 ------------ Accuracy: 89.9%\n",
            "Step: 795 ------------ Loss: 3091.7 ------------ Accuracy: 89.9%\n",
            "Step: 796 ------------ Loss: 3090.27 ------------ Accuracy: 89.9%\n",
            "Step: 797 ------------ Loss: 3088.84 ------------ Accuracy: 89.9%\n",
            "Step: 798 ------------ Loss: 3087.41 ------------ Accuracy: 89.9%\n",
            "Step: 799 ------------ Loss: 3085.99 ------------ Accuracy: 89.9%\n",
            "Step: 800 ------------ Loss: 3084.57 ------------ Accuracy: 89.9%\n",
            "Step: 801 ------------ Loss: 3083.15 ------------ Accuracy: 89.9%\n",
            "Step: 802 ------------ Loss: 3081.73 ------------ Accuracy: 89.9%\n",
            "Step: 803 ------------ Loss: 3080.32 ------------ Accuracy: 89.9%\n",
            "Step: 804 ------------ Loss: 3078.91 ------------ Accuracy: 89.9%\n",
            "Step: 805 ------------ Loss: 3077.5 ------------ Accuracy: 89.8%\n",
            "Step: 806 ------------ Loss: 3076.09 ------------ Accuracy: 89.8%\n",
            "Step: 807 ------------ Loss: 3074.69 ------------ Accuracy: 89.8%\n",
            "Step: 808 ------------ Loss: 3073.29 ------------ Accuracy: 89.8%\n",
            "Step: 809 ------------ Loss: 3071.89 ------------ Accuracy: 89.8%\n",
            "Step: 810 ------------ Loss: 3070.5 ------------ Accuracy: 89.8%\n",
            "Step: 811 ------------ Loss: 3069.1 ------------ Accuracy: 89.8%\n",
            "Step: 812 ------------ Loss: 3067.71 ------------ Accuracy: 89.8%\n",
            "Step: 813 ------------ Loss: 3066.32 ------------ Accuracy: 89.8%\n",
            "Step: 814 ------------ Loss: 3064.94 ------------ Accuracy: 89.8%\n",
            "Step: 815 ------------ Loss: 3063.56 ------------ Accuracy: 89.8%\n",
            "Step: 816 ------------ Loss: 3062.18 ------------ Accuracy: 89.8%\n",
            "Step: 817 ------------ Loss: 3060.8 ------------ Accuracy: 89.8%\n",
            "Step: 818 ------------ Loss: 3059.42 ------------ Accuracy: 89.8%\n",
            "Step: 819 ------------ Loss: 3058.05 ------------ Accuracy: 89.8%\n",
            "Step: 820 ------------ Loss: 3056.68 ------------ Accuracy: 89.8%\n",
            "Step: 821 ------------ Loss: 3055.31 ------------ Accuracy: 89.8%\n",
            "Step: 822 ------------ Loss: 3053.95 ------------ Accuracy: 89.8%\n",
            "Step: 823 ------------ Loss: 3052.58 ------------ Accuracy: 89.8%\n",
            "Step: 824 ------------ Loss: 3051.22 ------------ Accuracy: 89.8%\n",
            "Step: 825 ------------ Loss: 3049.87 ------------ Accuracy: 89.8%\n",
            "Step: 826 ------------ Loss: 3048.51 ------------ Accuracy: 89.8%\n",
            "Step: 827 ------------ Loss: 3047.16 ------------ Accuracy: 89.8%\n",
            "Step: 828 ------------ Loss: 3045.81 ------------ Accuracy: 89.8%\n",
            "Step: 829 ------------ Loss: 3044.46 ------------ Accuracy: 89.8%\n",
            "Step: 830 ------------ Loss: 3043.11 ------------ Accuracy: 89.9%\n",
            "Step: 831 ------------ Loss: 3041.77 ------------ Accuracy: 89.9%\n",
            "Step: 832 ------------ Loss: 3040.43 ------------ Accuracy: 89.9%\n",
            "Step: 833 ------------ Loss: 3039.09 ------------ Accuracy: 89.9%\n",
            "Step: 834 ------------ Loss: 3037.75 ------------ Accuracy: 89.9%\n",
            "Step: 835 ------------ Loss: 3036.42 ------------ Accuracy: 89.9%\n",
            "Step: 836 ------------ Loss: 3035.09 ------------ Accuracy: 89.9%\n",
            "Step: 837 ------------ Loss: 3033.76 ------------ Accuracy: 89.9%\n",
            "Step: 838 ------------ Loss: 3032.43 ------------ Accuracy: 89.9%\n",
            "Step: 839 ------------ Loss: 3031.11 ------------ Accuracy: 89.9%\n",
            "Step: 840 ------------ Loss: 3029.79 ------------ Accuracy: 89.9%\n",
            "Step: 841 ------------ Loss: 3028.47 ------------ Accuracy: 89.9%\n",
            "Step: 842 ------------ Loss: 3027.15 ------------ Accuracy: 89.9%\n",
            "Step: 843 ------------ Loss: 3025.84 ------------ Accuracy: 89.9%\n",
            "Step: 844 ------------ Loss: 3024.53 ------------ Accuracy: 89.9%\n",
            "Step: 845 ------------ Loss: 3023.22 ------------ Accuracy: 89.9%\n",
            "Step: 846 ------------ Loss: 3021.91 ------------ Accuracy: 89.9%\n",
            "Step: 847 ------------ Loss: 3020.6 ------------ Accuracy: 89.9%\n",
            "Step: 848 ------------ Loss: 3019.3 ------------ Accuracy: 89.9%\n",
            "Step: 849 ------------ Loss: 3018.0 ------------ Accuracy: 89.9%\n",
            "Step: 850 ------------ Loss: 3016.7 ------------ Accuracy: 89.9%\n",
            "Step: 851 ------------ Loss: 3015.4 ------------ Accuracy: 89.9%\n",
            "Step: 852 ------------ Loss: 3014.11 ------------ Accuracy: 89.9%\n",
            "Step: 853 ------------ Loss: 3012.82 ------------ Accuracy: 89.9%\n",
            "Step: 854 ------------ Loss: 3011.53 ------------ Accuracy: 90.0%\n",
            "Step: 855 ------------ Loss: 3010.24 ------------ Accuracy: 89.9%\n",
            "Step: 856 ------------ Loss: 3008.96 ------------ Accuracy: 89.9%\n",
            "Step: 857 ------------ Loss: 3007.67 ------------ Accuracy: 89.9%\n",
            "Step: 858 ------------ Loss: 3006.39 ------------ Accuracy: 89.9%\n",
            "Step: 859 ------------ Loss: 3005.12 ------------ Accuracy: 89.9%\n",
            "Step: 860 ------------ Loss: 3003.84 ------------ Accuracy: 89.9%\n",
            "Step: 861 ------------ Loss: 3002.57 ------------ Accuracy: 89.9%\n",
            "Step: 862 ------------ Loss: 3001.29 ------------ Accuracy: 90.0%\n",
            "Step: 863 ------------ Loss: 3000.03 ------------ Accuracy: 90.0%\n",
            "Step: 864 ------------ Loss: 2998.76 ------------ Accuracy: 90.0%\n",
            "Step: 865 ------------ Loss: 2997.49 ------------ Accuracy: 90.0%\n",
            "Step: 866 ------------ Loss: 2996.23 ------------ Accuracy: 90.0%\n",
            "Step: 867 ------------ Loss: 2994.97 ------------ Accuracy: 90.0%\n",
            "Step: 868 ------------ Loss: 2993.71 ------------ Accuracy: 90.0%\n",
            "Step: 869 ------------ Loss: 2992.46 ------------ Accuracy: 90.0%\n",
            "Step: 870 ------------ Loss: 2991.2 ------------ Accuracy: 90.0%\n",
            "Step: 871 ------------ Loss: 2989.95 ------------ Accuracy: 90.0%\n",
            "Step: 872 ------------ Loss: 2988.7 ------------ Accuracy: 90.0%\n",
            "Step: 873 ------------ Loss: 2987.45 ------------ Accuracy: 90.0%\n",
            "Step: 874 ------------ Loss: 2986.21 ------------ Accuracy: 90.0%\n",
            "Step: 875 ------------ Loss: 2984.97 ------------ Accuracy: 90.0%\n",
            "Step: 876 ------------ Loss: 2983.72 ------------ Accuracy: 90.0%\n",
            "Step: 877 ------------ Loss: 2982.49 ------------ Accuracy: 90.0%\n",
            "Step: 878 ------------ Loss: 2981.25 ------------ Accuracy: 90.0%\n",
            "Step: 879 ------------ Loss: 2980.01 ------------ Accuracy: 90.0%\n",
            "Step: 880 ------------ Loss: 2978.78 ------------ Accuracy: 90.0%\n",
            "Step: 881 ------------ Loss: 2977.55 ------------ Accuracy: 90.0%\n",
            "Step: 882 ------------ Loss: 2976.32 ------------ Accuracy: 90.0%\n",
            "Step: 883 ------------ Loss: 2975.1 ------------ Accuracy: 90.0%\n",
            "Step: 884 ------------ Loss: 2973.87 ------------ Accuracy: 90.0%\n",
            "Step: 885 ------------ Loss: 2972.65 ------------ Accuracy: 90.0%\n",
            "Step: 886 ------------ Loss: 2971.43 ------------ Accuracy: 90.0%\n",
            "Step: 887 ------------ Loss: 2970.21 ------------ Accuracy: 90.0%\n",
            "Step: 888 ------------ Loss: 2969.0 ------------ Accuracy: 90.0%\n",
            "Step: 889 ------------ Loss: 2967.78 ------------ Accuracy: 90.0%\n",
            "Step: 890 ------------ Loss: 2966.57 ------------ Accuracy: 90.0%\n",
            "Step: 891 ------------ Loss: 2965.36 ------------ Accuracy: 90.0%\n",
            "Step: 892 ------------ Loss: 2964.15 ------------ Accuracy: 90.0%\n",
            "Step: 893 ------------ Loss: 2962.95 ------------ Accuracy: 90.0%\n",
            "Step: 894 ------------ Loss: 2961.74 ------------ Accuracy: 90.0%\n",
            "Step: 895 ------------ Loss: 2960.54 ------------ Accuracy: 90.0%\n",
            "Step: 896 ------------ Loss: 2959.34 ------------ Accuracy: 90.0%\n",
            "Step: 897 ------------ Loss: 2958.15 ------------ Accuracy: 90.0%\n",
            "Step: 898 ------------ Loss: 2956.95 ------------ Accuracy: 90.0%\n",
            "Step: 899 ------------ Loss: 2955.76 ------------ Accuracy: 90.0%\n",
            "Step: 900 ------------ Loss: 2954.57 ------------ Accuracy: 90.0%\n",
            "Step: 901 ------------ Loss: 2953.38 ------------ Accuracy: 90.0%\n",
            "Step: 902 ------------ Loss: 2952.19 ------------ Accuracy: 90.0%\n",
            "Step: 903 ------------ Loss: 2951.0 ------------ Accuracy: 90.0%\n",
            "Step: 904 ------------ Loss: 2949.82 ------------ Accuracy: 90.0%\n",
            "Step: 905 ------------ Loss: 2948.64 ------------ Accuracy: 90.0%\n",
            "Step: 906 ------------ Loss: 2947.46 ------------ Accuracy: 90.0%\n",
            "Step: 907 ------------ Loss: 2946.28 ------------ Accuracy: 89.9%\n",
            "Step: 908 ------------ Loss: 2945.11 ------------ Accuracy: 89.9%\n",
            "Step: 909 ------------ Loss: 2943.93 ------------ Accuracy: 89.9%\n",
            "Step: 910 ------------ Loss: 2942.76 ------------ Accuracy: 89.9%\n",
            "Step: 911 ------------ Loss: 2941.59 ------------ Accuracy: 89.9%\n",
            "Step: 912 ------------ Loss: 2940.42 ------------ Accuracy: 89.9%\n",
            "Step: 913 ------------ Loss: 2939.26 ------------ Accuracy: 89.9%\n",
            "Step: 914 ------------ Loss: 2938.09 ------------ Accuracy: 89.9%\n",
            "Step: 915 ------------ Loss: 2936.93 ------------ Accuracy: 89.9%\n",
            "Step: 916 ------------ Loss: 2935.77 ------------ Accuracy: 89.9%\n",
            "Step: 917 ------------ Loss: 2934.61 ------------ Accuracy: 90.0%\n",
            "Step: 918 ------------ Loss: 2933.46 ------------ Accuracy: 90.0%\n",
            "Step: 919 ------------ Loss: 2932.3 ------------ Accuracy: 90.0%\n",
            "Step: 920 ------------ Loss: 2931.15 ------------ Accuracy: 90.0%\n",
            "Step: 921 ------------ Loss: 2930.0 ------------ Accuracy: 90.0%\n",
            "Step: 922 ------------ Loss: 2928.85 ------------ Accuracy: 90.0%\n",
            "Step: 923 ------------ Loss: 2927.7 ------------ Accuracy: 90.0%\n",
            "Step: 924 ------------ Loss: 2926.56 ------------ Accuracy: 90.0%\n",
            "Step: 925 ------------ Loss: 2925.42 ------------ Accuracy: 90.0%\n",
            "Step: 926 ------------ Loss: 2924.28 ------------ Accuracy: 90.0%\n",
            "Step: 927 ------------ Loss: 2923.14 ------------ Accuracy: 90.0%\n",
            "Step: 928 ------------ Loss: 2922.0 ------------ Accuracy: 90.0%\n",
            "Step: 929 ------------ Loss: 2920.86 ------------ Accuracy: 90.0%\n",
            "Step: 930 ------------ Loss: 2919.73 ------------ Accuracy: 90.0%\n",
            "Step: 931 ------------ Loss: 2918.6 ------------ Accuracy: 90.0%\n",
            "Step: 932 ------------ Loss: 2917.47 ------------ Accuracy: 90.0%\n",
            "Step: 933 ------------ Loss: 2916.34 ------------ Accuracy: 90.0%\n",
            "Step: 934 ------------ Loss: 2915.21 ------------ Accuracy: 90.0%\n",
            "Step: 935 ------------ Loss: 2914.09 ------------ Accuracy: 90.0%\n",
            "Step: 936 ------------ Loss: 2912.97 ------------ Accuracy: 90.0%\n",
            "Step: 937 ------------ Loss: 2911.84 ------------ Accuracy: 90.0%\n",
            "Step: 938 ------------ Loss: 2910.73 ------------ Accuracy: 90.0%\n",
            "Step: 939 ------------ Loss: 2909.61 ------------ Accuracy: 90.0%\n",
            "Step: 940 ------------ Loss: 2908.49 ------------ Accuracy: 90.0%\n",
            "Step: 941 ------------ Loss: 2907.38 ------------ Accuracy: 90.0%\n",
            "Step: 942 ------------ Loss: 2906.27 ------------ Accuracy: 90.0%\n",
            "Step: 943 ------------ Loss: 2905.16 ------------ Accuracy: 90.0%\n",
            "Step: 944 ------------ Loss: 2904.05 ------------ Accuracy: 90.0%\n",
            "Step: 945 ------------ Loss: 2902.94 ------------ Accuracy: 90.0%\n",
            "Step: 946 ------------ Loss: 2901.84 ------------ Accuracy: 90.0%\n",
            "Step: 947 ------------ Loss: 2900.74 ------------ Accuracy: 90.0%\n",
            "Step: 948 ------------ Loss: 2899.63 ------------ Accuracy: 90.0%\n",
            "Step: 949 ------------ Loss: 2898.53 ------------ Accuracy: 90.0%\n",
            "Step: 950 ------------ Loss: 2897.44 ------------ Accuracy: 90.0%\n",
            "Step: 951 ------------ Loss: 2896.34 ------------ Accuracy: 90.0%\n",
            "Step: 952 ------------ Loss: 2895.25 ------------ Accuracy: 90.0%\n",
            "Step: 953 ------------ Loss: 2894.15 ------------ Accuracy: 90.0%\n",
            "Step: 954 ------------ Loss: 2893.06 ------------ Accuracy: 90.0%\n",
            "Step: 955 ------------ Loss: 2891.98 ------------ Accuracy: 90.0%\n",
            "Step: 956 ------------ Loss: 2890.89 ------------ Accuracy: 90.0%\n",
            "Step: 957 ------------ Loss: 2889.8 ------------ Accuracy: 90.0%\n",
            "Step: 958 ------------ Loss: 2888.72 ------------ Accuracy: 90.0%\n",
            "Step: 959 ------------ Loss: 2887.64 ------------ Accuracy: 90.0%\n",
            "Step: 960 ------------ Loss: 2886.56 ------------ Accuracy: 90.0%\n",
            "Step: 961 ------------ Loss: 2885.48 ------------ Accuracy: 90.0%\n",
            "Step: 962 ------------ Loss: 2884.4 ------------ Accuracy: 90.0%\n",
            "Step: 963 ------------ Loss: 2883.33 ------------ Accuracy: 90.0%\n",
            "Step: 964 ------------ Loss: 2882.25 ------------ Accuracy: 90.0%\n",
            "Step: 965 ------------ Loss: 2881.18 ------------ Accuracy: 90.0%\n",
            "Step: 966 ------------ Loss: 2880.11 ------------ Accuracy: 90.0%\n",
            "Step: 967 ------------ Loss: 2879.04 ------------ Accuracy: 90.0%\n",
            "Step: 968 ------------ Loss: 2877.98 ------------ Accuracy: 90.0%\n",
            "Step: 969 ------------ Loss: 2876.91 ------------ Accuracy: 90.0%\n",
            "Step: 970 ------------ Loss: 2875.85 ------------ Accuracy: 90.0%\n",
            "Step: 971 ------------ Loss: 2874.79 ------------ Accuracy: 90.0%\n",
            "Step: 972 ------------ Loss: 2873.73 ------------ Accuracy: 90.0%\n",
            "Step: 973 ------------ Loss: 2872.67 ------------ Accuracy: 90.0%\n",
            "Step: 974 ------------ Loss: 2871.61 ------------ Accuracy: 90.0%\n",
            "Step: 975 ------------ Loss: 2870.56 ------------ Accuracy: 90.0%\n",
            "Step: 976 ------------ Loss: 2869.5 ------------ Accuracy: 90.0%\n",
            "Step: 977 ------------ Loss: 2868.45 ------------ Accuracy: 90.0%\n",
            "Step: 978 ------------ Loss: 2867.4 ------------ Accuracy: 90.0%\n",
            "Step: 979 ------------ Loss: 2866.35 ------------ Accuracy: 90.0%\n",
            "Step: 980 ------------ Loss: 2865.31 ------------ Accuracy: 90.0%\n",
            "Step: 981 ------------ Loss: 2864.26 ------------ Accuracy: 90.0%\n",
            "Step: 982 ------------ Loss: 2863.22 ------------ Accuracy: 90.0%\n",
            "Step: 983 ------------ Loss: 2862.17 ------------ Accuracy: 90.0%\n",
            "Step: 984 ------------ Loss: 2861.13 ------------ Accuracy: 90.0%\n",
            "Step: 985 ------------ Loss: 2860.1 ------------ Accuracy: 90.0%\n",
            "Step: 986 ------------ Loss: 2859.06 ------------ Accuracy: 90.0%\n",
            "Step: 987 ------------ Loss: 2858.02 ------------ Accuracy: 90.0%\n",
            "Step: 988 ------------ Loss: 2856.99 ------------ Accuracy: 90.0%\n",
            "Step: 989 ------------ Loss: 2855.96 ------------ Accuracy: 90.0%\n",
            "Step: 990 ------------ Loss: 2854.93 ------------ Accuracy: 90.0%\n",
            "Step: 991 ------------ Loss: 2853.9 ------------ Accuracy: 90.0%\n",
            "Step: 992 ------------ Loss: 2852.87 ------------ Accuracy: 90.0%\n",
            "Step: 993 ------------ Loss: 2851.84 ------------ Accuracy: 90.0%\n",
            "Step: 994 ------------ Loss: 2850.82 ------------ Accuracy: 90.0%\n",
            "Step: 995 ------------ Loss: 2849.8 ------------ Accuracy: 90.0%\n",
            "Step: 996 ------------ Loss: 2848.78 ------------ Accuracy: 90.0%\n",
            "Step: 997 ------------ Loss: 2847.76 ------------ Accuracy: 90.0%\n",
            "Step: 998 ------------ Loss: 2846.74 ------------ Accuracy: 90.0%\n",
            "Step: 999 ------------ Loss: 2845.72 ------------ Accuracy: 90.0%\n",
            "Step: 1000 ------------ Loss: 2844.71 ------------ Accuracy: 90.0%\n",
            "Step: 1001 ------------ Loss: 2843.69 ------------ Accuracy: 90.0%\n",
            "Step: 1002 ------------ Loss: 2842.68 ------------ Accuracy: 90.0%\n",
            "Step: 1003 ------------ Loss: 2841.67 ------------ Accuracy: 90.0%\n",
            "Step: 1004 ------------ Loss: 2840.66 ------------ Accuracy: 90.0%\n",
            "Step: 1005 ------------ Loss: 2839.65 ------------ Accuracy: 90.0%\n",
            "Step: 1006 ------------ Loss: 2838.65 ------------ Accuracy: 90.0%\n",
            "Step: 1007 ------------ Loss: 2837.64 ------------ Accuracy: 90.0%\n",
            "Step: 1008 ------------ Loss: 2836.64 ------------ Accuracy: 90.0%\n",
            "Step: 1009 ------------ Loss: 2835.64 ------------ Accuracy: 90.0%\n",
            "Step: 1010 ------------ Loss: 2834.64 ------------ Accuracy: 90.0%\n",
            "Step: 1011 ------------ Loss: 2833.64 ------------ Accuracy: 90.0%\n",
            "Step: 1012 ------------ Loss: 2832.65 ------------ Accuracy: 90.0%\n",
            "Step: 1013 ------------ Loss: 2831.65 ------------ Accuracy: 89.9%\n",
            "Step: 1014 ------------ Loss: 2830.66 ------------ Accuracy: 89.9%\n",
            "Step: 1015 ------------ Loss: 2829.67 ------------ Accuracy: 89.9%\n",
            "Step: 1016 ------------ Loss: 2828.68 ------------ Accuracy: 89.9%\n",
            "Step: 1017 ------------ Loss: 2827.69 ------------ Accuracy: 90.0%\n",
            "Step: 1018 ------------ Loss: 2826.7 ------------ Accuracy: 90.0%\n",
            "Step: 1019 ------------ Loss: 2825.71 ------------ Accuracy: 90.0%\n",
            "Step: 1020 ------------ Loss: 2824.73 ------------ Accuracy: 90.0%\n",
            "Step: 1021 ------------ Loss: 2823.75 ------------ Accuracy: 90.0%\n",
            "Step: 1022 ------------ Loss: 2822.76 ------------ Accuracy: 90.0%\n",
            "Step: 1023 ------------ Loss: 2821.78 ------------ Accuracy: 90.0%\n",
            "Step: 1024 ------------ Loss: 2820.8 ------------ Accuracy: 90.0%\n",
            "Step: 1025 ------------ Loss: 2819.83 ------------ Accuracy: 90.0%\n",
            "Step: 1026 ------------ Loss: 2818.85 ------------ Accuracy: 90.0%\n",
            "Step: 1027 ------------ Loss: 2817.88 ------------ Accuracy: 90.0%\n",
            "Step: 1028 ------------ Loss: 2816.9 ------------ Accuracy: 90.0%\n",
            "Step: 1029 ------------ Loss: 2815.93 ------------ Accuracy: 90.0%\n",
            "Step: 1030 ------------ Loss: 2814.96 ------------ Accuracy: 90.0%\n",
            "Step: 1031 ------------ Loss: 2813.99 ------------ Accuracy: 90.0%\n",
            "Step: 1032 ------------ Loss: 2813.03 ------------ Accuracy: 89.9%\n",
            "Step: 1033 ------------ Loss: 2812.06 ------------ Accuracy: 89.9%\n",
            "Step: 1034 ------------ Loss: 2811.1 ------------ Accuracy: 89.9%\n",
            "Step: 1035 ------------ Loss: 2810.13 ------------ Accuracy: 89.9%\n",
            "Step: 1036 ------------ Loss: 2809.17 ------------ Accuracy: 89.9%\n",
            "Step: 1037 ------------ Loss: 2808.21 ------------ Accuracy: 89.9%\n",
            "Step: 1038 ------------ Loss: 2807.26 ------------ Accuracy: 89.9%\n",
            "Step: 1039 ------------ Loss: 2806.3 ------------ Accuracy: 89.9%\n",
            "Step: 1040 ------------ Loss: 2805.34 ------------ Accuracy: 89.9%\n",
            "Step: 1041 ------------ Loss: 2804.39 ------------ Accuracy: 89.9%\n",
            "Step: 1042 ------------ Loss: 2803.44 ------------ Accuracy: 89.9%\n",
            "Step: 1043 ------------ Loss: 2802.48 ------------ Accuracy: 89.9%\n",
            "Step: 1044 ------------ Loss: 2801.53 ------------ Accuracy: 89.9%\n",
            "Step: 1045 ------------ Loss: 2800.59 ------------ Accuracy: 89.9%\n",
            "Step: 1046 ------------ Loss: 2799.64 ------------ Accuracy: 89.9%\n",
            "Step: 1047 ------------ Loss: 2798.69 ------------ Accuracy: 89.9%\n",
            "Step: 1048 ------------ Loss: 2797.75 ------------ Accuracy: 89.9%\n",
            "Step: 1049 ------------ Loss: 2796.8 ------------ Accuracy: 89.9%\n",
            "Step: 1050 ------------ Loss: 2795.86 ------------ Accuracy: 90.0%\n",
            "Step: 1051 ------------ Loss: 2794.92 ------------ Accuracy: 90.0%\n",
            "Step: 1052 ------------ Loss: 2793.98 ------------ Accuracy: 90.0%\n",
            "Step: 1053 ------------ Loss: 2793.05 ------------ Accuracy: 90.0%\n",
            "Step: 1054 ------------ Loss: 2792.11 ------------ Accuracy: 90.0%\n",
            "Step: 1055 ------------ Loss: 2791.18 ------------ Accuracy: 90.0%\n",
            "Step: 1056 ------------ Loss: 2790.24 ------------ Accuracy: 90.0%\n",
            "Step: 1057 ------------ Loss: 2789.31 ------------ Accuracy: 90.0%\n",
            "Step: 1058 ------------ Loss: 2788.38 ------------ Accuracy: 90.0%\n",
            "Step: 1059 ------------ Loss: 2787.45 ------------ Accuracy: 90.0%\n",
            "Step: 1060 ------------ Loss: 2786.52 ------------ Accuracy: 90.0%\n",
            "Step: 1061 ------------ Loss: 2785.6 ------------ Accuracy: 90.0%\n",
            "Step: 1062 ------------ Loss: 2784.67 ------------ Accuracy: 90.0%\n",
            "Step: 1063 ------------ Loss: 2783.75 ------------ Accuracy: 90.0%\n",
            "Step: 1064 ------------ Loss: 2782.82 ------------ Accuracy: 90.0%\n",
            "Step: 1065 ------------ Loss: 2781.9 ------------ Accuracy: 90.0%\n",
            "Step: 1066 ------------ Loss: 2780.98 ------------ Accuracy: 90.0%\n",
            "Step: 1067 ------------ Loss: 2780.06 ------------ Accuracy: 90.0%\n",
            "Step: 1068 ------------ Loss: 2779.15 ------------ Accuracy: 90.0%\n",
            "Step: 1069 ------------ Loss: 2778.23 ------------ Accuracy: 90.0%\n",
            "Step: 1070 ------------ Loss: 2777.32 ------------ Accuracy: 90.0%\n",
            "Step: 1071 ------------ Loss: 2776.4 ------------ Accuracy: 90.0%\n",
            "Step: 1072 ------------ Loss: 2775.49 ------------ Accuracy: 90.0%\n",
            "Step: 1073 ------------ Loss: 2774.58 ------------ Accuracy: 90.0%\n",
            "Step: 1074 ------------ Loss: 2773.67 ------------ Accuracy: 90.0%\n",
            "Step: 1075 ------------ Loss: 2772.76 ------------ Accuracy: 90.0%\n",
            "Step: 1076 ------------ Loss: 2771.86 ------------ Accuracy: 90.0%\n",
            "Step: 1077 ------------ Loss: 2770.95 ------------ Accuracy: 90.0%\n",
            "Step: 1078 ------------ Loss: 2770.05 ------------ Accuracy: 90.0%\n",
            "Step: 1079 ------------ Loss: 2769.14 ------------ Accuracy: 90.0%\n",
            "Step: 1080 ------------ Loss: 2768.24 ------------ Accuracy: 90.0%\n",
            "Step: 1081 ------------ Loss: 2767.34 ------------ Accuracy: 90.0%\n",
            "Step: 1082 ------------ Loss: 2766.44 ------------ Accuracy: 90.0%\n",
            "Step: 1083 ------------ Loss: 2765.54 ------------ Accuracy: 90.0%\n",
            "Step: 1084 ------------ Loss: 2764.65 ------------ Accuracy: 90.0%\n",
            "Step: 1085 ------------ Loss: 2763.75 ------------ Accuracy: 90.0%\n",
            "Step: 1086 ------------ Loss: 2762.86 ------------ Accuracy: 90.0%\n",
            "Step: 1087 ------------ Loss: 2761.97 ------------ Accuracy: 90.0%\n",
            "Step: 1088 ------------ Loss: 2761.07 ------------ Accuracy: 90.0%\n",
            "Step: 1089 ------------ Loss: 2760.18 ------------ Accuracy: 90.0%\n",
            "Step: 1090 ------------ Loss: 2759.3 ------------ Accuracy: 90.0%\n",
            "Step: 1091 ------------ Loss: 2758.41 ------------ Accuracy: 90.0%\n",
            "Step: 1092 ------------ Loss: 2757.52 ------------ Accuracy: 90.1%\n",
            "Step: 1093 ------------ Loss: 2756.64 ------------ Accuracy: 90.0%\n",
            "Step: 1094 ------------ Loss: 2755.75 ------------ Accuracy: 90.0%\n",
            "Step: 1095 ------------ Loss: 2754.87 ------------ Accuracy: 90.0%\n",
            "Step: 1096 ------------ Loss: 2753.99 ------------ Accuracy: 90.0%\n",
            "Step: 1097 ------------ Loss: 2753.11 ------------ Accuracy: 90.0%\n",
            "Step: 1098 ------------ Loss: 2752.23 ------------ Accuracy: 90.0%\n",
            "Step: 1099 ------------ Loss: 2751.35 ------------ Accuracy: 90.0%\n",
            "Step: 1100 ------------ Loss: 2750.48 ------------ Accuracy: 90.1%\n",
            "Step: 1101 ------------ Loss: 2749.6 ------------ Accuracy: 90.1%\n",
            "Step: 1102 ------------ Loss: 2748.73 ------------ Accuracy: 90.1%\n",
            "Step: 1103 ------------ Loss: 2747.86 ------------ Accuracy: 90.1%\n",
            "Step: 1104 ------------ Loss: 2746.98 ------------ Accuracy: 90.1%\n",
            "Step: 1105 ------------ Loss: 2746.11 ------------ Accuracy: 90.0%\n",
            "Step: 1106 ------------ Loss: 2745.24 ------------ Accuracy: 90.0%\n",
            "Step: 1107 ------------ Loss: 2744.38 ------------ Accuracy: 90.0%\n",
            "Step: 1108 ------------ Loss: 2743.51 ------------ Accuracy: 90.0%\n",
            "Step: 1109 ------------ Loss: 2742.64 ------------ Accuracy: 90.0%\n",
            "Step: 1110 ------------ Loss: 2741.78 ------------ Accuracy: 90.0%\n",
            "Step: 1111 ------------ Loss: 2740.92 ------------ Accuracy: 90.0%\n",
            "Step: 1112 ------------ Loss: 2740.06 ------------ Accuracy: 90.0%\n",
            "Step: 1113 ------------ Loss: 2739.2 ------------ Accuracy: 90.0%\n",
            "Step: 1114 ------------ Loss: 2738.34 ------------ Accuracy: 90.1%\n",
            "Step: 1115 ------------ Loss: 2737.48 ------------ Accuracy: 90.1%\n",
            "Step: 1116 ------------ Loss: 2736.62 ------------ Accuracy: 90.1%\n",
            "Step: 1117 ------------ Loss: 2735.77 ------------ Accuracy: 90.1%\n",
            "Step: 1118 ------------ Loss: 2734.91 ------------ Accuracy: 90.1%\n",
            "Step: 1119 ------------ Loss: 2734.06 ------------ Accuracy: 90.1%\n",
            "Step: 1120 ------------ Loss: 2733.21 ------------ Accuracy: 90.1%\n",
            "Step: 1121 ------------ Loss: 2732.35 ------------ Accuracy: 90.1%\n",
            "Step: 1122 ------------ Loss: 2731.5 ------------ Accuracy: 90.1%\n",
            "Step: 1123 ------------ Loss: 2730.66 ------------ Accuracy: 90.1%\n",
            "Step: 1124 ------------ Loss: 2729.81 ------------ Accuracy: 90.1%\n",
            "Step: 1125 ------------ Loss: 2728.96 ------------ Accuracy: 90.1%\n",
            "Step: 1126 ------------ Loss: 2728.12 ------------ Accuracy: 90.1%\n",
            "Step: 1127 ------------ Loss: 2727.27 ------------ Accuracy: 90.1%\n",
            "Step: 1128 ------------ Loss: 2726.43 ------------ Accuracy: 90.1%\n",
            "Step: 1129 ------------ Loss: 2725.59 ------------ Accuracy: 90.1%\n",
            "Step: 1130 ------------ Loss: 2724.75 ------------ Accuracy: 90.1%\n",
            "Step: 1131 ------------ Loss: 2723.91 ------------ Accuracy: 90.1%\n",
            "Step: 1132 ------------ Loss: 2723.07 ------------ Accuracy: 90.1%\n",
            "Step: 1133 ------------ Loss: 2722.23 ------------ Accuracy: 90.1%\n",
            "Step: 1134 ------------ Loss: 2721.4 ------------ Accuracy: 90.1%\n",
            "Step: 1135 ------------ Loss: 2720.56 ------------ Accuracy: 90.1%\n",
            "Step: 1136 ------------ Loss: 2719.73 ------------ Accuracy: 90.1%\n",
            "Step: 1137 ------------ Loss: 2718.9 ------------ Accuracy: 90.1%\n",
            "Step: 1138 ------------ Loss: 2718.07 ------------ Accuracy: 90.1%\n",
            "Step: 1139 ------------ Loss: 2717.23 ------------ Accuracy: 90.1%\n",
            "Step: 1140 ------------ Loss: 2716.41 ------------ Accuracy: 90.1%\n",
            "Step: 1141 ------------ Loss: 2715.58 ------------ Accuracy: 90.1%\n",
            "Step: 1142 ------------ Loss: 2714.75 ------------ Accuracy: 90.1%\n",
            "Step: 1143 ------------ Loss: 2713.93 ------------ Accuracy: 90.1%\n",
            "Step: 1144 ------------ Loss: 2713.1 ------------ Accuracy: 90.1%\n",
            "Step: 1145 ------------ Loss: 2712.28 ------------ Accuracy: 90.1%\n",
            "Step: 1146 ------------ Loss: 2711.46 ------------ Accuracy: 90.1%\n",
            "Step: 1147 ------------ Loss: 2710.63 ------------ Accuracy: 90.1%\n",
            "Step: 1148 ------------ Loss: 2709.81 ------------ Accuracy: 90.1%\n",
            "Step: 1149 ------------ Loss: 2708.99 ------------ Accuracy: 90.1%\n",
            "Step: 1150 ------------ Loss: 2708.18 ------------ Accuracy: 90.1%\n",
            "Step: 1151 ------------ Loss: 2707.36 ------------ Accuracy: 90.1%\n",
            "Step: 1152 ------------ Loss: 2706.54 ------------ Accuracy: 90.1%\n",
            "Step: 1153 ------------ Loss: 2705.73 ------------ Accuracy: 90.1%\n",
            "Step: 1154 ------------ Loss: 2704.92 ------------ Accuracy: 90.1%\n",
            "Step: 1155 ------------ Loss: 2704.1 ------------ Accuracy: 90.1%\n",
            "Step: 1156 ------------ Loss: 2703.29 ------------ Accuracy: 90.1%\n",
            "Step: 1157 ------------ Loss: 2702.48 ------------ Accuracy: 90.1%\n",
            "Step: 1158 ------------ Loss: 2701.67 ------------ Accuracy: 90.1%\n",
            "Step: 1159 ------------ Loss: 2700.87 ------------ Accuracy: 90.2%\n",
            "Step: 1160 ------------ Loss: 2700.06 ------------ Accuracy: 90.2%\n",
            "Step: 1161 ------------ Loss: 2699.25 ------------ Accuracy: 90.2%\n",
            "Step: 1162 ------------ Loss: 2698.45 ------------ Accuracy: 90.2%\n",
            "Step: 1163 ------------ Loss: 2697.64 ------------ Accuracy: 90.2%\n",
            "Step: 1164 ------------ Loss: 2696.84 ------------ Accuracy: 90.2%\n",
            "Step: 1165 ------------ Loss: 2696.04 ------------ Accuracy: 90.2%\n",
            "Step: 1166 ------------ Loss: 2695.24 ------------ Accuracy: 90.2%\n",
            "Step: 1167 ------------ Loss: 2694.44 ------------ Accuracy: 90.2%\n",
            "Step: 1168 ------------ Loss: 2693.64 ------------ Accuracy: 90.2%\n",
            "Step: 1169 ------------ Loss: 2692.85 ------------ Accuracy: 90.1%\n",
            "Step: 1170 ------------ Loss: 2692.05 ------------ Accuracy: 90.1%\n",
            "Step: 1171 ------------ Loss: 2691.25 ------------ Accuracy: 90.1%\n",
            "Step: 1172 ------------ Loss: 2690.46 ------------ Accuracy: 90.1%\n",
            "Step: 1173 ------------ Loss: 2689.67 ------------ Accuracy: 90.1%\n",
            "Step: 1174 ------------ Loss: 2688.87 ------------ Accuracy: 90.1%\n",
            "Step: 1175 ------------ Loss: 2688.08 ------------ Accuracy: 90.1%\n",
            "Step: 1176 ------------ Loss: 2687.29 ------------ Accuracy: 90.1%\n",
            "Step: 1177 ------------ Loss: 2686.51 ------------ Accuracy: 90.1%\n",
            "Step: 1178 ------------ Loss: 2685.72 ------------ Accuracy: 90.1%\n",
            "Step: 1179 ------------ Loss: 2684.93 ------------ Accuracy: 90.2%\n",
            "Step: 1180 ------------ Loss: 2684.15 ------------ Accuracy: 90.2%\n",
            "Step: 1181 ------------ Loss: 2683.36 ------------ Accuracy: 90.2%\n",
            "Step: 1182 ------------ Loss: 2682.58 ------------ Accuracy: 90.2%\n",
            "Step: 1183 ------------ Loss: 2681.79 ------------ Accuracy: 90.2%\n",
            "Step: 1184 ------------ Loss: 2681.01 ------------ Accuracy: 90.1%\n",
            "Step: 1185 ------------ Loss: 2680.23 ------------ Accuracy: 90.1%\n",
            "Step: 1186 ------------ Loss: 2679.45 ------------ Accuracy: 90.1%\n",
            "Step: 1187 ------------ Loss: 2678.67 ------------ Accuracy: 90.1%\n",
            "Step: 1188 ------------ Loss: 2677.9 ------------ Accuracy: 90.2%\n",
            "Step: 1189 ------------ Loss: 2677.12 ------------ Accuracy: 90.2%\n",
            "Step: 1190 ------------ Loss: 2676.35 ------------ Accuracy: 90.2%\n",
            "Step: 1191 ------------ Loss: 2675.57 ------------ Accuracy: 90.2%\n",
            "Step: 1192 ------------ Loss: 2674.8 ------------ Accuracy: 90.2%\n",
            "Step: 1193 ------------ Loss: 2674.03 ------------ Accuracy: 90.2%\n",
            "Step: 1194 ------------ Loss: 2673.25 ------------ Accuracy: 90.2%\n",
            "Step: 1195 ------------ Loss: 2672.48 ------------ Accuracy: 90.2%\n",
            "Step: 1196 ------------ Loss: 2671.71 ------------ Accuracy: 90.1%\n",
            "Step: 1197 ------------ Loss: 2670.95 ------------ Accuracy: 90.1%\n",
            "Step: 1198 ------------ Loss: 2670.18 ------------ Accuracy: 90.1%\n",
            "Step: 1199 ------------ Loss: 2669.41 ------------ Accuracy: 90.1%\n",
            "Step: 1200 ------------ Loss: 2668.65 ------------ Accuracy: 90.1%\n",
            "Step: 1201 ------------ Loss: 2667.88 ------------ Accuracy: 90.1%\n",
            "Step: 1202 ------------ Loss: 2667.12 ------------ Accuracy: 90.1%\n",
            "Step: 1203 ------------ Loss: 2666.36 ------------ Accuracy: 90.1%\n",
            "Step: 1204 ------------ Loss: 2665.6 ------------ Accuracy: 90.1%\n",
            "Step: 1205 ------------ Loss: 2664.84 ------------ Accuracy: 90.1%\n",
            "Step: 1206 ------------ Loss: 2664.08 ------------ Accuracy: 90.1%\n",
            "Step: 1207 ------------ Loss: 2663.32 ------------ Accuracy: 90.1%\n",
            "Step: 1208 ------------ Loss: 2662.56 ------------ Accuracy: 90.1%\n",
            "Step: 1209 ------------ Loss: 2661.8 ------------ Accuracy: 90.1%\n",
            "Step: 1210 ------------ Loss: 2661.05 ------------ Accuracy: 90.1%\n",
            "Step: 1211 ------------ Loss: 2660.29 ------------ Accuracy: 90.1%\n",
            "Step: 1212 ------------ Loss: 2659.54 ------------ Accuracy: 90.2%\n",
            "Step: 1213 ------------ Loss: 2658.79 ------------ Accuracy: 90.2%\n",
            "Step: 1214 ------------ Loss: 2658.04 ------------ Accuracy: 90.2%\n",
            "Step: 1215 ------------ Loss: 2657.29 ------------ Accuracy: 90.2%\n",
            "Step: 1216 ------------ Loss: 2656.54 ------------ Accuracy: 90.2%\n",
            "Step: 1217 ------------ Loss: 2655.79 ------------ Accuracy: 90.2%\n",
            "Step: 1218 ------------ Loss: 2655.04 ------------ Accuracy: 90.2%\n",
            "Step: 1219 ------------ Loss: 2654.29 ------------ Accuracy: 90.2%\n",
            "Step: 1220 ------------ Loss: 2653.55 ------------ Accuracy: 90.2%\n",
            "Step: 1221 ------------ Loss: 2652.8 ------------ Accuracy: 90.2%\n",
            "Step: 1222 ------------ Loss: 2652.06 ------------ Accuracy: 90.2%\n",
            "Step: 1223 ------------ Loss: 2651.32 ------------ Accuracy: 90.2%\n",
            "Step: 1224 ------------ Loss: 2650.58 ------------ Accuracy: 90.2%\n",
            "Step: 1225 ------------ Loss: 2649.83 ------------ Accuracy: 90.2%\n",
            "Step: 1226 ------------ Loss: 2649.09 ------------ Accuracy: 90.2%\n",
            "Step: 1227 ------------ Loss: 2648.36 ------------ Accuracy: 90.2%\n",
            "Step: 1228 ------------ Loss: 2647.62 ------------ Accuracy: 90.2%\n",
            "Step: 1229 ------------ Loss: 2646.88 ------------ Accuracy: 90.2%\n",
            "Step: 1230 ------------ Loss: 2646.14 ------------ Accuracy: 90.2%\n",
            "Step: 1231 ------------ Loss: 2645.41 ------------ Accuracy: 90.2%\n",
            "Step: 1232 ------------ Loss: 2644.67 ------------ Accuracy: 90.2%\n",
            "Step: 1233 ------------ Loss: 2643.94 ------------ Accuracy: 90.2%\n",
            "Step: 1234 ------------ Loss: 2643.21 ------------ Accuracy: 90.2%\n",
            "Step: 1235 ------------ Loss: 2642.48 ------------ Accuracy: 90.2%\n",
            "Step: 1236 ------------ Loss: 2641.75 ------------ Accuracy: 90.2%\n",
            "Step: 1237 ------------ Loss: 2641.02 ------------ Accuracy: 90.2%\n",
            "Step: 1238 ------------ Loss: 2640.29 ------------ Accuracy: 90.2%\n",
            "Step: 1239 ------------ Loss: 2639.56 ------------ Accuracy: 90.2%\n",
            "Step: 1240 ------------ Loss: 2638.83 ------------ Accuracy: 90.2%\n",
            "Step: 1241 ------------ Loss: 2638.11 ------------ Accuracy: 90.2%\n",
            "Step: 1242 ------------ Loss: 2637.38 ------------ Accuracy: 90.2%\n",
            "Step: 1243 ------------ Loss: 2636.66 ------------ Accuracy: 90.2%\n",
            "Step: 1244 ------------ Loss: 2635.93 ------------ Accuracy: 90.2%\n",
            "Step: 1245 ------------ Loss: 2635.21 ------------ Accuracy: 90.2%\n",
            "Step: 1246 ------------ Loss: 2634.49 ------------ Accuracy: 90.2%\n",
            "Step: 1247 ------------ Loss: 2633.77 ------------ Accuracy: 90.2%\n",
            "Step: 1248 ------------ Loss: 2633.05 ------------ Accuracy: 90.2%\n",
            "Step: 1249 ------------ Loss: 2632.33 ------------ Accuracy: 90.2%\n",
            "Step: 1250 ------------ Loss: 2631.61 ------------ Accuracy: 90.2%\n",
            "Step: 1251 ------------ Loss: 2630.9 ------------ Accuracy: 90.2%\n",
            "Step: 1252 ------------ Loss: 2630.18 ------------ Accuracy: 90.2%\n",
            "Step: 1253 ------------ Loss: 2629.47 ------------ Accuracy: 90.2%\n",
            "Step: 1254 ------------ Loss: 2628.75 ------------ Accuracy: 90.2%\n",
            "Step: 1255 ------------ Loss: 2628.04 ------------ Accuracy: 90.2%\n",
            "Step: 1256 ------------ Loss: 2627.33 ------------ Accuracy: 90.2%\n",
            "Step: 1257 ------------ Loss: 2626.61 ------------ Accuracy: 90.2%\n",
            "Step: 1258 ------------ Loss: 2625.9 ------------ Accuracy: 90.2%\n",
            "Step: 1259 ------------ Loss: 2625.19 ------------ Accuracy: 90.2%\n",
            "Step: 1260 ------------ Loss: 2624.48 ------------ Accuracy: 90.2%\n",
            "Step: 1261 ------------ Loss: 2623.78 ------------ Accuracy: 90.2%\n",
            "Step: 1262 ------------ Loss: 2623.07 ------------ Accuracy: 90.2%\n",
            "Step: 1263 ------------ Loss: 2622.36 ------------ Accuracy: 90.2%\n",
            "Step: 1264 ------------ Loss: 2621.66 ------------ Accuracy: 90.2%\n",
            "Step: 1265 ------------ Loss: 2620.95 ------------ Accuracy: 90.2%\n",
            "Step: 1266 ------------ Loss: 2620.25 ------------ Accuracy: 90.2%\n",
            "Step: 1267 ------------ Loss: 2619.55 ------------ Accuracy: 90.2%\n",
            "Step: 1268 ------------ Loss: 2618.85 ------------ Accuracy: 90.2%\n",
            "Step: 1269 ------------ Loss: 2618.14 ------------ Accuracy: 90.2%\n",
            "Step: 1270 ------------ Loss: 2617.44 ------------ Accuracy: 90.2%\n",
            "Step: 1271 ------------ Loss: 2616.75 ------------ Accuracy: 90.2%\n",
            "Step: 1272 ------------ Loss: 2616.05 ------------ Accuracy: 90.2%\n",
            "Step: 1273 ------------ Loss: 2615.35 ------------ Accuracy: 90.2%\n",
            "Step: 1274 ------------ Loss: 2614.65 ------------ Accuracy: 90.2%\n",
            "Step: 1275 ------------ Loss: 2613.96 ------------ Accuracy: 90.2%\n",
            "Step: 1276 ------------ Loss: 2613.26 ------------ Accuracy: 90.2%\n",
            "Step: 1277 ------------ Loss: 2612.57 ------------ Accuracy: 90.2%\n",
            "Step: 1278 ------------ Loss: 2611.87 ------------ Accuracy: 90.2%\n",
            "Step: 1279 ------------ Loss: 2611.18 ------------ Accuracy: 90.2%\n",
            "Step: 1280 ------------ Loss: 2610.49 ------------ Accuracy: 90.2%\n",
            "Step: 1281 ------------ Loss: 2609.8 ------------ Accuracy: 90.2%\n",
            "Step: 1282 ------------ Loss: 2609.11 ------------ Accuracy: 90.2%\n",
            "Step: 1283 ------------ Loss: 2608.42 ------------ Accuracy: 90.2%\n",
            "Step: 1284 ------------ Loss: 2607.73 ------------ Accuracy: 90.2%\n",
            "Step: 1285 ------------ Loss: 2607.05 ------------ Accuracy: 90.2%\n",
            "Step: 1286 ------------ Loss: 2606.36 ------------ Accuracy: 90.2%\n",
            "Step: 1287 ------------ Loss: 2605.67 ------------ Accuracy: 90.2%\n",
            "Step: 1288 ------------ Loss: 2604.99 ------------ Accuracy: 90.3%\n",
            "Step: 1289 ------------ Loss: 2604.31 ------------ Accuracy: 90.3%\n",
            "Step: 1290 ------------ Loss: 2603.62 ------------ Accuracy: 90.3%\n",
            "Step: 1291 ------------ Loss: 2602.94 ------------ Accuracy: 90.3%\n",
            "Step: 1292 ------------ Loss: 2602.26 ------------ Accuracy: 90.3%\n",
            "Step: 1293 ------------ Loss: 2601.58 ------------ Accuracy: 90.3%\n",
            "Step: 1294 ------------ Loss: 2600.9 ------------ Accuracy: 90.3%\n",
            "Step: 1295 ------------ Loss: 2600.22 ------------ Accuracy: 90.3%\n",
            "Step: 1296 ------------ Loss: 2599.54 ------------ Accuracy: 90.3%\n",
            "Step: 1297 ------------ Loss: 2598.86 ------------ Accuracy: 90.3%\n",
            "Step: 1298 ------------ Loss: 2598.19 ------------ Accuracy: 90.3%\n",
            "Step: 1299 ------------ Loss: 2597.51 ------------ Accuracy: 90.3%\n",
            "Step: 1300 ------------ Loss: 2596.84 ------------ Accuracy: 90.3%\n",
            "Step: 1301 ------------ Loss: 2596.16 ------------ Accuracy: 90.3%\n",
            "Step: 1302 ------------ Loss: 2595.49 ------------ Accuracy: 90.3%\n",
            "Step: 1303 ------------ Loss: 2594.82 ------------ Accuracy: 90.3%\n",
            "Step: 1304 ------------ Loss: 2594.15 ------------ Accuracy: 90.3%\n",
            "Step: 1305 ------------ Loss: 2593.48 ------------ Accuracy: 90.3%\n",
            "Step: 1306 ------------ Loss: 2592.81 ------------ Accuracy: 90.3%\n",
            "Step: 1307 ------------ Loss: 2592.14 ------------ Accuracy: 90.3%\n",
            "Step: 1308 ------------ Loss: 2591.47 ------------ Accuracy: 90.3%\n",
            "Step: 1309 ------------ Loss: 2590.8 ------------ Accuracy: 90.3%\n",
            "Step: 1310 ------------ Loss: 2590.13 ------------ Accuracy: 90.3%\n",
            "Step: 1311 ------------ Loss: 2589.47 ------------ Accuracy: 90.3%\n",
            "Step: 1312 ------------ Loss: 2588.8 ------------ Accuracy: 90.3%\n",
            "Step: 1313 ------------ Loss: 2588.14 ------------ Accuracy: 90.3%\n",
            "Step: 1314 ------------ Loss: 2587.48 ------------ Accuracy: 90.3%\n",
            "Step: 1315 ------------ Loss: 2586.81 ------------ Accuracy: 90.3%\n",
            "Step: 1316 ------------ Loss: 2586.15 ------------ Accuracy: 90.3%\n",
            "Step: 1317 ------------ Loss: 2585.49 ------------ Accuracy: 90.3%\n",
            "Step: 1318 ------------ Loss: 2584.83 ------------ Accuracy: 90.3%\n",
            "Step: 1319 ------------ Loss: 2584.17 ------------ Accuracy: 90.3%\n",
            "Step: 1320 ------------ Loss: 2583.51 ------------ Accuracy: 90.3%\n",
            "Step: 1321 ------------ Loss: 2582.85 ------------ Accuracy: 90.3%\n",
            "Step: 1322 ------------ Loss: 2582.2 ------------ Accuracy: 90.3%\n",
            "Step: 1323 ------------ Loss: 2581.54 ------------ Accuracy: 90.3%\n",
            "Step: 1324 ------------ Loss: 2580.88 ------------ Accuracy: 90.3%\n",
            "Step: 1325 ------------ Loss: 2580.23 ------------ Accuracy: 90.3%\n",
            "Step: 1326 ------------ Loss: 2579.58 ------------ Accuracy: 90.3%\n",
            "Step: 1327 ------------ Loss: 2578.92 ------------ Accuracy: 90.3%\n",
            "Step: 1328 ------------ Loss: 2578.27 ------------ Accuracy: 90.3%\n",
            "Step: 1329 ------------ Loss: 2577.62 ------------ Accuracy: 90.3%\n",
            "Step: 1330 ------------ Loss: 2576.97 ------------ Accuracy: 90.3%\n",
            "Step: 1331 ------------ Loss: 2576.32 ------------ Accuracy: 90.3%\n",
            "Step: 1332 ------------ Loss: 2575.67 ------------ Accuracy: 90.3%\n",
            "Step: 1333 ------------ Loss: 2575.02 ------------ Accuracy: 90.3%\n",
            "Step: 1334 ------------ Loss: 2574.37 ------------ Accuracy: 90.3%\n",
            "Step: 1335 ------------ Loss: 2573.72 ------------ Accuracy: 90.3%\n",
            "Step: 1336 ------------ Loss: 2573.08 ------------ Accuracy: 90.3%\n",
            "Step: 1337 ------------ Loss: 2572.43 ------------ Accuracy: 90.3%\n",
            "Step: 1338 ------------ Loss: 2571.79 ------------ Accuracy: 90.3%\n",
            "Step: 1339 ------------ Loss: 2571.14 ------------ Accuracy: 90.3%\n",
            "Step: 1340 ------------ Loss: 2570.5 ------------ Accuracy: 90.3%\n",
            "Step: 1341 ------------ Loss: 2569.86 ------------ Accuracy: 90.3%\n",
            "Step: 1342 ------------ Loss: 2569.22 ------------ Accuracy: 90.3%\n",
            "Step: 1343 ------------ Loss: 2568.58 ------------ Accuracy: 90.3%\n",
            "Step: 1344 ------------ Loss: 2567.94 ------------ Accuracy: 90.3%\n",
            "Step: 1345 ------------ Loss: 2567.3 ------------ Accuracy: 90.3%\n",
            "Step: 1346 ------------ Loss: 2566.66 ------------ Accuracy: 90.3%\n",
            "Step: 1347 ------------ Loss: 2566.02 ------------ Accuracy: 90.3%\n",
            "Step: 1348 ------------ Loss: 2565.38 ------------ Accuracy: 90.3%\n",
            "Step: 1349 ------------ Loss: 2564.75 ------------ Accuracy: 90.3%\n",
            "Step: 1350 ------------ Loss: 2564.11 ------------ Accuracy: 90.3%\n",
            "Step: 1351 ------------ Loss: 2563.48 ------------ Accuracy: 90.3%\n",
            "Step: 1352 ------------ Loss: 2562.84 ------------ Accuracy: 90.3%\n",
            "Step: 1353 ------------ Loss: 2562.21 ------------ Accuracy: 90.3%\n",
            "Step: 1354 ------------ Loss: 2561.57 ------------ Accuracy: 90.3%\n",
            "Step: 1355 ------------ Loss: 2560.94 ------------ Accuracy: 90.3%\n",
            "Step: 1356 ------------ Loss: 2560.31 ------------ Accuracy: 90.3%\n",
            "Step: 1357 ------------ Loss: 2559.68 ------------ Accuracy: 90.3%\n",
            "Step: 1358 ------------ Loss: 2559.05 ------------ Accuracy: 90.3%\n",
            "Step: 1359 ------------ Loss: 2558.42 ------------ Accuracy: 90.3%\n",
            "Step: 1360 ------------ Loss: 2557.79 ------------ Accuracy: 90.3%\n",
            "Step: 1361 ------------ Loss: 2557.17 ------------ Accuracy: 90.3%\n",
            "Step: 1362 ------------ Loss: 2556.54 ------------ Accuracy: 90.3%\n",
            "Step: 1363 ------------ Loss: 2555.91 ------------ Accuracy: 90.3%\n",
            "Step: 1364 ------------ Loss: 2555.29 ------------ Accuracy: 90.3%\n",
            "Step: 1365 ------------ Loss: 2554.66 ------------ Accuracy: 90.3%\n",
            "Step: 1366 ------------ Loss: 2554.04 ------------ Accuracy: 90.3%\n",
            "Step: 1367 ------------ Loss: 2553.42 ------------ Accuracy: 90.3%\n",
            "Step: 1368 ------------ Loss: 2552.79 ------------ Accuracy: 90.3%\n",
            "Step: 1369 ------------ Loss: 2552.17 ------------ Accuracy: 90.3%\n",
            "Step: 1370 ------------ Loss: 2551.55 ------------ Accuracy: 90.3%\n",
            "Step: 1371 ------------ Loss: 2550.93 ------------ Accuracy: 90.3%\n",
            "Step: 1372 ------------ Loss: 2550.31 ------------ Accuracy: 90.3%\n",
            "Step: 1373 ------------ Loss: 2549.69 ------------ Accuracy: 90.3%\n",
            "Step: 1374 ------------ Loss: 2549.07 ------------ Accuracy: 90.3%\n",
            "Step: 1375 ------------ Loss: 2548.46 ------------ Accuracy: 90.3%\n",
            "Step: 1376 ------------ Loss: 2547.84 ------------ Accuracy: 90.3%\n",
            "Step: 1377 ------------ Loss: 2547.22 ------------ Accuracy: 90.3%\n",
            "Step: 1378 ------------ Loss: 2546.61 ------------ Accuracy: 90.3%\n",
            "Step: 1379 ------------ Loss: 2545.99 ------------ Accuracy: 90.3%\n",
            "Step: 1380 ------------ Loss: 2545.38 ------------ Accuracy: 90.3%\n",
            "Step: 1381 ------------ Loss: 2544.77 ------------ Accuracy: 90.3%\n",
            "Step: 1382 ------------ Loss: 2544.15 ------------ Accuracy: 90.3%\n",
            "Step: 1383 ------------ Loss: 2543.54 ------------ Accuracy: 90.3%\n",
            "Step: 1384 ------------ Loss: 2542.93 ------------ Accuracy: 90.3%\n",
            "Step: 1385 ------------ Loss: 2542.32 ------------ Accuracy: 90.3%\n",
            "Step: 1386 ------------ Loss: 2541.71 ------------ Accuracy: 90.3%\n",
            "Step: 1387 ------------ Loss: 2541.1 ------------ Accuracy: 90.3%\n",
            "Step: 1388 ------------ Loss: 2540.49 ------------ Accuracy: 90.3%\n",
            "Step: 1389 ------------ Loss: 2539.89 ------------ Accuracy: 90.3%\n",
            "Step: 1390 ------------ Loss: 2539.28 ------------ Accuracy: 90.3%\n",
            "Step: 1391 ------------ Loss: 2538.67 ------------ Accuracy: 90.3%\n",
            "Step: 1392 ------------ Loss: 2538.07 ------------ Accuracy: 90.3%\n",
            "Step: 1393 ------------ Loss: 2537.46 ------------ Accuracy: 90.3%\n",
            "Step: 1394 ------------ Loss: 2536.86 ------------ Accuracy: 90.3%\n",
            "Step: 1395 ------------ Loss: 2536.26 ------------ Accuracy: 90.3%\n",
            "Step: 1396 ------------ Loss: 2535.65 ------------ Accuracy: 90.3%\n",
            "Step: 1397 ------------ Loss: 2535.05 ------------ Accuracy: 90.3%\n",
            "Step: 1398 ------------ Loss: 2534.45 ------------ Accuracy: 90.3%\n",
            "Step: 1399 ------------ Loss: 2533.85 ------------ Accuracy: 90.3%\n",
            "Step: 1400 ------------ Loss: 2533.25 ------------ Accuracy: 90.3%\n",
            "Step: 1401 ------------ Loss: 2532.65 ------------ Accuracy: 90.3%\n",
            "Step: 1402 ------------ Loss: 2532.05 ------------ Accuracy: 90.3%\n",
            "Step: 1403 ------------ Loss: 2531.45 ------------ Accuracy: 90.3%\n",
            "Step: 1404 ------------ Loss: 2530.86 ------------ Accuracy: 90.3%\n",
            "Step: 1405 ------------ Loss: 2530.26 ------------ Accuracy: 90.3%\n",
            "Step: 1406 ------------ Loss: 2529.66 ------------ Accuracy: 90.3%\n",
            "Step: 1407 ------------ Loss: 2529.07 ------------ Accuracy: 90.3%\n",
            "Step: 1408 ------------ Loss: 2528.47 ------------ Accuracy: 90.3%\n",
            "Step: 1409 ------------ Loss: 2527.88 ------------ Accuracy: 90.3%\n",
            "Step: 1410 ------------ Loss: 2527.29 ------------ Accuracy: 90.3%\n",
            "Step: 1411 ------------ Loss: 2526.69 ------------ Accuracy: 90.3%\n",
            "Step: 1412 ------------ Loss: 2526.1 ------------ Accuracy: 90.3%\n",
            "Step: 1413 ------------ Loss: 2525.51 ------------ Accuracy: 90.3%\n",
            "Step: 1414 ------------ Loss: 2524.92 ------------ Accuracy: 90.3%\n",
            "Step: 1415 ------------ Loss: 2524.33 ------------ Accuracy: 90.3%\n",
            "Step: 1416 ------------ Loss: 2523.74 ------------ Accuracy: 90.3%\n",
            "Step: 1417 ------------ Loss: 2523.15 ------------ Accuracy: 90.3%\n",
            "Step: 1418 ------------ Loss: 2522.56 ------------ Accuracy: 90.3%\n",
            "Step: 1419 ------------ Loss: 2521.98 ------------ Accuracy: 90.3%\n",
            "Step: 1420 ------------ Loss: 2521.39 ------------ Accuracy: 90.3%\n",
            "Step: 1421 ------------ Loss: 2520.8 ------------ Accuracy: 90.3%\n",
            "Step: 1422 ------------ Loss: 2520.22 ------------ Accuracy: 90.3%\n",
            "Step: 1423 ------------ Loss: 2519.63 ------------ Accuracy: 90.3%\n",
            "Step: 1424 ------------ Loss: 2519.05 ------------ Accuracy: 90.3%\n",
            "Step: 1425 ------------ Loss: 2518.47 ------------ Accuracy: 90.3%\n",
            "Step: 1426 ------------ Loss: 2517.88 ------------ Accuracy: 90.3%\n",
            "Step: 1427 ------------ Loss: 2517.3 ------------ Accuracy: 90.2%\n",
            "Step: 1428 ------------ Loss: 2516.72 ------------ Accuracy: 90.2%\n",
            "Step: 1429 ------------ Loss: 2516.14 ------------ Accuracy: 90.2%\n",
            "Step: 1430 ------------ Loss: 2515.56 ------------ Accuracy: 90.2%\n",
            "Step: 1431 ------------ Loss: 2514.98 ------------ Accuracy: 90.2%\n",
            "Step: 1432 ------------ Loss: 2514.4 ------------ Accuracy: 90.2%\n",
            "Step: 1433 ------------ Loss: 2513.82 ------------ Accuracy: 90.2%\n",
            "Step: 1434 ------------ Loss: 2513.25 ------------ Accuracy: 90.2%\n",
            "Step: 1435 ------------ Loss: 2512.67 ------------ Accuracy: 90.2%\n",
            "Step: 1436 ------------ Loss: 2512.09 ------------ Accuracy: 90.2%\n",
            "Step: 1437 ------------ Loss: 2511.52 ------------ Accuracy: 90.2%\n",
            "Step: 1438 ------------ Loss: 2510.94 ------------ Accuracy: 90.2%\n",
            "Step: 1439 ------------ Loss: 2510.37 ------------ Accuracy: 90.2%\n",
            "Step: 1440 ------------ Loss: 2509.79 ------------ Accuracy: 90.2%\n",
            "Step: 1441 ------------ Loss: 2509.22 ------------ Accuracy: 90.2%\n",
            "Step: 1442 ------------ Loss: 2508.65 ------------ Accuracy: 90.2%\n",
            "Step: 1443 ------------ Loss: 2508.08 ------------ Accuracy: 90.2%\n",
            "Step: 1444 ------------ Loss: 2507.51 ------------ Accuracy: 90.2%\n",
            "Step: 1445 ------------ Loss: 2506.94 ------------ Accuracy: 90.2%\n",
            "Step: 1446 ------------ Loss: 2506.37 ------------ Accuracy: 90.2%\n",
            "Step: 1447 ------------ Loss: 2505.8 ------------ Accuracy: 90.2%\n",
            "Step: 1448 ------------ Loss: 2505.23 ------------ Accuracy: 90.2%\n",
            "Step: 1449 ------------ Loss: 2504.66 ------------ Accuracy: 90.2%\n",
            "Step: 1450 ------------ Loss: 2504.09 ------------ Accuracy: 90.3%\n",
            "Step: 1451 ------------ Loss: 2503.53 ------------ Accuracy: 90.3%\n",
            "Step: 1452 ------------ Loss: 2502.96 ------------ Accuracy: 90.3%\n",
            "Step: 1453 ------------ Loss: 2502.39 ------------ Accuracy: 90.3%\n",
            "Step: 1454 ------------ Loss: 2501.83 ------------ Accuracy: 90.3%\n",
            "Step: 1455 ------------ Loss: 2501.27 ------------ Accuracy: 90.3%\n",
            "Step: 1456 ------------ Loss: 2500.7 ------------ Accuracy: 90.3%\n",
            "Step: 1457 ------------ Loss: 2500.14 ------------ Accuracy: 90.3%\n",
            "Step: 1458 ------------ Loss: 2499.58 ------------ Accuracy: 90.3%\n",
            "Step: 1459 ------------ Loss: 2499.01 ------------ Accuracy: 90.3%\n",
            "Step: 1460 ------------ Loss: 2498.45 ------------ Accuracy: 90.3%\n",
            "Step: 1461 ------------ Loss: 2497.89 ------------ Accuracy: 90.3%\n",
            "Step: 1462 ------------ Loss: 2497.33 ------------ Accuracy: 90.3%\n",
            "Step: 1463 ------------ Loss: 2496.77 ------------ Accuracy: 90.3%\n",
            "Step: 1464 ------------ Loss: 2496.21 ------------ Accuracy: 90.3%\n",
            "Step: 1465 ------------ Loss: 2495.66 ------------ Accuracy: 90.3%\n",
            "Step: 1466 ------------ Loss: 2495.1 ------------ Accuracy: 90.3%\n",
            "Step: 1467 ------------ Loss: 2494.54 ------------ Accuracy: 90.3%\n",
            "Step: 1468 ------------ Loss: 2493.99 ------------ Accuracy: 90.3%\n",
            "Step: 1469 ------------ Loss: 2493.43 ------------ Accuracy: 90.3%\n",
            "Step: 1470 ------------ Loss: 2492.88 ------------ Accuracy: 90.3%\n",
            "Step: 1471 ------------ Loss: 2492.32 ------------ Accuracy: 90.3%\n",
            "Step: 1472 ------------ Loss: 2491.77 ------------ Accuracy: 90.3%\n",
            "Step: 1473 ------------ Loss: 2491.21 ------------ Accuracy: 90.3%\n",
            "Step: 1474 ------------ Loss: 2490.66 ------------ Accuracy: 90.3%\n",
            "Step: 1475 ------------ Loss: 2490.11 ------------ Accuracy: 90.3%\n",
            "Step: 1476 ------------ Loss: 2489.56 ------------ Accuracy: 90.3%\n",
            "Step: 1477 ------------ Loss: 2489.01 ------------ Accuracy: 90.3%\n",
            "Step: 1478 ------------ Loss: 2488.46 ------------ Accuracy: 90.3%\n",
            "Step: 1479 ------------ Loss: 2487.91 ------------ Accuracy: 90.3%\n",
            "Step: 1480 ------------ Loss: 2487.36 ------------ Accuracy: 90.3%\n",
            "Step: 1481 ------------ Loss: 2486.81 ------------ Accuracy: 90.3%\n",
            "Step: 1482 ------------ Loss: 2486.26 ------------ Accuracy: 90.3%\n",
            "Step: 1483 ------------ Loss: 2485.71 ------------ Accuracy: 90.3%\n",
            "Step: 1484 ------------ Loss: 2485.17 ------------ Accuracy: 90.3%\n",
            "Step: 1485 ------------ Loss: 2484.62 ------------ Accuracy: 90.3%\n",
            "Step: 1486 ------------ Loss: 2484.08 ------------ Accuracy: 90.3%\n",
            "Step: 1487 ------------ Loss: 2483.53 ------------ Accuracy: 90.3%\n",
            "Step: 1488 ------------ Loss: 2482.99 ------------ Accuracy: 90.3%\n",
            "Step: 1489 ------------ Loss: 2482.44 ------------ Accuracy: 90.3%\n",
            "Step: 1490 ------------ Loss: 2481.9 ------------ Accuracy: 90.3%\n",
            "Step: 1491 ------------ Loss: 2481.36 ------------ Accuracy: 90.3%\n",
            "Step: 1492 ------------ Loss: 2480.81 ------------ Accuracy: 90.3%\n",
            "Step: 1493 ------------ Loss: 2480.27 ------------ Accuracy: 90.3%\n",
            "Step: 1494 ------------ Loss: 2479.73 ------------ Accuracy: 90.3%\n",
            "Step: 1495 ------------ Loss: 2479.19 ------------ Accuracy: 90.3%\n",
            "Step: 1496 ------------ Loss: 2478.65 ------------ Accuracy: 90.3%\n",
            "Step: 1497 ------------ Loss: 2478.11 ------------ Accuracy: 90.3%\n",
            "Step: 1498 ------------ Loss: 2477.57 ------------ Accuracy: 90.3%\n",
            "Step: 1499 ------------ Loss: 2477.04 ------------ Accuracy: 90.3%\n",
            "Step: 1500 ------------ Loss: 2476.5 ------------ Accuracy: 90.3%\n",
            "Step: 1501 ------------ Loss: 2475.96 ------------ Accuracy: 90.3%\n",
            "Step: 1502 ------------ Loss: 2475.43 ------------ Accuracy: 90.3%\n",
            "Step: 1503 ------------ Loss: 2474.89 ------------ Accuracy: 90.3%\n",
            "Step: 1504 ------------ Loss: 2474.35 ------------ Accuracy: 90.3%\n",
            "Step: 1505 ------------ Loss: 2473.82 ------------ Accuracy: 90.3%\n",
            "Step: 1506 ------------ Loss: 2473.29 ------------ Accuracy: 90.3%\n",
            "Step: 1507 ------------ Loss: 2472.75 ------------ Accuracy: 90.3%\n",
            "Step: 1508 ------------ Loss: 2472.22 ------------ Accuracy: 90.3%\n",
            "Step: 1509 ------------ Loss: 2471.69 ------------ Accuracy: 90.3%\n",
            "Step: 1510 ------------ Loss: 2471.16 ------------ Accuracy: 90.3%\n",
            "Step: 1511 ------------ Loss: 2470.62 ------------ Accuracy: 90.3%\n",
            "Step: 1512 ------------ Loss: 2470.09 ------------ Accuracy: 90.3%\n",
            "Step: 1513 ------------ Loss: 2469.56 ------------ Accuracy: 90.3%\n",
            "Step: 1514 ------------ Loss: 2469.03 ------------ Accuracy: 90.3%\n",
            "Step: 1515 ------------ Loss: 2468.51 ------------ Accuracy: 90.3%\n",
            "Step: 1516 ------------ Loss: 2467.98 ------------ Accuracy: 90.3%\n",
            "Step: 1517 ------------ Loss: 2467.45 ------------ Accuracy: 90.3%\n",
            "Step: 1518 ------------ Loss: 2466.92 ------------ Accuracy: 90.3%\n",
            "Step: 1519 ------------ Loss: 2466.4 ------------ Accuracy: 90.3%\n",
            "Step: 1520 ------------ Loss: 2465.87 ------------ Accuracy: 90.3%\n",
            "Step: 1521 ------------ Loss: 2465.34 ------------ Accuracy: 90.3%\n",
            "Step: 1522 ------------ Loss: 2464.82 ------------ Accuracy: 90.3%\n",
            "Step: 1523 ------------ Loss: 2464.29 ------------ Accuracy: 90.3%\n",
            "Step: 1524 ------------ Loss: 2463.77 ------------ Accuracy: 90.3%\n",
            "Step: 1525 ------------ Loss: 2463.25 ------------ Accuracy: 90.3%\n",
            "Step: 1526 ------------ Loss: 2462.72 ------------ Accuracy: 90.3%\n",
            "Step: 1527 ------------ Loss: 2462.2 ------------ Accuracy: 90.3%\n",
            "Step: 1528 ------------ Loss: 2461.68 ------------ Accuracy: 90.3%\n",
            "Step: 1529 ------------ Loss: 2461.16 ------------ Accuracy: 90.3%\n",
            "Step: 1530 ------------ Loss: 2460.64 ------------ Accuracy: 90.3%\n",
            "Step: 1531 ------------ Loss: 2460.12 ------------ Accuracy: 90.3%\n",
            "Step: 1532 ------------ Loss: 2459.6 ------------ Accuracy: 90.3%\n",
            "Step: 1533 ------------ Loss: 2459.08 ------------ Accuracy: 90.3%\n",
            "Step: 1534 ------------ Loss: 2458.56 ------------ Accuracy: 90.3%\n",
            "Step: 1535 ------------ Loss: 2458.04 ------------ Accuracy: 90.3%\n",
            "Step: 1536 ------------ Loss: 2457.53 ------------ Accuracy: 90.3%\n",
            "Step: 1537 ------------ Loss: 2457.01 ------------ Accuracy: 90.3%\n",
            "Step: 1538 ------------ Loss: 2456.49 ------------ Accuracy: 90.3%\n",
            "Step: 1539 ------------ Loss: 2455.98 ------------ Accuracy: 90.3%\n",
            "Step: 1540 ------------ Loss: 2455.46 ------------ Accuracy: 90.3%\n",
            "Step: 1541 ------------ Loss: 2454.95 ------------ Accuracy: 90.3%\n",
            "Step: 1542 ------------ Loss: 2454.43 ------------ Accuracy: 90.3%\n",
            "Step: 1543 ------------ Loss: 2453.92 ------------ Accuracy: 90.3%\n",
            "Step: 1544 ------------ Loss: 2453.41 ------------ Accuracy: 90.3%\n",
            "Step: 1545 ------------ Loss: 2452.89 ------------ Accuracy: 90.3%\n",
            "Step: 1546 ------------ Loss: 2452.38 ------------ Accuracy: 90.3%\n",
            "Step: 1547 ------------ Loss: 2451.87 ------------ Accuracy: 90.3%\n",
            "Step: 1548 ------------ Loss: 2451.36 ------------ Accuracy: 90.3%\n",
            "Step: 1549 ------------ Loss: 2450.85 ------------ Accuracy: 90.3%\n",
            "Step: 1550 ------------ Loss: 2450.34 ------------ Accuracy: 90.3%\n",
            "Step: 1551 ------------ Loss: 2449.83 ------------ Accuracy: 90.3%\n",
            "Step: 1552 ------------ Loss: 2449.32 ------------ Accuracy: 90.3%\n",
            "Step: 1553 ------------ Loss: 2448.81 ------------ Accuracy: 90.3%\n",
            "Step: 1554 ------------ Loss: 2448.3 ------------ Accuracy: 90.3%\n",
            "Step: 1555 ------------ Loss: 2447.8 ------------ Accuracy: 90.3%\n",
            "Step: 1556 ------------ Loss: 2447.29 ------------ Accuracy: 90.3%\n",
            "Step: 1557 ------------ Loss: 2446.78 ------------ Accuracy: 90.3%\n",
            "Step: 1558 ------------ Loss: 2446.28 ------------ Accuracy: 90.3%\n",
            "Step: 1559 ------------ Loss: 2445.77 ------------ Accuracy: 90.3%\n",
            "Step: 1560 ------------ Loss: 2445.27 ------------ Accuracy: 90.3%\n",
            "Step: 1561 ------------ Loss: 2444.77 ------------ Accuracy: 90.3%\n",
            "Step: 1562 ------------ Loss: 2444.26 ------------ Accuracy: 90.3%\n",
            "Step: 1563 ------------ Loss: 2443.76 ------------ Accuracy: 90.3%\n",
            "Step: 1564 ------------ Loss: 2443.26 ------------ Accuracy: 90.3%\n",
            "Step: 1565 ------------ Loss: 2442.75 ------------ Accuracy: 90.3%\n",
            "Step: 1566 ------------ Loss: 2442.25 ------------ Accuracy: 90.3%\n",
            "Step: 1567 ------------ Loss: 2441.75 ------------ Accuracy: 90.3%\n",
            "Step: 1568 ------------ Loss: 2441.25 ------------ Accuracy: 90.3%\n",
            "Step: 1569 ------------ Loss: 2440.75 ------------ Accuracy: 90.3%\n",
            "Step: 1570 ------------ Loss: 2440.25 ------------ Accuracy: 90.3%\n",
            "Step: 1571 ------------ Loss: 2439.75 ------------ Accuracy: 90.3%\n",
            "Step: 1572 ------------ Loss: 2439.25 ------------ Accuracy: 90.3%\n",
            "Step: 1573 ------------ Loss: 2438.76 ------------ Accuracy: 90.3%\n",
            "Step: 1574 ------------ Loss: 2438.26 ------------ Accuracy: 90.3%\n",
            "Step: 1575 ------------ Loss: 2437.76 ------------ Accuracy: 90.3%\n",
            "Step: 1576 ------------ Loss: 2437.27 ------------ Accuracy: 90.3%\n",
            "Step: 1577 ------------ Loss: 2436.77 ------------ Accuracy: 90.3%\n",
            "Step: 1578 ------------ Loss: 2436.27 ------------ Accuracy: 90.3%\n",
            "Step: 1579 ------------ Loss: 2435.78 ------------ Accuracy: 90.3%\n",
            "Step: 1580 ------------ Loss: 2435.28 ------------ Accuracy: 90.3%\n",
            "Step: 1581 ------------ Loss: 2434.79 ------------ Accuracy: 90.3%\n",
            "Step: 1582 ------------ Loss: 2434.3 ------------ Accuracy: 90.3%\n",
            "Step: 1583 ------------ Loss: 2433.8 ------------ Accuracy: 90.3%\n",
            "Step: 1584 ------------ Loss: 2433.31 ------------ Accuracy: 90.3%\n",
            "Step: 1585 ------------ Loss: 2432.82 ------------ Accuracy: 90.3%\n",
            "Step: 1586 ------------ Loss: 2432.33 ------------ Accuracy: 90.3%\n",
            "Step: 1587 ------------ Loss: 2431.84 ------------ Accuracy: 90.3%\n",
            "Step: 1588 ------------ Loss: 2431.35 ------------ Accuracy: 90.3%\n",
            "Step: 1589 ------------ Loss: 2430.86 ------------ Accuracy: 90.3%\n",
            "Step: 1590 ------------ Loss: 2430.37 ------------ Accuracy: 90.3%\n",
            "Step: 1591 ------------ Loss: 2429.88 ------------ Accuracy: 90.3%\n",
            "Step: 1592 ------------ Loss: 2429.39 ------------ Accuracy: 90.3%\n",
            "Step: 1593 ------------ Loss: 2428.9 ------------ Accuracy: 90.3%\n",
            "Step: 1594 ------------ Loss: 2428.42 ------------ Accuracy: 90.3%\n",
            "Step: 1595 ------------ Loss: 2427.93 ------------ Accuracy: 90.3%\n",
            "Step: 1596 ------------ Loss: 2427.44 ------------ Accuracy: 90.3%\n",
            "Step: 1597 ------------ Loss: 2426.96 ------------ Accuracy: 90.3%\n",
            "Step: 1598 ------------ Loss: 2426.47 ------------ Accuracy: 90.3%\n",
            "Step: 1599 ------------ Loss: 2425.99 ------------ Accuracy: 90.3%\n",
            "Step: 1600 ------------ Loss: 2425.5 ------------ Accuracy: 90.3%\n",
            "Step: 1601 ------------ Loss: 2425.02 ------------ Accuracy: 90.3%\n",
            "Step: 1602 ------------ Loss: 2424.53 ------------ Accuracy: 90.3%\n",
            "Step: 1603 ------------ Loss: 2424.05 ------------ Accuracy: 90.3%\n",
            "Step: 1604 ------------ Loss: 2423.57 ------------ Accuracy: 90.3%\n",
            "Step: 1605 ------------ Loss: 2423.09 ------------ Accuracy: 90.3%\n",
            "Step: 1606 ------------ Loss: 2422.6 ------------ Accuracy: 90.3%\n",
            "Step: 1607 ------------ Loss: 2422.12 ------------ Accuracy: 90.3%\n",
            "Step: 1608 ------------ Loss: 2421.64 ------------ Accuracy: 90.3%\n",
            "Step: 1609 ------------ Loss: 2421.16 ------------ Accuracy: 90.3%\n",
            "Step: 1610 ------------ Loss: 2420.68 ------------ Accuracy: 90.3%\n",
            "Step: 1611 ------------ Loss: 2420.2 ------------ Accuracy: 90.3%\n",
            "Step: 1612 ------------ Loss: 2419.73 ------------ Accuracy: 90.3%\n",
            "Step: 1613 ------------ Loss: 2419.25 ------------ Accuracy: 90.3%\n",
            "Step: 1614 ------------ Loss: 2418.77 ------------ Accuracy: 90.3%\n",
            "Step: 1615 ------------ Loss: 2418.29 ------------ Accuracy: 90.3%\n",
            "Step: 1616 ------------ Loss: 2417.82 ------------ Accuracy: 90.3%\n",
            "Step: 1617 ------------ Loss: 2417.34 ------------ Accuracy: 90.3%\n",
            "Step: 1618 ------------ Loss: 2416.86 ------------ Accuracy: 90.3%\n",
            "Step: 1619 ------------ Loss: 2416.39 ------------ Accuracy: 90.3%\n",
            "Step: 1620 ------------ Loss: 2415.91 ------------ Accuracy: 90.3%\n",
            "Step: 1621 ------------ Loss: 2415.44 ------------ Accuracy: 90.3%\n",
            "Step: 1622 ------------ Loss: 2414.96 ------------ Accuracy: 90.3%\n",
            "Step: 1623 ------------ Loss: 2414.49 ------------ Accuracy: 90.3%\n",
            "Step: 1624 ------------ Loss: 2414.02 ------------ Accuracy: 90.3%\n",
            "Step: 1625 ------------ Loss: 2413.55 ------------ Accuracy: 90.3%\n",
            "Step: 1626 ------------ Loss: 2413.07 ------------ Accuracy: 90.3%\n",
            "Step: 1627 ------------ Loss: 2412.6 ------------ Accuracy: 90.3%\n",
            "Step: 1628 ------------ Loss: 2412.13 ------------ Accuracy: 90.3%\n",
            "Step: 1629 ------------ Loss: 2411.66 ------------ Accuracy: 90.3%\n",
            "Step: 1630 ------------ Loss: 2411.19 ------------ Accuracy: 90.3%\n",
            "Step: 1631 ------------ Loss: 2410.72 ------------ Accuracy: 90.3%\n",
            "Step: 1632 ------------ Loss: 2410.25 ------------ Accuracy: 90.3%\n",
            "Step: 1633 ------------ Loss: 2409.78 ------------ Accuracy: 90.3%\n",
            "Step: 1634 ------------ Loss: 2409.31 ------------ Accuracy: 90.3%\n",
            "Step: 1635 ------------ Loss: 2408.85 ------------ Accuracy: 90.3%\n",
            "Step: 1636 ------------ Loss: 2408.38 ------------ Accuracy: 90.3%\n",
            "Step: 1637 ------------ Loss: 2407.91 ------------ Accuracy: 90.3%\n",
            "Step: 1638 ------------ Loss: 2407.45 ------------ Accuracy: 90.3%\n",
            "Step: 1639 ------------ Loss: 2406.98 ------------ Accuracy: 90.3%\n",
            "Step: 1640 ------------ Loss: 2406.51 ------------ Accuracy: 90.3%\n",
            "Step: 1641 ------------ Loss: 2406.05 ------------ Accuracy: 90.3%\n",
            "Step: 1642 ------------ Loss: 2405.58 ------------ Accuracy: 90.3%\n",
            "Step: 1643 ------------ Loss: 2405.12 ------------ Accuracy: 90.3%\n",
            "Step: 1644 ------------ Loss: 2404.66 ------------ Accuracy: 90.3%\n",
            "Step: 1645 ------------ Loss: 2404.19 ------------ Accuracy: 90.3%\n",
            "Step: 1646 ------------ Loss: 2403.73 ------------ Accuracy: 90.3%\n",
            "Step: 1647 ------------ Loss: 2403.27 ------------ Accuracy: 90.3%\n",
            "Step: 1648 ------------ Loss: 2402.81 ------------ Accuracy: 90.3%\n",
            "Step: 1649 ------------ Loss: 2402.34 ------------ Accuracy: 90.3%\n",
            "Step: 1650 ------------ Loss: 2401.88 ------------ Accuracy: 90.3%\n",
            "Step: 1651 ------------ Loss: 2401.42 ------------ Accuracy: 90.3%\n",
            "Step: 1652 ------------ Loss: 2400.96 ------------ Accuracy: 90.3%\n",
            "Step: 1653 ------------ Loss: 2400.5 ------------ Accuracy: 90.3%\n",
            "Step: 1654 ------------ Loss: 2400.04 ------------ Accuracy: 90.3%\n",
            "Step: 1655 ------------ Loss: 2399.59 ------------ Accuracy: 90.3%\n",
            "Step: 1656 ------------ Loss: 2399.13 ------------ Accuracy: 90.3%\n",
            "Step: 1657 ------------ Loss: 2398.67 ------------ Accuracy: 90.3%\n",
            "Step: 1658 ------------ Loss: 2398.21 ------------ Accuracy: 90.3%\n",
            "Step: 1659 ------------ Loss: 2397.75 ------------ Accuracy: 90.3%\n",
            "Step: 1660 ------------ Loss: 2397.3 ------------ Accuracy: 90.3%\n",
            "Step: 1661 ------------ Loss: 2396.84 ------------ Accuracy: 90.3%\n",
            "Step: 1662 ------------ Loss: 2396.39 ------------ Accuracy: 90.3%\n",
            "Step: 1663 ------------ Loss: 2395.93 ------------ Accuracy: 90.3%\n",
            "Step: 1664 ------------ Loss: 2395.48 ------------ Accuracy: 90.3%\n",
            "Step: 1665 ------------ Loss: 2395.02 ------------ Accuracy: 90.3%\n",
            "Step: 1666 ------------ Loss: 2394.57 ------------ Accuracy: 90.3%\n",
            "Step: 1667 ------------ Loss: 2394.11 ------------ Accuracy: 90.3%\n",
            "Step: 1668 ------------ Loss: 2393.66 ------------ Accuracy: 90.3%\n",
            "Step: 1669 ------------ Loss: 2393.21 ------------ Accuracy: 90.3%\n",
            "Step: 1670 ------------ Loss: 2392.76 ------------ Accuracy: 90.3%\n",
            "Step: 1671 ------------ Loss: 2392.31 ------------ Accuracy: 90.3%\n",
            "Step: 1672 ------------ Loss: 2391.85 ------------ Accuracy: 90.3%\n",
            "Step: 1673 ------------ Loss: 2391.4 ------------ Accuracy: 90.3%\n",
            "Step: 1674 ------------ Loss: 2390.95 ------------ Accuracy: 90.3%\n",
            "Step: 1675 ------------ Loss: 2390.5 ------------ Accuracy: 90.3%\n",
            "Step: 1676 ------------ Loss: 2390.05 ------------ Accuracy: 90.3%\n",
            "Step: 1677 ------------ Loss: 2389.6 ------------ Accuracy: 90.3%\n",
            "Step: 1678 ------------ Loss: 2389.16 ------------ Accuracy: 90.3%\n",
            "Step: 1679 ------------ Loss: 2388.71 ------------ Accuracy: 90.3%\n",
            "Step: 1680 ------------ Loss: 2388.26 ------------ Accuracy: 90.3%\n",
            "Step: 1681 ------------ Loss: 2387.81 ------------ Accuracy: 90.3%\n",
            "Step: 1682 ------------ Loss: 2387.37 ------------ Accuracy: 90.3%\n",
            "Step: 1683 ------------ Loss: 2386.92 ------------ Accuracy: 90.3%\n",
            "Step: 1684 ------------ Loss: 2386.47 ------------ Accuracy: 90.3%\n",
            "Step: 1685 ------------ Loss: 2386.03 ------------ Accuracy: 90.3%\n",
            "Step: 1686 ------------ Loss: 2385.58 ------------ Accuracy: 90.3%\n",
            "Step: 1687 ------------ Loss: 2385.14 ------------ Accuracy: 90.3%\n",
            "Step: 1688 ------------ Loss: 2384.69 ------------ Accuracy: 90.3%\n",
            "Step: 1689 ------------ Loss: 2384.25 ------------ Accuracy: 90.3%\n",
            "Step: 1690 ------------ Loss: 2383.81 ------------ Accuracy: 90.3%\n",
            "Step: 1691 ------------ Loss: 2383.36 ------------ Accuracy: 90.3%\n",
            "Step: 1692 ------------ Loss: 2382.92 ------------ Accuracy: 90.3%\n",
            "Step: 1693 ------------ Loss: 2382.48 ------------ Accuracy: 90.3%\n",
            "Step: 1694 ------------ Loss: 2382.04 ------------ Accuracy: 90.3%\n",
            "Step: 1695 ------------ Loss: 2381.59 ------------ Accuracy: 90.3%\n",
            "Step: 1696 ------------ Loss: 2381.15 ------------ Accuracy: 90.3%\n",
            "Step: 1697 ------------ Loss: 2380.71 ------------ Accuracy: 90.3%\n",
            "Step: 1698 ------------ Loss: 2380.27 ------------ Accuracy: 90.3%\n",
            "Step: 1699 ------------ Loss: 2379.83 ------------ Accuracy: 90.3%\n",
            "Step: 1700 ------------ Loss: 2379.39 ------------ Accuracy: 90.3%\n",
            "Step: 1701 ------------ Loss: 2378.96 ------------ Accuracy: 90.3%\n",
            "Step: 1702 ------------ Loss: 2378.52 ------------ Accuracy: 90.3%\n",
            "Step: 1703 ------------ Loss: 2378.08 ------------ Accuracy: 90.3%\n",
            "Step: 1704 ------------ Loss: 2377.64 ------------ Accuracy: 90.3%\n",
            "Step: 1705 ------------ Loss: 2377.2 ------------ Accuracy: 90.3%\n",
            "Step: 1706 ------------ Loss: 2376.77 ------------ Accuracy: 90.3%\n",
            "Step: 1707 ------------ Loss: 2376.33 ------------ Accuracy: 90.3%\n",
            "Step: 1708 ------------ Loss: 2375.9 ------------ Accuracy: 90.3%\n",
            "Step: 1709 ------------ Loss: 2375.46 ------------ Accuracy: 90.3%\n",
            "Step: 1710 ------------ Loss: 2375.02 ------------ Accuracy: 90.3%\n",
            "Step: 1711 ------------ Loss: 2374.59 ------------ Accuracy: 90.3%\n",
            "Step: 1712 ------------ Loss: 2374.16 ------------ Accuracy: 90.3%\n",
            "Step: 1713 ------------ Loss: 2373.72 ------------ Accuracy: 90.3%\n",
            "Step: 1714 ------------ Loss: 2373.29 ------------ Accuracy: 90.3%\n",
            "Step: 1715 ------------ Loss: 2372.86 ------------ Accuracy: 90.3%\n",
            "Step: 1716 ------------ Loss: 2372.42 ------------ Accuracy: 90.3%\n",
            "Step: 1717 ------------ Loss: 2371.99 ------------ Accuracy: 90.3%\n",
            "Step: 1718 ------------ Loss: 2371.56 ------------ Accuracy: 90.3%\n",
            "Step: 1719 ------------ Loss: 2371.13 ------------ Accuracy: 90.3%\n",
            "Step: 1720 ------------ Loss: 2370.7 ------------ Accuracy: 90.3%\n",
            "Step: 1721 ------------ Loss: 2370.27 ------------ Accuracy: 90.3%\n",
            "Step: 1722 ------------ Loss: 2369.84 ------------ Accuracy: 90.3%\n",
            "Step: 1723 ------------ Loss: 2369.41 ------------ Accuracy: 90.3%\n",
            "Step: 1724 ------------ Loss: 2368.98 ------------ Accuracy: 90.3%\n",
            "Step: 1725 ------------ Loss: 2368.55 ------------ Accuracy: 90.3%\n",
            "Step: 1726 ------------ Loss: 2368.12 ------------ Accuracy: 90.3%\n",
            "Step: 1727 ------------ Loss: 2367.69 ------------ Accuracy: 90.3%\n",
            "Step: 1728 ------------ Loss: 2367.26 ------------ Accuracy: 90.3%\n",
            "Step: 1729 ------------ Loss: 2366.84 ------------ Accuracy: 90.3%\n",
            "Step: 1730 ------------ Loss: 2366.41 ------------ Accuracy: 90.3%\n",
            "Step: 1731 ------------ Loss: 2365.98 ------------ Accuracy: 90.3%\n",
            "Step: 1732 ------------ Loss: 2365.56 ------------ Accuracy: 90.3%\n",
            "Step: 1733 ------------ Loss: 2365.13 ------------ Accuracy: 90.3%\n",
            "Step: 1734 ------------ Loss: 2364.7 ------------ Accuracy: 90.3%\n",
            "Step: 1735 ------------ Loss: 2364.28 ------------ Accuracy: 90.3%\n",
            "Step: 1736 ------------ Loss: 2363.85 ------------ Accuracy: 90.3%\n",
            "Step: 1737 ------------ Loss: 2363.43 ------------ Accuracy: 90.3%\n",
            "Step: 1738 ------------ Loss: 2363.01 ------------ Accuracy: 90.3%\n",
            "Step: 1739 ------------ Loss: 2362.58 ------------ Accuracy: 90.3%\n",
            "Step: 1740 ------------ Loss: 2362.16 ------------ Accuracy: 90.3%\n",
            "Step: 1741 ------------ Loss: 2361.74 ------------ Accuracy: 90.3%\n",
            "Step: 1742 ------------ Loss: 2361.32 ------------ Accuracy: 90.3%\n",
            "Step: 1743 ------------ Loss: 2360.89 ------------ Accuracy: 90.3%\n",
            "Step: 1744 ------------ Loss: 2360.47 ------------ Accuracy: 90.3%\n",
            "Step: 1745 ------------ Loss: 2360.05 ------------ Accuracy: 90.3%\n",
            "Step: 1746 ------------ Loss: 2359.63 ------------ Accuracy: 90.3%\n",
            "Step: 1747 ------------ Loss: 2359.21 ------------ Accuracy: 90.3%\n",
            "Step: 1748 ------------ Loss: 2358.79 ------------ Accuracy: 90.3%\n",
            "Step: 1749 ------------ Loss: 2358.37 ------------ Accuracy: 90.3%\n",
            "Step: 1750 ------------ Loss: 2357.95 ------------ Accuracy: 90.4%\n",
            "Step: 1751 ------------ Loss: 2357.53 ------------ Accuracy: 90.4%\n",
            "Step: 1752 ------------ Loss: 2357.12 ------------ Accuracy: 90.4%\n",
            "Step: 1753 ------------ Loss: 2356.7 ------------ Accuracy: 90.4%\n",
            "Step: 1754 ------------ Loss: 2356.28 ------------ Accuracy: 90.4%\n",
            "Step: 1755 ------------ Loss: 2355.86 ------------ Accuracy: 90.4%\n",
            "Step: 1756 ------------ Loss: 2355.45 ------------ Accuracy: 90.4%\n",
            "Step: 1757 ------------ Loss: 2355.03 ------------ Accuracy: 90.4%\n",
            "Step: 1758 ------------ Loss: 2354.61 ------------ Accuracy: 90.4%\n",
            "Step: 1759 ------------ Loss: 2354.2 ------------ Accuracy: 90.4%\n",
            "Step: 1760 ------------ Loss: 2353.78 ------------ Accuracy: 90.4%\n",
            "Step: 1761 ------------ Loss: 2353.37 ------------ Accuracy: 90.4%\n",
            "Step: 1762 ------------ Loss: 2352.95 ------------ Accuracy: 90.4%\n",
            "Step: 1763 ------------ Loss: 2352.54 ------------ Accuracy: 90.4%\n",
            "Step: 1764 ------------ Loss: 2352.13 ------------ Accuracy: 90.4%\n",
            "Step: 1765 ------------ Loss: 2351.71 ------------ Accuracy: 90.4%\n",
            "Step: 1766 ------------ Loss: 2351.3 ------------ Accuracy: 90.4%\n",
            "Step: 1767 ------------ Loss: 2350.89 ------------ Accuracy: 90.4%\n",
            "Step: 1768 ------------ Loss: 2350.47 ------------ Accuracy: 90.4%\n",
            "Step: 1769 ------------ Loss: 2350.06 ------------ Accuracy: 90.4%\n",
            "Step: 1770 ------------ Loss: 2349.65 ------------ Accuracy: 90.4%\n",
            "Step: 1771 ------------ Loss: 2349.24 ------------ Accuracy: 90.4%\n",
            "Step: 1772 ------------ Loss: 2348.83 ------------ Accuracy: 90.4%\n",
            "Step: 1773 ------------ Loss: 2348.42 ------------ Accuracy: 90.4%\n",
            "Step: 1774 ------------ Loss: 2348.01 ------------ Accuracy: 90.4%\n",
            "Step: 1775 ------------ Loss: 2347.6 ------------ Accuracy: 90.4%\n",
            "Step: 1776 ------------ Loss: 2347.19 ------------ Accuracy: 90.4%\n",
            "Step: 1777 ------------ Loss: 2346.78 ------------ Accuracy: 90.4%\n",
            "Step: 1778 ------------ Loss: 2346.37 ------------ Accuracy: 90.4%\n",
            "Step: 1779 ------------ Loss: 2345.97 ------------ Accuracy: 90.4%\n",
            "Step: 1780 ------------ Loss: 2345.56 ------------ Accuracy: 90.4%\n",
            "Step: 1781 ------------ Loss: 2345.15 ------------ Accuracy: 90.4%\n",
            "Step: 1782 ------------ Loss: 2344.74 ------------ Accuracy: 90.4%\n",
            "Step: 1783 ------------ Loss: 2344.34 ------------ Accuracy: 90.4%\n",
            "Step: 1784 ------------ Loss: 2343.93 ------------ Accuracy: 90.4%\n",
            "Step: 1785 ------------ Loss: 2343.53 ------------ Accuracy: 90.4%\n",
            "Step: 1786 ------------ Loss: 2343.12 ------------ Accuracy: 90.4%\n",
            "Step: 1787 ------------ Loss: 2342.71 ------------ Accuracy: 90.4%\n",
            "Step: 1788 ------------ Loss: 2342.31 ------------ Accuracy: 90.4%\n",
            "Step: 1789 ------------ Loss: 2341.91 ------------ Accuracy: 90.4%\n",
            "Step: 1790 ------------ Loss: 2341.5 ------------ Accuracy: 90.4%\n",
            "Step: 1791 ------------ Loss: 2341.1 ------------ Accuracy: 90.4%\n",
            "Step: 1792 ------------ Loss: 2340.69 ------------ Accuracy: 90.4%\n",
            "Step: 1793 ------------ Loss: 2340.29 ------------ Accuracy: 90.4%\n",
            "Step: 1794 ------------ Loss: 2339.89 ------------ Accuracy: 90.4%\n",
            "Step: 1795 ------------ Loss: 2339.49 ------------ Accuracy: 90.4%\n",
            "Step: 1796 ------------ Loss: 2339.09 ------------ Accuracy: 90.4%\n",
            "Step: 1797 ------------ Loss: 2338.68 ------------ Accuracy: 90.4%\n",
            "Step: 1798 ------------ Loss: 2338.28 ------------ Accuracy: 90.4%\n",
            "Step: 1799 ------------ Loss: 2337.88 ------------ Accuracy: 90.4%\n",
            "Step: 1800 ------------ Loss: 2337.48 ------------ Accuracy: 90.4%\n",
            "Step: 1801 ------------ Loss: 2337.08 ------------ Accuracy: 90.4%\n",
            "Step: 1802 ------------ Loss: 2336.68 ------------ Accuracy: 90.4%\n",
            "Step: 1803 ------------ Loss: 2336.28 ------------ Accuracy: 90.4%\n",
            "Step: 1804 ------------ Loss: 2335.88 ------------ Accuracy: 90.4%\n",
            "Step: 1805 ------------ Loss: 2335.49 ------------ Accuracy: 90.4%\n",
            "Step: 1806 ------------ Loss: 2335.09 ------------ Accuracy: 90.4%\n",
            "Step: 1807 ------------ Loss: 2334.69 ------------ Accuracy: 90.4%\n",
            "Step: 1808 ------------ Loss: 2334.29 ------------ Accuracy: 90.4%\n",
            "Step: 1809 ------------ Loss: 2333.9 ------------ Accuracy: 90.4%\n",
            "Step: 1810 ------------ Loss: 2333.5 ------------ Accuracy: 90.4%\n",
            "Step: 1811 ------------ Loss: 2333.1 ------------ Accuracy: 90.4%\n",
            "Step: 1812 ------------ Loss: 2332.71 ------------ Accuracy: 90.4%\n",
            "Step: 1813 ------------ Loss: 2332.31 ------------ Accuracy: 90.4%\n",
            "Step: 1814 ------------ Loss: 2331.92 ------------ Accuracy: 90.4%\n",
            "Step: 1815 ------------ Loss: 2331.52 ------------ Accuracy: 90.4%\n",
            "Step: 1816 ------------ Loss: 2331.13 ------------ Accuracy: 90.4%\n",
            "Step: 1817 ------------ Loss: 2330.73 ------------ Accuracy: 90.4%\n",
            "Step: 1818 ------------ Loss: 2330.34 ------------ Accuracy: 90.4%\n",
            "Step: 1819 ------------ Loss: 2329.94 ------------ Accuracy: 90.4%\n",
            "Step: 1820 ------------ Loss: 2329.55 ------------ Accuracy: 90.4%\n",
            "Step: 1821 ------------ Loss: 2329.16 ------------ Accuracy: 90.4%\n",
            "Step: 1822 ------------ Loss: 2328.77 ------------ Accuracy: 90.4%\n",
            "Step: 1823 ------------ Loss: 2328.37 ------------ Accuracy: 90.4%\n",
            "Step: 1824 ------------ Loss: 2327.98 ------------ Accuracy: 90.4%\n",
            "Step: 1825 ------------ Loss: 2327.59 ------------ Accuracy: 90.4%\n",
            "Step: 1826 ------------ Loss: 2327.2 ------------ Accuracy: 90.4%\n",
            "Step: 1827 ------------ Loss: 2326.81 ------------ Accuracy: 90.4%\n",
            "Step: 1828 ------------ Loss: 2326.42 ------------ Accuracy: 90.4%\n",
            "Step: 1829 ------------ Loss: 2326.03 ------------ Accuracy: 90.4%\n",
            "Step: 1830 ------------ Loss: 2325.64 ------------ Accuracy: 90.4%\n",
            "Step: 1831 ------------ Loss: 2325.25 ------------ Accuracy: 90.4%\n",
            "Step: 1832 ------------ Loss: 2324.86 ------------ Accuracy: 90.4%\n",
            "Step: 1833 ------------ Loss: 2324.47 ------------ Accuracy: 90.4%\n",
            "Step: 1834 ------------ Loss: 2324.08 ------------ Accuracy: 90.4%\n",
            "Step: 1835 ------------ Loss: 2323.7 ------------ Accuracy: 90.4%\n",
            "Step: 1836 ------------ Loss: 2323.31 ------------ Accuracy: 90.4%\n",
            "Step: 1837 ------------ Loss: 2322.92 ------------ Accuracy: 90.4%\n",
            "Step: 1838 ------------ Loss: 2322.53 ------------ Accuracy: 90.4%\n",
            "Step: 1839 ------------ Loss: 2322.15 ------------ Accuracy: 90.4%\n",
            "Step: 1840 ------------ Loss: 2321.76 ------------ Accuracy: 90.4%\n",
            "Step: 1841 ------------ Loss: 2321.38 ------------ Accuracy: 90.4%\n",
            "Step: 1842 ------------ Loss: 2320.99 ------------ Accuracy: 90.4%\n",
            "Step: 1843 ------------ Loss: 2320.6 ------------ Accuracy: 90.4%\n",
            "Step: 1844 ------------ Loss: 2320.22 ------------ Accuracy: 90.4%\n",
            "Step: 1845 ------------ Loss: 2319.84 ------------ Accuracy: 90.4%\n",
            "Step: 1846 ------------ Loss: 2319.45 ------------ Accuracy: 90.4%\n",
            "Step: 1847 ------------ Loss: 2319.07 ------------ Accuracy: 90.4%\n",
            "Step: 1848 ------------ Loss: 2318.68 ------------ Accuracy: 90.4%\n",
            "Step: 1849 ------------ Loss: 2318.3 ------------ Accuracy: 90.4%\n",
            "Step: 1850 ------------ Loss: 2317.92 ------------ Accuracy: 90.4%\n",
            "Step: 1851 ------------ Loss: 2317.54 ------------ Accuracy: 90.4%\n",
            "Step: 1852 ------------ Loss: 2317.15 ------------ Accuracy: 90.4%\n",
            "Step: 1853 ------------ Loss: 2316.77 ------------ Accuracy: 90.4%\n",
            "Step: 1854 ------------ Loss: 2316.39 ------------ Accuracy: 90.4%\n",
            "Step: 1855 ------------ Loss: 2316.01 ------------ Accuracy: 90.4%\n",
            "Step: 1856 ------------ Loss: 2315.63 ------------ Accuracy: 90.4%\n",
            "Step: 1857 ------------ Loss: 2315.25 ------------ Accuracy: 90.4%\n",
            "Step: 1858 ------------ Loss: 2314.87 ------------ Accuracy: 90.4%\n",
            "Step: 1859 ------------ Loss: 2314.49 ------------ Accuracy: 90.4%\n",
            "Step: 1860 ------------ Loss: 2314.11 ------------ Accuracy: 90.4%\n",
            "Step: 1861 ------------ Loss: 2313.73 ------------ Accuracy: 90.4%\n",
            "Step: 1862 ------------ Loss: 2313.35 ------------ Accuracy: 90.4%\n",
            "Step: 1863 ------------ Loss: 2312.97 ------------ Accuracy: 90.4%\n",
            "Step: 1864 ------------ Loss: 2312.59 ------------ Accuracy: 90.4%\n",
            "Step: 1865 ------------ Loss: 2312.22 ------------ Accuracy: 90.4%\n",
            "Step: 1866 ------------ Loss: 2311.84 ------------ Accuracy: 90.4%\n",
            "Step: 1867 ------------ Loss: 2311.46 ------------ Accuracy: 90.4%\n",
            "Step: 1868 ------------ Loss: 2311.08 ------------ Accuracy: 90.4%\n",
            "Step: 1869 ------------ Loss: 2310.71 ------------ Accuracy: 90.4%\n",
            "Step: 1870 ------------ Loss: 2310.33 ------------ Accuracy: 90.4%\n",
            "Step: 1871 ------------ Loss: 2309.96 ------------ Accuracy: 90.4%\n",
            "Step: 1872 ------------ Loss: 2309.58 ------------ Accuracy: 90.4%\n",
            "Step: 1873 ------------ Loss: 2309.2 ------------ Accuracy: 90.4%\n",
            "Step: 1874 ------------ Loss: 2308.83 ------------ Accuracy: 90.4%\n",
            "Step: 1875 ------------ Loss: 2308.46 ------------ Accuracy: 90.4%\n",
            "Step: 1876 ------------ Loss: 2308.08 ------------ Accuracy: 90.4%\n",
            "Step: 1877 ------------ Loss: 2307.71 ------------ Accuracy: 90.4%\n",
            "Step: 1878 ------------ Loss: 2307.33 ------------ Accuracy: 90.4%\n",
            "Step: 1879 ------------ Loss: 2306.96 ------------ Accuracy: 90.4%\n",
            "Step: 1880 ------------ Loss: 2306.59 ------------ Accuracy: 90.4%\n",
            "Step: 1881 ------------ Loss: 2306.22 ------------ Accuracy: 90.4%\n",
            "Step: 1882 ------------ Loss: 2305.84 ------------ Accuracy: 90.4%\n",
            "Step: 1883 ------------ Loss: 2305.47 ------------ Accuracy: 90.4%\n",
            "Step: 1884 ------------ Loss: 2305.1 ------------ Accuracy: 90.4%\n",
            "Step: 1885 ------------ Loss: 2304.73 ------------ Accuracy: 90.4%\n",
            "Step: 1886 ------------ Loss: 2304.36 ------------ Accuracy: 90.4%\n",
            "Step: 1887 ------------ Loss: 2303.99 ------------ Accuracy: 90.4%\n",
            "Step: 1888 ------------ Loss: 2303.62 ------------ Accuracy: 90.4%\n",
            "Step: 1889 ------------ Loss: 2303.25 ------------ Accuracy: 90.4%\n",
            "Step: 1890 ------------ Loss: 2302.88 ------------ Accuracy: 90.4%\n",
            "Step: 1891 ------------ Loss: 2302.51 ------------ Accuracy: 90.4%\n",
            "Step: 1892 ------------ Loss: 2302.14 ------------ Accuracy: 90.4%\n",
            "Step: 1893 ------------ Loss: 2301.77 ------------ Accuracy: 90.4%\n",
            "Step: 1894 ------------ Loss: 2301.4 ------------ Accuracy: 90.4%\n",
            "Step: 1895 ------------ Loss: 2301.03 ------------ Accuracy: 90.4%\n",
            "Step: 1896 ------------ Loss: 2300.66 ------------ Accuracy: 90.4%\n",
            "Step: 1897 ------------ Loss: 2300.3 ------------ Accuracy: 90.4%\n",
            "Step: 1898 ------------ Loss: 2299.93 ------------ Accuracy: 90.4%\n",
            "Step: 1899 ------------ Loss: 2299.56 ------------ Accuracy: 90.4%\n",
            "Step: 1900 ------------ Loss: 2299.2 ------------ Accuracy: 90.4%\n",
            "Step: 1901 ------------ Loss: 2298.83 ------------ Accuracy: 90.4%\n",
            "Step: 1902 ------------ Loss: 2298.46 ------------ Accuracy: 90.4%\n",
            "Step: 1903 ------------ Loss: 2298.1 ------------ Accuracy: 90.4%\n",
            "Step: 1904 ------------ Loss: 2297.73 ------------ Accuracy: 90.4%\n",
            "Step: 1905 ------------ Loss: 2297.37 ------------ Accuracy: 90.4%\n",
            "Step: 1906 ------------ Loss: 2297.0 ------------ Accuracy: 90.4%\n",
            "Step: 1907 ------------ Loss: 2296.64 ------------ Accuracy: 90.4%\n",
            "Step: 1908 ------------ Loss: 2296.28 ------------ Accuracy: 90.4%\n",
            "Step: 1909 ------------ Loss: 2295.91 ------------ Accuracy: 90.4%\n",
            "Step: 1910 ------------ Loss: 2295.55 ------------ Accuracy: 90.4%\n",
            "Step: 1911 ------------ Loss: 2295.19 ------------ Accuracy: 90.4%\n",
            "Step: 1912 ------------ Loss: 2294.82 ------------ Accuracy: 90.4%\n",
            "Step: 1913 ------------ Loss: 2294.46 ------------ Accuracy: 90.4%\n",
            "Step: 1914 ------------ Loss: 2294.1 ------------ Accuracy: 90.4%\n",
            "Step: 1915 ------------ Loss: 2293.74 ------------ Accuracy: 90.4%\n",
            "Step: 1916 ------------ Loss: 2293.38 ------------ Accuracy: 90.4%\n",
            "Step: 1917 ------------ Loss: 2293.01 ------------ Accuracy: 90.4%\n",
            "Step: 1918 ------------ Loss: 2292.65 ------------ Accuracy: 90.4%\n",
            "Step: 1919 ------------ Loss: 2292.29 ------------ Accuracy: 90.4%\n",
            "Step: 1920 ------------ Loss: 2291.93 ------------ Accuracy: 90.4%\n",
            "Step: 1921 ------------ Loss: 2291.57 ------------ Accuracy: 90.4%\n",
            "Step: 1922 ------------ Loss: 2291.21 ------------ Accuracy: 90.4%\n",
            "Step: 1923 ------------ Loss: 2290.85 ------------ Accuracy: 90.4%\n",
            "Step: 1924 ------------ Loss: 2290.49 ------------ Accuracy: 90.4%\n",
            "Step: 1925 ------------ Loss: 2290.14 ------------ Accuracy: 90.4%\n",
            "Step: 1926 ------------ Loss: 2289.78 ------------ Accuracy: 90.4%\n",
            "Step: 1927 ------------ Loss: 2289.42 ------------ Accuracy: 90.4%\n",
            "Step: 1928 ------------ Loss: 2289.06 ------------ Accuracy: 90.4%\n",
            "Step: 1929 ------------ Loss: 2288.7 ------------ Accuracy: 90.4%\n",
            "Step: 1930 ------------ Loss: 2288.35 ------------ Accuracy: 90.4%\n",
            "Step: 1931 ------------ Loss: 2287.99 ------------ Accuracy: 90.4%\n",
            "Step: 1932 ------------ Loss: 2287.63 ------------ Accuracy: 90.4%\n",
            "Step: 1933 ------------ Loss: 2287.28 ------------ Accuracy: 90.4%\n",
            "Step: 1934 ------------ Loss: 2286.92 ------------ Accuracy: 90.4%\n",
            "Step: 1935 ------------ Loss: 2286.56 ------------ Accuracy: 90.4%\n",
            "Step: 1936 ------------ Loss: 2286.21 ------------ Accuracy: 90.4%\n",
            "Step: 1937 ------------ Loss: 2285.85 ------------ Accuracy: 90.4%\n",
            "Step: 1938 ------------ Loss: 2285.5 ------------ Accuracy: 90.4%\n",
            "Step: 1939 ------------ Loss: 2285.15 ------------ Accuracy: 90.4%\n",
            "Step: 1940 ------------ Loss: 2284.79 ------------ Accuracy: 90.4%\n",
            "Step: 1941 ------------ Loss: 2284.44 ------------ Accuracy: 90.4%\n",
            "Step: 1942 ------------ Loss: 2284.08 ------------ Accuracy: 90.4%\n",
            "Step: 1943 ------------ Loss: 2283.73 ------------ Accuracy: 90.4%\n",
            "Step: 1944 ------------ Loss: 2283.38 ------------ Accuracy: 90.4%\n",
            "Step: 1945 ------------ Loss: 2283.02 ------------ Accuracy: 90.4%\n",
            "Step: 1946 ------------ Loss: 2282.67 ------------ Accuracy: 90.4%\n",
            "Step: 1947 ------------ Loss: 2282.32 ------------ Accuracy: 90.4%\n",
            "Step: 1948 ------------ Loss: 2281.97 ------------ Accuracy: 90.4%\n",
            "Step: 1949 ------------ Loss: 2281.62 ------------ Accuracy: 90.4%\n",
            "Step: 1950 ------------ Loss: 2281.27 ------------ Accuracy: 90.4%\n",
            "Step: 1951 ------------ Loss: 2280.91 ------------ Accuracy: 90.4%\n",
            "Step: 1952 ------------ Loss: 2280.56 ------------ Accuracy: 90.4%\n",
            "Step: 1953 ------------ Loss: 2280.21 ------------ Accuracy: 90.4%\n",
            "Step: 1954 ------------ Loss: 2279.86 ------------ Accuracy: 90.4%\n",
            "Step: 1955 ------------ Loss: 2279.51 ------------ Accuracy: 90.5%\n",
            "Step: 1956 ------------ Loss: 2279.16 ------------ Accuracy: 90.5%\n",
            "Step: 1957 ------------ Loss: 2278.81 ------------ Accuracy: 90.5%\n",
            "Step: 1958 ------------ Loss: 2278.47 ------------ Accuracy: 90.5%\n",
            "Step: 1959 ------------ Loss: 2278.12 ------------ Accuracy: 90.5%\n",
            "Step: 1960 ------------ Loss: 2277.77 ------------ Accuracy: 90.5%\n",
            "Step: 1961 ------------ Loss: 2277.42 ------------ Accuracy: 90.5%\n",
            "Step: 1962 ------------ Loss: 2277.07 ------------ Accuracy: 90.5%\n",
            "Step: 1963 ------------ Loss: 2276.73 ------------ Accuracy: 90.5%\n",
            "Step: 1964 ------------ Loss: 2276.38 ------------ Accuracy: 90.5%\n",
            "Step: 1965 ------------ Loss: 2276.03 ------------ Accuracy: 90.5%\n",
            "Step: 1966 ------------ Loss: 2275.68 ------------ Accuracy: 90.5%\n",
            "Step: 1967 ------------ Loss: 2275.34 ------------ Accuracy: 90.5%\n",
            "Step: 1968 ------------ Loss: 2274.99 ------------ Accuracy: 90.5%\n",
            "Step: 1969 ------------ Loss: 2274.65 ------------ Accuracy: 90.5%\n",
            "Step: 1970 ------------ Loss: 2274.3 ------------ Accuracy: 90.5%\n",
            "Step: 1971 ------------ Loss: 2273.96 ------------ Accuracy: 90.5%\n",
            "Step: 1972 ------------ Loss: 2273.61 ------------ Accuracy: 90.5%\n",
            "Step: 1973 ------------ Loss: 2273.27 ------------ Accuracy: 90.5%\n",
            "Step: 1974 ------------ Loss: 2272.92 ------------ Accuracy: 90.5%\n",
            "Step: 1975 ------------ Loss: 2272.58 ------------ Accuracy: 90.5%\n",
            "Step: 1976 ------------ Loss: 2272.24 ------------ Accuracy: 90.5%\n",
            "Step: 1977 ------------ Loss: 2271.89 ------------ Accuracy: 90.5%\n",
            "Step: 1978 ------------ Loss: 2271.55 ------------ Accuracy: 90.5%\n",
            "Step: 1979 ------------ Loss: 2271.21 ------------ Accuracy: 90.5%\n",
            "Step: 1980 ------------ Loss: 2270.86 ------------ Accuracy: 90.5%\n",
            "Step: 1981 ------------ Loss: 2270.52 ------------ Accuracy: 90.5%\n",
            "Step: 1982 ------------ Loss: 2270.18 ------------ Accuracy: 90.5%\n",
            "Step: 1983 ------------ Loss: 2269.84 ------------ Accuracy: 90.5%\n",
            "Step: 1984 ------------ Loss: 2269.5 ------------ Accuracy: 90.5%\n",
            "Step: 1985 ------------ Loss: 2269.15 ------------ Accuracy: 90.5%\n",
            "Step: 1986 ------------ Loss: 2268.81 ------------ Accuracy: 90.5%\n",
            "Step: 1987 ------------ Loss: 2268.47 ------------ Accuracy: 90.5%\n",
            "Step: 1988 ------------ Loss: 2268.13 ------------ Accuracy: 90.5%\n",
            "Step: 1989 ------------ Loss: 2267.79 ------------ Accuracy: 90.5%\n",
            "Step: 1990 ------------ Loss: 2267.45 ------------ Accuracy: 90.5%\n",
            "Step: 1991 ------------ Loss: 2267.11 ------------ Accuracy: 90.5%\n",
            "Step: 1992 ------------ Loss: 2266.77 ------------ Accuracy: 90.5%\n",
            "Step: 1993 ------------ Loss: 2266.44 ------------ Accuracy: 90.5%\n",
            "Step: 1994 ------------ Loss: 2266.1 ------------ Accuracy: 90.5%\n",
            "Step: 1995 ------------ Loss: 2265.76 ------------ Accuracy: 90.5%\n",
            "Step: 1996 ------------ Loss: 2265.42 ------------ Accuracy: 90.5%\n",
            "Step: 1997 ------------ Loss: 2265.08 ------------ Accuracy: 90.5%\n",
            "Step: 1998 ------------ Loss: 2264.75 ------------ Accuracy: 90.5%\n",
            "Step: 1999 ------------ Loss: 2264.41 ------------ Accuracy: 90.5%\n",
            "Step: 2000 ------------ Loss: 2264.07 ------------ Accuracy: 90.5%\n",
            "Step: 2001 ------------ Loss: 2263.73 ------------ Accuracy: 90.5%\n",
            "Step: 2002 ------------ Loss: 2263.4 ------------ Accuracy: 90.5%\n",
            "Step: 2003 ------------ Loss: 2263.06 ------------ Accuracy: 90.5%\n",
            "Step: 2004 ------------ Loss: 2262.73 ------------ Accuracy: 90.5%\n",
            "Step: 2005 ------------ Loss: 2262.39 ------------ Accuracy: 90.5%\n",
            "Step: 2006 ------------ Loss: 2262.06 ------------ Accuracy: 90.5%\n",
            "Step: 2007 ------------ Loss: 2261.72 ------------ Accuracy: 90.5%\n",
            "Step: 2008 ------------ Loss: 2261.39 ------------ Accuracy: 90.5%\n",
            "Step: 2009 ------------ Loss: 2261.05 ------------ Accuracy: 90.5%\n",
            "Step: 2010 ------------ Loss: 2260.72 ------------ Accuracy: 90.5%\n",
            "Step: 2011 ------------ Loss: 2260.38 ------------ Accuracy: 90.5%\n",
            "Step: 2012 ------------ Loss: 2260.05 ------------ Accuracy: 90.5%\n",
            "Step: 2013 ------------ Loss: 2259.72 ------------ Accuracy: 90.5%\n",
            "Step: 2014 ------------ Loss: 2259.38 ------------ Accuracy: 90.5%\n",
            "Step: 2015 ------------ Loss: 2259.05 ------------ Accuracy: 90.5%\n",
            "Step: 2016 ------------ Loss: 2258.72 ------------ Accuracy: 90.5%\n",
            "Step: 2017 ------------ Loss: 2258.38 ------------ Accuracy: 90.5%\n",
            "Step: 2018 ------------ Loss: 2258.05 ------------ Accuracy: 90.5%\n",
            "Step: 2019 ------------ Loss: 2257.72 ------------ Accuracy: 90.5%\n",
            "Step: 2020 ------------ Loss: 2257.39 ------------ Accuracy: 90.5%\n",
            "Step: 2021 ------------ Loss: 2257.06 ------------ Accuracy: 90.5%\n",
            "Step: 2022 ------------ Loss: 2256.73 ------------ Accuracy: 90.5%\n",
            "Step: 2023 ------------ Loss: 2256.4 ------------ Accuracy: 90.5%\n",
            "Step: 2024 ------------ Loss: 2256.07 ------------ Accuracy: 90.5%\n",
            "Step: 2025 ------------ Loss: 2255.74 ------------ Accuracy: 90.5%\n",
            "Step: 2026 ------------ Loss: 2255.41 ------------ Accuracy: 90.5%\n",
            "Step: 2027 ------------ Loss: 2255.08 ------------ Accuracy: 90.5%\n",
            "Step: 2028 ------------ Loss: 2254.75 ------------ Accuracy: 90.5%\n",
            "Step: 2029 ------------ Loss: 2254.42 ------------ Accuracy: 90.5%\n",
            "Step: 2030 ------------ Loss: 2254.09 ------------ Accuracy: 90.5%\n",
            "Step: 2031 ------------ Loss: 2253.76 ------------ Accuracy: 90.5%\n",
            "Step: 2032 ------------ Loss: 2253.43 ------------ Accuracy: 90.5%\n",
            "Step: 2033 ------------ Loss: 2253.1 ------------ Accuracy: 90.5%\n",
            "Step: 2034 ------------ Loss: 2252.78 ------------ Accuracy: 90.5%\n",
            "Step: 2035 ------------ Loss: 2252.45 ------------ Accuracy: 90.5%\n",
            "Step: 2036 ------------ Loss: 2252.12 ------------ Accuracy: 90.5%\n",
            "Step: 2037 ------------ Loss: 2251.79 ------------ Accuracy: 90.5%\n",
            "Step: 2038 ------------ Loss: 2251.47 ------------ Accuracy: 90.5%\n",
            "Step: 2039 ------------ Loss: 2251.14 ------------ Accuracy: 90.5%\n",
            "Step: 2040 ------------ Loss: 2250.82 ------------ Accuracy: 90.5%\n",
            "Step: 2041 ------------ Loss: 2250.49 ------------ Accuracy: 90.5%\n",
            "Step: 2042 ------------ Loss: 2250.16 ------------ Accuracy: 90.5%\n",
            "Step: 2043 ------------ Loss: 2249.84 ------------ Accuracy: 90.5%\n",
            "Step: 2044 ------------ Loss: 2249.51 ------------ Accuracy: 90.5%\n",
            "Step: 2045 ------------ Loss: 2249.19 ------------ Accuracy: 90.5%\n",
            "Step: 2046 ------------ Loss: 2248.86 ------------ Accuracy: 90.5%\n",
            "Step: 2047 ------------ Loss: 2248.54 ------------ Accuracy: 90.5%\n",
            "Step: 2048 ------------ Loss: 2248.22 ------------ Accuracy: 90.5%\n",
            "Step: 2049 ------------ Loss: 2247.89 ------------ Accuracy: 90.5%\n",
            "Step: 2050 ------------ Loss: 2247.57 ------------ Accuracy: 90.5%\n",
            "Step: 2051 ------------ Loss: 2247.25 ------------ Accuracy: 90.5%\n",
            "Step: 2052 ------------ Loss: 2246.92 ------------ Accuracy: 90.5%\n",
            "Step: 2053 ------------ Loss: 2246.6 ------------ Accuracy: 90.5%\n",
            "Step: 2054 ------------ Loss: 2246.28 ------------ Accuracy: 90.5%\n",
            "Step: 2055 ------------ Loss: 2245.95 ------------ Accuracy: 90.5%\n",
            "Step: 2056 ------------ Loss: 2245.63 ------------ Accuracy: 90.5%\n",
            "Step: 2057 ------------ Loss: 2245.31 ------------ Accuracy: 90.5%\n",
            "Step: 2058 ------------ Loss: 2244.99 ------------ Accuracy: 90.5%\n",
            "Step: 2059 ------------ Loss: 2244.67 ------------ Accuracy: 90.5%\n",
            "Step: 2060 ------------ Loss: 2244.35 ------------ Accuracy: 90.5%\n",
            "Step: 2061 ------------ Loss: 2244.03 ------------ Accuracy: 90.5%\n",
            "Step: 2062 ------------ Loss: 2243.71 ------------ Accuracy: 90.5%\n",
            "Step: 2063 ------------ Loss: 2243.39 ------------ Accuracy: 90.5%\n",
            "Step: 2064 ------------ Loss: 2243.07 ------------ Accuracy: 90.5%\n",
            "Step: 2065 ------------ Loss: 2242.75 ------------ Accuracy: 90.5%\n",
            "Step: 2066 ------------ Loss: 2242.43 ------------ Accuracy: 90.5%\n",
            "Step: 2067 ------------ Loss: 2242.11 ------------ Accuracy: 90.5%\n",
            "Step: 2068 ------------ Loss: 2241.79 ------------ Accuracy: 90.5%\n",
            "Step: 2069 ------------ Loss: 2241.47 ------------ Accuracy: 90.5%\n",
            "Step: 2070 ------------ Loss: 2241.15 ------------ Accuracy: 90.5%\n",
            "Step: 2071 ------------ Loss: 2240.83 ------------ Accuracy: 90.5%\n",
            "Step: 2072 ------------ Loss: 2240.52 ------------ Accuracy: 90.5%\n",
            "Step: 2073 ------------ Loss: 2240.2 ------------ Accuracy: 90.5%\n",
            "Step: 2074 ------------ Loss: 2239.88 ------------ Accuracy: 90.5%\n",
            "Step: 2075 ------------ Loss: 2239.56 ------------ Accuracy: 90.5%\n",
            "Step: 2076 ------------ Loss: 2239.25 ------------ Accuracy: 90.5%\n",
            "Step: 2077 ------------ Loss: 2238.93 ------------ Accuracy: 90.5%\n",
            "Step: 2078 ------------ Loss: 2238.61 ------------ Accuracy: 90.5%\n",
            "Step: 2079 ------------ Loss: 2238.3 ------------ Accuracy: 90.5%\n",
            "Step: 2080 ------------ Loss: 2237.98 ------------ Accuracy: 90.5%\n",
            "Step: 2081 ------------ Loss: 2237.67 ------------ Accuracy: 90.5%\n",
            "Step: 2082 ------------ Loss: 2237.35 ------------ Accuracy: 90.5%\n",
            "Step: 2083 ------------ Loss: 2237.03 ------------ Accuracy: 90.5%\n",
            "Step: 2084 ------------ Loss: 2236.72 ------------ Accuracy: 90.5%\n",
            "Step: 2085 ------------ Loss: 2236.41 ------------ Accuracy: 90.5%\n",
            "Step: 2086 ------------ Loss: 2236.09 ------------ Accuracy: 90.5%\n",
            "Step: 2087 ------------ Loss: 2235.78 ------------ Accuracy: 90.5%\n",
            "Step: 2088 ------------ Loss: 2235.46 ------------ Accuracy: 90.5%\n",
            "Step: 2089 ------------ Loss: 2235.15 ------------ Accuracy: 90.5%\n",
            "Step: 2090 ------------ Loss: 2234.84 ------------ Accuracy: 90.5%\n",
            "Step: 2091 ------------ Loss: 2234.52 ------------ Accuracy: 90.5%\n",
            "Step: 2092 ------------ Loss: 2234.21 ------------ Accuracy: 90.5%\n",
            "Step: 2093 ------------ Loss: 2233.9 ------------ Accuracy: 90.5%\n",
            "Step: 2094 ------------ Loss: 2233.58 ------------ Accuracy: 90.5%\n",
            "Step: 2095 ------------ Loss: 2233.27 ------------ Accuracy: 90.5%\n",
            "Step: 2096 ------------ Loss: 2232.96 ------------ Accuracy: 90.5%\n",
            "Step: 2097 ------------ Loss: 2232.65 ------------ Accuracy: 90.5%\n",
            "Step: 2098 ------------ Loss: 2232.34 ------------ Accuracy: 90.5%\n",
            "Step: 2099 ------------ Loss: 2232.03 ------------ Accuracy: 90.5%\n",
            "Step: 2100 ------------ Loss: 2231.71 ------------ Accuracy: 90.5%\n",
            "Step: 2101 ------------ Loss: 2231.4 ------------ Accuracy: 90.5%\n",
            "Step: 2102 ------------ Loss: 2231.09 ------------ Accuracy: 90.5%\n",
            "Step: 2103 ------------ Loss: 2230.78 ------------ Accuracy: 90.5%\n",
            "Step: 2104 ------------ Loss: 2230.47 ------------ Accuracy: 90.5%\n",
            "Step: 2105 ------------ Loss: 2230.16 ------------ Accuracy: 90.5%\n",
            "Step: 2106 ------------ Loss: 2229.85 ------------ Accuracy: 90.5%\n",
            "Step: 2107 ------------ Loss: 2229.54 ------------ Accuracy: 90.5%\n",
            "Step: 2108 ------------ Loss: 2229.24 ------------ Accuracy: 90.5%\n",
            "Step: 2109 ------------ Loss: 2228.93 ------------ Accuracy: 90.5%\n",
            "Step: 2110 ------------ Loss: 2228.62 ------------ Accuracy: 90.5%\n",
            "Step: 2111 ------------ Loss: 2228.31 ------------ Accuracy: 90.5%\n",
            "Step: 2112 ------------ Loss: 2228.0 ------------ Accuracy: 90.5%\n",
            "Step: 2113 ------------ Loss: 2227.69 ------------ Accuracy: 90.5%\n",
            "Step: 2114 ------------ Loss: 2227.39 ------------ Accuracy: 90.5%\n",
            "Step: 2115 ------------ Loss: 2227.08 ------------ Accuracy: 90.5%\n",
            "Step: 2116 ------------ Loss: 2226.77 ------------ Accuracy: 90.5%\n",
            "Step: 2117 ------------ Loss: 2226.47 ------------ Accuracy: 90.5%\n",
            "Step: 2118 ------------ Loss: 2226.16 ------------ Accuracy: 90.5%\n",
            "Step: 2119 ------------ Loss: 2225.85 ------------ Accuracy: 90.5%\n",
            "Step: 2120 ------------ Loss: 2225.55 ------------ Accuracy: 90.5%\n",
            "Step: 2121 ------------ Loss: 2225.24 ------------ Accuracy: 90.5%\n",
            "Step: 2122 ------------ Loss: 2224.93 ------------ Accuracy: 90.5%\n",
            "Step: 2123 ------------ Loss: 2224.63 ------------ Accuracy: 90.5%\n",
            "Step: 2124 ------------ Loss: 2224.32 ------------ Accuracy: 90.5%\n",
            "Step: 2125 ------------ Loss: 2224.02 ------------ Accuracy: 90.5%\n",
            "Step: 2126 ------------ Loss: 2223.71 ------------ Accuracy: 90.5%\n",
            "Step: 2127 ------------ Loss: 2223.41 ------------ Accuracy: 90.5%\n",
            "Step: 2128 ------------ Loss: 2223.11 ------------ Accuracy: 90.5%\n",
            "Step: 2129 ------------ Loss: 2222.8 ------------ Accuracy: 90.5%\n",
            "Step: 2130 ------------ Loss: 2222.5 ------------ Accuracy: 90.5%\n",
            "Step: 2131 ------------ Loss: 2222.19 ------------ Accuracy: 90.5%\n",
            "Step: 2132 ------------ Loss: 2221.89 ------------ Accuracy: 90.5%\n",
            "Step: 2133 ------------ Loss: 2221.59 ------------ Accuracy: 90.5%\n",
            "Step: 2134 ------------ Loss: 2221.28 ------------ Accuracy: 90.5%\n",
            "Step: 2135 ------------ Loss: 2220.98 ------------ Accuracy: 90.5%\n",
            "Step: 2136 ------------ Loss: 2220.68 ------------ Accuracy: 90.5%\n",
            "Step: 2137 ------------ Loss: 2220.38 ------------ Accuracy: 90.5%\n",
            "Step: 2138 ------------ Loss: 2220.08 ------------ Accuracy: 90.5%\n",
            "Step: 2139 ------------ Loss: 2219.77 ------------ Accuracy: 90.5%\n",
            "Step: 2140 ------------ Loss: 2219.47 ------------ Accuracy: 90.5%\n",
            "Step: 2141 ------------ Loss: 2219.17 ------------ Accuracy: 90.5%\n",
            "Step: 2142 ------------ Loss: 2218.87 ------------ Accuracy: 90.5%\n",
            "Step: 2143 ------------ Loss: 2218.57 ------------ Accuracy: 90.5%\n",
            "Step: 2144 ------------ Loss: 2218.27 ------------ Accuracy: 90.5%\n",
            "Step: 2145 ------------ Loss: 2217.97 ------------ Accuracy: 90.5%\n",
            "Step: 2146 ------------ Loss: 2217.67 ------------ Accuracy: 90.5%\n",
            "Step: 2147 ------------ Loss: 2217.37 ------------ Accuracy: 90.5%\n",
            "Step: 2148 ------------ Loss: 2217.07 ------------ Accuracy: 90.5%\n",
            "Step: 2149 ------------ Loss: 2216.77 ------------ Accuracy: 90.5%\n",
            "Step: 2150 ------------ Loss: 2216.47 ------------ Accuracy: 90.5%\n",
            "Step: 2151 ------------ Loss: 2216.17 ------------ Accuracy: 90.5%\n",
            "Step: 2152 ------------ Loss: 2215.87 ------------ Accuracy: 90.5%\n",
            "Step: 2153 ------------ Loss: 2215.57 ------------ Accuracy: 90.5%\n",
            "Step: 2154 ------------ Loss: 2215.28 ------------ Accuracy: 90.5%\n",
            "Step: 2155 ------------ Loss: 2214.98 ------------ Accuracy: 90.5%\n",
            "Step: 2156 ------------ Loss: 2214.68 ------------ Accuracy: 90.5%\n",
            "Step: 2157 ------------ Loss: 2214.38 ------------ Accuracy: 90.5%\n",
            "Step: 2158 ------------ Loss: 2214.09 ------------ Accuracy: 90.5%\n",
            "Step: 2159 ------------ Loss: 2213.79 ------------ Accuracy: 90.5%\n",
            "Step: 2160 ------------ Loss: 2213.49 ------------ Accuracy: 90.5%\n",
            "Step: 2161 ------------ Loss: 2213.2 ------------ Accuracy: 90.5%\n",
            "Step: 2162 ------------ Loss: 2212.9 ------------ Accuracy: 90.5%\n",
            "Step: 2163 ------------ Loss: 2212.6 ------------ Accuracy: 90.5%\n",
            "Step: 2164 ------------ Loss: 2212.31 ------------ Accuracy: 90.5%\n",
            "Step: 2165 ------------ Loss: 2212.01 ------------ Accuracy: 90.5%\n",
            "Step: 2166 ------------ Loss: 2211.72 ------------ Accuracy: 90.5%\n",
            "Step: 2167 ------------ Loss: 2211.42 ------------ Accuracy: 90.5%\n",
            "Step: 2168 ------------ Loss: 2211.13 ------------ Accuracy: 90.5%\n",
            "Step: 2169 ------------ Loss: 2210.83 ------------ Accuracy: 90.5%\n",
            "Step: 2170 ------------ Loss: 2210.54 ------------ Accuracy: 90.5%\n",
            "Step: 2171 ------------ Loss: 2210.24 ------------ Accuracy: 90.5%\n",
            "Step: 2172 ------------ Loss: 2209.95 ------------ Accuracy: 90.5%\n",
            "Step: 2173 ------------ Loss: 2209.65 ------------ Accuracy: 90.5%\n",
            "Step: 2174 ------------ Loss: 2209.36 ------------ Accuracy: 90.5%\n",
            "Step: 2175 ------------ Loss: 2209.07 ------------ Accuracy: 90.5%\n",
            "Step: 2176 ------------ Loss: 2208.77 ------------ Accuracy: 90.5%\n",
            "Step: 2177 ------------ Loss: 2208.48 ------------ Accuracy: 90.5%\n",
            "Step: 2178 ------------ Loss: 2208.19 ------------ Accuracy: 90.5%\n",
            "Step: 2179 ------------ Loss: 2207.89 ------------ Accuracy: 90.5%\n",
            "Step: 2180 ------------ Loss: 2207.6 ------------ Accuracy: 90.5%\n",
            "Step: 2181 ------------ Loss: 2207.31 ------------ Accuracy: 90.5%\n",
            "Step: 2182 ------------ Loss: 2207.02 ------------ Accuracy: 90.5%\n",
            "Step: 2183 ------------ Loss: 2206.73 ------------ Accuracy: 90.5%\n",
            "Step: 2184 ------------ Loss: 2206.44 ------------ Accuracy: 90.5%\n",
            "Step: 2185 ------------ Loss: 2206.14 ------------ Accuracy: 90.5%\n",
            "Step: 2186 ------------ Loss: 2205.85 ------------ Accuracy: 90.5%\n",
            "Step: 2187 ------------ Loss: 2205.56 ------------ Accuracy: 90.5%\n",
            "Step: 2188 ------------ Loss: 2205.27 ------------ Accuracy: 90.5%\n",
            "Step: 2189 ------------ Loss: 2204.98 ------------ Accuracy: 90.5%\n",
            "Step: 2190 ------------ Loss: 2204.69 ------------ Accuracy: 90.5%\n",
            "Step: 2191 ------------ Loss: 2204.4 ------------ Accuracy: 90.5%\n",
            "Step: 2192 ------------ Loss: 2204.11 ------------ Accuracy: 90.5%\n",
            "Step: 2193 ------------ Loss: 2203.82 ------------ Accuracy: 90.5%\n",
            "Step: 2194 ------------ Loss: 2203.53 ------------ Accuracy: 90.5%\n",
            "Step: 2195 ------------ Loss: 2203.24 ------------ Accuracy: 90.5%\n",
            "Step: 2196 ------------ Loss: 2202.95 ------------ Accuracy: 90.5%\n",
            "Step: 2197 ------------ Loss: 2202.67 ------------ Accuracy: 90.5%\n",
            "Step: 2198 ------------ Loss: 2202.38 ------------ Accuracy: 90.5%\n",
            "Step: 2199 ------------ Loss: 2202.09 ------------ Accuracy: 90.5%\n",
            "Step: 2200 ------------ Loss: 2201.8 ------------ Accuracy: 90.5%\n",
            "Step: 2201 ------------ Loss: 2201.51 ------------ Accuracy: 90.5%\n",
            "Step: 2202 ------------ Loss: 2201.23 ------------ Accuracy: 90.5%\n",
            "Step: 2203 ------------ Loss: 2200.94 ------------ Accuracy: 90.5%\n",
            "Step: 2204 ------------ Loss: 2200.65 ------------ Accuracy: 90.5%\n",
            "Step: 2205 ------------ Loss: 2200.36 ------------ Accuracy: 90.5%\n",
            "Step: 2206 ------------ Loss: 2200.08 ------------ Accuracy: 90.5%\n",
            "Step: 2207 ------------ Loss: 2199.79 ------------ Accuracy: 90.5%\n",
            "Step: 2208 ------------ Loss: 2199.51 ------------ Accuracy: 90.5%\n",
            "Step: 2209 ------------ Loss: 2199.22 ------------ Accuracy: 90.5%\n",
            "Step: 2210 ------------ Loss: 2198.93 ------------ Accuracy: 90.5%\n",
            "Step: 2211 ------------ Loss: 2198.65 ------------ Accuracy: 90.5%\n",
            "Step: 2212 ------------ Loss: 2198.36 ------------ Accuracy: 90.5%\n",
            "Step: 2213 ------------ Loss: 2198.08 ------------ Accuracy: 90.5%\n",
            "Step: 2214 ------------ Loss: 2197.79 ------------ Accuracy: 90.5%\n",
            "Step: 2215 ------------ Loss: 2197.51 ------------ Accuracy: 90.5%\n",
            "Step: 2216 ------------ Loss: 2197.22 ------------ Accuracy: 90.5%\n",
            "Step: 2217 ------------ Loss: 2196.94 ------------ Accuracy: 90.5%\n",
            "Step: 2218 ------------ Loss: 2196.65 ------------ Accuracy: 90.5%\n",
            "Step: 2219 ------------ Loss: 2196.37 ------------ Accuracy: 90.5%\n",
            "Step: 2220 ------------ Loss: 2196.09 ------------ Accuracy: 90.5%\n",
            "Step: 2221 ------------ Loss: 2195.8 ------------ Accuracy: 90.5%\n",
            "Step: 2222 ------------ Loss: 2195.52 ------------ Accuracy: 90.5%\n",
            "Step: 2223 ------------ Loss: 2195.24 ------------ Accuracy: 90.5%\n",
            "Step: 2224 ------------ Loss: 2194.95 ------------ Accuracy: 90.5%\n",
            "Step: 2225 ------------ Loss: 2194.67 ------------ Accuracy: 90.5%\n",
            "Step: 2226 ------------ Loss: 2194.39 ------------ Accuracy: 90.5%\n",
            "Step: 2227 ------------ Loss: 2194.11 ------------ Accuracy: 90.5%\n",
            "Step: 2228 ------------ Loss: 2193.82 ------------ Accuracy: 90.5%\n",
            "Step: 2229 ------------ Loss: 2193.54 ------------ Accuracy: 90.5%\n",
            "Step: 2230 ------------ Loss: 2193.26 ------------ Accuracy: 90.5%\n",
            "Step: 2231 ------------ Loss: 2192.98 ------------ Accuracy: 90.5%\n",
            "Step: 2232 ------------ Loss: 2192.7 ------------ Accuracy: 90.5%\n",
            "Step: 2233 ------------ Loss: 2192.42 ------------ Accuracy: 90.5%\n",
            "Step: 2234 ------------ Loss: 2192.14 ------------ Accuracy: 90.5%\n",
            "Step: 2235 ------------ Loss: 2191.86 ------------ Accuracy: 90.5%\n",
            "Step: 2236 ------------ Loss: 2191.58 ------------ Accuracy: 90.5%\n",
            "Step: 2237 ------------ Loss: 2191.3 ------------ Accuracy: 90.5%\n",
            "Step: 2238 ------------ Loss: 2191.02 ------------ Accuracy: 90.5%\n",
            "Step: 2239 ------------ Loss: 2190.74 ------------ Accuracy: 90.5%\n",
            "Step: 2240 ------------ Loss: 2190.46 ------------ Accuracy: 90.5%\n",
            "Step: 2241 ------------ Loss: 2190.18 ------------ Accuracy: 90.5%\n",
            "Step: 2242 ------------ Loss: 2189.9 ------------ Accuracy: 90.5%\n",
            "Step: 2243 ------------ Loss: 2189.62 ------------ Accuracy: 90.5%\n",
            "Step: 2244 ------------ Loss: 2189.34 ------------ Accuracy: 90.5%\n",
            "Step: 2245 ------------ Loss: 2189.06 ------------ Accuracy: 90.5%\n",
            "Step: 2246 ------------ Loss: 2188.78 ------------ Accuracy: 90.5%\n",
            "Step: 2247 ------------ Loss: 2188.51 ------------ Accuracy: 90.5%\n",
            "Step: 2248 ------------ Loss: 2188.23 ------------ Accuracy: 90.5%\n",
            "Step: 2249 ------------ Loss: 2187.95 ------------ Accuracy: 90.5%\n",
            "Step: 2250 ------------ Loss: 2187.67 ------------ Accuracy: 90.5%\n",
            "Step: 2251 ------------ Loss: 2187.4 ------------ Accuracy: 90.5%\n",
            "Step: 2252 ------------ Loss: 2187.12 ------------ Accuracy: 90.5%\n",
            "Step: 2253 ------------ Loss: 2186.84 ------------ Accuracy: 90.5%\n",
            "Step: 2254 ------------ Loss: 2186.56 ------------ Accuracy: 90.5%\n",
            "Step: 2255 ------------ Loss: 2186.29 ------------ Accuracy: 90.5%\n",
            "Step: 2256 ------------ Loss: 2186.01 ------------ Accuracy: 90.5%\n",
            "Step: 2257 ------------ Loss: 2185.74 ------------ Accuracy: 90.5%\n",
            "Step: 2258 ------------ Loss: 2185.46 ------------ Accuracy: 90.5%\n",
            "Step: 2259 ------------ Loss: 2185.18 ------------ Accuracy: 90.5%\n",
            "Step: 2260 ------------ Loss: 2184.91 ------------ Accuracy: 90.5%\n",
            "Step: 2261 ------------ Loss: 2184.63 ------------ Accuracy: 90.5%\n",
            "Step: 2262 ------------ Loss: 2184.36 ------------ Accuracy: 90.5%\n",
            "Step: 2263 ------------ Loss: 2184.08 ------------ Accuracy: 90.5%\n",
            "Step: 2264 ------------ Loss: 2183.81 ------------ Accuracy: 90.5%\n",
            "Step: 2265 ------------ Loss: 2183.53 ------------ Accuracy: 90.5%\n",
            "Step: 2266 ------------ Loss: 2183.26 ------------ Accuracy: 90.5%\n",
            "Step: 2267 ------------ Loss: 2182.99 ------------ Accuracy: 90.5%\n",
            "Step: 2268 ------------ Loss: 2182.71 ------------ Accuracy: 90.5%\n",
            "Step: 2269 ------------ Loss: 2182.44 ------------ Accuracy: 90.5%\n",
            "Step: 2270 ------------ Loss: 2182.17 ------------ Accuracy: 90.5%\n",
            "Step: 2271 ------------ Loss: 2181.89 ------------ Accuracy: 90.5%\n",
            "Step: 2272 ------------ Loss: 2181.62 ------------ Accuracy: 90.5%\n",
            "Step: 2273 ------------ Loss: 2181.35 ------------ Accuracy: 90.5%\n",
            "Step: 2274 ------------ Loss: 2181.07 ------------ Accuracy: 90.5%\n",
            "Step: 2275 ------------ Loss: 2180.8 ------------ Accuracy: 90.5%\n",
            "Step: 2276 ------------ Loss: 2180.53 ------------ Accuracy: 90.5%\n",
            "Step: 2277 ------------ Loss: 2180.26 ------------ Accuracy: 90.5%\n",
            "Step: 2278 ------------ Loss: 2179.99 ------------ Accuracy: 90.5%\n",
            "Step: 2279 ------------ Loss: 2179.71 ------------ Accuracy: 90.5%\n",
            "Step: 2280 ------------ Loss: 2179.44 ------------ Accuracy: 90.5%\n",
            "Step: 2281 ------------ Loss: 2179.17 ------------ Accuracy: 90.5%\n",
            "Step: 2282 ------------ Loss: 2178.9 ------------ Accuracy: 90.5%\n",
            "Step: 2283 ------------ Loss: 2178.63 ------------ Accuracy: 90.5%\n",
            "Step: 2284 ------------ Loss: 2178.36 ------------ Accuracy: 90.5%\n",
            "Step: 2285 ------------ Loss: 2178.09 ------------ Accuracy: 90.5%\n",
            "Step: 2286 ------------ Loss: 2177.82 ------------ Accuracy: 90.5%\n",
            "Step: 2287 ------------ Loss: 2177.55 ------------ Accuracy: 90.5%\n",
            "Step: 2288 ------------ Loss: 2177.28 ------------ Accuracy: 90.5%\n",
            "Step: 2289 ------------ Loss: 2177.01 ------------ Accuracy: 90.5%\n",
            "Step: 2290 ------------ Loss: 2176.74 ------------ Accuracy: 90.5%\n",
            "Step: 2291 ------------ Loss: 2176.47 ------------ Accuracy: 90.5%\n",
            "Step: 2292 ------------ Loss: 2176.2 ------------ Accuracy: 90.5%\n",
            "Step: 2293 ------------ Loss: 2175.93 ------------ Accuracy: 90.5%\n",
            "Step: 2294 ------------ Loss: 2175.66 ------------ Accuracy: 90.5%\n",
            "Step: 2295 ------------ Loss: 2175.39 ------------ Accuracy: 90.5%\n",
            "Step: 2296 ------------ Loss: 2175.13 ------------ Accuracy: 90.5%\n",
            "Step: 2297 ------------ Loss: 2174.86 ------------ Accuracy: 90.5%\n",
            "Step: 2298 ------------ Loss: 2174.59 ------------ Accuracy: 90.5%\n",
            "Step: 2299 ------------ Loss: 2174.32 ------------ Accuracy: 90.5%\n",
            "Step: 2300 ------------ Loss: 2174.05 ------------ Accuracy: 90.5%\n",
            "Step: 2301 ------------ Loss: 2173.79 ------------ Accuracy: 90.5%\n",
            "Step: 2302 ------------ Loss: 2173.52 ------------ Accuracy: 90.5%\n",
            "Step: 2303 ------------ Loss: 2173.25 ------------ Accuracy: 90.5%\n",
            "Step: 2304 ------------ Loss: 2172.99 ------------ Accuracy: 90.5%\n",
            "Step: 2305 ------------ Loss: 2172.72 ------------ Accuracy: 90.5%\n",
            "Step: 2306 ------------ Loss: 2172.45 ------------ Accuracy: 90.5%\n",
            "Step: 2307 ------------ Loss: 2172.19 ------------ Accuracy: 90.5%\n",
            "Step: 2308 ------------ Loss: 2171.92 ------------ Accuracy: 90.5%\n",
            "Step: 2309 ------------ Loss: 2171.65 ------------ Accuracy: 90.5%\n",
            "Step: 2310 ------------ Loss: 2171.39 ------------ Accuracy: 90.5%\n",
            "Step: 2311 ------------ Loss: 2171.12 ------------ Accuracy: 90.5%\n",
            "Step: 2312 ------------ Loss: 2170.86 ------------ Accuracy: 90.5%\n",
            "Step: 2313 ------------ Loss: 2170.59 ------------ Accuracy: 90.5%\n",
            "Step: 2314 ------------ Loss: 2170.33 ------------ Accuracy: 90.5%\n",
            "Step: 2315 ------------ Loss: 2170.06 ------------ Accuracy: 90.5%\n",
            "Step: 2316 ------------ Loss: 2169.8 ------------ Accuracy: 90.5%\n",
            "Step: 2317 ------------ Loss: 2169.53 ------------ Accuracy: 90.5%\n",
            "Step: 2318 ------------ Loss: 2169.27 ------------ Accuracy: 90.5%\n",
            "Step: 2319 ------------ Loss: 2169.01 ------------ Accuracy: 90.5%\n",
            "Step: 2320 ------------ Loss: 2168.74 ------------ Accuracy: 90.5%\n",
            "Step: 2321 ------------ Loss: 2168.48 ------------ Accuracy: 90.5%\n",
            "Step: 2322 ------------ Loss: 2168.22 ------------ Accuracy: 90.5%\n",
            "Step: 2323 ------------ Loss: 2167.95 ------------ Accuracy: 90.5%\n",
            "Step: 2324 ------------ Loss: 2167.69 ------------ Accuracy: 90.5%\n",
            "Step: 2325 ------------ Loss: 2167.43 ------------ Accuracy: 90.5%\n",
            "Step: 2326 ------------ Loss: 2167.16 ------------ Accuracy: 90.5%\n",
            "Step: 2327 ------------ Loss: 2166.9 ------------ Accuracy: 90.5%\n",
            "Step: 2328 ------------ Loss: 2166.64 ------------ Accuracy: 90.5%\n",
            "Step: 2329 ------------ Loss: 2166.38 ------------ Accuracy: 90.5%\n",
            "Step: 2330 ------------ Loss: 2166.12 ------------ Accuracy: 90.5%\n",
            "Step: 2331 ------------ Loss: 2165.85 ------------ Accuracy: 90.5%\n",
            "Step: 2332 ------------ Loss: 2165.59 ------------ Accuracy: 90.5%\n",
            "Step: 2333 ------------ Loss: 2165.33 ------------ Accuracy: 90.6%\n",
            "Step: 2334 ------------ Loss: 2165.07 ------------ Accuracy: 90.6%\n",
            "Step: 2335 ------------ Loss: 2164.81 ------------ Accuracy: 90.6%\n",
            "Step: 2336 ------------ Loss: 2164.55 ------------ Accuracy: 90.6%\n",
            "Step: 2337 ------------ Loss: 2164.29 ------------ Accuracy: 90.6%\n",
            "Step: 2338 ------------ Loss: 2164.03 ------------ Accuracy: 90.6%\n",
            "Step: 2339 ------------ Loss: 2163.77 ------------ Accuracy: 90.6%\n",
            "Step: 2340 ------------ Loss: 2163.51 ------------ Accuracy: 90.6%\n",
            "Step: 2341 ------------ Loss: 2163.25 ------------ Accuracy: 90.6%\n",
            "Step: 2342 ------------ Loss: 2162.99 ------------ Accuracy: 90.6%\n",
            "Step: 2343 ------------ Loss: 2162.73 ------------ Accuracy: 90.6%\n",
            "Step: 2344 ------------ Loss: 2162.47 ------------ Accuracy: 90.6%\n",
            "Step: 2345 ------------ Loss: 2162.21 ------------ Accuracy: 90.6%\n",
            "Step: 2346 ------------ Loss: 2161.95 ------------ Accuracy: 90.6%\n",
            "Step: 2347 ------------ Loss: 2161.69 ------------ Accuracy: 90.6%\n",
            "Step: 2348 ------------ Loss: 2161.43 ------------ Accuracy: 90.6%\n",
            "Step: 2349 ------------ Loss: 2161.18 ------------ Accuracy: 90.6%\n",
            "Step: 2350 ------------ Loss: 2160.92 ------------ Accuracy: 90.6%\n",
            "Step: 2351 ------------ Loss: 2160.66 ------------ Accuracy: 90.6%\n",
            "Step: 2352 ------------ Loss: 2160.4 ------------ Accuracy: 90.6%\n",
            "Step: 2353 ------------ Loss: 2160.14 ------------ Accuracy: 90.6%\n",
            "Step: 2354 ------------ Loss: 2159.89 ------------ Accuracy: 90.6%\n",
            "Step: 2355 ------------ Loss: 2159.63 ------------ Accuracy: 90.6%\n",
            "Step: 2356 ------------ Loss: 2159.37 ------------ Accuracy: 90.6%\n",
            "Step: 2357 ------------ Loss: 2159.12 ------------ Accuracy: 90.6%\n",
            "Step: 2358 ------------ Loss: 2158.86 ------------ Accuracy: 90.6%\n",
            "Step: 2359 ------------ Loss: 2158.6 ------------ Accuracy: 90.6%\n",
            "Step: 2360 ------------ Loss: 2158.35 ------------ Accuracy: 90.6%\n",
            "Step: 2361 ------------ Loss: 2158.09 ------------ Accuracy: 90.6%\n",
            "Step: 2362 ------------ Loss: 2157.83 ------------ Accuracy: 90.6%\n",
            "Step: 2363 ------------ Loss: 2157.58 ------------ Accuracy: 90.6%\n",
            "Step: 2364 ------------ Loss: 2157.32 ------------ Accuracy: 90.6%\n",
            "Step: 2365 ------------ Loss: 2157.07 ------------ Accuracy: 90.6%\n",
            "Step: 2366 ------------ Loss: 2156.81 ------------ Accuracy: 90.6%\n",
            "Step: 2367 ------------ Loss: 2156.56 ------------ Accuracy: 90.6%\n",
            "Step: 2368 ------------ Loss: 2156.3 ------------ Accuracy: 90.6%\n",
            "Step: 2369 ------------ Loss: 2156.05 ------------ Accuracy: 90.6%\n",
            "Step: 2370 ------------ Loss: 2155.79 ------------ Accuracy: 90.6%\n",
            "Step: 2371 ------------ Loss: 2155.54 ------------ Accuracy: 90.6%\n",
            "Step: 2372 ------------ Loss: 2155.28 ------------ Accuracy: 90.6%\n",
            "Step: 2373 ------------ Loss: 2155.03 ------------ Accuracy: 90.6%\n",
            "Step: 2374 ------------ Loss: 2154.78 ------------ Accuracy: 90.6%\n",
            "Step: 2375 ------------ Loss: 2154.52 ------------ Accuracy: 90.6%\n",
            "Step: 2376 ------------ Loss: 2154.27 ------------ Accuracy: 90.6%\n",
            "Step: 2377 ------------ Loss: 2154.02 ------------ Accuracy: 90.6%\n",
            "Step: 2378 ------------ Loss: 2153.76 ------------ Accuracy: 90.6%\n",
            "Step: 2379 ------------ Loss: 2153.51 ------------ Accuracy: 90.6%\n",
            "Step: 2380 ------------ Loss: 2153.26 ------------ Accuracy: 90.6%\n",
            "Step: 2381 ------------ Loss: 2153.0 ------------ Accuracy: 90.6%\n",
            "Step: 2382 ------------ Loss: 2152.75 ------------ Accuracy: 90.6%\n",
            "Step: 2383 ------------ Loss: 2152.5 ------------ Accuracy: 90.6%\n",
            "Step: 2384 ------------ Loss: 2152.25 ------------ Accuracy: 90.6%\n",
            "Step: 2385 ------------ Loss: 2151.99 ------------ Accuracy: 90.6%\n",
            "Step: 2386 ------------ Loss: 2151.74 ------------ Accuracy: 90.6%\n",
            "Step: 2387 ------------ Loss: 2151.49 ------------ Accuracy: 90.6%\n",
            "Step: 2388 ------------ Loss: 2151.24 ------------ Accuracy: 90.6%\n",
            "Step: 2389 ------------ Loss: 2150.99 ------------ Accuracy: 90.6%\n",
            "Step: 2390 ------------ Loss: 2150.74 ------------ Accuracy: 90.6%\n",
            "Step: 2391 ------------ Loss: 2150.49 ------------ Accuracy: 90.6%\n",
            "Step: 2392 ------------ Loss: 2150.24 ------------ Accuracy: 90.6%\n",
            "Step: 2393 ------------ Loss: 2149.99 ------------ Accuracy: 90.6%\n",
            "Step: 2394 ------------ Loss: 2149.74 ------------ Accuracy: 90.6%\n",
            "Step: 2395 ------------ Loss: 2149.49 ------------ Accuracy: 90.6%\n",
            "Step: 2396 ------------ Loss: 2149.24 ------------ Accuracy: 90.6%\n",
            "Step: 2397 ------------ Loss: 2148.99 ------------ Accuracy: 90.6%\n",
            "Step: 2398 ------------ Loss: 2148.74 ------------ Accuracy: 90.6%\n",
            "Step: 2399 ------------ Loss: 2148.49 ------------ Accuracy: 90.6%\n",
            "Step: 2400 ------------ Loss: 2148.24 ------------ Accuracy: 90.6%\n",
            "Step: 2401 ------------ Loss: 2147.99 ------------ Accuracy: 90.6%\n",
            "Step: 2402 ------------ Loss: 2147.74 ------------ Accuracy: 90.6%\n",
            "Step: 2403 ------------ Loss: 2147.49 ------------ Accuracy: 90.6%\n",
            "Step: 2404 ------------ Loss: 2147.24 ------------ Accuracy: 90.6%\n",
            "Step: 2405 ------------ Loss: 2146.99 ------------ Accuracy: 90.6%\n",
            "Step: 2406 ------------ Loss: 2146.74 ------------ Accuracy: 90.6%\n",
            "Step: 2407 ------------ Loss: 2146.5 ------------ Accuracy: 90.6%\n",
            "Step: 2408 ------------ Loss: 2146.25 ------------ Accuracy: 90.6%\n",
            "Step: 2409 ------------ Loss: 2146.0 ------------ Accuracy: 90.6%\n",
            "Step: 2410 ------------ Loss: 2145.75 ------------ Accuracy: 90.6%\n",
            "Step: 2411 ------------ Loss: 2145.51 ------------ Accuracy: 90.6%\n",
            "Step: 2412 ------------ Loss: 2145.26 ------------ Accuracy: 90.6%\n",
            "Step: 2413 ------------ Loss: 2145.01 ------------ Accuracy: 90.6%\n",
            "Step: 2414 ------------ Loss: 2144.76 ------------ Accuracy: 90.6%\n",
            "Step: 2415 ------------ Loss: 2144.52 ------------ Accuracy: 90.6%\n",
            "Step: 2416 ------------ Loss: 2144.27 ------------ Accuracy: 90.6%\n",
            "Step: 2417 ------------ Loss: 2144.03 ------------ Accuracy: 90.6%\n",
            "Step: 2418 ------------ Loss: 2143.78 ------------ Accuracy: 90.6%\n",
            "Step: 2419 ------------ Loss: 2143.53 ------------ Accuracy: 90.6%\n",
            "Step: 2420 ------------ Loss: 2143.29 ------------ Accuracy: 90.6%\n",
            "Step: 2421 ------------ Loss: 2143.04 ------------ Accuracy: 90.6%\n",
            "Step: 2422 ------------ Loss: 2142.8 ------------ Accuracy: 90.6%\n",
            "Step: 2423 ------------ Loss: 2142.55 ------------ Accuracy: 90.6%\n",
            "Step: 2424 ------------ Loss: 2142.31 ------------ Accuracy: 90.6%\n",
            "Step: 2425 ------------ Loss: 2142.06 ------------ Accuracy: 90.6%\n",
            "Step: 2426 ------------ Loss: 2141.82 ------------ Accuracy: 90.6%\n",
            "Step: 2427 ------------ Loss: 2141.57 ------------ Accuracy: 90.6%\n",
            "Step: 2428 ------------ Loss: 2141.33 ------------ Accuracy: 90.6%\n",
            "Step: 2429 ------------ Loss: 2141.08 ------------ Accuracy: 90.6%\n",
            "Step: 2430 ------------ Loss: 2140.84 ------------ Accuracy: 90.6%\n",
            "Step: 2431 ------------ Loss: 2140.59 ------------ Accuracy: 90.6%\n",
            "Step: 2432 ------------ Loss: 2140.35 ------------ Accuracy: 90.6%\n",
            "Step: 2433 ------------ Loss: 2140.11 ------------ Accuracy: 90.6%\n",
            "Step: 2434 ------------ Loss: 2139.86 ------------ Accuracy: 90.6%\n",
            "Step: 2435 ------------ Loss: 2139.62 ------------ Accuracy: 90.6%\n",
            "Step: 2436 ------------ Loss: 2139.38 ------------ Accuracy: 90.6%\n",
            "Step: 2437 ------------ Loss: 2139.13 ------------ Accuracy: 90.6%\n",
            "Step: 2438 ------------ Loss: 2138.89 ------------ Accuracy: 90.6%\n",
            "Step: 2439 ------------ Loss: 2138.65 ------------ Accuracy: 90.6%\n",
            "Step: 2440 ------------ Loss: 2138.4 ------------ Accuracy: 90.6%\n",
            "Step: 2441 ------------ Loss: 2138.16 ------------ Accuracy: 90.6%\n",
            "Step: 2442 ------------ Loss: 2137.92 ------------ Accuracy: 90.6%\n",
            "Step: 2443 ------------ Loss: 2137.68 ------------ Accuracy: 90.6%\n",
            "Step: 2444 ------------ Loss: 2137.44 ------------ Accuracy: 90.6%\n",
            "Step: 2445 ------------ Loss: 2137.19 ------------ Accuracy: 90.6%\n",
            "Step: 2446 ------------ Loss: 2136.95 ------------ Accuracy: 90.6%\n",
            "Step: 2447 ------------ Loss: 2136.71 ------------ Accuracy: 90.6%\n",
            "Step: 2448 ------------ Loss: 2136.47 ------------ Accuracy: 90.6%\n",
            "Step: 2449 ------------ Loss: 2136.23 ------------ Accuracy: 90.6%\n",
            "Step: 2450 ------------ Loss: 2135.99 ------------ Accuracy: 90.6%\n",
            "Step: 2451 ------------ Loss: 2135.75 ------------ Accuracy: 90.6%\n",
            "Step: 2452 ------------ Loss: 2135.51 ------------ Accuracy: 90.6%\n",
            "Step: 2453 ------------ Loss: 2135.27 ------------ Accuracy: 90.6%\n",
            "Step: 2454 ------------ Loss: 2135.03 ------------ Accuracy: 90.6%\n",
            "Step: 2455 ------------ Loss: 2134.79 ------------ Accuracy: 90.6%\n",
            "Step: 2456 ------------ Loss: 2134.55 ------------ Accuracy: 90.6%\n",
            "Step: 2457 ------------ Loss: 2134.31 ------------ Accuracy: 90.6%\n",
            "Step: 2458 ------------ Loss: 2134.07 ------------ Accuracy: 90.6%\n",
            "Step: 2459 ------------ Loss: 2133.83 ------------ Accuracy: 90.6%\n",
            "Step: 2460 ------------ Loss: 2133.59 ------------ Accuracy: 90.6%\n",
            "Step: 2461 ------------ Loss: 2133.35 ------------ Accuracy: 90.6%\n",
            "Step: 2462 ------------ Loss: 2133.11 ------------ Accuracy: 90.6%\n",
            "Step: 2463 ------------ Loss: 2132.87 ------------ Accuracy: 90.6%\n",
            "Step: 2464 ------------ Loss: 2132.63 ------------ Accuracy: 90.6%\n",
            "Step: 2465 ------------ Loss: 2132.39 ------------ Accuracy: 90.6%\n",
            "Step: 2466 ------------ Loss: 2132.16 ------------ Accuracy: 90.6%\n",
            "Step: 2467 ------------ Loss: 2131.92 ------------ Accuracy: 90.6%\n",
            "Step: 2468 ------------ Loss: 2131.68 ------------ Accuracy: 90.6%\n",
            "Step: 2469 ------------ Loss: 2131.44 ------------ Accuracy: 90.6%\n",
            "Step: 2470 ------------ Loss: 2131.2 ------------ Accuracy: 90.6%\n",
            "Step: 2471 ------------ Loss: 2130.97 ------------ Accuracy: 90.6%\n",
            "Step: 2472 ------------ Loss: 2130.73 ------------ Accuracy: 90.6%\n",
            "Step: 2473 ------------ Loss: 2130.49 ------------ Accuracy: 90.6%\n",
            "Step: 2474 ------------ Loss: 2130.26 ------------ Accuracy: 90.6%\n",
            "Step: 2475 ------------ Loss: 2130.02 ------------ Accuracy: 90.6%\n",
            "Step: 2476 ------------ Loss: 2129.78 ------------ Accuracy: 90.6%\n",
            "Step: 2477 ------------ Loss: 2129.55 ------------ Accuracy: 90.6%\n",
            "Step: 2478 ------------ Loss: 2129.31 ------------ Accuracy: 90.6%\n",
            "Step: 2479 ------------ Loss: 2129.07 ------------ Accuracy: 90.6%\n",
            "Step: 2480 ------------ Loss: 2128.84 ------------ Accuracy: 90.6%\n",
            "Step: 2481 ------------ Loss: 2128.6 ------------ Accuracy: 90.6%\n",
            "Step: 2482 ------------ Loss: 2128.37 ------------ Accuracy: 90.6%\n",
            "Step: 2483 ------------ Loss: 2128.13 ------------ Accuracy: 90.6%\n",
            "Step: 2484 ------------ Loss: 2127.89 ------------ Accuracy: 90.6%\n",
            "Step: 2485 ------------ Loss: 2127.66 ------------ Accuracy: 90.6%\n",
            "Step: 2486 ------------ Loss: 2127.42 ------------ Accuracy: 90.6%\n",
            "Step: 2487 ------------ Loss: 2127.19 ------------ Accuracy: 90.6%\n",
            "Step: 2488 ------------ Loss: 2126.95 ------------ Accuracy: 90.6%\n",
            "Step: 2489 ------------ Loss: 2126.72 ------------ Accuracy: 90.6%\n",
            "Step: 2490 ------------ Loss: 2126.48 ------------ Accuracy: 90.6%\n",
            "Step: 2491 ------------ Loss: 2126.25 ------------ Accuracy: 90.6%\n",
            "Step: 2492 ------------ Loss: 2126.02 ------------ Accuracy: 90.6%\n",
            "Step: 2493 ------------ Loss: 2125.78 ------------ Accuracy: 90.6%\n",
            "Step: 2494 ------------ Loss: 2125.55 ------------ Accuracy: 90.6%\n",
            "Step: 2495 ------------ Loss: 2125.31 ------------ Accuracy: 90.6%\n",
            "Step: 2496 ------------ Loss: 2125.08 ------------ Accuracy: 90.6%\n",
            "Step: 2497 ------------ Loss: 2124.85 ------------ Accuracy: 90.6%\n",
            "Step: 2498 ------------ Loss: 2124.61 ------------ Accuracy: 90.6%\n",
            "Step: 2499 ------------ Loss: 2124.38 ------------ Accuracy: 90.6%\n",
            "Step: 2500 ------------ Loss: 2124.15 ------------ Accuracy: 90.6%\n",
            "Step: 2501 ------------ Loss: 2123.92 ------------ Accuracy: 90.6%\n",
            "Step: 2502 ------------ Loss: 2123.68 ------------ Accuracy: 90.6%\n",
            "Step: 2503 ------------ Loss: 2123.45 ------------ Accuracy: 90.6%\n",
            "Step: 2504 ------------ Loss: 2123.22 ------------ Accuracy: 90.6%\n",
            "Step: 2505 ------------ Loss: 2122.99 ------------ Accuracy: 90.6%\n",
            "Step: 2506 ------------ Loss: 2122.75 ------------ Accuracy: 90.6%\n",
            "Step: 2507 ------------ Loss: 2122.52 ------------ Accuracy: 90.6%\n",
            "Step: 2508 ------------ Loss: 2122.29 ------------ Accuracy: 90.6%\n",
            "Step: 2509 ------------ Loss: 2122.06 ------------ Accuracy: 90.6%\n",
            "Step: 2510 ------------ Loss: 2121.83 ------------ Accuracy: 90.6%\n",
            "Step: 2511 ------------ Loss: 2121.6 ------------ Accuracy: 90.6%\n",
            "Step: 2512 ------------ Loss: 2121.37 ------------ Accuracy: 90.6%\n",
            "Step: 2513 ------------ Loss: 2121.13 ------------ Accuracy: 90.6%\n",
            "Step: 2514 ------------ Loss: 2120.9 ------------ Accuracy: 90.6%\n",
            "Step: 2515 ------------ Loss: 2120.67 ------------ Accuracy: 90.6%\n",
            "Step: 2516 ------------ Loss: 2120.44 ------------ Accuracy: 90.6%\n",
            "Step: 2517 ------------ Loss: 2120.21 ------------ Accuracy: 90.6%\n",
            "Step: 2518 ------------ Loss: 2119.98 ------------ Accuracy: 90.6%\n",
            "Step: 2519 ------------ Loss: 2119.75 ------------ Accuracy: 90.6%\n",
            "Step: 2520 ------------ Loss: 2119.52 ------------ Accuracy: 90.6%\n",
            "Step: 2521 ------------ Loss: 2119.29 ------------ Accuracy: 90.6%\n",
            "Step: 2522 ------------ Loss: 2119.06 ------------ Accuracy: 90.6%\n",
            "Step: 2523 ------------ Loss: 2118.83 ------------ Accuracy: 90.6%\n",
            "Step: 2524 ------------ Loss: 2118.6 ------------ Accuracy: 90.6%\n",
            "Step: 2525 ------------ Loss: 2118.38 ------------ Accuracy: 90.6%\n",
            "Step: 2526 ------------ Loss: 2118.15 ------------ Accuracy: 90.6%\n",
            "Step: 2527 ------------ Loss: 2117.92 ------------ Accuracy: 90.6%\n",
            "Step: 2528 ------------ Loss: 2117.69 ------------ Accuracy: 90.6%\n",
            "Step: 2529 ------------ Loss: 2117.46 ------------ Accuracy: 90.6%\n",
            "Step: 2530 ------------ Loss: 2117.23 ------------ Accuracy: 90.6%\n",
            "Step: 2531 ------------ Loss: 2117.0 ------------ Accuracy: 90.6%\n",
            "Step: 2532 ------------ Loss: 2116.78 ------------ Accuracy: 90.6%\n",
            "Step: 2533 ------------ Loss: 2116.55 ------------ Accuracy: 90.6%\n",
            "Step: 2534 ------------ Loss: 2116.32 ------------ Accuracy: 90.6%\n",
            "Step: 2535 ------------ Loss: 2116.09 ------------ Accuracy: 90.6%\n",
            "Step: 2536 ------------ Loss: 2115.87 ------------ Accuracy: 90.6%\n",
            "Step: 2537 ------------ Loss: 2115.64 ------------ Accuracy: 90.6%\n",
            "Step: 2538 ------------ Loss: 2115.41 ------------ Accuracy: 90.6%\n",
            "Step: 2539 ------------ Loss: 2115.18 ------------ Accuracy: 90.6%\n",
            "Step: 2540 ------------ Loss: 2114.96 ------------ Accuracy: 90.6%\n",
            "Step: 2541 ------------ Loss: 2114.73 ------------ Accuracy: 90.6%\n",
            "Step: 2542 ------------ Loss: 2114.5 ------------ Accuracy: 90.6%\n",
            "Step: 2543 ------------ Loss: 2114.28 ------------ Accuracy: 90.6%\n",
            "Step: 2544 ------------ Loss: 2114.05 ------------ Accuracy: 90.6%\n",
            "Step: 2545 ------------ Loss: 2113.83 ------------ Accuracy: 90.6%\n",
            "Step: 2546 ------------ Loss: 2113.6 ------------ Accuracy: 90.6%\n",
            "Step: 2547 ------------ Loss: 2113.37 ------------ Accuracy: 90.6%\n",
            "Step: 2548 ------------ Loss: 2113.15 ------------ Accuracy: 90.6%\n",
            "Step: 2549 ------------ Loss: 2112.92 ------------ Accuracy: 90.6%\n",
            "Step: 2550 ------------ Loss: 2112.7 ------------ Accuracy: 90.6%\n",
            "Step: 2551 ------------ Loss: 2112.47 ------------ Accuracy: 90.6%\n",
            "Step: 2552 ------------ Loss: 2112.25 ------------ Accuracy: 90.6%\n",
            "Step: 2553 ------------ Loss: 2112.02 ------------ Accuracy: 90.6%\n",
            "Step: 2554 ------------ Loss: 2111.8 ------------ Accuracy: 90.6%\n",
            "Step: 2555 ------------ Loss: 2111.57 ------------ Accuracy: 90.6%\n",
            "Step: 2556 ------------ Loss: 2111.35 ------------ Accuracy: 90.6%\n",
            "Step: 2557 ------------ Loss: 2111.12 ------------ Accuracy: 90.6%\n",
            "Step: 2558 ------------ Loss: 2110.9 ------------ Accuracy: 90.6%\n",
            "Step: 2559 ------------ Loss: 2110.68 ------------ Accuracy: 90.6%\n",
            "Step: 2560 ------------ Loss: 2110.45 ------------ Accuracy: 90.6%\n",
            "Step: 2561 ------------ Loss: 2110.23 ------------ Accuracy: 90.6%\n",
            "Step: 2562 ------------ Loss: 2110.0 ------------ Accuracy: 90.6%\n",
            "Step: 2563 ------------ Loss: 2109.78 ------------ Accuracy: 90.6%\n",
            "Step: 2564 ------------ Loss: 2109.56 ------------ Accuracy: 90.6%\n",
            "Step: 2565 ------------ Loss: 2109.33 ------------ Accuracy: 90.6%\n",
            "Step: 2566 ------------ Loss: 2109.11 ------------ Accuracy: 90.6%\n",
            "Step: 2567 ------------ Loss: 2108.89 ------------ Accuracy: 90.6%\n",
            "Step: 2568 ------------ Loss: 2108.67 ------------ Accuracy: 90.6%\n",
            "Step: 2569 ------------ Loss: 2108.44 ------------ Accuracy: 90.6%\n",
            "Step: 2570 ------------ Loss: 2108.22 ------------ Accuracy: 90.6%\n",
            "Step: 2571 ------------ Loss: 2108.0 ------------ Accuracy: 90.6%\n",
            "Step: 2572 ------------ Loss: 2107.78 ------------ Accuracy: 90.6%\n",
            "Step: 2573 ------------ Loss: 2107.55 ------------ Accuracy: 90.6%\n",
            "Step: 2574 ------------ Loss: 2107.33 ------------ Accuracy: 90.6%\n",
            "Step: 2575 ------------ Loss: 2107.11 ------------ Accuracy: 90.6%\n",
            "Step: 2576 ------------ Loss: 2106.89 ------------ Accuracy: 90.6%\n",
            "Step: 2577 ------------ Loss: 2106.67 ------------ Accuracy: 90.6%\n",
            "Step: 2578 ------------ Loss: 2106.45 ------------ Accuracy: 90.6%\n",
            "Step: 2579 ------------ Loss: 2106.23 ------------ Accuracy: 90.6%\n",
            "Step: 2580 ------------ Loss: 2106.0 ------------ Accuracy: 90.6%\n",
            "Step: 2581 ------------ Loss: 2105.78 ------------ Accuracy: 90.6%\n",
            "Step: 2582 ------------ Loss: 2105.56 ------------ Accuracy: 90.6%\n",
            "Step: 2583 ------------ Loss: 2105.34 ------------ Accuracy: 90.6%\n",
            "Step: 2584 ------------ Loss: 2105.12 ------------ Accuracy: 90.6%\n",
            "Step: 2585 ------------ Loss: 2104.9 ------------ Accuracy: 90.6%\n",
            "Step: 2586 ------------ Loss: 2104.68 ------------ Accuracy: 90.6%\n",
            "Step: 2587 ------------ Loss: 2104.46 ------------ Accuracy: 90.6%\n",
            "Step: 2588 ------------ Loss: 2104.24 ------------ Accuracy: 90.6%\n",
            "Step: 2589 ------------ Loss: 2104.02 ------------ Accuracy: 90.6%\n",
            "Step: 2590 ------------ Loss: 2103.8 ------------ Accuracy: 90.6%\n",
            "Step: 2591 ------------ Loss: 2103.58 ------------ Accuracy: 90.6%\n",
            "Step: 2592 ------------ Loss: 2103.36 ------------ Accuracy: 90.6%\n",
            "Step: 2593 ------------ Loss: 2103.14 ------------ Accuracy: 90.6%\n",
            "Step: 2594 ------------ Loss: 2102.93 ------------ Accuracy: 90.6%\n",
            "Step: 2595 ------------ Loss: 2102.71 ------------ Accuracy: 90.6%\n",
            "Step: 2596 ------------ Loss: 2102.49 ------------ Accuracy: 90.6%\n",
            "Step: 2597 ------------ Loss: 2102.27 ------------ Accuracy: 90.6%\n",
            "Step: 2598 ------------ Loss: 2102.05 ------------ Accuracy: 90.6%\n",
            "Step: 2599 ------------ Loss: 2101.83 ------------ Accuracy: 90.6%\n",
            "Step: 2600 ------------ Loss: 2101.61 ------------ Accuracy: 90.6%\n",
            "Step: 2601 ------------ Loss: 2101.4 ------------ Accuracy: 90.6%\n",
            "Step: 2602 ------------ Loss: 2101.18 ------------ Accuracy: 90.6%\n",
            "Step: 2603 ------------ Loss: 2100.96 ------------ Accuracy: 90.6%\n",
            "Step: 2604 ------------ Loss: 2100.74 ------------ Accuracy: 90.6%\n",
            "Step: 2605 ------------ Loss: 2100.53 ------------ Accuracy: 90.6%\n",
            "Step: 2606 ------------ Loss: 2100.31 ------------ Accuracy: 90.6%\n",
            "Step: 2607 ------------ Loss: 2100.09 ------------ Accuracy: 90.6%\n",
            "Step: 2608 ------------ Loss: 2099.87 ------------ Accuracy: 90.6%\n",
            "Step: 2609 ------------ Loss: 2099.66 ------------ Accuracy: 90.6%\n",
            "Step: 2610 ------------ Loss: 2099.44 ------------ Accuracy: 90.6%\n",
            "Step: 2611 ------------ Loss: 2099.22 ------------ Accuracy: 90.6%\n",
            "Step: 2612 ------------ Loss: 2099.01 ------------ Accuracy: 90.6%\n",
            "Step: 2613 ------------ Loss: 2098.79 ------------ Accuracy: 90.6%\n",
            "Step: 2614 ------------ Loss: 2098.57 ------------ Accuracy: 90.6%\n",
            "Step: 2615 ------------ Loss: 2098.36 ------------ Accuracy: 90.6%\n",
            "Step: 2616 ------------ Loss: 2098.14 ------------ Accuracy: 90.6%\n",
            "Step: 2617 ------------ Loss: 2097.93 ------------ Accuracy: 90.6%\n",
            "Step: 2618 ------------ Loss: 2097.71 ------------ Accuracy: 90.6%\n",
            "Step: 2619 ------------ Loss: 2097.5 ------------ Accuracy: 90.6%\n",
            "Step: 2620 ------------ Loss: 2097.28 ------------ Accuracy: 90.6%\n",
            "Step: 2621 ------------ Loss: 2097.06 ------------ Accuracy: 90.6%\n",
            "Step: 2622 ------------ Loss: 2096.85 ------------ Accuracy: 90.6%\n",
            "Step: 2623 ------------ Loss: 2096.63 ------------ Accuracy: 90.6%\n",
            "Step: 2624 ------------ Loss: 2096.42 ------------ Accuracy: 90.6%\n",
            "Step: 2625 ------------ Loss: 2096.21 ------------ Accuracy: 90.6%\n",
            "Step: 2626 ------------ Loss: 2095.99 ------------ Accuracy: 90.6%\n",
            "Step: 2627 ------------ Loss: 2095.78 ------------ Accuracy: 90.6%\n",
            "Step: 2628 ------------ Loss: 2095.56 ------------ Accuracy: 90.6%\n",
            "Step: 2629 ------------ Loss: 2095.35 ------------ Accuracy: 90.6%\n",
            "Step: 2630 ------------ Loss: 2095.13 ------------ Accuracy: 90.6%\n",
            "Step: 2631 ------------ Loss: 2094.92 ------------ Accuracy: 90.6%\n",
            "Step: 2632 ------------ Loss: 2094.71 ------------ Accuracy: 90.6%\n",
            "Step: 2633 ------------ Loss: 2094.49 ------------ Accuracy: 90.6%\n",
            "Step: 2634 ------------ Loss: 2094.28 ------------ Accuracy: 90.6%\n",
            "Step: 2635 ------------ Loss: 2094.07 ------------ Accuracy: 90.6%\n",
            "Step: 2636 ------------ Loss: 2093.85 ------------ Accuracy: 90.6%\n",
            "Step: 2637 ------------ Loss: 2093.64 ------------ Accuracy: 90.6%\n",
            "Step: 2638 ------------ Loss: 2093.43 ------------ Accuracy: 90.6%\n",
            "Step: 2639 ------------ Loss: 2093.21 ------------ Accuracy: 90.6%\n",
            "Step: 2640 ------------ Loss: 2093.0 ------------ Accuracy: 90.6%\n",
            "Step: 2641 ------------ Loss: 2092.79 ------------ Accuracy: 90.6%\n",
            "Step: 2642 ------------ Loss: 2092.58 ------------ Accuracy: 90.6%\n",
            "Step: 2643 ------------ Loss: 2092.36 ------------ Accuracy: 90.6%\n",
            "Step: 2644 ------------ Loss: 2092.15 ------------ Accuracy: 90.6%\n",
            "Step: 2645 ------------ Loss: 2091.94 ------------ Accuracy: 90.6%\n",
            "Step: 2646 ------------ Loss: 2091.73 ------------ Accuracy: 90.6%\n",
            "Step: 2647 ------------ Loss: 2091.52 ------------ Accuracy: 90.6%\n",
            "Step: 2648 ------------ Loss: 2091.3 ------------ Accuracy: 90.6%\n",
            "Step: 2649 ------------ Loss: 2091.09 ------------ Accuracy: 90.6%\n",
            "Step: 2650 ------------ Loss: 2090.88 ------------ Accuracy: 90.6%\n",
            "Step: 2651 ------------ Loss: 2090.67 ------------ Accuracy: 90.6%\n",
            "Step: 2652 ------------ Loss: 2090.46 ------------ Accuracy: 90.6%\n",
            "Step: 2653 ------------ Loss: 2090.25 ------------ Accuracy: 90.6%\n",
            "Step: 2654 ------------ Loss: 2090.04 ------------ Accuracy: 90.6%\n",
            "Step: 2655 ------------ Loss: 2089.83 ------------ Accuracy: 90.6%\n",
            "Step: 2656 ------------ Loss: 2089.62 ------------ Accuracy: 90.6%\n",
            "Step: 2657 ------------ Loss: 2089.41 ------------ Accuracy: 90.6%\n",
            "Step: 2658 ------------ Loss: 2089.2 ------------ Accuracy: 90.6%\n",
            "Step: 2659 ------------ Loss: 2088.99 ------------ Accuracy: 90.6%\n",
            "Step: 2660 ------------ Loss: 2088.78 ------------ Accuracy: 90.6%\n",
            "Step: 2661 ------------ Loss: 2088.57 ------------ Accuracy: 90.6%\n",
            "Step: 2662 ------------ Loss: 2088.36 ------------ Accuracy: 90.6%\n",
            "Step: 2663 ------------ Loss: 2088.15 ------------ Accuracy: 90.6%\n",
            "Step: 2664 ------------ Loss: 2087.94 ------------ Accuracy: 90.6%\n",
            "Step: 2665 ------------ Loss: 2087.73 ------------ Accuracy: 90.6%\n",
            "Step: 2666 ------------ Loss: 2087.52 ------------ Accuracy: 90.6%\n",
            "Step: 2667 ------------ Loss: 2087.31 ------------ Accuracy: 90.6%\n",
            "Step: 2668 ------------ Loss: 2087.1 ------------ Accuracy: 90.6%\n",
            "Step: 2669 ------------ Loss: 2086.89 ------------ Accuracy: 90.6%\n",
            "Step: 2670 ------------ Loss: 2086.68 ------------ Accuracy: 90.6%\n",
            "Step: 2671 ------------ Loss: 2086.47 ------------ Accuracy: 90.6%\n",
            "Step: 2672 ------------ Loss: 2086.27 ------------ Accuracy: 90.6%\n",
            "Step: 2673 ------------ Loss: 2086.06 ------------ Accuracy: 90.6%\n",
            "Step: 2674 ------------ Loss: 2085.85 ------------ Accuracy: 90.6%\n",
            "Step: 2675 ------------ Loss: 2085.64 ------------ Accuracy: 90.6%\n",
            "Step: 2676 ------------ Loss: 2085.43 ------------ Accuracy: 90.6%\n",
            "Step: 2677 ------------ Loss: 2085.23 ------------ Accuracy: 90.6%\n",
            "Step: 2678 ------------ Loss: 2085.02 ------------ Accuracy: 90.6%\n",
            "Step: 2679 ------------ Loss: 2084.81 ------------ Accuracy: 90.6%\n",
            "Step: 2680 ------------ Loss: 2084.6 ------------ Accuracy: 90.6%\n",
            "Step: 2681 ------------ Loss: 2084.4 ------------ Accuracy: 90.6%\n",
            "Step: 2682 ------------ Loss: 2084.19 ------------ Accuracy: 90.6%\n",
            "Step: 2683 ------------ Loss: 2083.98 ------------ Accuracy: 90.6%\n",
            "Step: 2684 ------------ Loss: 2083.77 ------------ Accuracy: 90.6%\n",
            "Step: 2685 ------------ Loss: 2083.57 ------------ Accuracy: 90.6%\n",
            "Step: 2686 ------------ Loss: 2083.36 ------------ Accuracy: 90.6%\n",
            "Step: 2687 ------------ Loss: 2083.16 ------------ Accuracy: 90.6%\n",
            "Step: 2688 ------------ Loss: 2082.95 ------------ Accuracy: 90.6%\n",
            "Step: 2689 ------------ Loss: 2082.74 ------------ Accuracy: 90.6%\n",
            "Step: 2690 ------------ Loss: 2082.54 ------------ Accuracy: 90.6%\n",
            "Step: 2691 ------------ Loss: 2082.33 ------------ Accuracy: 90.6%\n",
            "Step: 2692 ------------ Loss: 2082.12 ------------ Accuracy: 90.6%\n",
            "Step: 2693 ------------ Loss: 2081.92 ------------ Accuracy: 90.6%\n",
            "Step: 2694 ------------ Loss: 2081.71 ------------ Accuracy: 90.6%\n",
            "Step: 2695 ------------ Loss: 2081.51 ------------ Accuracy: 90.6%\n",
            "Step: 2696 ------------ Loss: 2081.3 ------------ Accuracy: 90.6%\n",
            "Step: 2697 ------------ Loss: 2081.1 ------------ Accuracy: 90.6%\n",
            "Step: 2698 ------------ Loss: 2080.89 ------------ Accuracy: 90.6%\n",
            "Step: 2699 ------------ Loss: 2080.69 ------------ Accuracy: 90.6%\n",
            "Step: 2700 ------------ Loss: 2080.48 ------------ Accuracy: 90.6%\n",
            "Step: 2701 ------------ Loss: 2080.28 ------------ Accuracy: 90.6%\n",
            "Step: 2702 ------------ Loss: 2080.07 ------------ Accuracy: 90.6%\n",
            "Step: 2703 ------------ Loss: 2079.87 ------------ Accuracy: 90.6%\n",
            "Step: 2704 ------------ Loss: 2079.66 ------------ Accuracy: 90.6%\n",
            "Step: 2705 ------------ Loss: 2079.46 ------------ Accuracy: 90.6%\n",
            "Step: 2706 ------------ Loss: 2079.26 ------------ Accuracy: 90.6%\n",
            "Step: 2707 ------------ Loss: 2079.05 ------------ Accuracy: 90.6%\n",
            "Step: 2708 ------------ Loss: 2078.85 ------------ Accuracy: 90.6%\n",
            "Step: 2709 ------------ Loss: 2078.64 ------------ Accuracy: 90.6%\n",
            "Step: 2710 ------------ Loss: 2078.44 ------------ Accuracy: 90.6%\n",
            "Step: 2711 ------------ Loss: 2078.24 ------------ Accuracy: 90.6%\n",
            "Step: 2712 ------------ Loss: 2078.03 ------------ Accuracy: 90.6%\n",
            "Step: 2713 ------------ Loss: 2077.83 ------------ Accuracy: 90.6%\n",
            "Step: 2714 ------------ Loss: 2077.63 ------------ Accuracy: 90.6%\n",
            "Step: 2715 ------------ Loss: 2077.43 ------------ Accuracy: 90.6%\n",
            "Step: 2716 ------------ Loss: 2077.22 ------------ Accuracy: 90.6%\n",
            "Step: 2717 ------------ Loss: 2077.02 ------------ Accuracy: 90.6%\n",
            "Step: 2718 ------------ Loss: 2076.82 ------------ Accuracy: 90.6%\n",
            "Step: 2719 ------------ Loss: 2076.61 ------------ Accuracy: 90.6%\n",
            "Step: 2720 ------------ Loss: 2076.41 ------------ Accuracy: 90.6%\n",
            "Step: 2721 ------------ Loss: 2076.21 ------------ Accuracy: 90.6%\n",
            "Step: 2722 ------------ Loss: 2076.01 ------------ Accuracy: 90.6%\n",
            "Step: 2723 ------------ Loss: 2075.81 ------------ Accuracy: 90.6%\n",
            "Step: 2724 ------------ Loss: 2075.6 ------------ Accuracy: 90.6%\n",
            "Step: 2725 ------------ Loss: 2075.4 ------------ Accuracy: 90.6%\n",
            "Step: 2726 ------------ Loss: 2075.2 ------------ Accuracy: 90.6%\n",
            "Step: 2727 ------------ Loss: 2075.0 ------------ Accuracy: 90.6%\n",
            "Step: 2728 ------------ Loss: 2074.8 ------------ Accuracy: 90.6%\n",
            "Step: 2729 ------------ Loss: 2074.6 ------------ Accuracy: 90.6%\n",
            "Step: 2730 ------------ Loss: 2074.4 ------------ Accuracy: 90.6%\n",
            "Step: 2731 ------------ Loss: 2074.2 ------------ Accuracy: 90.6%\n",
            "Step: 2732 ------------ Loss: 2073.99 ------------ Accuracy: 90.6%\n",
            "Step: 2733 ------------ Loss: 2073.79 ------------ Accuracy: 90.6%\n",
            "Step: 2734 ------------ Loss: 2073.59 ------------ Accuracy: 90.6%\n",
            "Step: 2735 ------------ Loss: 2073.39 ------------ Accuracy: 90.6%\n",
            "Step: 2736 ------------ Loss: 2073.19 ------------ Accuracy: 90.6%\n",
            "Step: 2737 ------------ Loss: 2072.99 ------------ Accuracy: 90.6%\n",
            "Step: 2738 ------------ Loss: 2072.79 ------------ Accuracy: 90.6%\n",
            "Step: 2739 ------------ Loss: 2072.59 ------------ Accuracy: 90.6%\n",
            "Step: 2740 ------------ Loss: 2072.39 ------------ Accuracy: 90.6%\n",
            "Step: 2741 ------------ Loss: 2072.19 ------------ Accuracy: 90.6%\n",
            "Step: 2742 ------------ Loss: 2071.99 ------------ Accuracy: 90.6%\n",
            "Step: 2743 ------------ Loss: 2071.79 ------------ Accuracy: 90.6%\n",
            "Step: 2744 ------------ Loss: 2071.59 ------------ Accuracy: 90.6%\n",
            "Step: 2745 ------------ Loss: 2071.39 ------------ Accuracy: 90.6%\n",
            "Step: 2746 ------------ Loss: 2071.2 ------------ Accuracy: 90.6%\n",
            "Step: 2747 ------------ Loss: 2071.0 ------------ Accuracy: 90.6%\n",
            "Step: 2748 ------------ Loss: 2070.8 ------------ Accuracy: 90.6%\n",
            "Step: 2749 ------------ Loss: 2070.6 ------------ Accuracy: 90.6%\n",
            "Step: 2750 ------------ Loss: 2070.4 ------------ Accuracy: 90.6%\n",
            "Step: 2751 ------------ Loss: 2070.2 ------------ Accuracy: 90.6%\n",
            "Step: 2752 ------------ Loss: 2070.0 ------------ Accuracy: 90.6%\n",
            "Step: 2753 ------------ Loss: 2069.81 ------------ Accuracy: 90.6%\n",
            "Step: 2754 ------------ Loss: 2069.61 ------------ Accuracy: 90.6%\n",
            "Step: 2755 ------------ Loss: 2069.41 ------------ Accuracy: 90.6%\n",
            "Step: 2756 ------------ Loss: 2069.21 ------------ Accuracy: 90.6%\n",
            "Step: 2757 ------------ Loss: 2069.01 ------------ Accuracy: 90.6%\n",
            "Step: 2758 ------------ Loss: 2068.82 ------------ Accuracy: 90.6%\n",
            "Step: 2759 ------------ Loss: 2068.62 ------------ Accuracy: 90.6%\n",
            "Step: 2760 ------------ Loss: 2068.42 ------------ Accuracy: 90.6%\n",
            "Step: 2761 ------------ Loss: 2068.22 ------------ Accuracy: 90.6%\n",
            "Step: 2762 ------------ Loss: 2068.03 ------------ Accuracy: 90.6%\n",
            "Step: 2763 ------------ Loss: 2067.83 ------------ Accuracy: 90.6%\n",
            "Step: 2764 ------------ Loss: 2067.63 ------------ Accuracy: 90.6%\n",
            "Step: 2765 ------------ Loss: 2067.44 ------------ Accuracy: 90.6%\n",
            "Step: 2766 ------------ Loss: 2067.24 ------------ Accuracy: 90.6%\n",
            "Step: 2767 ------------ Loss: 2067.04 ------------ Accuracy: 90.6%\n",
            "Step: 2768 ------------ Loss: 2066.85 ------------ Accuracy: 90.6%\n",
            "Step: 2769 ------------ Loss: 2066.65 ------------ Accuracy: 90.6%\n",
            "Step: 2770 ------------ Loss: 2066.45 ------------ Accuracy: 90.6%\n",
            "Step: 2771 ------------ Loss: 2066.26 ------------ Accuracy: 90.6%\n",
            "Step: 2772 ------------ Loss: 2066.06 ------------ Accuracy: 90.6%\n",
            "Step: 2773 ------------ Loss: 2065.87 ------------ Accuracy: 90.6%\n",
            "Step: 2774 ------------ Loss: 2065.67 ------------ Accuracy: 90.6%\n",
            "Step: 2775 ------------ Loss: 2065.47 ------------ Accuracy: 90.6%\n",
            "Step: 2776 ------------ Loss: 2065.28 ------------ Accuracy: 90.6%\n",
            "Step: 2777 ------------ Loss: 2065.08 ------------ Accuracy: 90.6%\n",
            "Step: 2778 ------------ Loss: 2064.89 ------------ Accuracy: 90.6%\n",
            "Step: 2779 ------------ Loss: 2064.69 ------------ Accuracy: 90.6%\n",
            "Step: 2780 ------------ Loss: 2064.5 ------------ Accuracy: 90.6%\n",
            "Step: 2781 ------------ Loss: 2064.3 ------------ Accuracy: 90.6%\n",
            "Step: 2782 ------------ Loss: 2064.11 ------------ Accuracy: 90.6%\n",
            "Step: 2783 ------------ Loss: 2063.91 ------------ Accuracy: 90.6%\n",
            "Step: 2784 ------------ Loss: 2063.72 ------------ Accuracy: 90.6%\n",
            "Step: 2785 ------------ Loss: 2063.52 ------------ Accuracy: 90.6%\n",
            "Step: 2786 ------------ Loss: 2063.33 ------------ Accuracy: 90.6%\n",
            "Step: 2787 ------------ Loss: 2063.14 ------------ Accuracy: 90.6%\n",
            "Step: 2788 ------------ Loss: 2062.94 ------------ Accuracy: 90.6%\n",
            "Step: 2789 ------------ Loss: 2062.75 ------------ Accuracy: 90.6%\n",
            "Step: 2790 ------------ Loss: 2062.55 ------------ Accuracy: 90.6%\n",
            "Step: 2791 ------------ Loss: 2062.36 ------------ Accuracy: 90.6%\n",
            "Step: 2792 ------------ Loss: 2062.17 ------------ Accuracy: 90.6%\n",
            "Step: 2793 ------------ Loss: 2061.97 ------------ Accuracy: 90.6%\n",
            "Step: 2794 ------------ Loss: 2061.78 ------------ Accuracy: 90.6%\n",
            "Step: 2795 ------------ Loss: 2061.59 ------------ Accuracy: 90.6%\n",
            "Step: 2796 ------------ Loss: 2061.39 ------------ Accuracy: 90.6%\n",
            "Step: 2797 ------------ Loss: 2061.2 ------------ Accuracy: 90.6%\n",
            "Step: 2798 ------------ Loss: 2061.01 ------------ Accuracy: 90.6%\n",
            "Step: 2799 ------------ Loss: 2060.81 ------------ Accuracy: 90.6%\n",
            "Step: 2800 ------------ Loss: 2060.62 ------------ Accuracy: 90.6%\n",
            "Step: 2801 ------------ Loss: 2060.43 ------------ Accuracy: 90.6%\n",
            "Step: 2802 ------------ Loss: 2060.24 ------------ Accuracy: 90.6%\n",
            "Step: 2803 ------------ Loss: 2060.04 ------------ Accuracy: 90.6%\n",
            "Step: 2804 ------------ Loss: 2059.85 ------------ Accuracy: 90.6%\n",
            "Step: 2805 ------------ Loss: 2059.66 ------------ Accuracy: 90.6%\n",
            "Step: 2806 ------------ Loss: 2059.47 ------------ Accuracy: 90.6%\n",
            "Step: 2807 ------------ Loss: 2059.28 ------------ Accuracy: 90.6%\n",
            "Step: 2808 ------------ Loss: 2059.08 ------------ Accuracy: 90.6%\n",
            "Step: 2809 ------------ Loss: 2058.89 ------------ Accuracy: 90.6%\n",
            "Step: 2810 ------------ Loss: 2058.7 ------------ Accuracy: 90.6%\n",
            "Step: 2811 ------------ Loss: 2058.51 ------------ Accuracy: 90.6%\n",
            "Step: 2812 ------------ Loss: 2058.32 ------------ Accuracy: 90.6%\n",
            "Step: 2813 ------------ Loss: 2058.13 ------------ Accuracy: 90.6%\n",
            "Step: 2814 ------------ Loss: 2057.94 ------------ Accuracy: 90.6%\n",
            "Step: 2815 ------------ Loss: 2057.74 ------------ Accuracy: 90.6%\n",
            "Step: 2816 ------------ Loss: 2057.55 ------------ Accuracy: 90.6%\n",
            "Step: 2817 ------------ Loss: 2057.36 ------------ Accuracy: 90.6%\n",
            "Step: 2818 ------------ Loss: 2057.17 ------------ Accuracy: 90.6%\n",
            "Step: 2819 ------------ Loss: 2056.98 ------------ Accuracy: 90.6%\n",
            "Step: 2820 ------------ Loss: 2056.79 ------------ Accuracy: 90.6%\n",
            "Step: 2821 ------------ Loss: 2056.6 ------------ Accuracy: 90.7%\n",
            "Step: 2822 ------------ Loss: 2056.41 ------------ Accuracy: 90.7%\n",
            "Step: 2823 ------------ Loss: 2056.22 ------------ Accuracy: 90.7%\n",
            "Step: 2824 ------------ Loss: 2056.03 ------------ Accuracy: 90.7%\n",
            "Step: 2825 ------------ Loss: 2055.84 ------------ Accuracy: 90.7%\n",
            "Step: 2826 ------------ Loss: 2055.65 ------------ Accuracy: 90.7%\n",
            "Step: 2827 ------------ Loss: 2055.46 ------------ Accuracy: 90.7%\n",
            "Step: 2828 ------------ Loss: 2055.27 ------------ Accuracy: 90.7%\n",
            "Step: 2829 ------------ Loss: 2055.08 ------------ Accuracy: 90.7%\n",
            "Step: 2830 ------------ Loss: 2054.89 ------------ Accuracy: 90.7%\n",
            "Step: 2831 ------------ Loss: 2054.7 ------------ Accuracy: 90.7%\n",
            "Step: 2832 ------------ Loss: 2054.51 ------------ Accuracy: 90.7%\n",
            "Step: 2833 ------------ Loss: 2054.33 ------------ Accuracy: 90.7%\n",
            "Step: 2834 ------------ Loss: 2054.14 ------------ Accuracy: 90.7%\n",
            "Step: 2835 ------------ Loss: 2053.95 ------------ Accuracy: 90.7%\n",
            "Step: 2836 ------------ Loss: 2053.76 ------------ Accuracy: 90.7%\n",
            "Step: 2837 ------------ Loss: 2053.57 ------------ Accuracy: 90.7%\n",
            "Step: 2838 ------------ Loss: 2053.38 ------------ Accuracy: 90.7%\n",
            "Step: 2839 ------------ Loss: 2053.19 ------------ Accuracy: 90.7%\n",
            "Step: 2840 ------------ Loss: 2053.01 ------------ Accuracy: 90.7%\n",
            "Step: 2841 ------------ Loss: 2052.82 ------------ Accuracy: 90.7%\n",
            "Step: 2842 ------------ Loss: 2052.63 ------------ Accuracy: 90.7%\n",
            "Step: 2843 ------------ Loss: 2052.44 ------------ Accuracy: 90.7%\n",
            "Step: 2844 ------------ Loss: 2052.25 ------------ Accuracy: 90.7%\n",
            "Step: 2845 ------------ Loss: 2052.07 ------------ Accuracy: 90.7%\n",
            "Step: 2846 ------------ Loss: 2051.88 ------------ Accuracy: 90.7%\n",
            "Step: 2847 ------------ Loss: 2051.69 ------------ Accuracy: 90.7%\n",
            "Step: 2848 ------------ Loss: 2051.5 ------------ Accuracy: 90.7%\n",
            "Step: 2849 ------------ Loss: 2051.32 ------------ Accuracy: 90.7%\n",
            "Step: 2850 ------------ Loss: 2051.13 ------------ Accuracy: 90.7%\n",
            "Step: 2851 ------------ Loss: 2050.94 ------------ Accuracy: 90.7%\n",
            "Step: 2852 ------------ Loss: 2050.76 ------------ Accuracy: 90.7%\n",
            "Step: 2853 ------------ Loss: 2050.57 ------------ Accuracy: 90.7%\n",
            "Step: 2854 ------------ Loss: 2050.38 ------------ Accuracy: 90.7%\n",
            "Step: 2855 ------------ Loss: 2050.2 ------------ Accuracy: 90.7%\n",
            "Step: 2856 ------------ Loss: 2050.01 ------------ Accuracy: 90.7%\n",
            "Step: 2857 ------------ Loss: 2049.82 ------------ Accuracy: 90.7%\n",
            "Step: 2858 ------------ Loss: 2049.64 ------------ Accuracy: 90.7%\n",
            "Step: 2859 ------------ Loss: 2049.45 ------------ Accuracy: 90.7%\n",
            "Step: 2860 ------------ Loss: 2049.27 ------------ Accuracy: 90.7%\n",
            "Step: 2861 ------------ Loss: 2049.08 ------------ Accuracy: 90.7%\n",
            "Step: 2862 ------------ Loss: 2048.89 ------------ Accuracy: 90.7%\n",
            "Step: 2863 ------------ Loss: 2048.71 ------------ Accuracy: 90.7%\n",
            "Step: 2864 ------------ Loss: 2048.52 ------------ Accuracy: 90.7%\n",
            "Step: 2865 ------------ Loss: 2048.34 ------------ Accuracy: 90.7%\n",
            "Step: 2866 ------------ Loss: 2048.15 ------------ Accuracy: 90.7%\n",
            "Step: 2867 ------------ Loss: 2047.97 ------------ Accuracy: 90.7%\n",
            "Step: 2868 ------------ Loss: 2047.78 ------------ Accuracy: 90.7%\n",
            "Step: 2869 ------------ Loss: 2047.6 ------------ Accuracy: 90.7%\n",
            "Step: 2870 ------------ Loss: 2047.41 ------------ Accuracy: 90.7%\n",
            "Step: 2871 ------------ Loss: 2047.23 ------------ Accuracy: 90.7%\n",
            "Step: 2872 ------------ Loss: 2047.04 ------------ Accuracy: 90.7%\n",
            "Step: 2873 ------------ Loss: 2046.86 ------------ Accuracy: 90.7%\n",
            "Step: 2874 ------------ Loss: 2046.67 ------------ Accuracy: 90.7%\n",
            "Step: 2875 ------------ Loss: 2046.49 ------------ Accuracy: 90.7%\n",
            "Step: 2876 ------------ Loss: 2046.3 ------------ Accuracy: 90.7%\n",
            "Step: 2877 ------------ Loss: 2046.12 ------------ Accuracy: 90.7%\n",
            "Step: 2878 ------------ Loss: 2045.94 ------------ Accuracy: 90.7%\n",
            "Step: 2879 ------------ Loss: 2045.75 ------------ Accuracy: 90.7%\n",
            "Step: 2880 ------------ Loss: 2045.57 ------------ Accuracy: 90.7%\n",
            "Step: 2881 ------------ Loss: 2045.39 ------------ Accuracy: 90.7%\n",
            "Step: 2882 ------------ Loss: 2045.2 ------------ Accuracy: 90.7%\n",
            "Step: 2883 ------------ Loss: 2045.02 ------------ Accuracy: 90.7%\n",
            "Step: 2884 ------------ Loss: 2044.83 ------------ Accuracy: 90.7%\n",
            "Step: 2885 ------------ Loss: 2044.65 ------------ Accuracy: 90.7%\n",
            "Step: 2886 ------------ Loss: 2044.47 ------------ Accuracy: 90.7%\n",
            "Step: 2887 ------------ Loss: 2044.29 ------------ Accuracy: 90.7%\n",
            "Step: 2888 ------------ Loss: 2044.1 ------------ Accuracy: 90.7%\n",
            "Step: 2889 ------------ Loss: 2043.92 ------------ Accuracy: 90.7%\n",
            "Step: 2890 ------------ Loss: 2043.74 ------------ Accuracy: 90.7%\n",
            "Step: 2891 ------------ Loss: 2043.55 ------------ Accuracy: 90.7%\n",
            "Step: 2892 ------------ Loss: 2043.37 ------------ Accuracy: 90.7%\n",
            "Step: 2893 ------------ Loss: 2043.19 ------------ Accuracy: 90.7%\n",
            "Step: 2894 ------------ Loss: 2043.01 ------------ Accuracy: 90.7%\n",
            "Step: 2895 ------------ Loss: 2042.82 ------------ Accuracy: 90.7%\n",
            "Step: 2896 ------------ Loss: 2042.64 ------------ Accuracy: 90.7%\n",
            "Step: 2897 ------------ Loss: 2042.46 ------------ Accuracy: 90.7%\n",
            "Step: 2898 ------------ Loss: 2042.28 ------------ Accuracy: 90.7%\n",
            "Step: 2899 ------------ Loss: 2042.1 ------------ Accuracy: 90.7%\n",
            "Step: 2900 ------------ Loss: 2041.91 ------------ Accuracy: 90.7%\n",
            "Step: 2901 ------------ Loss: 2041.73 ------------ Accuracy: 90.7%\n",
            "Step: 2902 ------------ Loss: 2041.55 ------------ Accuracy: 90.7%\n",
            "Step: 2903 ------------ Loss: 2041.37 ------------ Accuracy: 90.7%\n",
            "Step: 2904 ------------ Loss: 2041.19 ------------ Accuracy: 90.7%\n",
            "Step: 2905 ------------ Loss: 2041.01 ------------ Accuracy: 90.7%\n",
            "Step: 2906 ------------ Loss: 2040.83 ------------ Accuracy: 90.7%\n",
            "Step: 2907 ------------ Loss: 2040.65 ------------ Accuracy: 90.7%\n",
            "Step: 2908 ------------ Loss: 2040.47 ------------ Accuracy: 90.7%\n",
            "Step: 2909 ------------ Loss: 2040.28 ------------ Accuracy: 90.7%\n",
            "Step: 2910 ------------ Loss: 2040.1 ------------ Accuracy: 90.7%\n",
            "Step: 2911 ------------ Loss: 2039.92 ------------ Accuracy: 90.7%\n",
            "Step: 2912 ------------ Loss: 2039.74 ------------ Accuracy: 90.7%\n",
            "Step: 2913 ------------ Loss: 2039.56 ------------ Accuracy: 90.7%\n",
            "Step: 2914 ------------ Loss: 2039.38 ------------ Accuracy: 90.7%\n",
            "Step: 2915 ------------ Loss: 2039.2 ------------ Accuracy: 90.7%\n",
            "Step: 2916 ------------ Loss: 2039.02 ------------ Accuracy: 90.7%\n",
            "Step: 2917 ------------ Loss: 2038.84 ------------ Accuracy: 90.7%\n",
            "Step: 2918 ------------ Loss: 2038.66 ------------ Accuracy: 90.7%\n",
            "Step: 2919 ------------ Loss: 2038.48 ------------ Accuracy: 90.7%\n",
            "Step: 2920 ------------ Loss: 2038.3 ------------ Accuracy: 90.7%\n",
            "Step: 2921 ------------ Loss: 2038.12 ------------ Accuracy: 90.7%\n",
            "Step: 2922 ------------ Loss: 2037.94 ------------ Accuracy: 90.7%\n",
            "Step: 2923 ------------ Loss: 2037.76 ------------ Accuracy: 90.7%\n",
            "Step: 2924 ------------ Loss: 2037.59 ------------ Accuracy: 90.7%\n",
            "Step: 2925 ------------ Loss: 2037.41 ------------ Accuracy: 90.7%\n",
            "Step: 2926 ------------ Loss: 2037.23 ------------ Accuracy: 90.7%\n",
            "Step: 2927 ------------ Loss: 2037.05 ------------ Accuracy: 90.7%\n",
            "Step: 2928 ------------ Loss: 2036.87 ------------ Accuracy: 90.7%\n",
            "Step: 2929 ------------ Loss: 2036.69 ------------ Accuracy: 90.7%\n",
            "Step: 2930 ------------ Loss: 2036.51 ------------ Accuracy: 90.7%\n",
            "Step: 2931 ------------ Loss: 2036.33 ------------ Accuracy: 90.7%\n",
            "Step: 2932 ------------ Loss: 2036.16 ------------ Accuracy: 90.7%\n",
            "Step: 2933 ------------ Loss: 2035.98 ------------ Accuracy: 90.7%\n",
            "Step: 2934 ------------ Loss: 2035.8 ------------ Accuracy: 90.7%\n",
            "Step: 2935 ------------ Loss: 2035.62 ------------ Accuracy: 90.7%\n",
            "Step: 2936 ------------ Loss: 2035.44 ------------ Accuracy: 90.7%\n",
            "Step: 2937 ------------ Loss: 2035.27 ------------ Accuracy: 90.7%\n",
            "Step: 2938 ------------ Loss: 2035.09 ------------ Accuracy: 90.7%\n",
            "Step: 2939 ------------ Loss: 2034.91 ------------ Accuracy: 90.7%\n",
            "Step: 2940 ------------ Loss: 2034.73 ------------ Accuracy: 90.7%\n",
            "Step: 2941 ------------ Loss: 2034.56 ------------ Accuracy: 90.7%\n",
            "Step: 2942 ------------ Loss: 2034.38 ------------ Accuracy: 90.7%\n",
            "Step: 2943 ------------ Loss: 2034.2 ------------ Accuracy: 90.7%\n",
            "Step: 2944 ------------ Loss: 2034.02 ------------ Accuracy: 90.7%\n",
            "Step: 2945 ------------ Loss: 2033.85 ------------ Accuracy: 90.7%\n",
            "Step: 2946 ------------ Loss: 2033.67 ------------ Accuracy: 90.7%\n",
            "Step: 2947 ------------ Loss: 2033.49 ------------ Accuracy: 90.7%\n",
            "Step: 2948 ------------ Loss: 2033.32 ------------ Accuracy: 90.7%\n",
            "Step: 2949 ------------ Loss: 2033.14 ------------ Accuracy: 90.7%\n",
            "Step: 2950 ------------ Loss: 2032.96 ------------ Accuracy: 90.7%\n",
            "Step: 2951 ------------ Loss: 2032.79 ------------ Accuracy: 90.7%\n",
            "Step: 2952 ------------ Loss: 2032.61 ------------ Accuracy: 90.7%\n",
            "Step: 2953 ------------ Loss: 2032.43 ------------ Accuracy: 90.7%\n",
            "Step: 2954 ------------ Loss: 2032.26 ------------ Accuracy: 90.7%\n",
            "Step: 2955 ------------ Loss: 2032.08 ------------ Accuracy: 90.7%\n",
            "Step: 2956 ------------ Loss: 2031.91 ------------ Accuracy: 90.7%\n",
            "Step: 2957 ------------ Loss: 2031.73 ------------ Accuracy: 90.7%\n",
            "Step: 2958 ------------ Loss: 2031.55 ------------ Accuracy: 90.7%\n",
            "Step: 2959 ------------ Loss: 2031.38 ------------ Accuracy: 90.7%\n",
            "Step: 2960 ------------ Loss: 2031.2 ------------ Accuracy: 90.7%\n",
            "Step: 2961 ------------ Loss: 2031.03 ------------ Accuracy: 90.7%\n",
            "Step: 2962 ------------ Loss: 2030.85 ------------ Accuracy: 90.7%\n",
            "Step: 2963 ------------ Loss: 2030.68 ------------ Accuracy: 90.7%\n",
            "Step: 2964 ------------ Loss: 2030.5 ------------ Accuracy: 90.7%\n",
            "Step: 2965 ------------ Loss: 2030.33 ------------ Accuracy: 90.7%\n",
            "Step: 2966 ------------ Loss: 2030.15 ------------ Accuracy: 90.7%\n",
            "Step: 2967 ------------ Loss: 2029.98 ------------ Accuracy: 90.7%\n",
            "Step: 2968 ------------ Loss: 2029.8 ------------ Accuracy: 90.7%\n",
            "Step: 2969 ------------ Loss: 2029.63 ------------ Accuracy: 90.7%\n",
            "Step: 2970 ------------ Loss: 2029.45 ------------ Accuracy: 90.7%\n",
            "Step: 2971 ------------ Loss: 2029.28 ------------ Accuracy: 90.7%\n",
            "Step: 2972 ------------ Loss: 2029.1 ------------ Accuracy: 90.7%\n",
            "Step: 2973 ------------ Loss: 2028.93 ------------ Accuracy: 90.7%\n",
            "Step: 2974 ------------ Loss: 2028.76 ------------ Accuracy: 90.7%\n",
            "Step: 2975 ------------ Loss: 2028.58 ------------ Accuracy: 90.7%\n",
            "Step: 2976 ------------ Loss: 2028.41 ------------ Accuracy: 90.7%\n",
            "Step: 2977 ------------ Loss: 2028.23 ------------ Accuracy: 90.7%\n",
            "Step: 2978 ------------ Loss: 2028.06 ------------ Accuracy: 90.7%\n",
            "Step: 2979 ------------ Loss: 2027.89 ------------ Accuracy: 90.7%\n",
            "Step: 2980 ------------ Loss: 2027.71 ------------ Accuracy: 90.7%\n",
            "Step: 2981 ------------ Loss: 2027.54 ------------ Accuracy: 90.7%\n",
            "Step: 2982 ------------ Loss: 2027.37 ------------ Accuracy: 90.7%\n",
            "Step: 2983 ------------ Loss: 2027.19 ------------ Accuracy: 90.7%\n",
            "Step: 2984 ------------ Loss: 2027.02 ------------ Accuracy: 90.7%\n",
            "Step: 2985 ------------ Loss: 2026.85 ------------ Accuracy: 90.7%\n",
            "Step: 2986 ------------ Loss: 2026.67 ------------ Accuracy: 90.7%\n",
            "Step: 2987 ------------ Loss: 2026.5 ------------ Accuracy: 90.7%\n",
            "Step: 2988 ------------ Loss: 2026.33 ------------ Accuracy: 90.7%\n",
            "Step: 2989 ------------ Loss: 2026.15 ------------ Accuracy: 90.7%\n",
            "Step: 2990 ------------ Loss: 2025.98 ------------ Accuracy: 90.7%\n",
            "Step: 2991 ------------ Loss: 2025.81 ------------ Accuracy: 90.7%\n",
            "Step: 2992 ------------ Loss: 2025.64 ------------ Accuracy: 90.7%\n",
            "Step: 2993 ------------ Loss: 2025.47 ------------ Accuracy: 90.7%\n",
            "Step: 2994 ------------ Loss: 2025.29 ------------ Accuracy: 90.7%\n",
            "Step: 2995 ------------ Loss: 2025.12 ------------ Accuracy: 90.7%\n",
            "Step: 2996 ------------ Loss: 2024.95 ------------ Accuracy: 90.7%\n",
            "Step: 2997 ------------ Loss: 2024.78 ------------ Accuracy: 90.7%\n",
            "Step: 2998 ------------ Loss: 2024.61 ------------ Accuracy: 90.7%\n",
            "Step: 2999 ------------ Loss: 2024.43 ------------ Accuracy: 90.7%\n",
            "Step: 3000 ------------ Loss: 2024.26 ------------ Accuracy: 90.7%\n",
            "Step: 3001 ------------ Loss: 2024.09 ------------ Accuracy: 90.7%\n",
            "Step: 3002 ------------ Loss: 2023.92 ------------ Accuracy: 90.7%\n",
            "Step: 3003 ------------ Loss: 2023.75 ------------ Accuracy: 90.7%\n",
            "Step: 3004 ------------ Loss: 2023.58 ------------ Accuracy: 90.7%\n",
            "Step: 3005 ------------ Loss: 2023.41 ------------ Accuracy: 90.7%\n",
            "Step: 3006 ------------ Loss: 2023.23 ------------ Accuracy: 90.7%\n",
            "Step: 3007 ------------ Loss: 2023.06 ------------ Accuracy: 90.7%\n",
            "Step: 3008 ------------ Loss: 2022.89 ------------ Accuracy: 90.7%\n",
            "Step: 3009 ------------ Loss: 2022.72 ------------ Accuracy: 90.7%\n",
            "Step: 3010 ------------ Loss: 2022.55 ------------ Accuracy: 90.7%\n",
            "Step: 3011 ------------ Loss: 2022.38 ------------ Accuracy: 90.7%\n",
            "Step: 3012 ------------ Loss: 2022.21 ------------ Accuracy: 90.7%\n",
            "Step: 3013 ------------ Loss: 2022.04 ------------ Accuracy: 90.7%\n",
            "Step: 3014 ------------ Loss: 2021.87 ------------ Accuracy: 90.7%\n",
            "Step: 3015 ------------ Loss: 2021.7 ------------ Accuracy: 90.7%\n",
            "Step: 3016 ------------ Loss: 2021.53 ------------ Accuracy: 90.7%\n",
            "Step: 3017 ------------ Loss: 2021.36 ------------ Accuracy: 90.7%\n",
            "Step: 3018 ------------ Loss: 2021.19 ------------ Accuracy: 90.7%\n",
            "Step: 3019 ------------ Loss: 2021.02 ------------ Accuracy: 90.7%\n",
            "Step: 3020 ------------ Loss: 2020.85 ------------ Accuracy: 90.7%\n",
            "Step: 3021 ------------ Loss: 2020.68 ------------ Accuracy: 90.7%\n",
            "Step: 3022 ------------ Loss: 2020.51 ------------ Accuracy: 90.7%\n",
            "Step: 3023 ------------ Loss: 2020.34 ------------ Accuracy: 90.7%\n",
            "Step: 3024 ------------ Loss: 2020.17 ------------ Accuracy: 90.7%\n",
            "Step: 3025 ------------ Loss: 2020.0 ------------ Accuracy: 90.7%\n",
            "Step: 3026 ------------ Loss: 2019.83 ------------ Accuracy: 90.7%\n",
            "Step: 3027 ------------ Loss: 2019.66 ------------ Accuracy: 90.7%\n",
            "Step: 3028 ------------ Loss: 2019.5 ------------ Accuracy: 90.7%\n",
            "Step: 3029 ------------ Loss: 2019.33 ------------ Accuracy: 90.7%\n",
            "Step: 3030 ------------ Loss: 2019.16 ------------ Accuracy: 90.7%\n",
            "Step: 3031 ------------ Loss: 2018.99 ------------ Accuracy: 90.7%\n",
            "Step: 3032 ------------ Loss: 2018.82 ------------ Accuracy: 90.7%\n",
            "Step: 3033 ------------ Loss: 2018.65 ------------ Accuracy: 90.7%\n",
            "Step: 3034 ------------ Loss: 2018.48 ------------ Accuracy: 90.7%\n",
            "Step: 3035 ------------ Loss: 2018.31 ------------ Accuracy: 90.7%\n",
            "Step: 3036 ------------ Loss: 2018.15 ------------ Accuracy: 90.7%\n",
            "Step: 3037 ------------ Loss: 2017.98 ------------ Accuracy: 90.7%\n",
            "Step: 3038 ------------ Loss: 2017.81 ------------ Accuracy: 90.7%\n",
            "Step: 3039 ------------ Loss: 2017.64 ------------ Accuracy: 90.7%\n",
            "Step: 3040 ------------ Loss: 2017.47 ------------ Accuracy: 90.7%\n",
            "Step: 3041 ------------ Loss: 2017.31 ------------ Accuracy: 90.7%\n",
            "Step: 3042 ------------ Loss: 2017.14 ------------ Accuracy: 90.7%\n",
            "Step: 3043 ------------ Loss: 2016.97 ------------ Accuracy: 90.7%\n",
            "Step: 3044 ------------ Loss: 2016.8 ------------ Accuracy: 90.7%\n",
            "Step: 3045 ------------ Loss: 2016.64 ------------ Accuracy: 90.7%\n",
            "Step: 3046 ------------ Loss: 2016.47 ------------ Accuracy: 90.7%\n",
            "Step: 3047 ------------ Loss: 2016.3 ------------ Accuracy: 90.7%\n",
            "Step: 3048 ------------ Loss: 2016.14 ------------ Accuracy: 90.7%\n",
            "Step: 3049 ------------ Loss: 2015.97 ------------ Accuracy: 90.7%\n",
            "Step: 3050 ------------ Loss: 2015.8 ------------ Accuracy: 90.7%\n",
            "Step: 3051 ------------ Loss: 2015.63 ------------ Accuracy: 90.7%\n",
            "Step: 3052 ------------ Loss: 2015.47 ------------ Accuracy: 90.7%\n",
            "Step: 3053 ------------ Loss: 2015.3 ------------ Accuracy: 90.7%\n",
            "Step: 3054 ------------ Loss: 2015.13 ------------ Accuracy: 90.7%\n",
            "Step: 3055 ------------ Loss: 2014.97 ------------ Accuracy: 90.7%\n",
            "Step: 3056 ------------ Loss: 2014.8 ------------ Accuracy: 90.7%\n",
            "Step: 3057 ------------ Loss: 2014.64 ------------ Accuracy: 90.7%\n",
            "Step: 3058 ------------ Loss: 2014.47 ------------ Accuracy: 90.7%\n",
            "Step: 3059 ------------ Loss: 2014.3 ------------ Accuracy: 90.7%\n",
            "Step: 3060 ------------ Loss: 2014.14 ------------ Accuracy: 90.7%\n",
            "Step: 3061 ------------ Loss: 2013.97 ------------ Accuracy: 90.7%\n",
            "Step: 3062 ------------ Loss: 2013.81 ------------ Accuracy: 90.7%\n",
            "Step: 3063 ------------ Loss: 2013.64 ------------ Accuracy: 90.7%\n",
            "Step: 3064 ------------ Loss: 2013.47 ------------ Accuracy: 90.7%\n",
            "Step: 3065 ------------ Loss: 2013.31 ------------ Accuracy: 90.7%\n",
            "Step: 3066 ------------ Loss: 2013.14 ------------ Accuracy: 90.7%\n",
            "Step: 3067 ------------ Loss: 2012.98 ------------ Accuracy: 90.7%\n",
            "Step: 3068 ------------ Loss: 2012.81 ------------ Accuracy: 90.7%\n",
            "Step: 3069 ------------ Loss: 2012.65 ------------ Accuracy: 90.7%\n",
            "Step: 3070 ------------ Loss: 2012.48 ------------ Accuracy: 90.7%\n",
            "Step: 3071 ------------ Loss: 2012.32 ------------ Accuracy: 90.7%\n",
            "Step: 3072 ------------ Loss: 2012.15 ------------ Accuracy: 90.7%\n",
            "Step: 3073 ------------ Loss: 2011.99 ------------ Accuracy: 90.7%\n",
            "Step: 3074 ------------ Loss: 2011.82 ------------ Accuracy: 90.7%\n",
            "Step: 3075 ------------ Loss: 2011.66 ------------ Accuracy: 90.7%\n",
            "Step: 3076 ------------ Loss: 2011.49 ------------ Accuracy: 90.7%\n",
            "Step: 3077 ------------ Loss: 2011.33 ------------ Accuracy: 90.7%\n",
            "Step: 3078 ------------ Loss: 2011.17 ------------ Accuracy: 90.7%\n",
            "Step: 3079 ------------ Loss: 2011.0 ------------ Accuracy: 90.7%\n",
            "Step: 3080 ------------ Loss: 2010.84 ------------ Accuracy: 90.7%\n",
            "Step: 3081 ------------ Loss: 2010.67 ------------ Accuracy: 90.7%\n",
            "Step: 3082 ------------ Loss: 2010.51 ------------ Accuracy: 90.7%\n",
            "Step: 3083 ------------ Loss: 2010.34 ------------ Accuracy: 90.7%\n",
            "Step: 3084 ------------ Loss: 2010.18 ------------ Accuracy: 90.7%\n",
            "Step: 3085 ------------ Loss: 2010.02 ------------ Accuracy: 90.7%\n",
            "Step: 3086 ------------ Loss: 2009.85 ------------ Accuracy: 90.7%\n",
            "Step: 3087 ------------ Loss: 2009.69 ------------ Accuracy: 90.7%\n",
            "Step: 3088 ------------ Loss: 2009.53 ------------ Accuracy: 90.7%\n",
            "Step: 3089 ------------ Loss: 2009.36 ------------ Accuracy: 90.7%\n",
            "Step: 3090 ------------ Loss: 2009.2 ------------ Accuracy: 90.7%\n",
            "Step: 3091 ------------ Loss: 2009.04 ------------ Accuracy: 90.7%\n",
            "Step: 3092 ------------ Loss: 2008.87 ------------ Accuracy: 90.7%\n",
            "Step: 3093 ------------ Loss: 2008.71 ------------ Accuracy: 90.7%\n",
            "Step: 3094 ------------ Loss: 2008.55 ------------ Accuracy: 90.7%\n",
            "Step: 3095 ------------ Loss: 2008.38 ------------ Accuracy: 90.7%\n",
            "Step: 3096 ------------ Loss: 2008.22 ------------ Accuracy: 90.7%\n",
            "Step: 3097 ------------ Loss: 2008.06 ------------ Accuracy: 90.7%\n",
            "Step: 3098 ------------ Loss: 2007.9 ------------ Accuracy: 90.7%\n",
            "Step: 3099 ------------ Loss: 2007.73 ------------ Accuracy: 90.7%\n",
            "Step: 3100 ------------ Loss: 2007.57 ------------ Accuracy: 90.7%\n",
            "Step: 3101 ------------ Loss: 2007.41 ------------ Accuracy: 90.7%\n",
            "Step: 3102 ------------ Loss: 2007.25 ------------ Accuracy: 90.7%\n",
            "Step: 3103 ------------ Loss: 2007.09 ------------ Accuracy: 90.7%\n",
            "Step: 3104 ------------ Loss: 2006.92 ------------ Accuracy: 90.7%\n",
            "Step: 3105 ------------ Loss: 2006.76 ------------ Accuracy: 90.7%\n",
            "Step: 3106 ------------ Loss: 2006.6 ------------ Accuracy: 90.7%\n",
            "Step: 3107 ------------ Loss: 2006.44 ------------ Accuracy: 90.7%\n",
            "Step: 3108 ------------ Loss: 2006.28 ------------ Accuracy: 90.7%\n",
            "Step: 3109 ------------ Loss: 2006.11 ------------ Accuracy: 90.7%\n",
            "Step: 3110 ------------ Loss: 2005.95 ------------ Accuracy: 90.7%\n",
            "Step: 3111 ------------ Loss: 2005.79 ------------ Accuracy: 90.7%\n",
            "Step: 3112 ------------ Loss: 2005.63 ------------ Accuracy: 90.7%\n",
            "Step: 3113 ------------ Loss: 2005.47 ------------ Accuracy: 90.7%\n",
            "Step: 3114 ------------ Loss: 2005.31 ------------ Accuracy: 90.7%\n",
            "Step: 3115 ------------ Loss: 2005.15 ------------ Accuracy: 90.7%\n",
            "Step: 3116 ------------ Loss: 2004.99 ------------ Accuracy: 90.7%\n",
            "Step: 3117 ------------ Loss: 2004.82 ------------ Accuracy: 90.7%\n",
            "Step: 3118 ------------ Loss: 2004.66 ------------ Accuracy: 90.7%\n",
            "Step: 3119 ------------ Loss: 2004.5 ------------ Accuracy: 90.7%\n",
            "Step: 3120 ------------ Loss: 2004.34 ------------ Accuracy: 90.7%\n",
            "Step: 3121 ------------ Loss: 2004.18 ------------ Accuracy: 90.7%\n",
            "Step: 3122 ------------ Loss: 2004.02 ------------ Accuracy: 90.7%\n",
            "Step: 3123 ------------ Loss: 2003.86 ------------ Accuracy: 90.7%\n",
            "Step: 3124 ------------ Loss: 2003.7 ------------ Accuracy: 90.7%\n",
            "Step: 3125 ------------ Loss: 2003.54 ------------ Accuracy: 90.7%\n",
            "Step: 3126 ------------ Loss: 2003.38 ------------ Accuracy: 90.7%\n",
            "Step: 3127 ------------ Loss: 2003.22 ------------ Accuracy: 90.7%\n",
            "Step: 3128 ------------ Loss: 2003.06 ------------ Accuracy: 90.7%\n",
            "Step: 3129 ------------ Loss: 2002.9 ------------ Accuracy: 90.7%\n",
            "Step: 3130 ------------ Loss: 2002.74 ------------ Accuracy: 90.7%\n",
            "Step: 3131 ------------ Loss: 2002.58 ------------ Accuracy: 90.7%\n",
            "Step: 3132 ------------ Loss: 2002.42 ------------ Accuracy: 90.7%\n",
            "Step: 3133 ------------ Loss: 2002.26 ------------ Accuracy: 90.7%\n",
            "Step: 3134 ------------ Loss: 2002.1 ------------ Accuracy: 90.7%\n",
            "Step: 3135 ------------ Loss: 2001.94 ------------ Accuracy: 90.7%\n",
            "Step: 3136 ------------ Loss: 2001.78 ------------ Accuracy: 90.7%\n",
            "Step: 3137 ------------ Loss: 2001.62 ------------ Accuracy: 90.7%\n",
            "Step: 3138 ------------ Loss: 2001.47 ------------ Accuracy: 90.7%\n",
            "Step: 3139 ------------ Loss: 2001.31 ------------ Accuracy: 90.7%\n",
            "Step: 3140 ------------ Loss: 2001.15 ------------ Accuracy: 90.7%\n",
            "Step: 3141 ------------ Loss: 2000.99 ------------ Accuracy: 90.7%\n",
            "Step: 3142 ------------ Loss: 2000.83 ------------ Accuracy: 90.7%\n",
            "Step: 3143 ------------ Loss: 2000.67 ------------ Accuracy: 90.7%\n",
            "Step: 3144 ------------ Loss: 2000.51 ------------ Accuracy: 90.7%\n",
            "Step: 3145 ------------ Loss: 2000.35 ------------ Accuracy: 90.7%\n",
            "Step: 3146 ------------ Loss: 2000.2 ------------ Accuracy: 90.7%\n",
            "Step: 3147 ------------ Loss: 2000.04 ------------ Accuracy: 90.7%\n",
            "Step: 3148 ------------ Loss: 1999.88 ------------ Accuracy: 90.7%\n",
            "Step: 3149 ------------ Loss: 1999.72 ------------ Accuracy: 90.7%\n",
            "Step: 3150 ------------ Loss: 1999.56 ------------ Accuracy: 90.7%\n",
            "Step: 3151 ------------ Loss: 1999.4 ------------ Accuracy: 90.7%\n",
            "Step: 3152 ------------ Loss: 1999.25 ------------ Accuracy: 90.7%\n",
            "Step: 3153 ------------ Loss: 1999.09 ------------ Accuracy: 90.7%\n",
            "Step: 3154 ------------ Loss: 1998.93 ------------ Accuracy: 90.7%\n",
            "Step: 3155 ------------ Loss: 1998.77 ------------ Accuracy: 90.7%\n",
            "Step: 3156 ------------ Loss: 1998.62 ------------ Accuracy: 90.7%\n",
            "Step: 3157 ------------ Loss: 1998.46 ------------ Accuracy: 90.7%\n",
            "Step: 3158 ------------ Loss: 1998.3 ------------ Accuracy: 90.7%\n",
            "Step: 3159 ------------ Loss: 1998.14 ------------ Accuracy: 90.7%\n",
            "Step: 3160 ------------ Loss: 1997.99 ------------ Accuracy: 90.7%\n",
            "Step: 3161 ------------ Loss: 1997.83 ------------ Accuracy: 90.7%\n",
            "Step: 3162 ------------ Loss: 1997.67 ------------ Accuracy: 90.7%\n",
            "Step: 3163 ------------ Loss: 1997.52 ------------ Accuracy: 90.7%\n",
            "Step: 3164 ------------ Loss: 1997.36 ------------ Accuracy: 90.7%\n",
            "Step: 3165 ------------ Loss: 1997.2 ------------ Accuracy: 90.7%\n",
            "Step: 3166 ------------ Loss: 1997.04 ------------ Accuracy: 90.7%\n",
            "Step: 3167 ------------ Loss: 1996.89 ------------ Accuracy: 90.7%\n",
            "Step: 3168 ------------ Loss: 1996.73 ------------ Accuracy: 90.7%\n",
            "Step: 3169 ------------ Loss: 1996.58 ------------ Accuracy: 90.7%\n",
            "Step: 3170 ------------ Loss: 1996.42 ------------ Accuracy: 90.7%\n",
            "Step: 3171 ------------ Loss: 1996.26 ------------ Accuracy: 90.7%\n",
            "Step: 3172 ------------ Loss: 1996.11 ------------ Accuracy: 90.7%\n",
            "Step: 3173 ------------ Loss: 1995.95 ------------ Accuracy: 90.7%\n",
            "Step: 3174 ------------ Loss: 1995.79 ------------ Accuracy: 90.7%\n",
            "Step: 3175 ------------ Loss: 1995.64 ------------ Accuracy: 90.7%\n",
            "Step: 3176 ------------ Loss: 1995.48 ------------ Accuracy: 90.7%\n",
            "Step: 3177 ------------ Loss: 1995.33 ------------ Accuracy: 90.7%\n",
            "Step: 3178 ------------ Loss: 1995.17 ------------ Accuracy: 90.7%\n",
            "Step: 3179 ------------ Loss: 1995.01 ------------ Accuracy: 90.7%\n",
            "Step: 3180 ------------ Loss: 1994.86 ------------ Accuracy: 90.7%\n",
            "Step: 3181 ------------ Loss: 1994.7 ------------ Accuracy: 90.7%\n",
            "Step: 3182 ------------ Loss: 1994.55 ------------ Accuracy: 90.7%\n",
            "Step: 3183 ------------ Loss: 1994.39 ------------ Accuracy: 90.7%\n",
            "Step: 3184 ------------ Loss: 1994.24 ------------ Accuracy: 90.7%\n",
            "Step: 3185 ------------ Loss: 1994.08 ------------ Accuracy: 90.7%\n",
            "Step: 3186 ------------ Loss: 1993.93 ------------ Accuracy: 90.7%\n",
            "Step: 3187 ------------ Loss: 1993.77 ------------ Accuracy: 90.7%\n",
            "Step: 3188 ------------ Loss: 1993.62 ------------ Accuracy: 90.7%\n",
            "Step: 3189 ------------ Loss: 1993.46 ------------ Accuracy: 90.7%\n",
            "Step: 3190 ------------ Loss: 1993.31 ------------ Accuracy: 90.7%\n",
            "Step: 3191 ------------ Loss: 1993.15 ------------ Accuracy: 90.7%\n",
            "Step: 3192 ------------ Loss: 1993.0 ------------ Accuracy: 90.7%\n",
            "Step: 3193 ------------ Loss: 1992.84 ------------ Accuracy: 90.7%\n",
            "Step: 3194 ------------ Loss: 1992.69 ------------ Accuracy: 90.7%\n",
            "Step: 3195 ------------ Loss: 1992.54 ------------ Accuracy: 90.7%\n",
            "Step: 3196 ------------ Loss: 1992.38 ------------ Accuracy: 90.7%\n",
            "Step: 3197 ------------ Loss: 1992.23 ------------ Accuracy: 90.7%\n",
            "Step: 3198 ------------ Loss: 1992.07 ------------ Accuracy: 90.7%\n",
            "Step: 3199 ------------ Loss: 1991.92 ------------ Accuracy: 90.7%\n",
            "Step: 3200 ------------ Loss: 1991.77 ------------ Accuracy: 90.7%\n",
            "Step: 3201 ------------ Loss: 1991.61 ------------ Accuracy: 90.7%\n",
            "Step: 3202 ------------ Loss: 1991.46 ------------ Accuracy: 90.7%\n",
            "Step: 3203 ------------ Loss: 1991.3 ------------ Accuracy: 90.7%\n",
            "Step: 3204 ------------ Loss: 1991.15 ------------ Accuracy: 90.7%\n",
            "Step: 3205 ------------ Loss: 1991.0 ------------ Accuracy: 90.7%\n",
            "Step: 3206 ------------ Loss: 1990.84 ------------ Accuracy: 90.7%\n",
            "Step: 3207 ------------ Loss: 1990.69 ------------ Accuracy: 90.7%\n",
            "Step: 3208 ------------ Loss: 1990.54 ------------ Accuracy: 90.7%\n",
            "Step: 3209 ------------ Loss: 1990.38 ------------ Accuracy: 90.7%\n",
            "Step: 3210 ------------ Loss: 1990.23 ------------ Accuracy: 90.7%\n",
            "Step: 3211 ------------ Loss: 1990.08 ------------ Accuracy: 90.7%\n",
            "Step: 3212 ------------ Loss: 1989.92 ------------ Accuracy: 90.7%\n",
            "Step: 3213 ------------ Loss: 1989.77 ------------ Accuracy: 90.7%\n",
            "Step: 3214 ------------ Loss: 1989.62 ------------ Accuracy: 90.7%\n",
            "Step: 3215 ------------ Loss: 1989.47 ------------ Accuracy: 90.7%\n",
            "Step: 3216 ------------ Loss: 1989.31 ------------ Accuracy: 90.7%\n",
            "Step: 3217 ------------ Loss: 1989.16 ------------ Accuracy: 90.7%\n",
            "Step: 3218 ------------ Loss: 1989.01 ------------ Accuracy: 90.7%\n",
            "Step: 3219 ------------ Loss: 1988.86 ------------ Accuracy: 90.7%\n",
            "Step: 3220 ------------ Loss: 1988.7 ------------ Accuracy: 90.7%\n",
            "Step: 3221 ------------ Loss: 1988.55 ------------ Accuracy: 90.7%\n",
            "Step: 3222 ------------ Loss: 1988.4 ------------ Accuracy: 90.7%\n",
            "Step: 3223 ------------ Loss: 1988.25 ------------ Accuracy: 90.7%\n",
            "Step: 3224 ------------ Loss: 1988.09 ------------ Accuracy: 90.7%\n",
            "Step: 3225 ------------ Loss: 1987.94 ------------ Accuracy: 90.7%\n",
            "Step: 3226 ------------ Loss: 1987.79 ------------ Accuracy: 90.7%\n",
            "Step: 3227 ------------ Loss: 1987.64 ------------ Accuracy: 90.7%\n",
            "Step: 3228 ------------ Loss: 1987.49 ------------ Accuracy: 90.7%\n",
            "Step: 3229 ------------ Loss: 1987.34 ------------ Accuracy: 90.7%\n",
            "Step: 3230 ------------ Loss: 1987.18 ------------ Accuracy: 90.7%\n",
            "Step: 3231 ------------ Loss: 1987.03 ------------ Accuracy: 90.7%\n",
            "Step: 3232 ------------ Loss: 1986.88 ------------ Accuracy: 90.7%\n",
            "Step: 3233 ------------ Loss: 1986.73 ------------ Accuracy: 90.7%\n",
            "Step: 3234 ------------ Loss: 1986.58 ------------ Accuracy: 90.7%\n",
            "Step: 3235 ------------ Loss: 1986.43 ------------ Accuracy: 90.7%\n",
            "Step: 3236 ------------ Loss: 1986.28 ------------ Accuracy: 90.7%\n",
            "Step: 3237 ------------ Loss: 1986.13 ------------ Accuracy: 90.7%\n",
            "Step: 3238 ------------ Loss: 1985.98 ------------ Accuracy: 90.7%\n",
            "Step: 3239 ------------ Loss: 1985.82 ------------ Accuracy: 90.7%\n",
            "Step: 3240 ------------ Loss: 1985.67 ------------ Accuracy: 90.7%\n",
            "Step: 3241 ------------ Loss: 1985.52 ------------ Accuracy: 90.7%\n",
            "Step: 3242 ------------ Loss: 1985.37 ------------ Accuracy: 90.7%\n",
            "Step: 3243 ------------ Loss: 1985.22 ------------ Accuracy: 90.7%\n",
            "Step: 3244 ------------ Loss: 1985.07 ------------ Accuracy: 90.7%\n",
            "Step: 3245 ------------ Loss: 1984.92 ------------ Accuracy: 90.7%\n",
            "Step: 3246 ------------ Loss: 1984.77 ------------ Accuracy: 90.7%\n",
            "Step: 3247 ------------ Loss: 1984.62 ------------ Accuracy: 90.7%\n",
            "Step: 3248 ------------ Loss: 1984.47 ------------ Accuracy: 90.7%\n",
            "Step: 3249 ------------ Loss: 1984.32 ------------ Accuracy: 90.7%\n",
            "Step: 3250 ------------ Loss: 1984.17 ------------ Accuracy: 90.7%\n",
            "Step: 3251 ------------ Loss: 1984.02 ------------ Accuracy: 90.7%\n",
            "Step: 3252 ------------ Loss: 1983.87 ------------ Accuracy: 90.8%\n",
            "Step: 3253 ------------ Loss: 1983.72 ------------ Accuracy: 90.8%\n",
            "Step: 3254 ------------ Loss: 1983.57 ------------ Accuracy: 90.8%\n",
            "Step: 3255 ------------ Loss: 1983.42 ------------ Accuracy: 90.8%\n",
            "Step: 3256 ------------ Loss: 1983.27 ------------ Accuracy: 90.8%\n",
            "Step: 3257 ------------ Loss: 1983.12 ------------ Accuracy: 90.8%\n",
            "Step: 3258 ------------ Loss: 1982.97 ------------ Accuracy: 90.8%\n",
            "Step: 3259 ------------ Loss: 1982.82 ------------ Accuracy: 90.8%\n",
            "Step: 3260 ------------ Loss: 1982.68 ------------ Accuracy: 90.8%\n",
            "Step: 3261 ------------ Loss: 1982.53 ------------ Accuracy: 90.8%\n",
            "Step: 3262 ------------ Loss: 1982.38 ------------ Accuracy: 90.8%\n",
            "Step: 3263 ------------ Loss: 1982.23 ------------ Accuracy: 90.8%\n",
            "Step: 3264 ------------ Loss: 1982.08 ------------ Accuracy: 90.8%\n",
            "Step: 3265 ------------ Loss: 1981.93 ------------ Accuracy: 90.8%\n",
            "Step: 3266 ------------ Loss: 1981.78 ------------ Accuracy: 90.8%\n",
            "Step: 3267 ------------ Loss: 1981.63 ------------ Accuracy: 90.8%\n",
            "Step: 3268 ------------ Loss: 1981.48 ------------ Accuracy: 90.8%\n",
            "Step: 3269 ------------ Loss: 1981.34 ------------ Accuracy: 90.8%\n",
            "Step: 3270 ------------ Loss: 1981.19 ------------ Accuracy: 90.8%\n",
            "Step: 3271 ------------ Loss: 1981.04 ------------ Accuracy: 90.8%\n",
            "Step: 3272 ------------ Loss: 1980.89 ------------ Accuracy: 90.8%\n",
            "Step: 3273 ------------ Loss: 1980.74 ------------ Accuracy: 90.8%\n",
            "Step: 3274 ------------ Loss: 1980.59 ------------ Accuracy: 90.8%\n",
            "Step: 3275 ------------ Loss: 1980.45 ------------ Accuracy: 90.8%\n",
            "Step: 3276 ------------ Loss: 1980.3 ------------ Accuracy: 90.8%\n",
            "Step: 3277 ------------ Loss: 1980.15 ------------ Accuracy: 90.8%\n",
            "Step: 3278 ------------ Loss: 1980.0 ------------ Accuracy: 90.8%\n",
            "Step: 3279 ------------ Loss: 1979.86 ------------ Accuracy: 90.8%\n",
            "Step: 3280 ------------ Loss: 1979.71 ------------ Accuracy: 90.8%\n",
            "Step: 3281 ------------ Loss: 1979.56 ------------ Accuracy: 90.8%\n",
            "Step: 3282 ------------ Loss: 1979.41 ------------ Accuracy: 90.8%\n",
            "Step: 3283 ------------ Loss: 1979.27 ------------ Accuracy: 90.8%\n",
            "Step: 3284 ------------ Loss: 1979.12 ------------ Accuracy: 90.8%\n",
            "Step: 3285 ------------ Loss: 1978.97 ------------ Accuracy: 90.8%\n",
            "Step: 3286 ------------ Loss: 1978.82 ------------ Accuracy: 90.8%\n",
            "Step: 3287 ------------ Loss: 1978.68 ------------ Accuracy: 90.8%\n",
            "Step: 3288 ------------ Loss: 1978.53 ------------ Accuracy: 90.8%\n",
            "Step: 3289 ------------ Loss: 1978.38 ------------ Accuracy: 90.8%\n",
            "Step: 3290 ------------ Loss: 1978.24 ------------ Accuracy: 90.8%\n",
            "Step: 3291 ------------ Loss: 1978.09 ------------ Accuracy: 90.8%\n",
            "Step: 3292 ------------ Loss: 1977.94 ------------ Accuracy: 90.8%\n",
            "Step: 3293 ------------ Loss: 1977.8 ------------ Accuracy: 90.8%\n",
            "Step: 3294 ------------ Loss: 1977.65 ------------ Accuracy: 90.8%\n",
            "Step: 3295 ------------ Loss: 1977.5 ------------ Accuracy: 90.8%\n",
            "Step: 3296 ------------ Loss: 1977.36 ------------ Accuracy: 90.8%\n",
            "Step: 3297 ------------ Loss: 1977.21 ------------ Accuracy: 90.8%\n",
            "Step: 3298 ------------ Loss: 1977.06 ------------ Accuracy: 90.8%\n",
            "Step: 3299 ------------ Loss: 1976.92 ------------ Accuracy: 90.8%\n",
            "Step: 3300 ------------ Loss: 1976.77 ------------ Accuracy: 90.8%\n",
            "Step: 3301 ------------ Loss: 1976.62 ------------ Accuracy: 90.8%\n",
            "Step: 3302 ------------ Loss: 1976.48 ------------ Accuracy: 90.8%\n",
            "Step: 3303 ------------ Loss: 1976.33 ------------ Accuracy: 90.8%\n",
            "Step: 3304 ------------ Loss: 1976.19 ------------ Accuracy: 90.8%\n",
            "Step: 3305 ------------ Loss: 1976.04 ------------ Accuracy: 90.8%\n",
            "Step: 3306 ------------ Loss: 1975.9 ------------ Accuracy: 90.8%\n",
            "Step: 3307 ------------ Loss: 1975.75 ------------ Accuracy: 90.8%\n",
            "Step: 3308 ------------ Loss: 1975.6 ------------ Accuracy: 90.8%\n",
            "Step: 3309 ------------ Loss: 1975.46 ------------ Accuracy: 90.8%\n",
            "Step: 3310 ------------ Loss: 1975.31 ------------ Accuracy: 90.8%\n",
            "Step: 3311 ------------ Loss: 1975.17 ------------ Accuracy: 90.8%\n",
            "Step: 3312 ------------ Loss: 1975.02 ------------ Accuracy: 90.8%\n",
            "Step: 3313 ------------ Loss: 1974.88 ------------ Accuracy: 90.8%\n",
            "Step: 3314 ------------ Loss: 1974.73 ------------ Accuracy: 90.8%\n",
            "Step: 3315 ------------ Loss: 1974.59 ------------ Accuracy: 90.8%\n",
            "Step: 3316 ------------ Loss: 1974.44 ------------ Accuracy: 90.8%\n",
            "Step: 3317 ------------ Loss: 1974.3 ------------ Accuracy: 90.8%\n",
            "Step: 3318 ------------ Loss: 1974.15 ------------ Accuracy: 90.8%\n",
            "Step: 3319 ------------ Loss: 1974.01 ------------ Accuracy: 90.8%\n",
            "Step: 3320 ------------ Loss: 1973.86 ------------ Accuracy: 90.8%\n",
            "Step: 3321 ------------ Loss: 1973.72 ------------ Accuracy: 90.8%\n",
            "Step: 3322 ------------ Loss: 1973.57 ------------ Accuracy: 90.8%\n",
            "Step: 3323 ------------ Loss: 1973.43 ------------ Accuracy: 90.8%\n",
            "Step: 3324 ------------ Loss: 1973.29 ------------ Accuracy: 90.8%\n",
            "Step: 3325 ------------ Loss: 1973.14 ------------ Accuracy: 90.8%\n",
            "Step: 3326 ------------ Loss: 1973.0 ------------ Accuracy: 90.8%\n",
            "Step: 3327 ------------ Loss: 1972.85 ------------ Accuracy: 90.8%\n",
            "Step: 3328 ------------ Loss: 1972.71 ------------ Accuracy: 90.8%\n",
            "Step: 3329 ------------ Loss: 1972.56 ------------ Accuracy: 90.8%\n",
            "Step: 3330 ------------ Loss: 1972.42 ------------ Accuracy: 90.8%\n",
            "Step: 3331 ------------ Loss: 1972.28 ------------ Accuracy: 90.8%\n",
            "Step: 3332 ------------ Loss: 1972.13 ------------ Accuracy: 90.8%\n",
            "Step: 3333 ------------ Loss: 1971.99 ------------ Accuracy: 90.8%\n",
            "Step: 3334 ------------ Loss: 1971.85 ------------ Accuracy: 90.8%\n",
            "Step: 3335 ------------ Loss: 1971.7 ------------ Accuracy: 90.8%\n",
            "Step: 3336 ------------ Loss: 1971.56 ------------ Accuracy: 90.8%\n",
            "Step: 3337 ------------ Loss: 1971.42 ------------ Accuracy: 90.8%\n",
            "Step: 3338 ------------ Loss: 1971.27 ------------ Accuracy: 90.8%\n",
            "Step: 3339 ------------ Loss: 1971.13 ------------ Accuracy: 90.8%\n",
            "Step: 3340 ------------ Loss: 1970.99 ------------ Accuracy: 90.8%\n",
            "Step: 3341 ------------ Loss: 1970.84 ------------ Accuracy: 90.8%\n",
            "Step: 3342 ------------ Loss: 1970.7 ------------ Accuracy: 90.8%\n",
            "Step: 3343 ------------ Loss: 1970.56 ------------ Accuracy: 90.8%\n",
            "Step: 3344 ------------ Loss: 1970.41 ------------ Accuracy: 90.8%\n",
            "Step: 3345 ------------ Loss: 1970.27 ------------ Accuracy: 90.8%\n",
            "Step: 3346 ------------ Loss: 1970.13 ------------ Accuracy: 90.8%\n",
            "Step: 3347 ------------ Loss: 1969.99 ------------ Accuracy: 90.8%\n",
            "Step: 3348 ------------ Loss: 1969.84 ------------ Accuracy: 90.8%\n",
            "Step: 3349 ------------ Loss: 1969.7 ------------ Accuracy: 90.8%\n",
            "Step: 3350 ------------ Loss: 1969.56 ------------ Accuracy: 90.8%\n",
            "Step: 3351 ------------ Loss: 1969.42 ------------ Accuracy: 90.8%\n",
            "Step: 3352 ------------ Loss: 1969.27 ------------ Accuracy: 90.8%\n",
            "Step: 3353 ------------ Loss: 1969.13 ------------ Accuracy: 90.8%\n",
            "Step: 3354 ------------ Loss: 1968.99 ------------ Accuracy: 90.8%\n",
            "Step: 3355 ------------ Loss: 1968.85 ------------ Accuracy: 90.8%\n",
            "Step: 3356 ------------ Loss: 1968.7 ------------ Accuracy: 90.8%\n",
            "Step: 3357 ------------ Loss: 1968.56 ------------ Accuracy: 90.8%\n",
            "Step: 3358 ------------ Loss: 1968.42 ------------ Accuracy: 90.8%\n",
            "Step: 3359 ------------ Loss: 1968.28 ------------ Accuracy: 90.8%\n",
            "Step: 3360 ------------ Loss: 1968.14 ------------ Accuracy: 90.8%\n",
            "Step: 3361 ------------ Loss: 1968.0 ------------ Accuracy: 90.8%\n",
            "Step: 3362 ------------ Loss: 1967.85 ------------ Accuracy: 90.8%\n",
            "Step: 3363 ------------ Loss: 1967.71 ------------ Accuracy: 90.8%\n",
            "Step: 3364 ------------ Loss: 1967.57 ------------ Accuracy: 90.8%\n",
            "Step: 3365 ------------ Loss: 1967.43 ------------ Accuracy: 90.8%\n",
            "Step: 3366 ------------ Loss: 1967.29 ------------ Accuracy: 90.8%\n",
            "Step: 3367 ------------ Loss: 1967.15 ------------ Accuracy: 90.8%\n",
            "Step: 3368 ------------ Loss: 1967.01 ------------ Accuracy: 90.8%\n",
            "Step: 3369 ------------ Loss: 1966.86 ------------ Accuracy: 90.8%\n",
            "Step: 3370 ------------ Loss: 1966.72 ------------ Accuracy: 90.8%\n",
            "Step: 3371 ------------ Loss: 1966.58 ------------ Accuracy: 90.8%\n",
            "Step: 3372 ------------ Loss: 1966.44 ------------ Accuracy: 90.8%\n",
            "Step: 3373 ------------ Loss: 1966.3 ------------ Accuracy: 90.8%\n",
            "Step: 3374 ------------ Loss: 1966.16 ------------ Accuracy: 90.8%\n",
            "Step: 3375 ------------ Loss: 1966.02 ------------ Accuracy: 90.8%\n",
            "Step: 3376 ------------ Loss: 1965.88 ------------ Accuracy: 90.8%\n",
            "Step: 3377 ------------ Loss: 1965.74 ------------ Accuracy: 90.8%\n",
            "Step: 3378 ------------ Loss: 1965.6 ------------ Accuracy: 90.8%\n",
            "Step: 3379 ------------ Loss: 1965.46 ------------ Accuracy: 90.8%\n",
            "Step: 3380 ------------ Loss: 1965.32 ------------ Accuracy: 90.8%\n",
            "Step: 3381 ------------ Loss: 1965.18 ------------ Accuracy: 90.8%\n",
            "Step: 3382 ------------ Loss: 1965.04 ------------ Accuracy: 90.8%\n",
            "Step: 3383 ------------ Loss: 1964.9 ------------ Accuracy: 90.8%\n",
            "Step: 3384 ------------ Loss: 1964.76 ------------ Accuracy: 90.8%\n",
            "Step: 3385 ------------ Loss: 1964.62 ------------ Accuracy: 90.8%\n",
            "Step: 3386 ------------ Loss: 1964.48 ------------ Accuracy: 90.8%\n",
            "Step: 3387 ------------ Loss: 1964.34 ------------ Accuracy: 90.8%\n",
            "Step: 3388 ------------ Loss: 1964.2 ------------ Accuracy: 90.8%\n",
            "Step: 3389 ------------ Loss: 1964.06 ------------ Accuracy: 90.8%\n",
            "Step: 3390 ------------ Loss: 1963.92 ------------ Accuracy: 90.8%\n",
            "Step: 3391 ------------ Loss: 1963.78 ------------ Accuracy: 90.8%\n",
            "Step: 3392 ------------ Loss: 1963.64 ------------ Accuracy: 90.8%\n",
            "Step: 3393 ------------ Loss: 1963.5 ------------ Accuracy: 90.8%\n",
            "Step: 3394 ------------ Loss: 1963.36 ------------ Accuracy: 90.8%\n",
            "Step: 3395 ------------ Loss: 1963.22 ------------ Accuracy: 90.8%\n",
            "Step: 3396 ------------ Loss: 1963.08 ------------ Accuracy: 90.8%\n",
            "Step: 3397 ------------ Loss: 1962.94 ------------ Accuracy: 90.8%\n",
            "Step: 3398 ------------ Loss: 1962.8 ------------ Accuracy: 90.8%\n",
            "Step: 3399 ------------ Loss: 1962.66 ------------ Accuracy: 90.8%\n",
            "Step: 3400 ------------ Loss: 1962.52 ------------ Accuracy: 90.8%\n",
            "Step: 3401 ------------ Loss: 1962.39 ------------ Accuracy: 90.8%\n",
            "Step: 3402 ------------ Loss: 1962.25 ------------ Accuracy: 90.8%\n",
            "Step: 3403 ------------ Loss: 1962.11 ------------ Accuracy: 90.8%\n",
            "Step: 3404 ------------ Loss: 1961.97 ------------ Accuracy: 90.8%\n",
            "Step: 3405 ------------ Loss: 1961.83 ------------ Accuracy: 90.8%\n",
            "Step: 3406 ------------ Loss: 1961.69 ------------ Accuracy: 90.8%\n",
            "Step: 3407 ------------ Loss: 1961.55 ------------ Accuracy: 90.8%\n",
            "Step: 3408 ------------ Loss: 1961.42 ------------ Accuracy: 90.8%\n",
            "Step: 3409 ------------ Loss: 1961.28 ------------ Accuracy: 90.8%\n",
            "Step: 3410 ------------ Loss: 1961.14 ------------ Accuracy: 90.8%\n",
            "Step: 3411 ------------ Loss: 1961.0 ------------ Accuracy: 90.8%\n",
            "Step: 3412 ------------ Loss: 1960.86 ------------ Accuracy: 90.8%\n",
            "Step: 3413 ------------ Loss: 1960.72 ------------ Accuracy: 90.8%\n",
            "Step: 3414 ------------ Loss: 1960.59 ------------ Accuracy: 90.8%\n",
            "Step: 3415 ------------ Loss: 1960.45 ------------ Accuracy: 90.8%\n",
            "Step: 3416 ------------ Loss: 1960.31 ------------ Accuracy: 90.8%\n",
            "Step: 3417 ------------ Loss: 1960.17 ------------ Accuracy: 90.8%\n",
            "Step: 3418 ------------ Loss: 1960.04 ------------ Accuracy: 90.8%\n",
            "Step: 3419 ------------ Loss: 1959.9 ------------ Accuracy: 90.8%\n",
            "Step: 3420 ------------ Loss: 1959.76 ------------ Accuracy: 90.8%\n",
            "Step: 3421 ------------ Loss: 1959.62 ------------ Accuracy: 90.7%\n",
            "Step: 3422 ------------ Loss: 1959.49 ------------ Accuracy: 90.7%\n",
            "Step: 3423 ------------ Loss: 1959.35 ------------ Accuracy: 90.7%\n",
            "Step: 3424 ------------ Loss: 1959.21 ------------ Accuracy: 90.7%\n",
            "Step: 3425 ------------ Loss: 1959.07 ------------ Accuracy: 90.7%\n",
            "Step: 3426 ------------ Loss: 1958.94 ------------ Accuracy: 90.7%\n",
            "Step: 3427 ------------ Loss: 1958.8 ------------ Accuracy: 90.7%\n",
            "Step: 3428 ------------ Loss: 1958.66 ------------ Accuracy: 90.7%\n",
            "Step: 3429 ------------ Loss: 1958.53 ------------ Accuracy: 90.7%\n",
            "Step: 3430 ------------ Loss: 1958.39 ------------ Accuracy: 90.7%\n",
            "Step: 3431 ------------ Loss: 1958.25 ------------ Accuracy: 90.7%\n",
            "Step: 3432 ------------ Loss: 1958.11 ------------ Accuracy: 90.7%\n",
            "Step: 3433 ------------ Loss: 1957.98 ------------ Accuracy: 90.7%\n",
            "Step: 3434 ------------ Loss: 1957.84 ------------ Accuracy: 90.7%\n",
            "Step: 3435 ------------ Loss: 1957.71 ------------ Accuracy: 90.7%\n",
            "Step: 3436 ------------ Loss: 1957.57 ------------ Accuracy: 90.7%\n",
            "Step: 3437 ------------ Loss: 1957.43 ------------ Accuracy: 90.7%\n",
            "Step: 3438 ------------ Loss: 1957.3 ------------ Accuracy: 90.7%\n",
            "Step: 3439 ------------ Loss: 1957.16 ------------ Accuracy: 90.7%\n",
            "Step: 3440 ------------ Loss: 1957.02 ------------ Accuracy: 90.7%\n",
            "Step: 3441 ------------ Loss: 1956.89 ------------ Accuracy: 90.7%\n",
            "Step: 3442 ------------ Loss: 1956.75 ------------ Accuracy: 90.7%\n",
            "Step: 3443 ------------ Loss: 1956.61 ------------ Accuracy: 90.7%\n",
            "Step: 3444 ------------ Loss: 1956.48 ------------ Accuracy: 90.7%\n",
            "Step: 3445 ------------ Loss: 1956.34 ------------ Accuracy: 90.7%\n",
            "Step: 3446 ------------ Loss: 1956.21 ------------ Accuracy: 90.7%\n",
            "Step: 3447 ------------ Loss: 1956.07 ------------ Accuracy: 90.7%\n",
            "Step: 3448 ------------ Loss: 1955.94 ------------ Accuracy: 90.7%\n",
            "Step: 3449 ------------ Loss: 1955.8 ------------ Accuracy: 90.7%\n",
            "Step: 3450 ------------ Loss: 1955.66 ------------ Accuracy: 90.7%\n",
            "Step: 3451 ------------ Loss: 1955.53 ------------ Accuracy: 90.7%\n",
            "Step: 3452 ------------ Loss: 1955.39 ------------ Accuracy: 90.7%\n",
            "Step: 3453 ------------ Loss: 1955.26 ------------ Accuracy: 90.7%\n",
            "Step: 3454 ------------ Loss: 1955.12 ------------ Accuracy: 90.7%\n",
            "Step: 3455 ------------ Loss: 1954.99 ------------ Accuracy: 90.7%\n",
            "Step: 3456 ------------ Loss: 1954.85 ------------ Accuracy: 90.7%\n",
            "Step: 3457 ------------ Loss: 1954.72 ------------ Accuracy: 90.7%\n",
            "Step: 3458 ------------ Loss: 1954.58 ------------ Accuracy: 90.7%\n",
            "Step: 3459 ------------ Loss: 1954.45 ------------ Accuracy: 90.7%\n",
            "Step: 3460 ------------ Loss: 1954.31 ------------ Accuracy: 90.7%\n",
            "Step: 3461 ------------ Loss: 1954.18 ------------ Accuracy: 90.7%\n",
            "Step: 3462 ------------ Loss: 1954.04 ------------ Accuracy: 90.7%\n",
            "Step: 3463 ------------ Loss: 1953.91 ------------ Accuracy: 90.7%\n",
            "Step: 3464 ------------ Loss: 1953.77 ------------ Accuracy: 90.7%\n",
            "Step: 3465 ------------ Loss: 1953.64 ------------ Accuracy: 90.7%\n",
            "Step: 3466 ------------ Loss: 1953.5 ------------ Accuracy: 90.7%\n",
            "Step: 3467 ------------ Loss: 1953.37 ------------ Accuracy: 90.7%\n",
            "Step: 3468 ------------ Loss: 1953.24 ------------ Accuracy: 90.7%\n",
            "Step: 3469 ------------ Loss: 1953.1 ------------ Accuracy: 90.7%\n",
            "Step: 3470 ------------ Loss: 1952.97 ------------ Accuracy: 90.7%\n",
            "Step: 3471 ------------ Loss: 1952.83 ------------ Accuracy: 90.7%\n",
            "Step: 3472 ------------ Loss: 1952.7 ------------ Accuracy: 90.7%\n",
            "Step: 3473 ------------ Loss: 1952.57 ------------ Accuracy: 90.7%\n",
            "Step: 3474 ------------ Loss: 1952.43 ------------ Accuracy: 90.7%\n",
            "Step: 3475 ------------ Loss: 1952.3 ------------ Accuracy: 90.7%\n",
            "Step: 3476 ------------ Loss: 1952.16 ------------ Accuracy: 90.7%\n",
            "Step: 3477 ------------ Loss: 1952.03 ------------ Accuracy: 90.7%\n",
            "Step: 3478 ------------ Loss: 1951.9 ------------ Accuracy: 90.7%\n",
            "Step: 3479 ------------ Loss: 1951.76 ------------ Accuracy: 90.7%\n",
            "Step: 3480 ------------ Loss: 1951.63 ------------ Accuracy: 90.7%\n",
            "Step: 3481 ------------ Loss: 1951.5 ------------ Accuracy: 90.7%\n",
            "Step: 3482 ------------ Loss: 1951.36 ------------ Accuracy: 90.7%\n",
            "Step: 3483 ------------ Loss: 1951.23 ------------ Accuracy: 90.7%\n",
            "Step: 3484 ------------ Loss: 1951.1 ------------ Accuracy: 90.7%\n",
            "Step: 3485 ------------ Loss: 1950.96 ------------ Accuracy: 90.7%\n",
            "Step: 3486 ------------ Loss: 1950.83 ------------ Accuracy: 90.7%\n",
            "Step: 3487 ------------ Loss: 1950.7 ------------ Accuracy: 90.7%\n",
            "Step: 3488 ------------ Loss: 1950.56 ------------ Accuracy: 90.7%\n",
            "Step: 3489 ------------ Loss: 1950.43 ------------ Accuracy: 90.7%\n",
            "Step: 3490 ------------ Loss: 1950.3 ------------ Accuracy: 90.7%\n",
            "Step: 3491 ------------ Loss: 1950.16 ------------ Accuracy: 90.8%\n",
            "Step: 3492 ------------ Loss: 1950.03 ------------ Accuracy: 90.8%\n",
            "Step: 3493 ------------ Loss: 1949.9 ------------ Accuracy: 90.8%\n",
            "Step: 3494 ------------ Loss: 1949.77 ------------ Accuracy: 90.8%\n",
            "Step: 3495 ------------ Loss: 1949.63 ------------ Accuracy: 90.8%\n",
            "Step: 3496 ------------ Loss: 1949.5 ------------ Accuracy: 90.8%\n",
            "Step: 3497 ------------ Loss: 1949.37 ------------ Accuracy: 90.8%\n",
            "Step: 3498 ------------ Loss: 1949.24 ------------ Accuracy: 90.8%\n",
            "Step: 3499 ------------ Loss: 1949.1 ------------ Accuracy: 90.8%\n",
            "Step: 3500 ------------ Loss: 1948.97 ------------ Accuracy: 90.8%\n",
            "Step: 3501 ------------ Loss: 1948.84 ------------ Accuracy: 90.8%\n",
            "Step: 3502 ------------ Loss: 1948.71 ------------ Accuracy: 90.8%\n",
            "Step: 3503 ------------ Loss: 1948.57 ------------ Accuracy: 90.8%\n",
            "Step: 3504 ------------ Loss: 1948.44 ------------ Accuracy: 90.8%\n",
            "Step: 3505 ------------ Loss: 1948.31 ------------ Accuracy: 90.8%\n",
            "Step: 3506 ------------ Loss: 1948.18 ------------ Accuracy: 90.8%\n",
            "Step: 3507 ------------ Loss: 1948.05 ------------ Accuracy: 90.8%\n",
            "Step: 3508 ------------ Loss: 1947.91 ------------ Accuracy: 90.8%\n",
            "Step: 3509 ------------ Loss: 1947.78 ------------ Accuracy: 90.8%\n",
            "Step: 3510 ------------ Loss: 1947.65 ------------ Accuracy: 90.8%\n",
            "Step: 3511 ------------ Loss: 1947.52 ------------ Accuracy: 90.8%\n",
            "Step: 3512 ------------ Loss: 1947.39 ------------ Accuracy: 90.8%\n",
            "Step: 3513 ------------ Loss: 1947.26 ------------ Accuracy: 90.8%\n",
            "Step: 3514 ------------ Loss: 1947.13 ------------ Accuracy: 90.8%\n",
            "Step: 3515 ------------ Loss: 1946.99 ------------ Accuracy: 90.8%\n",
            "Step: 3516 ------------ Loss: 1946.86 ------------ Accuracy: 90.8%\n",
            "Step: 3517 ------------ Loss: 1946.73 ------------ Accuracy: 90.8%\n",
            "Step: 3518 ------------ Loss: 1946.6 ------------ Accuracy: 90.8%\n",
            "Step: 3519 ------------ Loss: 1946.47 ------------ Accuracy: 90.8%\n",
            "Step: 3520 ------------ Loss: 1946.34 ------------ Accuracy: 90.8%\n",
            "Step: 3521 ------------ Loss: 1946.21 ------------ Accuracy: 90.8%\n",
            "Step: 3522 ------------ Loss: 1946.08 ------------ Accuracy: 90.8%\n",
            "Step: 3523 ------------ Loss: 1945.95 ------------ Accuracy: 90.8%\n",
            "Step: 3524 ------------ Loss: 1945.81 ------------ Accuracy: 90.8%\n",
            "Step: 3525 ------------ Loss: 1945.68 ------------ Accuracy: 90.8%\n",
            "Step: 3526 ------------ Loss: 1945.55 ------------ Accuracy: 90.8%\n",
            "Step: 3527 ------------ Loss: 1945.42 ------------ Accuracy: 90.8%\n",
            "Step: 3528 ------------ Loss: 1945.29 ------------ Accuracy: 90.8%\n",
            "Step: 3529 ------------ Loss: 1945.16 ------------ Accuracy: 90.8%\n",
            "Step: 3530 ------------ Loss: 1945.03 ------------ Accuracy: 90.8%\n",
            "Step: 3531 ------------ Loss: 1944.9 ------------ Accuracy: 90.8%\n",
            "Step: 3532 ------------ Loss: 1944.77 ------------ Accuracy: 90.8%\n",
            "Step: 3533 ------------ Loss: 1944.64 ------------ Accuracy: 90.8%\n",
            "Step: 3534 ------------ Loss: 1944.51 ------------ Accuracy: 90.8%\n",
            "Step: 3535 ------------ Loss: 1944.38 ------------ Accuracy: 90.8%\n",
            "Step: 3536 ------------ Loss: 1944.25 ------------ Accuracy: 90.8%\n",
            "Step: 3537 ------------ Loss: 1944.12 ------------ Accuracy: 90.8%\n",
            "Step: 3538 ------------ Loss: 1943.99 ------------ Accuracy: 90.8%\n",
            "Step: 3539 ------------ Loss: 1943.86 ------------ Accuracy: 90.8%\n",
            "Step: 3540 ------------ Loss: 1943.73 ------------ Accuracy: 90.8%\n",
            "Step: 3541 ------------ Loss: 1943.6 ------------ Accuracy: 90.8%\n",
            "Step: 3542 ------------ Loss: 1943.47 ------------ Accuracy: 90.8%\n",
            "Step: 3543 ------------ Loss: 1943.34 ------------ Accuracy: 90.8%\n",
            "Step: 3544 ------------ Loss: 1943.21 ------------ Accuracy: 90.8%\n",
            "Step: 3545 ------------ Loss: 1943.08 ------------ Accuracy: 90.8%\n",
            "Step: 3546 ------------ Loss: 1942.95 ------------ Accuracy: 90.8%\n",
            "Step: 3547 ------------ Loss: 1942.82 ------------ Accuracy: 90.8%\n",
            "Step: 3548 ------------ Loss: 1942.7 ------------ Accuracy: 90.8%\n",
            "Step: 3549 ------------ Loss: 1942.57 ------------ Accuracy: 90.8%\n",
            "Step: 3550 ------------ Loss: 1942.44 ------------ Accuracy: 90.8%\n",
            "Step: 3551 ------------ Loss: 1942.31 ------------ Accuracy: 90.8%\n",
            "Step: 3552 ------------ Loss: 1942.18 ------------ Accuracy: 90.8%\n",
            "Step: 3553 ------------ Loss: 1942.05 ------------ Accuracy: 90.8%\n",
            "Step: 3554 ------------ Loss: 1941.92 ------------ Accuracy: 90.8%\n",
            "Step: 3555 ------------ Loss: 1941.79 ------------ Accuracy: 90.8%\n",
            "Step: 3556 ------------ Loss: 1941.66 ------------ Accuracy: 90.8%\n",
            "Step: 3557 ------------ Loss: 1941.53 ------------ Accuracy: 90.8%\n",
            "Step: 3558 ------------ Loss: 1941.41 ------------ Accuracy: 90.8%\n",
            "Step: 3559 ------------ Loss: 1941.28 ------------ Accuracy: 90.8%\n",
            "Step: 3560 ------------ Loss: 1941.15 ------------ Accuracy: 90.8%\n",
            "Step: 3561 ------------ Loss: 1941.02 ------------ Accuracy: 90.8%\n",
            "Step: 3562 ------------ Loss: 1940.89 ------------ Accuracy: 90.8%\n",
            "Step: 3563 ------------ Loss: 1940.76 ------------ Accuracy: 90.8%\n",
            "Step: 3564 ------------ Loss: 1940.64 ------------ Accuracy: 90.8%\n",
            "Step: 3565 ------------ Loss: 1940.51 ------------ Accuracy: 90.8%\n",
            "Step: 3566 ------------ Loss: 1940.38 ------------ Accuracy: 90.8%\n",
            "Step: 3567 ------------ Loss: 1940.25 ------------ Accuracy: 90.8%\n",
            "Step: 3568 ------------ Loss: 1940.12 ------------ Accuracy: 90.8%\n",
            "Step: 3569 ------------ Loss: 1939.99 ------------ Accuracy: 90.8%\n",
            "Step: 3570 ------------ Loss: 1939.87 ------------ Accuracy: 90.8%\n",
            "Step: 3571 ------------ Loss: 1939.74 ------------ Accuracy: 90.8%\n",
            "Step: 3572 ------------ Loss: 1939.61 ------------ Accuracy: 90.8%\n",
            "Step: 3573 ------------ Loss: 1939.48 ------------ Accuracy: 90.8%\n",
            "Step: 3574 ------------ Loss: 1939.36 ------------ Accuracy: 90.8%\n",
            "Step: 3575 ------------ Loss: 1939.23 ------------ Accuracy: 90.8%\n",
            "Step: 3576 ------------ Loss: 1939.1 ------------ Accuracy: 90.8%\n",
            "Step: 3577 ------------ Loss: 1938.97 ------------ Accuracy: 90.8%\n",
            "Step: 3578 ------------ Loss: 1938.85 ------------ Accuracy: 90.8%\n",
            "Step: 3579 ------------ Loss: 1938.72 ------------ Accuracy: 90.8%\n",
            "Step: 3580 ------------ Loss: 1938.59 ------------ Accuracy: 90.8%\n",
            "Step: 3581 ------------ Loss: 1938.46 ------------ Accuracy: 90.8%\n",
            "Step: 3582 ------------ Loss: 1938.34 ------------ Accuracy: 90.8%\n",
            "Step: 3583 ------------ Loss: 1938.21 ------------ Accuracy: 90.8%\n",
            "Step: 3584 ------------ Loss: 1938.08 ------------ Accuracy: 90.8%\n",
            "Step: 3585 ------------ Loss: 1937.96 ------------ Accuracy: 90.8%\n",
            "Step: 3586 ------------ Loss: 1937.83 ------------ Accuracy: 90.8%\n",
            "Step: 3587 ------------ Loss: 1937.7 ------------ Accuracy: 90.8%\n",
            "Step: 3588 ------------ Loss: 1937.57 ------------ Accuracy: 90.8%\n",
            "Step: 3589 ------------ Loss: 1937.45 ------------ Accuracy: 90.8%\n",
            "Step: 3590 ------------ Loss: 1937.32 ------------ Accuracy: 90.8%\n",
            "Step: 3591 ------------ Loss: 1937.19 ------------ Accuracy: 90.8%\n",
            "Step: 3592 ------------ Loss: 1937.07 ------------ Accuracy: 90.8%\n",
            "Step: 3593 ------------ Loss: 1936.94 ------------ Accuracy: 90.8%\n",
            "Step: 3594 ------------ Loss: 1936.81 ------------ Accuracy: 90.8%\n",
            "Step: 3595 ------------ Loss: 1936.69 ------------ Accuracy: 90.8%\n",
            "Step: 3596 ------------ Loss: 1936.56 ------------ Accuracy: 90.8%\n",
            "Step: 3597 ------------ Loss: 1936.44 ------------ Accuracy: 90.8%\n",
            "Step: 3598 ------------ Loss: 1936.31 ------------ Accuracy: 90.8%\n",
            "Step: 3599 ------------ Loss: 1936.18 ------------ Accuracy: 90.8%\n",
            "Step: 3600 ------------ Loss: 1936.06 ------------ Accuracy: 90.8%\n",
            "Step: 3601 ------------ Loss: 1935.93 ------------ Accuracy: 90.8%\n",
            "Step: 3602 ------------ Loss: 1935.81 ------------ Accuracy: 90.8%\n",
            "Step: 3603 ------------ Loss: 1935.68 ------------ Accuracy: 90.8%\n",
            "Step: 3604 ------------ Loss: 1935.55 ------------ Accuracy: 90.8%\n",
            "Step: 3605 ------------ Loss: 1935.43 ------------ Accuracy: 90.8%\n",
            "Step: 3606 ------------ Loss: 1935.3 ------------ Accuracy: 90.8%\n",
            "Step: 3607 ------------ Loss: 1935.18 ------------ Accuracy: 90.8%\n",
            "Step: 3608 ------------ Loss: 1935.05 ------------ Accuracy: 90.8%\n",
            "Step: 3609 ------------ Loss: 1934.92 ------------ Accuracy: 90.8%\n",
            "Step: 3610 ------------ Loss: 1934.8 ------------ Accuracy: 90.8%\n",
            "Step: 3611 ------------ Loss: 1934.67 ------------ Accuracy: 90.8%\n",
            "Step: 3612 ------------ Loss: 1934.55 ------------ Accuracy: 90.8%\n",
            "Step: 3613 ------------ Loss: 1934.42 ------------ Accuracy: 90.8%\n",
            "Step: 3614 ------------ Loss: 1934.3 ------------ Accuracy: 90.8%\n",
            "Step: 3615 ------------ Loss: 1934.17 ------------ Accuracy: 90.8%\n",
            "Step: 3616 ------------ Loss: 1934.05 ------------ Accuracy: 90.8%\n",
            "Step: 3617 ------------ Loss: 1933.92 ------------ Accuracy: 90.8%\n",
            "Step: 3618 ------------ Loss: 1933.8 ------------ Accuracy: 90.8%\n",
            "Step: 3619 ------------ Loss: 1933.67 ------------ Accuracy: 90.8%\n",
            "Step: 3620 ------------ Loss: 1933.55 ------------ Accuracy: 90.8%\n",
            "Step: 3621 ------------ Loss: 1933.42 ------------ Accuracy: 90.8%\n",
            "Step: 3622 ------------ Loss: 1933.3 ------------ Accuracy: 90.8%\n",
            "Step: 3623 ------------ Loss: 1933.17 ------------ Accuracy: 90.8%\n",
            "Step: 3624 ------------ Loss: 1933.05 ------------ Accuracy: 90.8%\n",
            "Step: 3625 ------------ Loss: 1932.92 ------------ Accuracy: 90.8%\n",
            "Step: 3626 ------------ Loss: 1932.8 ------------ Accuracy: 90.8%\n",
            "Step: 3627 ------------ Loss: 1932.67 ------------ Accuracy: 90.8%\n",
            "Step: 3628 ------------ Loss: 1932.55 ------------ Accuracy: 90.8%\n",
            "Step: 3629 ------------ Loss: 1932.43 ------------ Accuracy: 90.8%\n",
            "Step: 3630 ------------ Loss: 1932.3 ------------ Accuracy: 90.8%\n",
            "Step: 3631 ------------ Loss: 1932.18 ------------ Accuracy: 90.8%\n",
            "Step: 3632 ------------ Loss: 1932.05 ------------ Accuracy: 90.8%\n",
            "Step: 3633 ------------ Loss: 1931.93 ------------ Accuracy: 90.8%\n",
            "Step: 3634 ------------ Loss: 1931.8 ------------ Accuracy: 90.8%\n",
            "Step: 3635 ------------ Loss: 1931.68 ------------ Accuracy: 90.8%\n",
            "Step: 3636 ------------ Loss: 1931.56 ------------ Accuracy: 90.8%\n",
            "Step: 3637 ------------ Loss: 1931.43 ------------ Accuracy: 90.8%\n",
            "Step: 3638 ------------ Loss: 1931.31 ------------ Accuracy: 90.8%\n",
            "Step: 3639 ------------ Loss: 1931.18 ------------ Accuracy: 90.8%\n",
            "Step: 3640 ------------ Loss: 1931.06 ------------ Accuracy: 90.8%\n",
            "Step: 3641 ------------ Loss: 1930.94 ------------ Accuracy: 90.8%\n",
            "Step: 3642 ------------ Loss: 1930.81 ------------ Accuracy: 90.8%\n",
            "Step: 3643 ------------ Loss: 1930.69 ------------ Accuracy: 90.8%\n",
            "Step: 3644 ------------ Loss: 1930.57 ------------ Accuracy: 90.8%\n",
            "Step: 3645 ------------ Loss: 1930.44 ------------ Accuracy: 90.8%\n",
            "Step: 3646 ------------ Loss: 1930.32 ------------ Accuracy: 90.8%\n",
            "Step: 3647 ------------ Loss: 1930.2 ------------ Accuracy: 90.8%\n",
            "Step: 3648 ------------ Loss: 1930.07 ------------ Accuracy: 90.8%\n",
            "Step: 3649 ------------ Loss: 1929.95 ------------ Accuracy: 90.8%\n",
            "Step: 3650 ------------ Loss: 1929.83 ------------ Accuracy: 90.8%\n",
            "Step: 3651 ------------ Loss: 1929.7 ------------ Accuracy: 90.8%\n",
            "Step: 3652 ------------ Loss: 1929.58 ------------ Accuracy: 90.8%\n",
            "Step: 3653 ------------ Loss: 1929.46 ------------ Accuracy: 90.8%\n",
            "Step: 3654 ------------ Loss: 1929.33 ------------ Accuracy: 90.8%\n",
            "Step: 3655 ------------ Loss: 1929.21 ------------ Accuracy: 90.8%\n",
            "Step: 3656 ------------ Loss: 1929.09 ------------ Accuracy: 90.8%\n",
            "Step: 3657 ------------ Loss: 1928.97 ------------ Accuracy: 90.8%\n",
            "Step: 3658 ------------ Loss: 1928.84 ------------ Accuracy: 90.8%\n",
            "Step: 3659 ------------ Loss: 1928.72 ------------ Accuracy: 90.8%\n",
            "Step: 3660 ------------ Loss: 1928.6 ------------ Accuracy: 90.8%\n",
            "Step: 3661 ------------ Loss: 1928.47 ------------ Accuracy: 90.8%\n",
            "Step: 3662 ------------ Loss: 1928.35 ------------ Accuracy: 90.8%\n",
            "Step: 3663 ------------ Loss: 1928.23 ------------ Accuracy: 90.8%\n",
            "Step: 3664 ------------ Loss: 1928.11 ------------ Accuracy: 90.8%\n",
            "Step: 3665 ------------ Loss: 1927.98 ------------ Accuracy: 90.8%\n",
            "Step: 3666 ------------ Loss: 1927.86 ------------ Accuracy: 90.8%\n",
            "Step: 3667 ------------ Loss: 1927.74 ------------ Accuracy: 90.8%\n",
            "Step: 3668 ------------ Loss: 1927.62 ------------ Accuracy: 90.8%\n",
            "Step: 3669 ------------ Loss: 1927.5 ------------ Accuracy: 90.8%\n",
            "Step: 3670 ------------ Loss: 1927.37 ------------ Accuracy: 90.8%\n",
            "Step: 3671 ------------ Loss: 1927.25 ------------ Accuracy: 90.8%\n",
            "Step: 3672 ------------ Loss: 1927.13 ------------ Accuracy: 90.8%\n",
            "Step: 3673 ------------ Loss: 1927.01 ------------ Accuracy: 90.8%\n",
            "Step: 3674 ------------ Loss: 1926.89 ------------ Accuracy: 90.8%\n",
            "Step: 3675 ------------ Loss: 1926.76 ------------ Accuracy: 90.8%\n",
            "Step: 3676 ------------ Loss: 1926.64 ------------ Accuracy: 90.8%\n",
            "Step: 3677 ------------ Loss: 1926.52 ------------ Accuracy: 90.8%\n",
            "Step: 3678 ------------ Loss: 1926.4 ------------ Accuracy: 90.8%\n",
            "Step: 3679 ------------ Loss: 1926.28 ------------ Accuracy: 90.8%\n",
            "Step: 3680 ------------ Loss: 1926.16 ------------ Accuracy: 90.8%\n",
            "Step: 3681 ------------ Loss: 1926.03 ------------ Accuracy: 90.8%\n",
            "Step: 3682 ------------ Loss: 1925.91 ------------ Accuracy: 90.8%\n",
            "Step: 3683 ------------ Loss: 1925.79 ------------ Accuracy: 90.8%\n",
            "Step: 3684 ------------ Loss: 1925.67 ------------ Accuracy: 90.8%\n",
            "Step: 3685 ------------ Loss: 1925.55 ------------ Accuracy: 90.8%\n",
            "Step: 3686 ------------ Loss: 1925.43 ------------ Accuracy: 90.8%\n",
            "Step: 3687 ------------ Loss: 1925.31 ------------ Accuracy: 90.8%\n",
            "Step: 3688 ------------ Loss: 1925.19 ------------ Accuracy: 90.8%\n",
            "Step: 3689 ------------ Loss: 1925.07 ------------ Accuracy: 90.8%\n",
            "Step: 3690 ------------ Loss: 1924.94 ------------ Accuracy: 90.8%\n",
            "Step: 3691 ------------ Loss: 1924.82 ------------ Accuracy: 90.8%\n",
            "Step: 3692 ------------ Loss: 1924.7 ------------ Accuracy: 90.8%\n",
            "Step: 3693 ------------ Loss: 1924.58 ------------ Accuracy: 90.8%\n",
            "Step: 3694 ------------ Loss: 1924.46 ------------ Accuracy: 90.8%\n",
            "Step: 3695 ------------ Loss: 1924.34 ------------ Accuracy: 90.8%\n",
            "Step: 3696 ------------ Loss: 1924.22 ------------ Accuracy: 90.8%\n",
            "Step: 3697 ------------ Loss: 1924.1 ------------ Accuracy: 90.8%\n",
            "Step: 3698 ------------ Loss: 1923.98 ------------ Accuracy: 90.8%\n",
            "Step: 3699 ------------ Loss: 1923.86 ------------ Accuracy: 90.8%\n",
            "Step: 3700 ------------ Loss: 1923.74 ------------ Accuracy: 90.8%\n",
            "Step: 3701 ------------ Loss: 1923.62 ------------ Accuracy: 90.8%\n",
            "Step: 3702 ------------ Loss: 1923.5 ------------ Accuracy: 90.8%\n",
            "Step: 3703 ------------ Loss: 1923.38 ------------ Accuracy: 90.8%\n",
            "Step: 3704 ------------ Loss: 1923.26 ------------ Accuracy: 90.8%\n",
            "Step: 3705 ------------ Loss: 1923.14 ------------ Accuracy: 90.8%\n",
            "Step: 3706 ------------ Loss: 1923.02 ------------ Accuracy: 90.8%\n",
            "Step: 3707 ------------ Loss: 1922.9 ------------ Accuracy: 90.8%\n",
            "Step: 3708 ------------ Loss: 1922.78 ------------ Accuracy: 90.8%\n",
            "Step: 3709 ------------ Loss: 1922.66 ------------ Accuracy: 90.8%\n",
            "Step: 3710 ------------ Loss: 1922.54 ------------ Accuracy: 90.8%\n",
            "Step: 3711 ------------ Loss: 1922.42 ------------ Accuracy: 90.8%\n",
            "Step: 3712 ------------ Loss: 1922.3 ------------ Accuracy: 90.8%\n",
            "Step: 3713 ------------ Loss: 1922.18 ------------ Accuracy: 90.8%\n",
            "Step: 3714 ------------ Loss: 1922.06 ------------ Accuracy: 90.8%\n",
            "Step: 3715 ------------ Loss: 1921.94 ------------ Accuracy: 90.8%\n",
            "Step: 3716 ------------ Loss: 1921.82 ------------ Accuracy: 90.8%\n",
            "Step: 3717 ------------ Loss: 1921.7 ------------ Accuracy: 90.8%\n",
            "Step: 3718 ------------ Loss: 1921.58 ------------ Accuracy: 90.8%\n",
            "Step: 3719 ------------ Loss: 1921.46 ------------ Accuracy: 90.8%\n",
            "Step: 3720 ------------ Loss: 1921.34 ------------ Accuracy: 90.8%\n",
            "Step: 3721 ------------ Loss: 1921.22 ------------ Accuracy: 90.8%\n",
            "Step: 3722 ------------ Loss: 1921.1 ------------ Accuracy: 90.8%\n",
            "Step: 3723 ------------ Loss: 1920.98 ------------ Accuracy: 90.8%\n",
            "Step: 3724 ------------ Loss: 1920.86 ------------ Accuracy: 90.8%\n",
            "Step: 3725 ------------ Loss: 1920.75 ------------ Accuracy: 90.8%\n",
            "Step: 3726 ------------ Loss: 1920.63 ------------ Accuracy: 90.8%\n",
            "Step: 3727 ------------ Loss: 1920.51 ------------ Accuracy: 90.8%\n",
            "Step: 3728 ------------ Loss: 1920.39 ------------ Accuracy: 90.8%\n",
            "Step: 3729 ------------ Loss: 1920.27 ------------ Accuracy: 90.8%\n",
            "Step: 3730 ------------ Loss: 1920.15 ------------ Accuracy: 90.8%\n",
            "Step: 3731 ------------ Loss: 1920.03 ------------ Accuracy: 90.8%\n",
            "Step: 3732 ------------ Loss: 1919.91 ------------ Accuracy: 90.8%\n",
            "Step: 3733 ------------ Loss: 1919.8 ------------ Accuracy: 90.8%\n",
            "Step: 3734 ------------ Loss: 1919.68 ------------ Accuracy: 90.8%\n",
            "Step: 3735 ------------ Loss: 1919.56 ------------ Accuracy: 90.8%\n",
            "Step: 3736 ------------ Loss: 1919.44 ------------ Accuracy: 90.8%\n",
            "Step: 3737 ------------ Loss: 1919.32 ------------ Accuracy: 90.8%\n",
            "Step: 3738 ------------ Loss: 1919.2 ------------ Accuracy: 90.8%\n",
            "Step: 3739 ------------ Loss: 1919.09 ------------ Accuracy: 90.8%\n",
            "Step: 3740 ------------ Loss: 1918.97 ------------ Accuracy: 90.8%\n",
            "Step: 3741 ------------ Loss: 1918.85 ------------ Accuracy: 90.8%\n",
            "Step: 3742 ------------ Loss: 1918.73 ------------ Accuracy: 90.8%\n",
            "Step: 3743 ------------ Loss: 1918.61 ------------ Accuracy: 90.8%\n",
            "Step: 3744 ------------ Loss: 1918.49 ------------ Accuracy: 90.8%\n",
            "Step: 3745 ------------ Loss: 1918.38 ------------ Accuracy: 90.8%\n",
            "Step: 3746 ------------ Loss: 1918.26 ------------ Accuracy: 90.8%\n",
            "Step: 3747 ------------ Loss: 1918.14 ------------ Accuracy: 90.8%\n",
            "Step: 3748 ------------ Loss: 1918.02 ------------ Accuracy: 90.8%\n",
            "Step: 3749 ------------ Loss: 1917.91 ------------ Accuracy: 90.8%\n",
            "Step: 3750 ------------ Loss: 1917.79 ------------ Accuracy: 90.8%\n",
            "Step: 3751 ------------ Loss: 1917.67 ------------ Accuracy: 90.8%\n",
            "Step: 3752 ------------ Loss: 1917.55 ------------ Accuracy: 90.8%\n",
            "Step: 3753 ------------ Loss: 1917.43 ------------ Accuracy: 90.8%\n",
            "Step: 3754 ------------ Loss: 1917.32 ------------ Accuracy: 90.8%\n",
            "Step: 3755 ------------ Loss: 1917.2 ------------ Accuracy: 90.8%\n",
            "Step: 3756 ------------ Loss: 1917.08 ------------ Accuracy: 90.8%\n",
            "Step: 3757 ------------ Loss: 1916.97 ------------ Accuracy: 90.8%\n",
            "Step: 3758 ------------ Loss: 1916.85 ------------ Accuracy: 90.8%\n",
            "Step: 3759 ------------ Loss: 1916.73 ------------ Accuracy: 90.8%\n",
            "Step: 3760 ------------ Loss: 1916.61 ------------ Accuracy: 90.8%\n",
            "Step: 3761 ------------ Loss: 1916.5 ------------ Accuracy: 90.8%\n",
            "Step: 3762 ------------ Loss: 1916.38 ------------ Accuracy: 90.8%\n",
            "Step: 3763 ------------ Loss: 1916.26 ------------ Accuracy: 90.8%\n",
            "Step: 3764 ------------ Loss: 1916.15 ------------ Accuracy: 90.8%\n",
            "Step: 3765 ------------ Loss: 1916.03 ------------ Accuracy: 90.8%\n",
            "Step: 3766 ------------ Loss: 1915.91 ------------ Accuracy: 90.8%\n",
            "Step: 3767 ------------ Loss: 1915.8 ------------ Accuracy: 90.8%\n",
            "Step: 3768 ------------ Loss: 1915.68 ------------ Accuracy: 90.8%\n",
            "Step: 3769 ------------ Loss: 1915.56 ------------ Accuracy: 90.8%\n",
            "Step: 3770 ------------ Loss: 1915.45 ------------ Accuracy: 90.8%\n",
            "Step: 3771 ------------ Loss: 1915.33 ------------ Accuracy: 90.8%\n",
            "Step: 3772 ------------ Loss: 1915.21 ------------ Accuracy: 90.8%\n",
            "Step: 3773 ------------ Loss: 1915.1 ------------ Accuracy: 90.8%\n",
            "Step: 3774 ------------ Loss: 1914.98 ------------ Accuracy: 90.8%\n",
            "Step: 3775 ------------ Loss: 1914.86 ------------ Accuracy: 90.8%\n",
            "Step: 3776 ------------ Loss: 1914.75 ------------ Accuracy: 90.8%\n",
            "Step: 3777 ------------ Loss: 1914.63 ------------ Accuracy: 90.8%\n",
            "Step: 3778 ------------ Loss: 1914.51 ------------ Accuracy: 90.8%\n",
            "Step: 3779 ------------ Loss: 1914.4 ------------ Accuracy: 90.8%\n",
            "Step: 3780 ------------ Loss: 1914.28 ------------ Accuracy: 90.8%\n",
            "Step: 3781 ------------ Loss: 1914.17 ------------ Accuracy: 90.8%\n",
            "Step: 3782 ------------ Loss: 1914.05 ------------ Accuracy: 90.8%\n",
            "Step: 3783 ------------ Loss: 1913.93 ------------ Accuracy: 90.8%\n",
            "Step: 3784 ------------ Loss: 1913.82 ------------ Accuracy: 90.8%\n",
            "Step: 3785 ------------ Loss: 1913.7 ------------ Accuracy: 90.8%\n",
            "Step: 3786 ------------ Loss: 1913.59 ------------ Accuracy: 90.8%\n",
            "Step: 3787 ------------ Loss: 1913.47 ------------ Accuracy: 90.8%\n",
            "Step: 3788 ------------ Loss: 1913.35 ------------ Accuracy: 90.8%\n",
            "Step: 3789 ------------ Loss: 1913.24 ------------ Accuracy: 90.8%\n",
            "Step: 3790 ------------ Loss: 1913.12 ------------ Accuracy: 90.8%\n",
            "Step: 3791 ------------ Loss: 1913.01 ------------ Accuracy: 90.8%\n",
            "Step: 3792 ------------ Loss: 1912.89 ------------ Accuracy: 90.8%\n",
            "Step: 3793 ------------ Loss: 1912.78 ------------ Accuracy: 90.8%\n",
            "Step: 3794 ------------ Loss: 1912.66 ------------ Accuracy: 90.8%\n",
            "Step: 3795 ------------ Loss: 1912.55 ------------ Accuracy: 90.8%\n",
            "Step: 3796 ------------ Loss: 1912.43 ------------ Accuracy: 90.8%\n",
            "Step: 3797 ------------ Loss: 1912.32 ------------ Accuracy: 90.8%\n",
            "Step: 3798 ------------ Loss: 1912.2 ------------ Accuracy: 90.8%\n",
            "Step: 3799 ------------ Loss: 1912.09 ------------ Accuracy: 90.8%\n",
            "Step: 3800 ------------ Loss: 1911.97 ------------ Accuracy: 90.8%\n",
            "Step: 3801 ------------ Loss: 1911.86 ------------ Accuracy: 90.8%\n",
            "Step: 3802 ------------ Loss: 1911.74 ------------ Accuracy: 90.8%\n",
            "Step: 3803 ------------ Loss: 1911.63 ------------ Accuracy: 90.8%\n",
            "Step: 3804 ------------ Loss: 1911.51 ------------ Accuracy: 90.8%\n",
            "Step: 3805 ------------ Loss: 1911.4 ------------ Accuracy: 90.8%\n",
            "Step: 3806 ------------ Loss: 1911.28 ------------ Accuracy: 90.8%\n",
            "Step: 3807 ------------ Loss: 1911.17 ------------ Accuracy: 90.8%\n",
            "Step: 3808 ------------ Loss: 1911.05 ------------ Accuracy: 90.8%\n",
            "Step: 3809 ------------ Loss: 1910.94 ------------ Accuracy: 90.8%\n",
            "Step: 3810 ------------ Loss: 1910.82 ------------ Accuracy: 90.8%\n",
            "Step: 3811 ------------ Loss: 1910.71 ------------ Accuracy: 90.8%\n",
            "Step: 3812 ------------ Loss: 1910.59 ------------ Accuracy: 90.8%\n",
            "Step: 3813 ------------ Loss: 1910.48 ------------ Accuracy: 90.8%\n",
            "Step: 3814 ------------ Loss: 1910.37 ------------ Accuracy: 90.8%\n",
            "Step: 3815 ------------ Loss: 1910.25 ------------ Accuracy: 90.8%\n",
            "Step: 3816 ------------ Loss: 1910.14 ------------ Accuracy: 90.8%\n",
            "Step: 3817 ------------ Loss: 1910.02 ------------ Accuracy: 90.8%\n",
            "Step: 3818 ------------ Loss: 1909.91 ------------ Accuracy: 90.8%\n",
            "Step: 3819 ------------ Loss: 1909.79 ------------ Accuracy: 90.8%\n",
            "Step: 3820 ------------ Loss: 1909.68 ------------ Accuracy: 90.8%\n",
            "Step: 3821 ------------ Loss: 1909.57 ------------ Accuracy: 90.8%\n",
            "Step: 3822 ------------ Loss: 1909.45 ------------ Accuracy: 90.8%\n",
            "Step: 3823 ------------ Loss: 1909.34 ------------ Accuracy: 90.8%\n",
            "Step: 3824 ------------ Loss: 1909.22 ------------ Accuracy: 90.8%\n",
            "Step: 3825 ------------ Loss: 1909.11 ------------ Accuracy: 90.8%\n",
            "Step: 3826 ------------ Loss: 1909.0 ------------ Accuracy: 90.8%\n",
            "Step: 3827 ------------ Loss: 1908.88 ------------ Accuracy: 90.8%\n",
            "Step: 3828 ------------ Loss: 1908.77 ------------ Accuracy: 90.8%\n",
            "Step: 3829 ------------ Loss: 1908.66 ------------ Accuracy: 90.8%\n",
            "Step: 3830 ------------ Loss: 1908.54 ------------ Accuracy: 90.8%\n",
            "Step: 3831 ------------ Loss: 1908.43 ------------ Accuracy: 90.8%\n",
            "Step: 3832 ------------ Loss: 1908.32 ------------ Accuracy: 90.8%\n",
            "Step: 3833 ------------ Loss: 1908.2 ------------ Accuracy: 90.8%\n",
            "Step: 3834 ------------ Loss: 1908.09 ------------ Accuracy: 90.8%\n",
            "Step: 3835 ------------ Loss: 1907.98 ------------ Accuracy: 90.8%\n",
            "Step: 3836 ------------ Loss: 1907.86 ------------ Accuracy: 90.8%\n",
            "Step: 3837 ------------ Loss: 1907.75 ------------ Accuracy: 90.8%\n",
            "Step: 3838 ------------ Loss: 1907.64 ------------ Accuracy: 90.8%\n",
            "Step: 3839 ------------ Loss: 1907.52 ------------ Accuracy: 90.8%\n",
            "Step: 3840 ------------ Loss: 1907.41 ------------ Accuracy: 90.8%\n",
            "Step: 3841 ------------ Loss: 1907.3 ------------ Accuracy: 90.8%\n",
            "Step: 3842 ------------ Loss: 1907.18 ------------ Accuracy: 90.8%\n",
            "Step: 3843 ------------ Loss: 1907.07 ------------ Accuracy: 90.8%\n",
            "Step: 3844 ------------ Loss: 1906.96 ------------ Accuracy: 90.8%\n",
            "Step: 3845 ------------ Loss: 1906.85 ------------ Accuracy: 90.8%\n",
            "Step: 3846 ------------ Loss: 1906.73 ------------ Accuracy: 90.8%\n",
            "Step: 3847 ------------ Loss: 1906.62 ------------ Accuracy: 90.8%\n",
            "Step: 3848 ------------ Loss: 1906.51 ------------ Accuracy: 90.8%\n",
            "Step: 3849 ------------ Loss: 1906.39 ------------ Accuracy: 90.8%\n",
            "Step: 3850 ------------ Loss: 1906.28 ------------ Accuracy: 90.8%\n",
            "Step: 3851 ------------ Loss: 1906.17 ------------ Accuracy: 90.8%\n",
            "Step: 3852 ------------ Loss: 1906.06 ------------ Accuracy: 90.8%\n",
            "Step: 3853 ------------ Loss: 1905.95 ------------ Accuracy: 90.8%\n",
            "Step: 3854 ------------ Loss: 1905.83 ------------ Accuracy: 90.8%\n",
            "Step: 3855 ------------ Loss: 1905.72 ------------ Accuracy: 90.8%\n",
            "Step: 3856 ------------ Loss: 1905.61 ------------ Accuracy: 90.8%\n",
            "Step: 3857 ------------ Loss: 1905.5 ------------ Accuracy: 90.8%\n",
            "Step: 3858 ------------ Loss: 1905.38 ------------ Accuracy: 90.8%\n",
            "Step: 3859 ------------ Loss: 1905.27 ------------ Accuracy: 90.8%\n",
            "Step: 3860 ------------ Loss: 1905.16 ------------ Accuracy: 90.8%\n",
            "Step: 3861 ------------ Loss: 1905.05 ------------ Accuracy: 90.8%\n",
            "Step: 3862 ------------ Loss: 1904.94 ------------ Accuracy: 90.8%\n",
            "Step: 3863 ------------ Loss: 1904.82 ------------ Accuracy: 90.8%\n",
            "Step: 3864 ------------ Loss: 1904.71 ------------ Accuracy: 90.8%\n",
            "Step: 3865 ------------ Loss: 1904.6 ------------ Accuracy: 90.8%\n",
            "Step: 3866 ------------ Loss: 1904.49 ------------ Accuracy: 90.8%\n",
            "Step: 3867 ------------ Loss: 1904.38 ------------ Accuracy: 90.8%\n",
            "Step: 3868 ------------ Loss: 1904.27 ------------ Accuracy: 90.8%\n",
            "Step: 3869 ------------ Loss: 1904.15 ------------ Accuracy: 90.8%\n",
            "Step: 3870 ------------ Loss: 1904.04 ------------ Accuracy: 90.8%\n",
            "Step: 3871 ------------ Loss: 1903.93 ------------ Accuracy: 90.8%\n",
            "Step: 3872 ------------ Loss: 1903.82 ------------ Accuracy: 90.8%\n",
            "Step: 3873 ------------ Loss: 1903.71 ------------ Accuracy: 90.8%\n",
            "Step: 3874 ------------ Loss: 1903.6 ------------ Accuracy: 90.8%\n",
            "Step: 3875 ------------ Loss: 1903.49 ------------ Accuracy: 90.8%\n",
            "Step: 3876 ------------ Loss: 1903.37 ------------ Accuracy: 90.8%\n",
            "Step: 3877 ------------ Loss: 1903.26 ------------ Accuracy: 90.8%\n",
            "Step: 3878 ------------ Loss: 1903.15 ------------ Accuracy: 90.8%\n",
            "Step: 3879 ------------ Loss: 1903.04 ------------ Accuracy: 90.8%\n",
            "Step: 3880 ------------ Loss: 1902.93 ------------ Accuracy: 90.8%\n",
            "Step: 3881 ------------ Loss: 1902.82 ------------ Accuracy: 90.8%\n",
            "Step: 3882 ------------ Loss: 1902.71 ------------ Accuracy: 90.8%\n",
            "Step: 3883 ------------ Loss: 1902.6 ------------ Accuracy: 90.8%\n",
            "Step: 3884 ------------ Loss: 1902.49 ------------ Accuracy: 90.8%\n",
            "Step: 3885 ------------ Loss: 1902.37 ------------ Accuracy: 90.8%\n",
            "Step: 3886 ------------ Loss: 1902.26 ------------ Accuracy: 90.8%\n",
            "Step: 3887 ------------ Loss: 1902.15 ------------ Accuracy: 90.8%\n",
            "Step: 3888 ------------ Loss: 1902.04 ------------ Accuracy: 90.8%\n",
            "Step: 3889 ------------ Loss: 1901.93 ------------ Accuracy: 90.8%\n",
            "Step: 3890 ------------ Loss: 1901.82 ------------ Accuracy: 90.8%\n",
            "Step: 3891 ------------ Loss: 1901.71 ------------ Accuracy: 90.8%\n",
            "Step: 3892 ------------ Loss: 1901.6 ------------ Accuracy: 90.8%\n",
            "Step: 3893 ------------ Loss: 1901.49 ------------ Accuracy: 90.8%\n",
            "Step: 3894 ------------ Loss: 1901.38 ------------ Accuracy: 90.8%\n",
            "Step: 3895 ------------ Loss: 1901.27 ------------ Accuracy: 90.8%\n",
            "Step: 3896 ------------ Loss: 1901.16 ------------ Accuracy: 90.8%\n",
            "Step: 3897 ------------ Loss: 1901.05 ------------ Accuracy: 90.8%\n",
            "Step: 3898 ------------ Loss: 1900.94 ------------ Accuracy: 90.8%\n",
            "Step: 3899 ------------ Loss: 1900.83 ------------ Accuracy: 90.8%\n",
            "Step: 3900 ------------ Loss: 1900.72 ------------ Accuracy: 90.8%\n",
            "Step: 3901 ------------ Loss: 1900.61 ------------ Accuracy: 90.8%\n",
            "Step: 3902 ------------ Loss: 1900.5 ------------ Accuracy: 90.8%\n",
            "Step: 3903 ------------ Loss: 1900.39 ------------ Accuracy: 90.8%\n",
            "Step: 3904 ------------ Loss: 1900.28 ------------ Accuracy: 90.8%\n",
            "Step: 3905 ------------ Loss: 1900.17 ------------ Accuracy: 90.8%\n",
            "Step: 3906 ------------ Loss: 1900.06 ------------ Accuracy: 90.8%\n",
            "Step: 3907 ------------ Loss: 1899.95 ------------ Accuracy: 90.8%\n",
            "Step: 3908 ------------ Loss: 1899.84 ------------ Accuracy: 90.8%\n",
            "Step: 3909 ------------ Loss: 1899.73 ------------ Accuracy: 90.8%\n",
            "Step: 3910 ------------ Loss: 1899.62 ------------ Accuracy: 90.8%\n",
            "Step: 3911 ------------ Loss: 1899.51 ------------ Accuracy: 90.8%\n",
            "Step: 3912 ------------ Loss: 1899.4 ------------ Accuracy: 90.8%\n",
            "Step: 3913 ------------ Loss: 1899.29 ------------ Accuracy: 90.8%\n",
            "Step: 3914 ------------ Loss: 1899.18 ------------ Accuracy: 90.8%\n",
            "Step: 3915 ------------ Loss: 1899.07 ------------ Accuracy: 90.8%\n",
            "Step: 3916 ------------ Loss: 1898.96 ------------ Accuracy: 90.8%\n",
            "Step: 3917 ------------ Loss: 1898.85 ------------ Accuracy: 90.8%\n",
            "Step: 3918 ------------ Loss: 1898.74 ------------ Accuracy: 90.8%\n",
            "Step: 3919 ------------ Loss: 1898.64 ------------ Accuracy: 90.8%\n",
            "Step: 3920 ------------ Loss: 1898.53 ------------ Accuracy: 90.8%\n",
            "Step: 3921 ------------ Loss: 1898.42 ------------ Accuracy: 90.8%\n",
            "Step: 3922 ------------ Loss: 1898.31 ------------ Accuracy: 90.8%\n",
            "Step: 3923 ------------ Loss: 1898.2 ------------ Accuracy: 90.8%\n",
            "Step: 3924 ------------ Loss: 1898.09 ------------ Accuracy: 90.8%\n",
            "Step: 3925 ------------ Loss: 1897.98 ------------ Accuracy: 90.8%\n",
            "Step: 3926 ------------ Loss: 1897.87 ------------ Accuracy: 90.8%\n",
            "Step: 3927 ------------ Loss: 1897.76 ------------ Accuracy: 90.8%\n",
            "Step: 3928 ------------ Loss: 1897.65 ------------ Accuracy: 90.8%\n",
            "Step: 3929 ------------ Loss: 1897.55 ------------ Accuracy: 90.8%\n",
            "Step: 3930 ------------ Loss: 1897.44 ------------ Accuracy: 90.8%\n",
            "Step: 3931 ------------ Loss: 1897.33 ------------ Accuracy: 90.8%\n",
            "Step: 3932 ------------ Loss: 1897.22 ------------ Accuracy: 90.8%\n",
            "Step: 3933 ------------ Loss: 1897.11 ------------ Accuracy: 90.8%\n",
            "Step: 3934 ------------ Loss: 1897.0 ------------ Accuracy: 90.8%\n",
            "Step: 3935 ------------ Loss: 1896.89 ------------ Accuracy: 90.8%\n",
            "Step: 3936 ------------ Loss: 1896.79 ------------ Accuracy: 90.8%\n",
            "Step: 3937 ------------ Loss: 1896.68 ------------ Accuracy: 90.8%\n",
            "Step: 3938 ------------ Loss: 1896.57 ------------ Accuracy: 90.8%\n",
            "Step: 3939 ------------ Loss: 1896.46 ------------ Accuracy: 90.8%\n",
            "Step: 3940 ------------ Loss: 1896.35 ------------ Accuracy: 90.8%\n",
            "Step: 3941 ------------ Loss: 1896.25 ------------ Accuracy: 90.8%\n",
            "Step: 3942 ------------ Loss: 1896.14 ------------ Accuracy: 90.8%\n",
            "Step: 3943 ------------ Loss: 1896.03 ------------ Accuracy: 90.8%\n",
            "Step: 3944 ------------ Loss: 1895.92 ------------ Accuracy: 90.8%\n",
            "Step: 3945 ------------ Loss: 1895.81 ------------ Accuracy: 90.8%\n",
            "Step: 3946 ------------ Loss: 1895.71 ------------ Accuracy: 90.8%\n",
            "Step: 3947 ------------ Loss: 1895.6 ------------ Accuracy: 90.8%\n",
            "Step: 3948 ------------ Loss: 1895.49 ------------ Accuracy: 90.8%\n",
            "Step: 3949 ------------ Loss: 1895.38 ------------ Accuracy: 90.8%\n",
            "Step: 3950 ------------ Loss: 1895.27 ------------ Accuracy: 90.8%\n",
            "Step: 3951 ------------ Loss: 1895.17 ------------ Accuracy: 90.8%\n",
            "Step: 3952 ------------ Loss: 1895.06 ------------ Accuracy: 90.8%\n",
            "Step: 3953 ------------ Loss: 1894.95 ------------ Accuracy: 90.8%\n",
            "Step: 3954 ------------ Loss: 1894.84 ------------ Accuracy: 90.8%\n",
            "Step: 3955 ------------ Loss: 1894.74 ------------ Accuracy: 90.8%\n",
            "Step: 3956 ------------ Loss: 1894.63 ------------ Accuracy: 90.8%\n",
            "Step: 3957 ------------ Loss: 1894.52 ------------ Accuracy: 90.8%\n",
            "Step: 3958 ------------ Loss: 1894.41 ------------ Accuracy: 90.8%\n",
            "Step: 3959 ------------ Loss: 1894.31 ------------ Accuracy: 90.8%\n",
            "Step: 3960 ------------ Loss: 1894.2 ------------ Accuracy: 90.8%\n",
            "Step: 3961 ------------ Loss: 1894.09 ------------ Accuracy: 90.8%\n",
            "Step: 3962 ------------ Loss: 1893.98 ------------ Accuracy: 90.8%\n",
            "Step: 3963 ------------ Loss: 1893.88 ------------ Accuracy: 90.8%\n",
            "Step: 3964 ------------ Loss: 1893.77 ------------ Accuracy: 90.8%\n",
            "Step: 3965 ------------ Loss: 1893.66 ------------ Accuracy: 90.8%\n",
            "Step: 3966 ------------ Loss: 1893.56 ------------ Accuracy: 90.8%\n",
            "Step: 3967 ------------ Loss: 1893.45 ------------ Accuracy: 90.8%\n",
            "Step: 3968 ------------ Loss: 1893.34 ------------ Accuracy: 90.8%\n",
            "Step: 3969 ------------ Loss: 1893.24 ------------ Accuracy: 90.8%\n",
            "Step: 3970 ------------ Loss: 1893.13 ------------ Accuracy: 90.8%\n",
            "Step: 3971 ------------ Loss: 1893.02 ------------ Accuracy: 90.8%\n",
            "Step: 3972 ------------ Loss: 1892.92 ------------ Accuracy: 90.8%\n",
            "Step: 3973 ------------ Loss: 1892.81 ------------ Accuracy: 90.8%\n",
            "Step: 3974 ------------ Loss: 1892.7 ------------ Accuracy: 90.8%\n",
            "Step: 3975 ------------ Loss: 1892.6 ------------ Accuracy: 90.8%\n",
            "Step: 3976 ------------ Loss: 1892.49 ------------ Accuracy: 90.8%\n",
            "Step: 3977 ------------ Loss: 1892.38 ------------ Accuracy: 90.8%\n",
            "Step: 3978 ------------ Loss: 1892.28 ------------ Accuracy: 90.8%\n",
            "Step: 3979 ------------ Loss: 1892.17 ------------ Accuracy: 90.8%\n",
            "Step: 3980 ------------ Loss: 1892.06 ------------ Accuracy: 90.8%\n",
            "Step: 3981 ------------ Loss: 1891.96 ------------ Accuracy: 90.8%\n",
            "Step: 3982 ------------ Loss: 1891.85 ------------ Accuracy: 90.8%\n",
            "Step: 3983 ------------ Loss: 1891.74 ------------ Accuracy: 90.8%\n",
            "Step: 3984 ------------ Loss: 1891.64 ------------ Accuracy: 90.8%\n",
            "Step: 3985 ------------ Loss: 1891.53 ------------ Accuracy: 90.8%\n",
            "Step: 3986 ------------ Loss: 1891.43 ------------ Accuracy: 90.8%\n",
            "Step: 3987 ------------ Loss: 1891.32 ------------ Accuracy: 90.8%\n",
            "Step: 3988 ------------ Loss: 1891.21 ------------ Accuracy: 90.8%\n",
            "Step: 3989 ------------ Loss: 1891.11 ------------ Accuracy: 90.8%\n",
            "Step: 3990 ------------ Loss: 1891.0 ------------ Accuracy: 90.8%\n",
            "Step: 3991 ------------ Loss: 1890.9 ------------ Accuracy: 90.8%\n",
            "Step: 3992 ------------ Loss: 1890.79 ------------ Accuracy: 90.8%\n",
            "Step: 3993 ------------ Loss: 1890.68 ------------ Accuracy: 90.8%\n",
            "Step: 3994 ------------ Loss: 1890.58 ------------ Accuracy: 90.8%\n",
            "Step: 3995 ------------ Loss: 1890.47 ------------ Accuracy: 90.8%\n",
            "Step: 3996 ------------ Loss: 1890.37 ------------ Accuracy: 90.8%\n",
            "Step: 3997 ------------ Loss: 1890.26 ------------ Accuracy: 90.8%\n",
            "Step: 3998 ------------ Loss: 1890.16 ------------ Accuracy: 90.8%\n",
            "Step: 3999 ------------ Loss: 1890.05 ------------ Accuracy: 90.8%\n",
            "Step: 4000 ------------ Loss: 1889.95 ------------ Accuracy: 90.8%\n",
            "Step: 4001 ------------ Loss: 1889.84 ------------ Accuracy: 90.8%\n",
            "Step: 4002 ------------ Loss: 1889.74 ------------ Accuracy: 90.8%\n",
            "Step: 4003 ------------ Loss: 1889.63 ------------ Accuracy: 90.8%\n",
            "Step: 4004 ------------ Loss: 1889.52 ------------ Accuracy: 90.8%\n",
            "Step: 4005 ------------ Loss: 1889.42 ------------ Accuracy: 90.8%\n",
            "Step: 4006 ------------ Loss: 1889.31 ------------ Accuracy: 90.8%\n",
            "Step: 4007 ------------ Loss: 1889.21 ------------ Accuracy: 90.8%\n",
            "Step: 4008 ------------ Loss: 1889.1 ------------ Accuracy: 90.8%\n",
            "Step: 4009 ------------ Loss: 1889.0 ------------ Accuracy: 90.8%\n",
            "Step: 4010 ------------ Loss: 1888.89 ------------ Accuracy: 90.8%\n",
            "Step: 4011 ------------ Loss: 1888.79 ------------ Accuracy: 90.8%\n",
            "Step: 4012 ------------ Loss: 1888.68 ------------ Accuracy: 90.8%\n",
            "Step: 4013 ------------ Loss: 1888.58 ------------ Accuracy: 90.8%\n",
            "Step: 4014 ------------ Loss: 1888.47 ------------ Accuracy: 90.8%\n",
            "Step: 4015 ------------ Loss: 1888.37 ------------ Accuracy: 90.8%\n",
            "Step: 4016 ------------ Loss: 1888.26 ------------ Accuracy: 90.8%\n",
            "Step: 4017 ------------ Loss: 1888.16 ------------ Accuracy: 90.8%\n",
            "Step: 4018 ------------ Loss: 1888.06 ------------ Accuracy: 90.8%\n",
            "Step: 4019 ------------ Loss: 1887.95 ------------ Accuracy: 90.8%\n",
            "Step: 4020 ------------ Loss: 1887.85 ------------ Accuracy: 90.8%\n",
            "Step: 4021 ------------ Loss: 1887.74 ------------ Accuracy: 90.8%\n",
            "Step: 4022 ------------ Loss: 1887.64 ------------ Accuracy: 90.8%\n",
            "Step: 4023 ------------ Loss: 1887.53 ------------ Accuracy: 90.8%\n",
            "Step: 4024 ------------ Loss: 1887.43 ------------ Accuracy: 90.8%\n",
            "Step: 4025 ------------ Loss: 1887.32 ------------ Accuracy: 90.8%\n",
            "Step: 4026 ------------ Loss: 1887.22 ------------ Accuracy: 90.8%\n",
            "Step: 4027 ------------ Loss: 1887.12 ------------ Accuracy: 90.8%\n",
            "Step: 4028 ------------ Loss: 1887.01 ------------ Accuracy: 90.8%\n",
            "Step: 4029 ------------ Loss: 1886.91 ------------ Accuracy: 90.8%\n",
            "Step: 4030 ------------ Loss: 1886.8 ------------ Accuracy: 90.8%\n",
            "Step: 4031 ------------ Loss: 1886.7 ------------ Accuracy: 90.8%\n",
            "Step: 4032 ------------ Loss: 1886.59 ------------ Accuracy: 90.8%\n",
            "Step: 4033 ------------ Loss: 1886.49 ------------ Accuracy: 90.8%\n",
            "Step: 4034 ------------ Loss: 1886.39 ------------ Accuracy: 90.8%\n",
            "Step: 4035 ------------ Loss: 1886.28 ------------ Accuracy: 90.8%\n",
            "Step: 4036 ------------ Loss: 1886.18 ------------ Accuracy: 90.8%\n",
            "Step: 4037 ------------ Loss: 1886.08 ------------ Accuracy: 90.8%\n",
            "Step: 4038 ------------ Loss: 1885.97 ------------ Accuracy: 90.8%\n",
            "Step: 4039 ------------ Loss: 1885.87 ------------ Accuracy: 90.8%\n",
            "Step: 4040 ------------ Loss: 1885.76 ------------ Accuracy: 90.8%\n",
            "Step: 4041 ------------ Loss: 1885.66 ------------ Accuracy: 90.8%\n",
            "Step: 4042 ------------ Loss: 1885.56 ------------ Accuracy: 90.8%\n",
            "Step: 4043 ------------ Loss: 1885.45 ------------ Accuracy: 90.8%\n",
            "Step: 4044 ------------ Loss: 1885.35 ------------ Accuracy: 90.8%\n",
            "Step: 4045 ------------ Loss: 1885.25 ------------ Accuracy: 90.8%\n",
            "Step: 4046 ------------ Loss: 1885.14 ------------ Accuracy: 90.8%\n",
            "Step: 4047 ------------ Loss: 1885.04 ------------ Accuracy: 90.8%\n",
            "Step: 4048 ------------ Loss: 1884.94 ------------ Accuracy: 90.8%\n",
            "Step: 4049 ------------ Loss: 1884.83 ------------ Accuracy: 90.8%\n",
            "Step: 4050 ------------ Loss: 1884.73 ------------ Accuracy: 90.8%\n",
            "Step: 4051 ------------ Loss: 1884.63 ------------ Accuracy: 90.8%\n",
            "Step: 4052 ------------ Loss: 1884.52 ------------ Accuracy: 90.8%\n",
            "Step: 4053 ------------ Loss: 1884.42 ------------ Accuracy: 90.8%\n",
            "Step: 4054 ------------ Loss: 1884.32 ------------ Accuracy: 90.8%\n",
            "Step: 4055 ------------ Loss: 1884.21 ------------ Accuracy: 90.8%\n",
            "Step: 4056 ------------ Loss: 1884.11 ------------ Accuracy: 90.8%\n",
            "Step: 4057 ------------ Loss: 1884.01 ------------ Accuracy: 90.8%\n",
            "Step: 4058 ------------ Loss: 1883.91 ------------ Accuracy: 90.8%\n",
            "Step: 4059 ------------ Loss: 1883.8 ------------ Accuracy: 90.8%\n",
            "Step: 4060 ------------ Loss: 1883.7 ------------ Accuracy: 90.8%\n",
            "Step: 4061 ------------ Loss: 1883.6 ------------ Accuracy: 90.8%\n",
            "Step: 4062 ------------ Loss: 1883.49 ------------ Accuracy: 90.8%\n",
            "Step: 4063 ------------ Loss: 1883.39 ------------ Accuracy: 90.8%\n",
            "Step: 4064 ------------ Loss: 1883.29 ------------ Accuracy: 90.8%\n",
            "Step: 4065 ------------ Loss: 1883.19 ------------ Accuracy: 90.8%\n",
            "Step: 4066 ------------ Loss: 1883.08 ------------ Accuracy: 90.8%\n",
            "Step: 4067 ------------ Loss: 1882.98 ------------ Accuracy: 90.8%\n",
            "Step: 4068 ------------ Loss: 1882.88 ------------ Accuracy: 90.8%\n",
            "Step: 4069 ------------ Loss: 1882.78 ------------ Accuracy: 90.8%\n",
            "Step: 4070 ------------ Loss: 1882.67 ------------ Accuracy: 90.8%\n",
            "Step: 4071 ------------ Loss: 1882.57 ------------ Accuracy: 90.8%\n",
            "Step: 4072 ------------ Loss: 1882.47 ------------ Accuracy: 90.8%\n",
            "Step: 4073 ------------ Loss: 1882.37 ------------ Accuracy: 90.8%\n",
            "Step: 4074 ------------ Loss: 1882.26 ------------ Accuracy: 90.8%\n",
            "Step: 4075 ------------ Loss: 1882.16 ------------ Accuracy: 90.8%\n",
            "Step: 4076 ------------ Loss: 1882.06 ------------ Accuracy: 90.8%\n",
            "Step: 4077 ------------ Loss: 1881.96 ------------ Accuracy: 90.8%\n",
            "Step: 4078 ------------ Loss: 1881.86 ------------ Accuracy: 90.8%\n",
            "Step: 4079 ------------ Loss: 1881.75 ------------ Accuracy: 90.8%\n",
            "Step: 4080 ------------ Loss: 1881.65 ------------ Accuracy: 90.8%\n",
            "Step: 4081 ------------ Loss: 1881.55 ------------ Accuracy: 90.8%\n",
            "Step: 4082 ------------ Loss: 1881.45 ------------ Accuracy: 90.8%\n",
            "Step: 4083 ------------ Loss: 1881.35 ------------ Accuracy: 90.8%\n",
            "Step: 4084 ------------ Loss: 1881.24 ------------ Accuracy: 90.8%\n",
            "Step: 4085 ------------ Loss: 1881.14 ------------ Accuracy: 90.8%\n",
            "Step: 4086 ------------ Loss: 1881.04 ------------ Accuracy: 90.8%\n",
            "Step: 4087 ------------ Loss: 1880.94 ------------ Accuracy: 90.8%\n",
            "Step: 4088 ------------ Loss: 1880.84 ------------ Accuracy: 90.8%\n",
            "Step: 4089 ------------ Loss: 1880.74 ------------ Accuracy: 90.8%\n",
            "Step: 4090 ------------ Loss: 1880.64 ------------ Accuracy: 90.8%\n",
            "Step: 4091 ------------ Loss: 1880.53 ------------ Accuracy: 90.8%\n",
            "Step: 4092 ------------ Loss: 1880.43 ------------ Accuracy: 90.8%\n",
            "Step: 4093 ------------ Loss: 1880.33 ------------ Accuracy: 90.8%\n",
            "Step: 4094 ------------ Loss: 1880.23 ------------ Accuracy: 90.8%\n",
            "Step: 4095 ------------ Loss: 1880.13 ------------ Accuracy: 90.8%\n",
            "Step: 4096 ------------ Loss: 1880.03 ------------ Accuracy: 90.8%\n",
            "Step: 4097 ------------ Loss: 1879.93 ------------ Accuracy: 90.8%\n",
            "Step: 4098 ------------ Loss: 1879.82 ------------ Accuracy: 90.8%\n",
            "Step: 4099 ------------ Loss: 1879.72 ------------ Accuracy: 90.8%\n",
            "Step: 4100 ------------ Loss: 1879.62 ------------ Accuracy: 90.8%\n",
            "Step: 4101 ------------ Loss: 1879.52 ------------ Accuracy: 90.8%\n",
            "Step: 4102 ------------ Loss: 1879.42 ------------ Accuracy: 90.8%\n",
            "Step: 4103 ------------ Loss: 1879.32 ------------ Accuracy: 90.8%\n",
            "Step: 4104 ------------ Loss: 1879.22 ------------ Accuracy: 90.8%\n",
            "Step: 4105 ------------ Loss: 1879.12 ------------ Accuracy: 90.8%\n",
            "Step: 4106 ------------ Loss: 1879.02 ------------ Accuracy: 90.8%\n",
            "Step: 4107 ------------ Loss: 1878.92 ------------ Accuracy: 90.8%\n",
            "Step: 4108 ------------ Loss: 1878.81 ------------ Accuracy: 90.8%\n",
            "Step: 4109 ------------ Loss: 1878.71 ------------ Accuracy: 90.8%\n",
            "Step: 4110 ------------ Loss: 1878.61 ------------ Accuracy: 90.8%\n",
            "Step: 4111 ------------ Loss: 1878.51 ------------ Accuracy: 90.8%\n",
            "Step: 4112 ------------ Loss: 1878.41 ------------ Accuracy: 90.8%\n",
            "Step: 4113 ------------ Loss: 1878.31 ------------ Accuracy: 90.8%\n",
            "Step: 4114 ------------ Loss: 1878.21 ------------ Accuracy: 90.8%\n",
            "Step: 4115 ------------ Loss: 1878.11 ------------ Accuracy: 90.8%\n",
            "Step: 4116 ------------ Loss: 1878.01 ------------ Accuracy: 90.8%\n",
            "Step: 4117 ------------ Loss: 1877.91 ------------ Accuracy: 90.8%\n",
            "Step: 4118 ------------ Loss: 1877.81 ------------ Accuracy: 90.8%\n",
            "Step: 4119 ------------ Loss: 1877.71 ------------ Accuracy: 90.8%\n",
            "Step: 4120 ------------ Loss: 1877.61 ------------ Accuracy: 90.8%\n",
            "Step: 4121 ------------ Loss: 1877.51 ------------ Accuracy: 90.8%\n",
            "Step: 4122 ------------ Loss: 1877.41 ------------ Accuracy: 90.8%\n",
            "Step: 4123 ------------ Loss: 1877.31 ------------ Accuracy: 90.8%\n",
            "Step: 4124 ------------ Loss: 1877.21 ------------ Accuracy: 90.8%\n",
            "Step: 4125 ------------ Loss: 1877.11 ------------ Accuracy: 90.8%\n",
            "Step: 4126 ------------ Loss: 1877.01 ------------ Accuracy: 90.8%\n",
            "Step: 4127 ------------ Loss: 1876.91 ------------ Accuracy: 90.8%\n",
            "Step: 4128 ------------ Loss: 1876.81 ------------ Accuracy: 90.8%\n",
            "Step: 4129 ------------ Loss: 1876.71 ------------ Accuracy: 90.8%\n",
            "Step: 4130 ------------ Loss: 1876.61 ------------ Accuracy: 90.8%\n",
            "Step: 4131 ------------ Loss: 1876.51 ------------ Accuracy: 90.8%\n",
            "Step: 4132 ------------ Loss: 1876.41 ------------ Accuracy: 90.8%\n",
            "Step: 4133 ------------ Loss: 1876.31 ------------ Accuracy: 90.8%\n",
            "Step: 4134 ------------ Loss: 1876.21 ------------ Accuracy: 90.8%\n",
            "Step: 4135 ------------ Loss: 1876.11 ------------ Accuracy: 90.8%\n",
            "Step: 4136 ------------ Loss: 1876.01 ------------ Accuracy: 90.8%\n",
            "Step: 4137 ------------ Loss: 1875.91 ------------ Accuracy: 90.8%\n",
            "Step: 4138 ------------ Loss: 1875.81 ------------ Accuracy: 90.8%\n",
            "Step: 4139 ------------ Loss: 1875.71 ------------ Accuracy: 90.8%\n",
            "Step: 4140 ------------ Loss: 1875.61 ------------ Accuracy: 90.8%\n",
            "Step: 4141 ------------ Loss: 1875.51 ------------ Accuracy: 90.8%\n",
            "Step: 4142 ------------ Loss: 1875.41 ------------ Accuracy: 90.8%\n",
            "Step: 4143 ------------ Loss: 1875.31 ------------ Accuracy: 90.8%\n",
            "Step: 4144 ------------ Loss: 1875.21 ------------ Accuracy: 90.8%\n",
            "Step: 4145 ------------ Loss: 1875.12 ------------ Accuracy: 90.8%\n",
            "Step: 4146 ------------ Loss: 1875.02 ------------ Accuracy: 90.8%\n",
            "Step: 4147 ------------ Loss: 1874.92 ------------ Accuracy: 90.8%\n",
            "Step: 4148 ------------ Loss: 1874.82 ------------ Accuracy: 90.8%\n",
            "Step: 4149 ------------ Loss: 1874.72 ------------ Accuracy: 90.8%\n",
            "Step: 4150 ------------ Loss: 1874.62 ------------ Accuracy: 90.8%\n",
            "Step: 4151 ------------ Loss: 1874.52 ------------ Accuracy: 90.8%\n",
            "Step: 4152 ------------ Loss: 1874.42 ------------ Accuracy: 90.8%\n",
            "Step: 4153 ------------ Loss: 1874.32 ------------ Accuracy: 90.8%\n",
            "Step: 4154 ------------ Loss: 1874.22 ------------ Accuracy: 90.8%\n",
            "Step: 4155 ------------ Loss: 1874.12 ------------ Accuracy: 90.8%\n",
            "Step: 4156 ------------ Loss: 1874.03 ------------ Accuracy: 90.8%\n",
            "Step: 4157 ------------ Loss: 1873.93 ------------ Accuracy: 90.8%\n",
            "Step: 4158 ------------ Loss: 1873.83 ------------ Accuracy: 90.9%\n",
            "Step: 4159 ------------ Loss: 1873.73 ------------ Accuracy: 90.9%\n",
            "Step: 4160 ------------ Loss: 1873.63 ------------ Accuracy: 90.9%\n",
            "Step: 4161 ------------ Loss: 1873.53 ------------ Accuracy: 90.9%\n",
            "Step: 4162 ------------ Loss: 1873.43 ------------ Accuracy: 90.9%\n",
            "Step: 4163 ------------ Loss: 1873.34 ------------ Accuracy: 90.9%\n",
            "Step: 4164 ------------ Loss: 1873.24 ------------ Accuracy: 90.9%\n",
            "Step: 4165 ------------ Loss: 1873.14 ------------ Accuracy: 90.9%\n",
            "Step: 4166 ------------ Loss: 1873.04 ------------ Accuracy: 90.9%\n",
            "Step: 4167 ------------ Loss: 1872.94 ------------ Accuracy: 90.9%\n",
            "Step: 4168 ------------ Loss: 1872.84 ------------ Accuracy: 90.9%\n",
            "Step: 4169 ------------ Loss: 1872.75 ------------ Accuracy: 90.9%\n",
            "Step: 4170 ------------ Loss: 1872.65 ------------ Accuracy: 90.9%\n",
            "Step: 4171 ------------ Loss: 1872.55 ------------ Accuracy: 90.9%\n",
            "Step: 4172 ------------ Loss: 1872.45 ------------ Accuracy: 90.9%\n",
            "Step: 4173 ------------ Loss: 1872.35 ------------ Accuracy: 90.9%\n",
            "Step: 4174 ------------ Loss: 1872.25 ------------ Accuracy: 90.9%\n",
            "Step: 4175 ------------ Loss: 1872.16 ------------ Accuracy: 90.9%\n",
            "Step: 4176 ------------ Loss: 1872.06 ------------ Accuracy: 90.9%\n",
            "Step: 4177 ------------ Loss: 1871.96 ------------ Accuracy: 90.9%\n",
            "Step: 4178 ------------ Loss: 1871.86 ------------ Accuracy: 90.9%\n",
            "Step: 4179 ------------ Loss: 1871.76 ------------ Accuracy: 90.9%\n",
            "Step: 4180 ------------ Loss: 1871.67 ------------ Accuracy: 90.9%\n",
            "Step: 4181 ------------ Loss: 1871.57 ------------ Accuracy: 90.9%\n",
            "Step: 4182 ------------ Loss: 1871.47 ------------ Accuracy: 90.9%\n",
            "Step: 4183 ------------ Loss: 1871.37 ------------ Accuracy: 90.9%\n",
            "Step: 4184 ------------ Loss: 1871.28 ------------ Accuracy: 90.9%\n",
            "Step: 4185 ------------ Loss: 1871.18 ------------ Accuracy: 90.9%\n",
            "Step: 4186 ------------ Loss: 1871.08 ------------ Accuracy: 90.9%\n",
            "Step: 4187 ------------ Loss: 1870.98 ------------ Accuracy: 90.9%\n",
            "Step: 4188 ------------ Loss: 1870.89 ------------ Accuracy: 90.9%\n",
            "Step: 4189 ------------ Loss: 1870.79 ------------ Accuracy: 90.9%\n",
            "Step: 4190 ------------ Loss: 1870.69 ------------ Accuracy: 90.9%\n",
            "Step: 4191 ------------ Loss: 1870.59 ------------ Accuracy: 90.9%\n",
            "Step: 4192 ------------ Loss: 1870.5 ------------ Accuracy: 90.9%\n",
            "Step: 4193 ------------ Loss: 1870.4 ------------ Accuracy: 90.9%\n",
            "Step: 4194 ------------ Loss: 1870.3 ------------ Accuracy: 90.9%\n",
            "Step: 4195 ------------ Loss: 1870.2 ------------ Accuracy: 90.9%\n",
            "Step: 4196 ------------ Loss: 1870.11 ------------ Accuracy: 90.9%\n",
            "Step: 4197 ------------ Loss: 1870.01 ------------ Accuracy: 90.9%\n",
            "Step: 4198 ------------ Loss: 1869.91 ------------ Accuracy: 90.9%\n",
            "Step: 4199 ------------ Loss: 1869.82 ------------ Accuracy: 90.9%\n",
            "Step: 4200 ------------ Loss: 1869.72 ------------ Accuracy: 90.9%\n",
            "Step: 4201 ------------ Loss: 1869.62 ------------ Accuracy: 90.9%\n",
            "Step: 4202 ------------ Loss: 1869.52 ------------ Accuracy: 90.9%\n",
            "Step: 4203 ------------ Loss: 1869.43 ------------ Accuracy: 90.9%\n",
            "Step: 4204 ------------ Loss: 1869.33 ------------ Accuracy: 90.9%\n",
            "Step: 4205 ------------ Loss: 1869.23 ------------ Accuracy: 90.9%\n",
            "Step: 4206 ------------ Loss: 1869.14 ------------ Accuracy: 90.9%\n",
            "Step: 4207 ------------ Loss: 1869.04 ------------ Accuracy: 90.9%\n",
            "Step: 4208 ------------ Loss: 1868.94 ------------ Accuracy: 90.9%\n",
            "Step: 4209 ------------ Loss: 1868.85 ------------ Accuracy: 90.9%\n",
            "Step: 4210 ------------ Loss: 1868.75 ------------ Accuracy: 90.9%\n",
            "Step: 4211 ------------ Loss: 1868.65 ------------ Accuracy: 90.9%\n",
            "Step: 4212 ------------ Loss: 1868.56 ------------ Accuracy: 90.9%\n",
            "Step: 4213 ------------ Loss: 1868.46 ------------ Accuracy: 90.9%\n",
            "Step: 4214 ------------ Loss: 1868.36 ------------ Accuracy: 90.9%\n",
            "Step: 4215 ------------ Loss: 1868.27 ------------ Accuracy: 90.9%\n",
            "Step: 4216 ------------ Loss: 1868.17 ------------ Accuracy: 90.9%\n",
            "Step: 4217 ------------ Loss: 1868.07 ------------ Accuracy: 90.9%\n",
            "Step: 4218 ------------ Loss: 1867.98 ------------ Accuracy: 90.9%\n",
            "Step: 4219 ------------ Loss: 1867.88 ------------ Accuracy: 90.9%\n",
            "Step: 4220 ------------ Loss: 1867.79 ------------ Accuracy: 90.9%\n",
            "Step: 4221 ------------ Loss: 1867.69 ------------ Accuracy: 90.9%\n",
            "Step: 4222 ------------ Loss: 1867.59 ------------ Accuracy: 90.9%\n",
            "Step: 4223 ------------ Loss: 1867.5 ------------ Accuracy: 90.9%\n",
            "Step: 4224 ------------ Loss: 1867.4 ------------ Accuracy: 90.9%\n",
            "Step: 4225 ------------ Loss: 1867.31 ------------ Accuracy: 90.9%\n",
            "Step: 4226 ------------ Loss: 1867.21 ------------ Accuracy: 90.9%\n",
            "Step: 4227 ------------ Loss: 1867.11 ------------ Accuracy: 90.9%\n",
            "Step: 4228 ------------ Loss: 1867.02 ------------ Accuracy: 90.9%\n",
            "Step: 4229 ------------ Loss: 1866.92 ------------ Accuracy: 90.9%\n",
            "Step: 4230 ------------ Loss: 1866.83 ------------ Accuracy: 90.9%\n",
            "Step: 4231 ------------ Loss: 1866.73 ------------ Accuracy: 90.9%\n",
            "Step: 4232 ------------ Loss: 1866.63 ------------ Accuracy: 90.9%\n",
            "Step: 4233 ------------ Loss: 1866.54 ------------ Accuracy: 90.9%\n",
            "Step: 4234 ------------ Loss: 1866.44 ------------ Accuracy: 90.9%\n",
            "Step: 4235 ------------ Loss: 1866.35 ------------ Accuracy: 90.9%\n",
            "Step: 4236 ------------ Loss: 1866.25 ------------ Accuracy: 90.9%\n",
            "Step: 4237 ------------ Loss: 1866.16 ------------ Accuracy: 90.9%\n",
            "Step: 4238 ------------ Loss: 1866.06 ------------ Accuracy: 90.9%\n",
            "Step: 4239 ------------ Loss: 1865.96 ------------ Accuracy: 90.9%\n",
            "Step: 4240 ------------ Loss: 1865.87 ------------ Accuracy: 90.9%\n",
            "Step: 4241 ------------ Loss: 1865.77 ------------ Accuracy: 90.9%\n",
            "Step: 4242 ------------ Loss: 1865.68 ------------ Accuracy: 90.9%\n",
            "Step: 4243 ------------ Loss: 1865.58 ------------ Accuracy: 90.9%\n",
            "Step: 4244 ------------ Loss: 1865.49 ------------ Accuracy: 90.9%\n",
            "Step: 4245 ------------ Loss: 1865.39 ------------ Accuracy: 90.9%\n",
            "Step: 4246 ------------ Loss: 1865.3 ------------ Accuracy: 90.9%\n",
            "Step: 4247 ------------ Loss: 1865.2 ------------ Accuracy: 90.9%\n",
            "Step: 4248 ------------ Loss: 1865.11 ------------ Accuracy: 90.9%\n",
            "Step: 4249 ------------ Loss: 1865.01 ------------ Accuracy: 90.9%\n",
            "Step: 4250 ------------ Loss: 1864.92 ------------ Accuracy: 90.9%\n",
            "Step: 4251 ------------ Loss: 1864.82 ------------ Accuracy: 90.9%\n",
            "Step: 4252 ------------ Loss: 1864.73 ------------ Accuracy: 90.9%\n",
            "Step: 4253 ------------ Loss: 1864.63 ------------ Accuracy: 90.9%\n",
            "Step: 4254 ------------ Loss: 1864.54 ------------ Accuracy: 90.9%\n",
            "Step: 4255 ------------ Loss: 1864.44 ------------ Accuracy: 90.9%\n",
            "Step: 4256 ------------ Loss: 1864.35 ------------ Accuracy: 90.9%\n",
            "Step: 4257 ------------ Loss: 1864.25 ------------ Accuracy: 90.9%\n",
            "Step: 4258 ------------ Loss: 1864.16 ------------ Accuracy: 90.9%\n",
            "Step: 4259 ------------ Loss: 1864.06 ------------ Accuracy: 90.9%\n",
            "Step: 4260 ------------ Loss: 1863.97 ------------ Accuracy: 90.9%\n",
            "Step: 4261 ------------ Loss: 1863.87 ------------ Accuracy: 90.9%\n",
            "Step: 4262 ------------ Loss: 1863.78 ------------ Accuracy: 90.9%\n",
            "Step: 4263 ------------ Loss: 1863.68 ------------ Accuracy: 90.9%\n",
            "Step: 4264 ------------ Loss: 1863.59 ------------ Accuracy: 90.9%\n",
            "Step: 4265 ------------ Loss: 1863.49 ------------ Accuracy: 90.9%\n",
            "Step: 4266 ------------ Loss: 1863.4 ------------ Accuracy: 90.9%\n",
            "Step: 4267 ------------ Loss: 1863.3 ------------ Accuracy: 90.9%\n",
            "Step: 4268 ------------ Loss: 1863.21 ------------ Accuracy: 90.9%\n",
            "Step: 4269 ------------ Loss: 1863.12 ------------ Accuracy: 90.9%\n",
            "Step: 4270 ------------ Loss: 1863.02 ------------ Accuracy: 90.9%\n",
            "Step: 4271 ------------ Loss: 1862.93 ------------ Accuracy: 90.9%\n",
            "Step: 4272 ------------ Loss: 1862.83 ------------ Accuracy: 90.9%\n",
            "Step: 4273 ------------ Loss: 1862.74 ------------ Accuracy: 90.9%\n",
            "Step: 4274 ------------ Loss: 1862.64 ------------ Accuracy: 90.9%\n",
            "Step: 4275 ------------ Loss: 1862.55 ------------ Accuracy: 90.9%\n",
            "Step: 4276 ------------ Loss: 1862.46 ------------ Accuracy: 90.9%\n",
            "Step: 4277 ------------ Loss: 1862.36 ------------ Accuracy: 90.9%\n",
            "Step: 4278 ------------ Loss: 1862.27 ------------ Accuracy: 90.9%\n",
            "Step: 4279 ------------ Loss: 1862.17 ------------ Accuracy: 90.9%\n",
            "Step: 4280 ------------ Loss: 1862.08 ------------ Accuracy: 90.9%\n",
            "Step: 4281 ------------ Loss: 1861.99 ------------ Accuracy: 90.9%\n",
            "Step: 4282 ------------ Loss: 1861.89 ------------ Accuracy: 90.9%\n",
            "Step: 4283 ------------ Loss: 1861.8 ------------ Accuracy: 90.9%\n",
            "Step: 4284 ------------ Loss: 1861.7 ------------ Accuracy: 90.9%\n",
            "Step: 4285 ------------ Loss: 1861.61 ------------ Accuracy: 90.9%\n",
            "Step: 4286 ------------ Loss: 1861.52 ------------ Accuracy: 90.9%\n",
            "Step: 4287 ------------ Loss: 1861.42 ------------ Accuracy: 90.9%\n",
            "Step: 4288 ------------ Loss: 1861.33 ------------ Accuracy: 90.9%\n",
            "Step: 4289 ------------ Loss: 1861.24 ------------ Accuracy: 90.9%\n",
            "Step: 4290 ------------ Loss: 1861.14 ------------ Accuracy: 90.9%\n",
            "Step: 4291 ------------ Loss: 1861.05 ------------ Accuracy: 90.9%\n",
            "Step: 4292 ------------ Loss: 1860.96 ------------ Accuracy: 90.9%\n",
            "Step: 4293 ------------ Loss: 1860.86 ------------ Accuracy: 90.9%\n",
            "Step: 4294 ------------ Loss: 1860.77 ------------ Accuracy: 90.9%\n",
            "Step: 4295 ------------ Loss: 1860.68 ------------ Accuracy: 90.9%\n",
            "Step: 4296 ------------ Loss: 1860.58 ------------ Accuracy: 90.9%\n",
            "Step: 4297 ------------ Loss: 1860.49 ------------ Accuracy: 90.9%\n",
            "Step: 4298 ------------ Loss: 1860.4 ------------ Accuracy: 90.9%\n",
            "Step: 4299 ------------ Loss: 1860.3 ------------ Accuracy: 90.9%\n",
            "Step: 4300 ------------ Loss: 1860.21 ------------ Accuracy: 90.9%\n",
            "Step: 4301 ------------ Loss: 1860.12 ------------ Accuracy: 90.9%\n",
            "Step: 4302 ------------ Loss: 1860.02 ------------ Accuracy: 90.9%\n",
            "Step: 4303 ------------ Loss: 1859.93 ------------ Accuracy: 90.9%\n",
            "Step: 4304 ------------ Loss: 1859.84 ------------ Accuracy: 90.9%\n",
            "Step: 4305 ------------ Loss: 1859.74 ------------ Accuracy: 90.9%\n",
            "Step: 4306 ------------ Loss: 1859.65 ------------ Accuracy: 90.9%\n",
            "Step: 4307 ------------ Loss: 1859.56 ------------ Accuracy: 90.9%\n",
            "Step: 4308 ------------ Loss: 1859.46 ------------ Accuracy: 90.9%\n",
            "Step: 4309 ------------ Loss: 1859.37 ------------ Accuracy: 90.9%\n",
            "Step: 4310 ------------ Loss: 1859.28 ------------ Accuracy: 90.9%\n",
            "Step: 4311 ------------ Loss: 1859.19 ------------ Accuracy: 90.9%\n",
            "Step: 4312 ------------ Loss: 1859.09 ------------ Accuracy: 90.9%\n",
            "Step: 4313 ------------ Loss: 1859.0 ------------ Accuracy: 90.9%\n",
            "Step: 4314 ------------ Loss: 1858.91 ------------ Accuracy: 90.9%\n",
            "Step: 4315 ------------ Loss: 1858.81 ------------ Accuracy: 90.9%\n",
            "Step: 4316 ------------ Loss: 1858.72 ------------ Accuracy: 90.9%\n",
            "Step: 4317 ------------ Loss: 1858.63 ------------ Accuracy: 90.9%\n",
            "Step: 4318 ------------ Loss: 1858.54 ------------ Accuracy: 90.9%\n",
            "Step: 4319 ------------ Loss: 1858.44 ------------ Accuracy: 90.9%\n",
            "Step: 4320 ------------ Loss: 1858.35 ------------ Accuracy: 90.9%\n",
            "Step: 4321 ------------ Loss: 1858.26 ------------ Accuracy: 90.9%\n",
            "Step: 4322 ------------ Loss: 1858.17 ------------ Accuracy: 90.9%\n",
            "Step: 4323 ------------ Loss: 1858.07 ------------ Accuracy: 90.9%\n",
            "Step: 4324 ------------ Loss: 1857.98 ------------ Accuracy: 90.9%\n",
            "Step: 4325 ------------ Loss: 1857.89 ------------ Accuracy: 90.9%\n",
            "Step: 4326 ------------ Loss: 1857.8 ------------ Accuracy: 90.9%\n",
            "Step: 4327 ------------ Loss: 1857.71 ------------ Accuracy: 90.9%\n",
            "Step: 4328 ------------ Loss: 1857.61 ------------ Accuracy: 90.9%\n",
            "Step: 4329 ------------ Loss: 1857.52 ------------ Accuracy: 90.9%\n",
            "Step: 4330 ------------ Loss: 1857.43 ------------ Accuracy: 90.9%\n",
            "Step: 4331 ------------ Loss: 1857.34 ------------ Accuracy: 90.9%\n",
            "Step: 4332 ------------ Loss: 1857.24 ------------ Accuracy: 90.9%\n",
            "Step: 4333 ------------ Loss: 1857.15 ------------ Accuracy: 90.9%\n",
            "Step: 4334 ------------ Loss: 1857.06 ------------ Accuracy: 90.9%\n",
            "Step: 4335 ------------ Loss: 1856.97 ------------ Accuracy: 90.9%\n",
            "Step: 4336 ------------ Loss: 1856.88 ------------ Accuracy: 90.9%\n",
            "Step: 4337 ------------ Loss: 1856.78 ------------ Accuracy: 90.9%\n",
            "Step: 4338 ------------ Loss: 1856.69 ------------ Accuracy: 90.9%\n",
            "Step: 4339 ------------ Loss: 1856.6 ------------ Accuracy: 90.9%\n",
            "Step: 4340 ------------ Loss: 1856.51 ------------ Accuracy: 90.9%\n",
            "Step: 4341 ------------ Loss: 1856.42 ------------ Accuracy: 90.9%\n",
            "Step: 4342 ------------ Loss: 1856.33 ------------ Accuracy: 90.9%\n",
            "Step: 4343 ------------ Loss: 1856.23 ------------ Accuracy: 90.9%\n",
            "Step: 4344 ------------ Loss: 1856.14 ------------ Accuracy: 90.9%\n",
            "Step: 4345 ------------ Loss: 1856.05 ------------ Accuracy: 90.9%\n",
            "Step: 4346 ------------ Loss: 1855.96 ------------ Accuracy: 90.9%\n",
            "Step: 4347 ------------ Loss: 1855.87 ------------ Accuracy: 90.9%\n",
            "Step: 4348 ------------ Loss: 1855.78 ------------ Accuracy: 90.9%\n",
            "Step: 4349 ------------ Loss: 1855.69 ------------ Accuracy: 90.9%\n",
            "Step: 4350 ------------ Loss: 1855.59 ------------ Accuracy: 90.9%\n",
            "Step: 4351 ------------ Loss: 1855.5 ------------ Accuracy: 90.9%\n",
            "Step: 4352 ------------ Loss: 1855.41 ------------ Accuracy: 90.9%\n",
            "Step: 4353 ------------ Loss: 1855.32 ------------ Accuracy: 90.9%\n",
            "Step: 4354 ------------ Loss: 1855.23 ------------ Accuracy: 90.9%\n",
            "Step: 4355 ------------ Loss: 1855.14 ------------ Accuracy: 90.9%\n",
            "Step: 4356 ------------ Loss: 1855.05 ------------ Accuracy: 90.9%\n",
            "Step: 4357 ------------ Loss: 1854.95 ------------ Accuracy: 90.9%\n",
            "Step: 4358 ------------ Loss: 1854.86 ------------ Accuracy: 90.9%\n",
            "Step: 4359 ------------ Loss: 1854.77 ------------ Accuracy: 90.9%\n",
            "Step: 4360 ------------ Loss: 1854.68 ------------ Accuracy: 90.9%\n",
            "Step: 4361 ------------ Loss: 1854.59 ------------ Accuracy: 90.9%\n",
            "Step: 4362 ------------ Loss: 1854.5 ------------ Accuracy: 90.9%\n",
            "Step: 4363 ------------ Loss: 1854.41 ------------ Accuracy: 90.9%\n",
            "Step: 4364 ------------ Loss: 1854.32 ------------ Accuracy: 90.9%\n",
            "Step: 4365 ------------ Loss: 1854.23 ------------ Accuracy: 90.9%\n",
            "Step: 4366 ------------ Loss: 1854.14 ------------ Accuracy: 90.9%\n",
            "Step: 4367 ------------ Loss: 1854.05 ------------ Accuracy: 90.9%\n",
            "Step: 4368 ------------ Loss: 1853.95 ------------ Accuracy: 90.9%\n",
            "Step: 4369 ------------ Loss: 1853.86 ------------ Accuracy: 90.9%\n",
            "Step: 4370 ------------ Loss: 1853.77 ------------ Accuracy: 90.9%\n",
            "Step: 4371 ------------ Loss: 1853.68 ------------ Accuracy: 90.9%\n",
            "Step: 4372 ------------ Loss: 1853.59 ------------ Accuracy: 90.9%\n",
            "Step: 4373 ------------ Loss: 1853.5 ------------ Accuracy: 90.9%\n",
            "Step: 4374 ------------ Loss: 1853.41 ------------ Accuracy: 90.9%\n",
            "Step: 4375 ------------ Loss: 1853.32 ------------ Accuracy: 90.9%\n",
            "Step: 4376 ------------ Loss: 1853.23 ------------ Accuracy: 90.9%\n",
            "Step: 4377 ------------ Loss: 1853.14 ------------ Accuracy: 90.9%\n",
            "Step: 4378 ------------ Loss: 1853.05 ------------ Accuracy: 90.9%\n",
            "Step: 4379 ------------ Loss: 1852.96 ------------ Accuracy: 90.9%\n",
            "Step: 4380 ------------ Loss: 1852.87 ------------ Accuracy: 90.9%\n",
            "Step: 4381 ------------ Loss: 1852.78 ------------ Accuracy: 90.9%\n",
            "Step: 4382 ------------ Loss: 1852.69 ------------ Accuracy: 90.9%\n",
            "Step: 4383 ------------ Loss: 1852.6 ------------ Accuracy: 90.9%\n",
            "Step: 4384 ------------ Loss: 1852.51 ------------ Accuracy: 90.9%\n",
            "Step: 4385 ------------ Loss: 1852.42 ------------ Accuracy: 90.9%\n",
            "Step: 4386 ------------ Loss: 1852.33 ------------ Accuracy: 90.9%\n",
            "Step: 4387 ------------ Loss: 1852.24 ------------ Accuracy: 90.9%\n",
            "Step: 4388 ------------ Loss: 1852.15 ------------ Accuracy: 90.9%\n",
            "Step: 4389 ------------ Loss: 1852.06 ------------ Accuracy: 90.9%\n",
            "Step: 4390 ------------ Loss: 1851.97 ------------ Accuracy: 90.9%\n",
            "Step: 4391 ------------ Loss: 1851.88 ------------ Accuracy: 90.9%\n",
            "Step: 4392 ------------ Loss: 1851.79 ------------ Accuracy: 90.9%\n",
            "Step: 4393 ------------ Loss: 1851.7 ------------ Accuracy: 90.9%\n",
            "Step: 4394 ------------ Loss: 1851.61 ------------ Accuracy: 90.9%\n",
            "Step: 4395 ------------ Loss: 1851.52 ------------ Accuracy: 90.9%\n",
            "Step: 4396 ------------ Loss: 1851.43 ------------ Accuracy: 90.9%\n",
            "Step: 4397 ------------ Loss: 1851.34 ------------ Accuracy: 90.9%\n",
            "Step: 4398 ------------ Loss: 1851.25 ------------ Accuracy: 90.9%\n",
            "Step: 4399 ------------ Loss: 1851.16 ------------ Accuracy: 90.9%\n",
            "Step: 4400 ------------ Loss: 1851.07 ------------ Accuracy: 90.9%\n",
            "Step: 4401 ------------ Loss: 1850.98 ------------ Accuracy: 90.9%\n",
            "Step: 4402 ------------ Loss: 1850.89 ------------ Accuracy: 90.9%\n",
            "Step: 4403 ------------ Loss: 1850.8 ------------ Accuracy: 90.9%\n",
            "Step: 4404 ------------ Loss: 1850.71 ------------ Accuracy: 90.9%\n",
            "Step: 4405 ------------ Loss: 1850.62 ------------ Accuracy: 90.9%\n",
            "Step: 4406 ------------ Loss: 1850.53 ------------ Accuracy: 90.9%\n",
            "Step: 4407 ------------ Loss: 1850.44 ------------ Accuracy: 90.9%\n",
            "Step: 4408 ------------ Loss: 1850.35 ------------ Accuracy: 90.9%\n",
            "Step: 4409 ------------ Loss: 1850.26 ------------ Accuracy: 90.9%\n",
            "Step: 4410 ------------ Loss: 1850.17 ------------ Accuracy: 90.9%\n",
            "Step: 4411 ------------ Loss: 1850.08 ------------ Accuracy: 90.9%\n",
            "Step: 4412 ------------ Loss: 1850.0 ------------ Accuracy: 90.9%\n",
            "Step: 4413 ------------ Loss: 1849.91 ------------ Accuracy: 90.9%\n",
            "Step: 4414 ------------ Loss: 1849.82 ------------ Accuracy: 90.9%\n",
            "Step: 4415 ------------ Loss: 1849.73 ------------ Accuracy: 90.9%\n",
            "Step: 4416 ------------ Loss: 1849.64 ------------ Accuracy: 90.9%\n",
            "Step: 4417 ------------ Loss: 1849.55 ------------ Accuracy: 90.9%\n",
            "Step: 4418 ------------ Loss: 1849.46 ------------ Accuracy: 90.9%\n",
            "Step: 4419 ------------ Loss: 1849.37 ------------ Accuracy: 90.9%\n",
            "Step: 4420 ------------ Loss: 1849.28 ------------ Accuracy: 90.9%\n",
            "Step: 4421 ------------ Loss: 1849.19 ------------ Accuracy: 90.9%\n",
            "Step: 4422 ------------ Loss: 1849.11 ------------ Accuracy: 90.9%\n",
            "Step: 4423 ------------ Loss: 1849.02 ------------ Accuracy: 90.9%\n",
            "Step: 4424 ------------ Loss: 1848.93 ------------ Accuracy: 90.9%\n",
            "Step: 4425 ------------ Loss: 1848.84 ------------ Accuracy: 90.9%\n",
            "Step: 4426 ------------ Loss: 1848.75 ------------ Accuracy: 90.9%\n",
            "Step: 4427 ------------ Loss: 1848.66 ------------ Accuracy: 90.9%\n",
            "Step: 4428 ------------ Loss: 1848.57 ------------ Accuracy: 90.9%\n",
            "Step: 4429 ------------ Loss: 1848.48 ------------ Accuracy: 90.9%\n",
            "Step: 4430 ------------ Loss: 1848.4 ------------ Accuracy: 90.9%\n",
            "Step: 4431 ------------ Loss: 1848.31 ------------ Accuracy: 90.9%\n",
            "Step: 4432 ------------ Loss: 1848.22 ------------ Accuracy: 90.9%\n",
            "Step: 4433 ------------ Loss: 1848.13 ------------ Accuracy: 90.9%\n",
            "Step: 4434 ------------ Loss: 1848.04 ------------ Accuracy: 90.9%\n",
            "Step: 4435 ------------ Loss: 1847.95 ------------ Accuracy: 90.9%\n",
            "Step: 4436 ------------ Loss: 1847.86 ------------ Accuracy: 90.9%\n",
            "Step: 4437 ------------ Loss: 1847.78 ------------ Accuracy: 90.9%\n",
            "Step: 4438 ------------ Loss: 1847.69 ------------ Accuracy: 90.9%\n",
            "Step: 4439 ------------ Loss: 1847.6 ------------ Accuracy: 90.9%\n",
            "Step: 4440 ------------ Loss: 1847.51 ------------ Accuracy: 90.9%\n",
            "Step: 4441 ------------ Loss: 1847.42 ------------ Accuracy: 90.9%\n",
            "Step: 4442 ------------ Loss: 1847.33 ------------ Accuracy: 90.9%\n",
            "Step: 4443 ------------ Loss: 1847.25 ------------ Accuracy: 90.9%\n",
            "Step: 4444 ------------ Loss: 1847.16 ------------ Accuracy: 90.9%\n",
            "Step: 4445 ------------ Loss: 1847.07 ------------ Accuracy: 90.9%\n",
            "Step: 4446 ------------ Loss: 1846.98 ------------ Accuracy: 90.9%\n",
            "Step: 4447 ------------ Loss: 1846.89 ------------ Accuracy: 90.9%\n",
            "Step: 4448 ------------ Loss: 1846.81 ------------ Accuracy: 90.9%\n",
            "Step: 4449 ------------ Loss: 1846.72 ------------ Accuracy: 90.9%\n",
            "Step: 4450 ------------ Loss: 1846.63 ------------ Accuracy: 90.9%\n",
            "Step: 4451 ------------ Loss: 1846.54 ------------ Accuracy: 90.9%\n",
            "Step: 4452 ------------ Loss: 1846.45 ------------ Accuracy: 90.9%\n",
            "Step: 4453 ------------ Loss: 1846.37 ------------ Accuracy: 90.9%\n",
            "Step: 4454 ------------ Loss: 1846.28 ------------ Accuracy: 90.9%\n",
            "Step: 4455 ------------ Loss: 1846.19 ------------ Accuracy: 90.9%\n",
            "Step: 4456 ------------ Loss: 1846.1 ------------ Accuracy: 90.9%\n",
            "Step: 4457 ------------ Loss: 1846.02 ------------ Accuracy: 90.9%\n",
            "Step: 4458 ------------ Loss: 1845.93 ------------ Accuracy: 90.9%\n",
            "Step: 4459 ------------ Loss: 1845.84 ------------ Accuracy: 90.9%\n",
            "Step: 4460 ------------ Loss: 1845.75 ------------ Accuracy: 90.9%\n",
            "Step: 4461 ------------ Loss: 1845.67 ------------ Accuracy: 90.9%\n",
            "Step: 4462 ------------ Loss: 1845.58 ------------ Accuracy: 90.9%\n",
            "Step: 4463 ------------ Loss: 1845.49 ------------ Accuracy: 90.9%\n",
            "Step: 4464 ------------ Loss: 1845.4 ------------ Accuracy: 90.9%\n",
            "Step: 4465 ------------ Loss: 1845.32 ------------ Accuracy: 90.9%\n",
            "Step: 4466 ------------ Loss: 1845.23 ------------ Accuracy: 90.9%\n",
            "Step: 4467 ------------ Loss: 1845.14 ------------ Accuracy: 90.9%\n",
            "Step: 4468 ------------ Loss: 1845.05 ------------ Accuracy: 90.9%\n",
            "Step: 4469 ------------ Loss: 1844.97 ------------ Accuracy: 90.9%\n",
            "Step: 4470 ------------ Loss: 1844.88 ------------ Accuracy: 90.9%\n",
            "Step: 4471 ------------ Loss: 1844.79 ------------ Accuracy: 90.9%\n",
            "Step: 4472 ------------ Loss: 1844.7 ------------ Accuracy: 90.9%\n",
            "Step: 4473 ------------ Loss: 1844.62 ------------ Accuracy: 90.9%\n",
            "Step: 4474 ------------ Loss: 1844.53 ------------ Accuracy: 90.9%\n",
            "Step: 4475 ------------ Loss: 1844.44 ------------ Accuracy: 90.9%\n",
            "Step: 4476 ------------ Loss: 1844.36 ------------ Accuracy: 90.9%\n",
            "Step: 4477 ------------ Loss: 1844.27 ------------ Accuracy: 90.9%\n",
            "Step: 4478 ------------ Loss: 1844.18 ------------ Accuracy: 90.9%\n",
            "Step: 4479 ------------ Loss: 1844.09 ------------ Accuracy: 90.9%\n",
            "Step: 4480 ------------ Loss: 1844.01 ------------ Accuracy: 90.9%\n",
            "Step: 4481 ------------ Loss: 1843.92 ------------ Accuracy: 90.9%\n",
            "Step: 4482 ------------ Loss: 1843.83 ------------ Accuracy: 90.9%\n",
            "Step: 4483 ------------ Loss: 1843.75 ------------ Accuracy: 90.9%\n",
            "Step: 4484 ------------ Loss: 1843.66 ------------ Accuracy: 90.9%\n",
            "Step: 4485 ------------ Loss: 1843.57 ------------ Accuracy: 90.9%\n",
            "Step: 4486 ------------ Loss: 1843.49 ------------ Accuracy: 90.9%\n",
            "Step: 4487 ------------ Loss: 1843.4 ------------ Accuracy: 90.9%\n",
            "Step: 4488 ------------ Loss: 1843.31 ------------ Accuracy: 90.9%\n",
            "Step: 4489 ------------ Loss: 1843.23 ------------ Accuracy: 90.9%\n",
            "Step: 4490 ------------ Loss: 1843.14 ------------ Accuracy: 90.9%\n",
            "Step: 4491 ------------ Loss: 1843.05 ------------ Accuracy: 90.9%\n",
            "Step: 4492 ------------ Loss: 1842.97 ------------ Accuracy: 90.9%\n",
            "Step: 4493 ------------ Loss: 1842.88 ------------ Accuracy: 90.9%\n",
            "Step: 4494 ------------ Loss: 1842.79 ------------ Accuracy: 90.9%\n",
            "Step: 4495 ------------ Loss: 1842.71 ------------ Accuracy: 90.9%\n",
            "Step: 4496 ------------ Loss: 1842.62 ------------ Accuracy: 90.9%\n",
            "Step: 4497 ------------ Loss: 1842.54 ------------ Accuracy: 90.9%\n",
            "Step: 4498 ------------ Loss: 1842.45 ------------ Accuracy: 90.9%\n",
            "Step: 4499 ------------ Loss: 1842.36 ------------ Accuracy: 90.9%\n",
            "Step: 4500 ------------ Loss: 1842.28 ------------ Accuracy: 90.9%\n",
            "Step: 4501 ------------ Loss: 1842.19 ------------ Accuracy: 90.9%\n",
            "Step: 4502 ------------ Loss: 1842.1 ------------ Accuracy: 90.9%\n",
            "Step: 4503 ------------ Loss: 1842.02 ------------ Accuracy: 90.9%\n",
            "Step: 4504 ------------ Loss: 1841.93 ------------ Accuracy: 90.9%\n",
            "Step: 4505 ------------ Loss: 1841.85 ------------ Accuracy: 90.9%\n",
            "Step: 4506 ------------ Loss: 1841.76 ------------ Accuracy: 90.9%\n",
            "Step: 4507 ------------ Loss: 1841.67 ------------ Accuracy: 90.9%\n",
            "Step: 4508 ------------ Loss: 1841.59 ------------ Accuracy: 90.9%\n",
            "Step: 4509 ------------ Loss: 1841.5 ------------ Accuracy: 90.9%\n",
            "Step: 4510 ------------ Loss: 1841.42 ------------ Accuracy: 90.9%\n",
            "Step: 4511 ------------ Loss: 1841.33 ------------ Accuracy: 90.9%\n",
            "Step: 4512 ------------ Loss: 1841.24 ------------ Accuracy: 90.9%\n",
            "Step: 4513 ------------ Loss: 1841.16 ------------ Accuracy: 90.9%\n",
            "Step: 4514 ------------ Loss: 1841.07 ------------ Accuracy: 90.9%\n",
            "Step: 4515 ------------ Loss: 1840.99 ------------ Accuracy: 90.9%\n",
            "Step: 4516 ------------ Loss: 1840.9 ------------ Accuracy: 90.9%\n",
            "Step: 4517 ------------ Loss: 1840.81 ------------ Accuracy: 90.9%\n",
            "Step: 4518 ------------ Loss: 1840.73 ------------ Accuracy: 90.9%\n",
            "Step: 4519 ------------ Loss: 1840.64 ------------ Accuracy: 90.9%\n",
            "Step: 4520 ------------ Loss: 1840.56 ------------ Accuracy: 90.9%\n",
            "Step: 4521 ------------ Loss: 1840.47 ------------ Accuracy: 90.9%\n",
            "Step: 4522 ------------ Loss: 1840.39 ------------ Accuracy: 90.9%\n",
            "Step: 4523 ------------ Loss: 1840.3 ------------ Accuracy: 90.9%\n",
            "Step: 4524 ------------ Loss: 1840.22 ------------ Accuracy: 90.9%\n",
            "Step: 4525 ------------ Loss: 1840.13 ------------ Accuracy: 90.9%\n",
            "Step: 4526 ------------ Loss: 1840.04 ------------ Accuracy: 90.9%\n",
            "Step: 4527 ------------ Loss: 1839.96 ------------ Accuracy: 90.9%\n",
            "Step: 4528 ------------ Loss: 1839.87 ------------ Accuracy: 90.9%\n",
            "Step: 4529 ------------ Loss: 1839.79 ------------ Accuracy: 90.9%\n",
            "Step: 4530 ------------ Loss: 1839.7 ------------ Accuracy: 90.9%\n",
            "Step: 4531 ------------ Loss: 1839.62 ------------ Accuracy: 90.9%\n",
            "Step: 4532 ------------ Loss: 1839.53 ------------ Accuracy: 90.9%\n",
            "Step: 4533 ------------ Loss: 1839.45 ------------ Accuracy: 90.9%\n",
            "Step: 4534 ------------ Loss: 1839.36 ------------ Accuracy: 90.9%\n",
            "Step: 4535 ------------ Loss: 1839.28 ------------ Accuracy: 90.9%\n",
            "Step: 4536 ------------ Loss: 1839.19 ------------ Accuracy: 90.9%\n",
            "Step: 4537 ------------ Loss: 1839.11 ------------ Accuracy: 90.9%\n",
            "Step: 4538 ------------ Loss: 1839.02 ------------ Accuracy: 90.9%\n",
            "Step: 4539 ------------ Loss: 1838.94 ------------ Accuracy: 90.9%\n",
            "Step: 4540 ------------ Loss: 1838.85 ------------ Accuracy: 90.9%\n",
            "Step: 4541 ------------ Loss: 1838.77 ------------ Accuracy: 90.9%\n",
            "Step: 4542 ------------ Loss: 1838.68 ------------ Accuracy: 90.9%\n",
            "Step: 4543 ------------ Loss: 1838.6 ------------ Accuracy: 90.9%\n",
            "Step: 4544 ------------ Loss: 1838.51 ------------ Accuracy: 90.9%\n",
            "Step: 4545 ------------ Loss: 1838.43 ------------ Accuracy: 90.9%\n",
            "Step: 4546 ------------ Loss: 1838.34 ------------ Accuracy: 90.9%\n",
            "Step: 4547 ------------ Loss: 1838.26 ------------ Accuracy: 90.9%\n",
            "Step: 4548 ------------ Loss: 1838.17 ------------ Accuracy: 90.9%\n",
            "Step: 4549 ------------ Loss: 1838.09 ------------ Accuracy: 90.9%\n",
            "Step: 4550 ------------ Loss: 1838.0 ------------ Accuracy: 90.9%\n",
            "Step: 4551 ------------ Loss: 1837.92 ------------ Accuracy: 90.9%\n",
            "Step: 4552 ------------ Loss: 1837.83 ------------ Accuracy: 90.9%\n",
            "Step: 4553 ------------ Loss: 1837.75 ------------ Accuracy: 90.9%\n",
            "Step: 4554 ------------ Loss: 1837.67 ------------ Accuracy: 90.9%\n",
            "Step: 4555 ------------ Loss: 1837.58 ------------ Accuracy: 90.9%\n",
            "Step: 4556 ------------ Loss: 1837.5 ------------ Accuracy: 90.9%\n",
            "Step: 4557 ------------ Loss: 1837.41 ------------ Accuracy: 90.9%\n",
            "Step: 4558 ------------ Loss: 1837.33 ------------ Accuracy: 90.9%\n",
            "Step: 4559 ------------ Loss: 1837.24 ------------ Accuracy: 90.9%\n",
            "Step: 4560 ------------ Loss: 1837.16 ------------ Accuracy: 90.9%\n",
            "Step: 4561 ------------ Loss: 1837.07 ------------ Accuracy: 90.9%\n",
            "Step: 4562 ------------ Loss: 1836.99 ------------ Accuracy: 90.9%\n",
            "Step: 4563 ------------ Loss: 1836.91 ------------ Accuracy: 90.9%\n",
            "Step: 4564 ------------ Loss: 1836.82 ------------ Accuracy: 90.9%\n",
            "Step: 4565 ------------ Loss: 1836.74 ------------ Accuracy: 90.9%\n",
            "Step: 4566 ------------ Loss: 1836.65 ------------ Accuracy: 90.9%\n",
            "Step: 4567 ------------ Loss: 1836.57 ------------ Accuracy: 90.9%\n",
            "Step: 4568 ------------ Loss: 1836.49 ------------ Accuracy: 90.9%\n",
            "Step: 4569 ------------ Loss: 1836.4 ------------ Accuracy: 90.9%\n",
            "Step: 4570 ------------ Loss: 1836.32 ------------ Accuracy: 90.9%\n",
            "Step: 4571 ------------ Loss: 1836.23 ------------ Accuracy: 90.9%\n",
            "Step: 4572 ------------ Loss: 1836.15 ------------ Accuracy: 90.9%\n",
            "Step: 4573 ------------ Loss: 1836.07 ------------ Accuracy: 90.9%\n",
            "Step: 4574 ------------ Loss: 1835.98 ------------ Accuracy: 90.9%\n",
            "Step: 4575 ------------ Loss: 1835.9 ------------ Accuracy: 90.9%\n",
            "Step: 4576 ------------ Loss: 1835.81 ------------ Accuracy: 90.9%\n",
            "Step: 4577 ------------ Loss: 1835.73 ------------ Accuracy: 90.9%\n",
            "Step: 4578 ------------ Loss: 1835.65 ------------ Accuracy: 90.9%\n",
            "Step: 4579 ------------ Loss: 1835.56 ------------ Accuracy: 90.9%\n",
            "Step: 4580 ------------ Loss: 1835.48 ------------ Accuracy: 90.9%\n",
            "Step: 4581 ------------ Loss: 1835.4 ------------ Accuracy: 90.9%\n",
            "Step: 4582 ------------ Loss: 1835.31 ------------ Accuracy: 90.9%\n",
            "Step: 4583 ------------ Loss: 1835.23 ------------ Accuracy: 90.9%\n",
            "Step: 4584 ------------ Loss: 1835.14 ------------ Accuracy: 90.9%\n",
            "Step: 4585 ------------ Loss: 1835.06 ------------ Accuracy: 90.9%\n",
            "Step: 4586 ------------ Loss: 1834.98 ------------ Accuracy: 90.9%\n",
            "Step: 4587 ------------ Loss: 1834.89 ------------ Accuracy: 90.9%\n",
            "Step: 4588 ------------ Loss: 1834.81 ------------ Accuracy: 90.9%\n",
            "Step: 4589 ------------ Loss: 1834.73 ------------ Accuracy: 90.9%\n",
            "Step: 4590 ------------ Loss: 1834.64 ------------ Accuracy: 90.9%\n",
            "Step: 4591 ------------ Loss: 1834.56 ------------ Accuracy: 90.9%\n",
            "Step: 4592 ------------ Loss: 1834.48 ------------ Accuracy: 90.9%\n",
            "Step: 4593 ------------ Loss: 1834.39 ------------ Accuracy: 90.9%\n",
            "Step: 4594 ------------ Loss: 1834.31 ------------ Accuracy: 90.9%\n",
            "Step: 4595 ------------ Loss: 1834.23 ------------ Accuracy: 90.9%\n",
            "Step: 4596 ------------ Loss: 1834.14 ------------ Accuracy: 90.9%\n",
            "Step: 4597 ------------ Loss: 1834.06 ------------ Accuracy: 90.9%\n",
            "Step: 4598 ------------ Loss: 1833.98 ------------ Accuracy: 90.9%\n",
            "Step: 4599 ------------ Loss: 1833.89 ------------ Accuracy: 90.9%\n",
            "Step: 4600 ------------ Loss: 1833.81 ------------ Accuracy: 90.9%\n",
            "Step: 4601 ------------ Loss: 1833.73 ------------ Accuracy: 90.9%\n",
            "Step: 4602 ------------ Loss: 1833.65 ------------ Accuracy: 90.9%\n",
            "Step: 4603 ------------ Loss: 1833.56 ------------ Accuracy: 90.9%\n",
            "Step: 4604 ------------ Loss: 1833.48 ------------ Accuracy: 90.9%\n",
            "Step: 4605 ------------ Loss: 1833.4 ------------ Accuracy: 90.9%\n",
            "Step: 4606 ------------ Loss: 1833.31 ------------ Accuracy: 90.9%\n",
            "Step: 4607 ------------ Loss: 1833.23 ------------ Accuracy: 90.9%\n",
            "Step: 4608 ------------ Loss: 1833.15 ------------ Accuracy: 90.9%\n",
            "Step: 4609 ------------ Loss: 1833.06 ------------ Accuracy: 90.9%\n",
            "Step: 4610 ------------ Loss: 1832.98 ------------ Accuracy: 90.9%\n",
            "Step: 4611 ------------ Loss: 1832.9 ------------ Accuracy: 90.9%\n",
            "Step: 4612 ------------ Loss: 1832.82 ------------ Accuracy: 90.9%\n",
            "Step: 4613 ------------ Loss: 1832.73 ------------ Accuracy: 90.9%\n",
            "Step: 4614 ------------ Loss: 1832.65 ------------ Accuracy: 90.9%\n",
            "Step: 4615 ------------ Loss: 1832.57 ------------ Accuracy: 90.9%\n",
            "Step: 4616 ------------ Loss: 1832.49 ------------ Accuracy: 90.9%\n",
            "Step: 4617 ------------ Loss: 1832.4 ------------ Accuracy: 90.9%\n",
            "Step: 4618 ------------ Loss: 1832.32 ------------ Accuracy: 90.9%\n",
            "Step: 4619 ------------ Loss: 1832.24 ------------ Accuracy: 90.9%\n",
            "Step: 4620 ------------ Loss: 1832.16 ------------ Accuracy: 90.9%\n",
            "Step: 4621 ------------ Loss: 1832.07 ------------ Accuracy: 90.9%\n",
            "Step: 4622 ------------ Loss: 1831.99 ------------ Accuracy: 90.9%\n",
            "Step: 4623 ------------ Loss: 1831.91 ------------ Accuracy: 90.9%\n",
            "Step: 4624 ------------ Loss: 1831.83 ------------ Accuracy: 90.9%\n",
            "Step: 4625 ------------ Loss: 1831.74 ------------ Accuracy: 90.9%\n",
            "Step: 4626 ------------ Loss: 1831.66 ------------ Accuracy: 90.9%\n",
            "Step: 4627 ------------ Loss: 1831.58 ------------ Accuracy: 90.9%\n",
            "Step: 4628 ------------ Loss: 1831.5 ------------ Accuracy: 90.9%\n",
            "Step: 4629 ------------ Loss: 1831.41 ------------ Accuracy: 90.9%\n",
            "Step: 4630 ------------ Loss: 1831.33 ------------ Accuracy: 90.9%\n",
            "Step: 4631 ------------ Loss: 1831.25 ------------ Accuracy: 90.9%\n",
            "Step: 4632 ------------ Loss: 1831.17 ------------ Accuracy: 90.9%\n",
            "Step: 4633 ------------ Loss: 1831.09 ------------ Accuracy: 90.9%\n",
            "Step: 4634 ------------ Loss: 1831.0 ------------ Accuracy: 90.9%\n",
            "Step: 4635 ------------ Loss: 1830.92 ------------ Accuracy: 90.9%\n",
            "Step: 4636 ------------ Loss: 1830.84 ------------ Accuracy: 90.9%\n",
            "Step: 4637 ------------ Loss: 1830.76 ------------ Accuracy: 90.9%\n",
            "Step: 4638 ------------ Loss: 1830.68 ------------ Accuracy: 90.9%\n",
            "Step: 4639 ------------ Loss: 1830.59 ------------ Accuracy: 90.9%\n",
            "Step: 4640 ------------ Loss: 1830.51 ------------ Accuracy: 90.9%\n",
            "Step: 4641 ------------ Loss: 1830.43 ------------ Accuracy: 90.9%\n",
            "Step: 4642 ------------ Loss: 1830.35 ------------ Accuracy: 90.9%\n",
            "Step: 4643 ------------ Loss: 1830.27 ------------ Accuracy: 90.9%\n",
            "Step: 4644 ------------ Loss: 1830.19 ------------ Accuracy: 90.9%\n",
            "Step: 4645 ------------ Loss: 1830.1 ------------ Accuracy: 90.9%\n",
            "Step: 4646 ------------ Loss: 1830.02 ------------ Accuracy: 90.9%\n",
            "Step: 4647 ------------ Loss: 1829.94 ------------ Accuracy: 90.9%\n",
            "Step: 4648 ------------ Loss: 1829.86 ------------ Accuracy: 90.9%\n",
            "Step: 4649 ------------ Loss: 1829.78 ------------ Accuracy: 90.9%\n",
            "Step: 4650 ------------ Loss: 1829.7 ------------ Accuracy: 90.9%\n",
            "Step: 4651 ------------ Loss: 1829.61 ------------ Accuracy: 90.9%\n",
            "Step: 4652 ------------ Loss: 1829.53 ------------ Accuracy: 90.9%\n",
            "Step: 4653 ------------ Loss: 1829.45 ------------ Accuracy: 90.9%\n",
            "Step: 4654 ------------ Loss: 1829.37 ------------ Accuracy: 90.9%\n",
            "Step: 4655 ------------ Loss: 1829.29 ------------ Accuracy: 90.9%\n",
            "Step: 4656 ------------ Loss: 1829.21 ------------ Accuracy: 90.9%\n",
            "Step: 4657 ------------ Loss: 1829.13 ------------ Accuracy: 90.9%\n",
            "Step: 4658 ------------ Loss: 1829.04 ------------ Accuracy: 90.9%\n",
            "Step: 4659 ------------ Loss: 1828.96 ------------ Accuracy: 90.9%\n",
            "Step: 4660 ------------ Loss: 1828.88 ------------ Accuracy: 90.9%\n",
            "Step: 4661 ------------ Loss: 1828.8 ------------ Accuracy: 90.9%\n",
            "Step: 4662 ------------ Loss: 1828.72 ------------ Accuracy: 90.9%\n",
            "Step: 4663 ------------ Loss: 1828.64 ------------ Accuracy: 90.9%\n",
            "Step: 4664 ------------ Loss: 1828.56 ------------ Accuracy: 90.9%\n",
            "Step: 4665 ------------ Loss: 1828.48 ------------ Accuracy: 90.9%\n",
            "Step: 4666 ------------ Loss: 1828.39 ------------ Accuracy: 90.9%\n",
            "Step: 4667 ------------ Loss: 1828.31 ------------ Accuracy: 90.9%\n",
            "Step: 4668 ------------ Loss: 1828.23 ------------ Accuracy: 90.9%\n",
            "Step: 4669 ------------ Loss: 1828.15 ------------ Accuracy: 90.9%\n",
            "Step: 4670 ------------ Loss: 1828.07 ------------ Accuracy: 90.9%\n",
            "Step: 4671 ------------ Loss: 1827.99 ------------ Accuracy: 90.9%\n",
            "Step: 4672 ------------ Loss: 1827.91 ------------ Accuracy: 90.9%\n",
            "Step: 4673 ------------ Loss: 1827.83 ------------ Accuracy: 90.9%\n",
            "Step: 4674 ------------ Loss: 1827.75 ------------ Accuracy: 90.9%\n",
            "Step: 4675 ------------ Loss: 1827.67 ------------ Accuracy: 90.9%\n",
            "Step: 4676 ------------ Loss: 1827.59 ------------ Accuracy: 90.9%\n",
            "Step: 4677 ------------ Loss: 1827.5 ------------ Accuracy: 90.9%\n",
            "Step: 4678 ------------ Loss: 1827.42 ------------ Accuracy: 90.9%\n",
            "Step: 4679 ------------ Loss: 1827.34 ------------ Accuracy: 90.9%\n",
            "Step: 4680 ------------ Loss: 1827.26 ------------ Accuracy: 90.9%\n",
            "Step: 4681 ------------ Loss: 1827.18 ------------ Accuracy: 90.9%\n",
            "Step: 4682 ------------ Loss: 1827.1 ------------ Accuracy: 90.9%\n",
            "Step: 4683 ------------ Loss: 1827.02 ------------ Accuracy: 90.9%\n",
            "Step: 4684 ------------ Loss: 1826.94 ------------ Accuracy: 90.9%\n",
            "Step: 4685 ------------ Loss: 1826.86 ------------ Accuracy: 90.9%\n",
            "Step: 4686 ------------ Loss: 1826.78 ------------ Accuracy: 90.9%\n",
            "Step: 4687 ------------ Loss: 1826.7 ------------ Accuracy: 90.9%\n",
            "Step: 4688 ------------ Loss: 1826.62 ------------ Accuracy: 90.9%\n",
            "Step: 4689 ------------ Loss: 1826.54 ------------ Accuracy: 90.9%\n",
            "Step: 4690 ------------ Loss: 1826.46 ------------ Accuracy: 90.9%\n",
            "Step: 4691 ------------ Loss: 1826.38 ------------ Accuracy: 90.9%\n",
            "Step: 4692 ------------ Loss: 1826.3 ------------ Accuracy: 90.9%\n",
            "Step: 4693 ------------ Loss: 1826.22 ------------ Accuracy: 90.9%\n",
            "Step: 4694 ------------ Loss: 1826.14 ------------ Accuracy: 90.9%\n",
            "Step: 4695 ------------ Loss: 1826.06 ------------ Accuracy: 90.9%\n",
            "Step: 4696 ------------ Loss: 1825.98 ------------ Accuracy: 90.9%\n",
            "Step: 4697 ------------ Loss: 1825.9 ------------ Accuracy: 90.9%\n",
            "Step: 4698 ------------ Loss: 1825.81 ------------ Accuracy: 90.9%\n",
            "Step: 4699 ------------ Loss: 1825.73 ------------ Accuracy: 90.9%\n",
            "Step: 4700 ------------ Loss: 1825.65 ------------ Accuracy: 90.9%\n",
            "Step: 4701 ------------ Loss: 1825.57 ------------ Accuracy: 90.9%\n",
            "Step: 4702 ------------ Loss: 1825.49 ------------ Accuracy: 90.9%\n",
            "Step: 4703 ------------ Loss: 1825.41 ------------ Accuracy: 90.9%\n",
            "Step: 4704 ------------ Loss: 1825.33 ------------ Accuracy: 90.9%\n",
            "Step: 4705 ------------ Loss: 1825.25 ------------ Accuracy: 90.9%\n",
            "Step: 4706 ------------ Loss: 1825.17 ------------ Accuracy: 90.9%\n",
            "Step: 4707 ------------ Loss: 1825.09 ------------ Accuracy: 90.9%\n",
            "Step: 4708 ------------ Loss: 1825.01 ------------ Accuracy: 90.9%\n",
            "Step: 4709 ------------ Loss: 1824.94 ------------ Accuracy: 90.9%\n",
            "Step: 4710 ------------ Loss: 1824.86 ------------ Accuracy: 90.9%\n",
            "Step: 4711 ------------ Loss: 1824.78 ------------ Accuracy: 90.9%\n",
            "Step: 4712 ------------ Loss: 1824.7 ------------ Accuracy: 90.9%\n",
            "Step: 4713 ------------ Loss: 1824.62 ------------ Accuracy: 90.9%\n",
            "Step: 4714 ------------ Loss: 1824.54 ------------ Accuracy: 90.9%\n",
            "Step: 4715 ------------ Loss: 1824.46 ------------ Accuracy: 90.9%\n",
            "Step: 4716 ------------ Loss: 1824.38 ------------ Accuracy: 90.9%\n",
            "Step: 4717 ------------ Loss: 1824.3 ------------ Accuracy: 90.9%\n",
            "Step: 4718 ------------ Loss: 1824.22 ------------ Accuracy: 90.9%\n",
            "Step: 4719 ------------ Loss: 1824.14 ------------ Accuracy: 90.9%\n",
            "Step: 4720 ------------ Loss: 1824.06 ------------ Accuracy: 90.9%\n",
            "Step: 4721 ------------ Loss: 1823.98 ------------ Accuracy: 90.9%\n",
            "Step: 4722 ------------ Loss: 1823.9 ------------ Accuracy: 90.9%\n",
            "Step: 4723 ------------ Loss: 1823.82 ------------ Accuracy: 90.9%\n",
            "Step: 4724 ------------ Loss: 1823.74 ------------ Accuracy: 90.9%\n",
            "Step: 4725 ------------ Loss: 1823.66 ------------ Accuracy: 90.9%\n",
            "Step: 4726 ------------ Loss: 1823.58 ------------ Accuracy: 90.9%\n",
            "Step: 4727 ------------ Loss: 1823.5 ------------ Accuracy: 90.9%\n",
            "Step: 4728 ------------ Loss: 1823.42 ------------ Accuracy: 90.9%\n",
            "Step: 4729 ------------ Loss: 1823.34 ------------ Accuracy: 90.9%\n",
            "Step: 4730 ------------ Loss: 1823.27 ------------ Accuracy: 90.9%\n",
            "Step: 4731 ------------ Loss: 1823.19 ------------ Accuracy: 90.9%\n",
            "Step: 4732 ------------ Loss: 1823.11 ------------ Accuracy: 90.9%\n",
            "Step: 4733 ------------ Loss: 1823.03 ------------ Accuracy: 90.9%\n",
            "Step: 4734 ------------ Loss: 1822.95 ------------ Accuracy: 90.9%\n",
            "Step: 4735 ------------ Loss: 1822.87 ------------ Accuracy: 90.9%\n",
            "Step: 4736 ------------ Loss: 1822.79 ------------ Accuracy: 90.9%\n",
            "Step: 4737 ------------ Loss: 1822.71 ------------ Accuracy: 90.9%\n",
            "Step: 4738 ------------ Loss: 1822.63 ------------ Accuracy: 90.9%\n",
            "Step: 4739 ------------ Loss: 1822.55 ------------ Accuracy: 90.9%\n",
            "Step: 4740 ------------ Loss: 1822.47 ------------ Accuracy: 90.9%\n",
            "Step: 4741 ------------ Loss: 1822.4 ------------ Accuracy: 90.9%\n",
            "Step: 4742 ------------ Loss: 1822.32 ------------ Accuracy: 90.9%\n",
            "Step: 4743 ------------ Loss: 1822.24 ------------ Accuracy: 90.9%\n",
            "Step: 4744 ------------ Loss: 1822.16 ------------ Accuracy: 90.9%\n",
            "Step: 4745 ------------ Loss: 1822.08 ------------ Accuracy: 90.9%\n",
            "Step: 4746 ------------ Loss: 1822.0 ------------ Accuracy: 90.9%\n",
            "Step: 4747 ------------ Loss: 1821.92 ------------ Accuracy: 90.9%\n",
            "Step: 4748 ------------ Loss: 1821.84 ------------ Accuracy: 90.9%\n",
            "Step: 4749 ------------ Loss: 1821.77 ------------ Accuracy: 90.9%\n",
            "Step: 4750 ------------ Loss: 1821.69 ------------ Accuracy: 90.9%\n",
            "Step: 4751 ------------ Loss: 1821.61 ------------ Accuracy: 90.9%\n",
            "Step: 4752 ------------ Loss: 1821.53 ------------ Accuracy: 90.9%\n",
            "Step: 4753 ------------ Loss: 1821.45 ------------ Accuracy: 90.9%\n",
            "Step: 4754 ------------ Loss: 1821.37 ------------ Accuracy: 90.9%\n",
            "Step: 4755 ------------ Loss: 1821.29 ------------ Accuracy: 90.9%\n",
            "Step: 4756 ------------ Loss: 1821.22 ------------ Accuracy: 90.9%\n",
            "Step: 4757 ------------ Loss: 1821.14 ------------ Accuracy: 90.9%\n",
            "Step: 4758 ------------ Loss: 1821.06 ------------ Accuracy: 90.9%\n",
            "Step: 4759 ------------ Loss: 1820.98 ------------ Accuracy: 90.9%\n",
            "Step: 4760 ------------ Loss: 1820.9 ------------ Accuracy: 90.9%\n",
            "Step: 4761 ------------ Loss: 1820.82 ------------ Accuracy: 90.9%\n",
            "Step: 4762 ------------ Loss: 1820.75 ------------ Accuracy: 90.9%\n",
            "Step: 4763 ------------ Loss: 1820.67 ------------ Accuracy: 90.9%\n",
            "Step: 4764 ------------ Loss: 1820.59 ------------ Accuracy: 90.9%\n",
            "Step: 4765 ------------ Loss: 1820.51 ------------ Accuracy: 90.9%\n",
            "Step: 4766 ------------ Loss: 1820.43 ------------ Accuracy: 90.9%\n",
            "Step: 4767 ------------ Loss: 1820.35 ------------ Accuracy: 90.9%\n",
            "Step: 4768 ------------ Loss: 1820.28 ------------ Accuracy: 90.9%\n",
            "Step: 4769 ------------ Loss: 1820.2 ------------ Accuracy: 90.9%\n",
            "Step: 4770 ------------ Loss: 1820.12 ------------ Accuracy: 90.9%\n",
            "Step: 4771 ------------ Loss: 1820.04 ------------ Accuracy: 90.9%\n",
            "Step: 4772 ------------ Loss: 1819.96 ------------ Accuracy: 90.9%\n",
            "Step: 4773 ------------ Loss: 1819.89 ------------ Accuracy: 90.9%\n",
            "Step: 4774 ------------ Loss: 1819.81 ------------ Accuracy: 90.9%\n",
            "Step: 4775 ------------ Loss: 1819.73 ------------ Accuracy: 90.9%\n",
            "Step: 4776 ------------ Loss: 1819.65 ------------ Accuracy: 90.9%\n",
            "Step: 4777 ------------ Loss: 1819.57 ------------ Accuracy: 90.9%\n",
            "Step: 4778 ------------ Loss: 1819.5 ------------ Accuracy: 90.9%\n",
            "Step: 4779 ------------ Loss: 1819.42 ------------ Accuracy: 90.9%\n",
            "Step: 4780 ------------ Loss: 1819.34 ------------ Accuracy: 90.9%\n",
            "Step: 4781 ------------ Loss: 1819.26 ------------ Accuracy: 90.9%\n",
            "Step: 4782 ------------ Loss: 1819.18 ------------ Accuracy: 90.9%\n",
            "Step: 4783 ------------ Loss: 1819.11 ------------ Accuracy: 90.9%\n",
            "Step: 4784 ------------ Loss: 1819.03 ------------ Accuracy: 90.9%\n",
            "Step: 4785 ------------ Loss: 1818.95 ------------ Accuracy: 90.9%\n",
            "Step: 4786 ------------ Loss: 1818.87 ------------ Accuracy: 90.9%\n",
            "Step: 4787 ------------ Loss: 1818.8 ------------ Accuracy: 90.9%\n",
            "Step: 4788 ------------ Loss: 1818.72 ------------ Accuracy: 90.9%\n",
            "Step: 4789 ------------ Loss: 1818.64 ------------ Accuracy: 90.9%\n",
            "Step: 4790 ------------ Loss: 1818.56 ------------ Accuracy: 90.9%\n",
            "Step: 4791 ------------ Loss: 1818.49 ------------ Accuracy: 90.9%\n",
            "Step: 4792 ------------ Loss: 1818.41 ------------ Accuracy: 90.9%\n",
            "Step: 4793 ------------ Loss: 1818.33 ------------ Accuracy: 90.9%\n",
            "Step: 4794 ------------ Loss: 1818.25 ------------ Accuracy: 90.9%\n",
            "Step: 4795 ------------ Loss: 1818.18 ------------ Accuracy: 90.9%\n",
            "Step: 4796 ------------ Loss: 1818.1 ------------ Accuracy: 90.9%\n",
            "Step: 4797 ------------ Loss: 1818.02 ------------ Accuracy: 90.9%\n",
            "Step: 4798 ------------ Loss: 1817.94 ------------ Accuracy: 90.9%\n",
            "Step: 4799 ------------ Loss: 1817.87 ------------ Accuracy: 90.9%\n",
            "Step: 4800 ------------ Loss: 1817.79 ------------ Accuracy: 90.9%\n",
            "Step: 4801 ------------ Loss: 1817.71 ------------ Accuracy: 90.9%\n",
            "Step: 4802 ------------ Loss: 1817.64 ------------ Accuracy: 90.9%\n",
            "Step: 4803 ------------ Loss: 1817.56 ------------ Accuracy: 90.9%\n",
            "Step: 4804 ------------ Loss: 1817.48 ------------ Accuracy: 90.9%\n",
            "Step: 4805 ------------ Loss: 1817.4 ------------ Accuracy: 90.9%\n",
            "Step: 4806 ------------ Loss: 1817.33 ------------ Accuracy: 90.9%\n",
            "Step: 4807 ------------ Loss: 1817.25 ------------ Accuracy: 90.9%\n",
            "Step: 4808 ------------ Loss: 1817.17 ------------ Accuracy: 90.9%\n",
            "Step: 4809 ------------ Loss: 1817.1 ------------ Accuracy: 90.9%\n",
            "Step: 4810 ------------ Loss: 1817.02 ------------ Accuracy: 90.9%\n",
            "Step: 4811 ------------ Loss: 1816.94 ------------ Accuracy: 90.9%\n",
            "Step: 4812 ------------ Loss: 1816.86 ------------ Accuracy: 90.9%\n",
            "Step: 4813 ------------ Loss: 1816.79 ------------ Accuracy: 90.9%\n",
            "Step: 4814 ------------ Loss: 1816.71 ------------ Accuracy: 90.9%\n",
            "Step: 4815 ------------ Loss: 1816.63 ------------ Accuracy: 90.9%\n",
            "Step: 4816 ------------ Loss: 1816.56 ------------ Accuracy: 90.9%\n",
            "Step: 4817 ------------ Loss: 1816.48 ------------ Accuracy: 90.9%\n",
            "Step: 4818 ------------ Loss: 1816.4 ------------ Accuracy: 90.9%\n",
            "Step: 4819 ------------ Loss: 1816.33 ------------ Accuracy: 90.9%\n",
            "Step: 4820 ------------ Loss: 1816.25 ------------ Accuracy: 90.9%\n",
            "Step: 4821 ------------ Loss: 1816.17 ------------ Accuracy: 90.9%\n",
            "Step: 4822 ------------ Loss: 1816.1 ------------ Accuracy: 90.9%\n",
            "Step: 4823 ------------ Loss: 1816.02 ------------ Accuracy: 90.9%\n",
            "Step: 4824 ------------ Loss: 1815.94 ------------ Accuracy: 90.9%\n",
            "Step: 4825 ------------ Loss: 1815.87 ------------ Accuracy: 90.9%\n",
            "Step: 4826 ------------ Loss: 1815.79 ------------ Accuracy: 90.9%\n",
            "Step: 4827 ------------ Loss: 1815.71 ------------ Accuracy: 90.9%\n",
            "Step: 4828 ------------ Loss: 1815.64 ------------ Accuracy: 90.9%\n",
            "Step: 4829 ------------ Loss: 1815.56 ------------ Accuracy: 90.9%\n",
            "Step: 4830 ------------ Loss: 1815.48 ------------ Accuracy: 90.9%\n",
            "Step: 4831 ------------ Loss: 1815.41 ------------ Accuracy: 90.9%\n",
            "Step: 4832 ------------ Loss: 1815.33 ------------ Accuracy: 90.9%\n",
            "Step: 4833 ------------ Loss: 1815.26 ------------ Accuracy: 90.9%\n",
            "Step: 4834 ------------ Loss: 1815.18 ------------ Accuracy: 90.9%\n",
            "Step: 4835 ------------ Loss: 1815.1 ------------ Accuracy: 90.9%\n",
            "Step: 4836 ------------ Loss: 1815.03 ------------ Accuracy: 90.9%\n",
            "Step: 4837 ------------ Loss: 1814.95 ------------ Accuracy: 90.9%\n",
            "Step: 4838 ------------ Loss: 1814.87 ------------ Accuracy: 90.9%\n",
            "Step: 4839 ------------ Loss: 1814.8 ------------ Accuracy: 90.9%\n",
            "Step: 4840 ------------ Loss: 1814.72 ------------ Accuracy: 90.9%\n",
            "Step: 4841 ------------ Loss: 1814.65 ------------ Accuracy: 90.9%\n",
            "Step: 4842 ------------ Loss: 1814.57 ------------ Accuracy: 90.9%\n",
            "Step: 4843 ------------ Loss: 1814.49 ------------ Accuracy: 90.9%\n",
            "Step: 4844 ------------ Loss: 1814.42 ------------ Accuracy: 90.9%\n",
            "Step: 4845 ------------ Loss: 1814.34 ------------ Accuracy: 90.9%\n",
            "Step: 4846 ------------ Loss: 1814.26 ------------ Accuracy: 90.9%\n",
            "Step: 4847 ------------ Loss: 1814.19 ------------ Accuracy: 90.9%\n",
            "Step: 4848 ------------ Loss: 1814.11 ------------ Accuracy: 90.9%\n",
            "Step: 4849 ------------ Loss: 1814.04 ------------ Accuracy: 90.9%\n",
            "Step: 4850 ------------ Loss: 1813.96 ------------ Accuracy: 90.9%\n",
            "Step: 4851 ------------ Loss: 1813.89 ------------ Accuracy: 90.9%\n",
            "Step: 4852 ------------ Loss: 1813.81 ------------ Accuracy: 90.9%\n",
            "Step: 4853 ------------ Loss: 1813.73 ------------ Accuracy: 90.9%\n",
            "Step: 4854 ------------ Loss: 1813.66 ------------ Accuracy: 90.9%\n",
            "Step: 4855 ------------ Loss: 1813.58 ------------ Accuracy: 90.9%\n",
            "Step: 4856 ------------ Loss: 1813.51 ------------ Accuracy: 90.9%\n",
            "Step: 4857 ------------ Loss: 1813.43 ------------ Accuracy: 90.9%\n",
            "Step: 4858 ------------ Loss: 1813.35 ------------ Accuracy: 90.9%\n",
            "Step: 4859 ------------ Loss: 1813.28 ------------ Accuracy: 90.9%\n",
            "Step: 4860 ------------ Loss: 1813.2 ------------ Accuracy: 90.9%\n",
            "Step: 4861 ------------ Loss: 1813.13 ------------ Accuracy: 90.9%\n",
            "Step: 4862 ------------ Loss: 1813.05 ------------ Accuracy: 90.9%\n",
            "Step: 4863 ------------ Loss: 1812.98 ------------ Accuracy: 90.9%\n",
            "Step: 4864 ------------ Loss: 1812.9 ------------ Accuracy: 90.9%\n",
            "Step: 4865 ------------ Loss: 1812.83 ------------ Accuracy: 90.9%\n",
            "Step: 4866 ------------ Loss: 1812.75 ------------ Accuracy: 90.9%\n",
            "Step: 4867 ------------ Loss: 1812.67 ------------ Accuracy: 90.9%\n",
            "Step: 4868 ------------ Loss: 1812.6 ------------ Accuracy: 90.9%\n",
            "Step: 4869 ------------ Loss: 1812.52 ------------ Accuracy: 90.9%\n",
            "Step: 4870 ------------ Loss: 1812.45 ------------ Accuracy: 90.9%\n",
            "Step: 4871 ------------ Loss: 1812.37 ------------ Accuracy: 90.9%\n",
            "Step: 4872 ------------ Loss: 1812.3 ------------ Accuracy: 90.9%\n",
            "Step: 4873 ------------ Loss: 1812.22 ------------ Accuracy: 90.9%\n",
            "Step: 4874 ------------ Loss: 1812.15 ------------ Accuracy: 90.9%\n",
            "Step: 4875 ------------ Loss: 1812.07 ------------ Accuracy: 90.9%\n",
            "Step: 4876 ------------ Loss: 1812.0 ------------ Accuracy: 90.9%\n",
            "Step: 4877 ------------ Loss: 1811.92 ------------ Accuracy: 90.9%\n",
            "Step: 4878 ------------ Loss: 1811.85 ------------ Accuracy: 90.9%\n",
            "Step: 4879 ------------ Loss: 1811.77 ------------ Accuracy: 90.9%\n",
            "Step: 4880 ------------ Loss: 1811.7 ------------ Accuracy: 90.9%\n",
            "Step: 4881 ------------ Loss: 1811.62 ------------ Accuracy: 90.9%\n",
            "Step: 4882 ------------ Loss: 1811.55 ------------ Accuracy: 90.9%\n",
            "Step: 4883 ------------ Loss: 1811.47 ------------ Accuracy: 90.9%\n",
            "Step: 4884 ------------ Loss: 1811.4 ------------ Accuracy: 90.9%\n",
            "Step: 4885 ------------ Loss: 1811.32 ------------ Accuracy: 90.9%\n",
            "Step: 4886 ------------ Loss: 1811.25 ------------ Accuracy: 90.9%\n",
            "Step: 4887 ------------ Loss: 1811.17 ------------ Accuracy: 90.9%\n",
            "Step: 4888 ------------ Loss: 1811.1 ------------ Accuracy: 90.9%\n",
            "Step: 4889 ------------ Loss: 1811.02 ------------ Accuracy: 90.9%\n",
            "Step: 4890 ------------ Loss: 1810.95 ------------ Accuracy: 90.9%\n",
            "Step: 4891 ------------ Loss: 1810.87 ------------ Accuracy: 90.9%\n",
            "Step: 4892 ------------ Loss: 1810.8 ------------ Accuracy: 90.9%\n",
            "Step: 4893 ------------ Loss: 1810.72 ------------ Accuracy: 90.9%\n",
            "Step: 4894 ------------ Loss: 1810.65 ------------ Accuracy: 90.9%\n",
            "Step: 4895 ------------ Loss: 1810.57 ------------ Accuracy: 90.9%\n",
            "Step: 4896 ------------ Loss: 1810.5 ------------ Accuracy: 90.9%\n",
            "Step: 4897 ------------ Loss: 1810.42 ------------ Accuracy: 90.9%\n",
            "Step: 4898 ------------ Loss: 1810.35 ------------ Accuracy: 90.9%\n",
            "Step: 4899 ------------ Loss: 1810.27 ------------ Accuracy: 90.9%\n",
            "Step: 4900 ------------ Loss: 1810.2 ------------ Accuracy: 90.9%\n",
            "Step: 4901 ------------ Loss: 1810.13 ------------ Accuracy: 90.9%\n",
            "Step: 4902 ------------ Loss: 1810.05 ------------ Accuracy: 90.9%\n",
            "Step: 4903 ------------ Loss: 1809.98 ------------ Accuracy: 90.9%\n",
            "Step: 4904 ------------ Loss: 1809.9 ------------ Accuracy: 90.9%\n",
            "Step: 4905 ------------ Loss: 1809.83 ------------ Accuracy: 90.9%\n",
            "Step: 4906 ------------ Loss: 1809.75 ------------ Accuracy: 90.9%\n",
            "Step: 4907 ------------ Loss: 1809.68 ------------ Accuracy: 90.9%\n",
            "Step: 4908 ------------ Loss: 1809.6 ------------ Accuracy: 90.9%\n",
            "Step: 4909 ------------ Loss: 1809.53 ------------ Accuracy: 90.9%\n",
            "Step: 4910 ------------ Loss: 1809.46 ------------ Accuracy: 90.9%\n",
            "Step: 4911 ------------ Loss: 1809.38 ------------ Accuracy: 90.9%\n",
            "Step: 4912 ------------ Loss: 1809.31 ------------ Accuracy: 90.9%\n",
            "Step: 4913 ------------ Loss: 1809.23 ------------ Accuracy: 90.9%\n",
            "Step: 4914 ------------ Loss: 1809.16 ------------ Accuracy: 90.9%\n",
            "Step: 4915 ------------ Loss: 1809.08 ------------ Accuracy: 90.9%\n",
            "Step: 4916 ------------ Loss: 1809.01 ------------ Accuracy: 90.9%\n",
            "Step: 4917 ------------ Loss: 1808.94 ------------ Accuracy: 90.9%\n",
            "Step: 4918 ------------ Loss: 1808.86 ------------ Accuracy: 90.9%\n",
            "Step: 4919 ------------ Loss: 1808.79 ------------ Accuracy: 90.9%\n",
            "Step: 4920 ------------ Loss: 1808.71 ------------ Accuracy: 90.9%\n",
            "Step: 4921 ------------ Loss: 1808.64 ------------ Accuracy: 90.9%\n",
            "Step: 4922 ------------ Loss: 1808.57 ------------ Accuracy: 90.9%\n",
            "Step: 4923 ------------ Loss: 1808.49 ------------ Accuracy: 90.9%\n",
            "Step: 4924 ------------ Loss: 1808.42 ------------ Accuracy: 90.9%\n",
            "Step: 4925 ------------ Loss: 1808.34 ------------ Accuracy: 90.9%\n",
            "Step: 4926 ------------ Loss: 1808.27 ------------ Accuracy: 90.9%\n",
            "Step: 4927 ------------ Loss: 1808.2 ------------ Accuracy: 90.9%\n",
            "Step: 4928 ------------ Loss: 1808.12 ------------ Accuracy: 90.9%\n",
            "Step: 4929 ------------ Loss: 1808.05 ------------ Accuracy: 90.9%\n",
            "Step: 4930 ------------ Loss: 1807.97 ------------ Accuracy: 90.9%\n",
            "Step: 4931 ------------ Loss: 1807.9 ------------ Accuracy: 90.9%\n",
            "Step: 4932 ------------ Loss: 1807.83 ------------ Accuracy: 90.9%\n",
            "Step: 4933 ------------ Loss: 1807.75 ------------ Accuracy: 90.9%\n",
            "Step: 4934 ------------ Loss: 1807.68 ------------ Accuracy: 90.9%\n",
            "Step: 4935 ------------ Loss: 1807.61 ------------ Accuracy: 90.9%\n",
            "Step: 4936 ------------ Loss: 1807.53 ------------ Accuracy: 90.9%\n",
            "Step: 4937 ------------ Loss: 1807.46 ------------ Accuracy: 90.9%\n",
            "Step: 4938 ------------ Loss: 1807.38 ------------ Accuracy: 90.9%\n",
            "Step: 4939 ------------ Loss: 1807.31 ------------ Accuracy: 90.9%\n",
            "Step: 4940 ------------ Loss: 1807.24 ------------ Accuracy: 90.9%\n",
            "Step: 4941 ------------ Loss: 1807.16 ------------ Accuracy: 90.9%\n",
            "Step: 4942 ------------ Loss: 1807.09 ------------ Accuracy: 90.9%\n",
            "Step: 4943 ------------ Loss: 1807.02 ------------ Accuracy: 90.9%\n",
            "Step: 4944 ------------ Loss: 1806.94 ------------ Accuracy: 90.9%\n",
            "Step: 4945 ------------ Loss: 1806.87 ------------ Accuracy: 90.9%\n",
            "Step: 4946 ------------ Loss: 1806.8 ------------ Accuracy: 90.9%\n",
            "Step: 4947 ------------ Loss: 1806.72 ------------ Accuracy: 90.9%\n",
            "Step: 4948 ------------ Loss: 1806.65 ------------ Accuracy: 90.9%\n",
            "Step: 4949 ------------ Loss: 1806.58 ------------ Accuracy: 90.9%\n",
            "Step: 4950 ------------ Loss: 1806.5 ------------ Accuracy: 90.9%\n",
            "Step: 4951 ------------ Loss: 1806.43 ------------ Accuracy: 90.9%\n",
            "Step: 4952 ------------ Loss: 1806.36 ------------ Accuracy: 90.9%\n",
            "Step: 4953 ------------ Loss: 1806.28 ------------ Accuracy: 90.9%\n",
            "Step: 4954 ------------ Loss: 1806.21 ------------ Accuracy: 90.9%\n",
            "Step: 4955 ------------ Loss: 1806.14 ------------ Accuracy: 90.9%\n",
            "Step: 4956 ------------ Loss: 1806.06 ------------ Accuracy: 90.9%\n",
            "Step: 4957 ------------ Loss: 1805.99 ------------ Accuracy: 90.9%\n",
            "Step: 4958 ------------ Loss: 1805.92 ------------ Accuracy: 90.9%\n",
            "Step: 4959 ------------ Loss: 1805.84 ------------ Accuracy: 90.9%\n",
            "Step: 4960 ------------ Loss: 1805.77 ------------ Accuracy: 90.9%\n",
            "Step: 4961 ------------ Loss: 1805.7 ------------ Accuracy: 90.9%\n",
            "Step: 4962 ------------ Loss: 1805.63 ------------ Accuracy: 90.9%\n",
            "Step: 4963 ------------ Loss: 1805.55 ------------ Accuracy: 90.9%\n",
            "Step: 4964 ------------ Loss: 1805.48 ------------ Accuracy: 90.9%\n",
            "Step: 4965 ------------ Loss: 1805.41 ------------ Accuracy: 90.9%\n",
            "Step: 4966 ------------ Loss: 1805.33 ------------ Accuracy: 90.9%\n",
            "Step: 4967 ------------ Loss: 1805.26 ------------ Accuracy: 90.9%\n",
            "Step: 4968 ------------ Loss: 1805.19 ------------ Accuracy: 90.9%\n",
            "Step: 4969 ------------ Loss: 1805.12 ------------ Accuracy: 90.9%\n",
            "Step: 4970 ------------ Loss: 1805.04 ------------ Accuracy: 90.9%\n",
            "Step: 4971 ------------ Loss: 1804.97 ------------ Accuracy: 90.9%\n",
            "Step: 4972 ------------ Loss: 1804.9 ------------ Accuracy: 90.9%\n",
            "Step: 4973 ------------ Loss: 1804.82 ------------ Accuracy: 90.9%\n",
            "Step: 4974 ------------ Loss: 1804.75 ------------ Accuracy: 90.9%\n",
            "Step: 4975 ------------ Loss: 1804.68 ------------ Accuracy: 90.9%\n",
            "Step: 4976 ------------ Loss: 1804.61 ------------ Accuracy: 90.9%\n",
            "Step: 4977 ------------ Loss: 1804.53 ------------ Accuracy: 90.9%\n",
            "Step: 4978 ------------ Loss: 1804.46 ------------ Accuracy: 90.9%\n",
            "Step: 4979 ------------ Loss: 1804.39 ------------ Accuracy: 90.9%\n",
            "Step: 4980 ------------ Loss: 1804.32 ------------ Accuracy: 90.9%\n",
            "Step: 4981 ------------ Loss: 1804.24 ------------ Accuracy: 90.9%\n",
            "Step: 4982 ------------ Loss: 1804.17 ------------ Accuracy: 90.9%\n",
            "Step: 4983 ------------ Loss: 1804.1 ------------ Accuracy: 90.9%\n",
            "Step: 4984 ------------ Loss: 1804.03 ------------ Accuracy: 90.9%\n",
            "Step: 4985 ------------ Loss: 1803.95 ------------ Accuracy: 90.9%\n",
            "Step: 4986 ------------ Loss: 1803.88 ------------ Accuracy: 90.9%\n",
            "Step: 4987 ------------ Loss: 1803.81 ------------ Accuracy: 90.9%\n",
            "Step: 4988 ------------ Loss: 1803.74 ------------ Accuracy: 90.9%\n",
            "Step: 4989 ------------ Loss: 1803.66 ------------ Accuracy: 90.9%\n",
            "Step: 4990 ------------ Loss: 1803.59 ------------ Accuracy: 90.9%\n",
            "Step: 4991 ------------ Loss: 1803.52 ------------ Accuracy: 90.9%\n",
            "Step: 4992 ------------ Loss: 1803.45 ------------ Accuracy: 90.9%\n",
            "Step: 4993 ------------ Loss: 1803.38 ------------ Accuracy: 90.9%\n",
            "Step: 4994 ------------ Loss: 1803.3 ------------ Accuracy: 90.9%\n",
            "Step: 4995 ------------ Loss: 1803.23 ------------ Accuracy: 90.9%\n",
            "Step: 4996 ------------ Loss: 1803.16 ------------ Accuracy: 90.9%\n",
            "Step: 4997 ------------ Loss: 1803.09 ------------ Accuracy: 90.9%\n",
            "Step: 4998 ------------ Loss: 1803.01 ------------ Accuracy: 90.9%\n",
            "Step: 4999 ------------ Loss: 1802.94 ------------ Accuracy: 90.9%\n",
            "Step: 5000 ------------ Loss: 1802.87 ------------ Accuracy: 90.9%\n",
            "\n",
            " Time taken: 1473.36 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "# fit model\n",
        "model.fit(X_train, Y_train, type=\"GD\", alpha=0.0001, max_iter=5000, threshold=100)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"\\n Time taken: {np.round(end_time - start_time,2)} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GhInBIXvPEnv",
        "outputId": "396a99b3-7dcb-44f2-c40c-fae00bfb05b5",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Produce plots\n",
        "args = [\"Loss\", \"Accuracy\", \"CPU\"]\n",
        "for a in args: model.plot(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmBQqeXBPEZz",
        "outputId": "b6c0ec52-645a-4daa-9221-c041b43b4aa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score on test set: 91.11\n"
          ]
        }
      ],
      "source": [
        "# check accuracy on test set\n",
        "print(f\"Accuracy score on test set: {np.round(np.sum(model.predict(X_test) == Y_test) / X_test.shape[0] * 100,2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJYhfFY_vxUD"
      },
      "outputs": [],
      "source": [
        "# save the data for later comparison\n",
        "df_gd = model.backup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8p22mpOpN6D"
      },
      "source": [
        "## 3) BCGD Randomized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "r4CiMabepSwb",
        "outputId": "0e9e4c3d-8cca-4590-dc21-86186c625e48",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Step: 3 ------------ Loss: 12145.23 ------------ Accuracy: 26.2%\n",
            "Step: 4 ------------ Loss: 12101.33 ------------ Accuracy: 26.2%\n",
            "Step: 5 ------------ Loss: 12079.41 ------------ Accuracy: 26.2%\n",
            "Step: 6 ------------ Loss: 12004.84 ------------ Accuracy: 26.2%\n",
            "Step: 7 ------------ Loss: 11971.58 ------------ Accuracy: 26.2%\n",
            "Step: 8 ------------ Loss: 11970.34 ------------ Accuracy: 26.2%\n",
            "Step: 9 ------------ Loss: 11933.61 ------------ Accuracy: 26.2%\n",
            "Step: 10 ------------ Loss: 11891.06 ------------ Accuracy: 26.2%\n",
            "Step: 11 ------------ Loss: 11888.82 ------------ Accuracy: 26.2%\n",
            "Step: 12 ------------ Loss: 11855.04 ------------ Accuracy: 26.2%\n",
            "Step: 13 ------------ Loss: 11811.05 ------------ Accuracy: 26.2%\n",
            "Step: 14 ------------ Loss: 11765.72 ------------ Accuracy: 26.2%\n",
            "Step: 15 ------------ Loss: 11722.69 ------------ Accuracy: 26.2%\n",
            "Step: 16 ------------ Loss: 11700.35 ------------ Accuracy: 26.2%\n",
            "Step: 17 ------------ Loss: 11698.6 ------------ Accuracy: 26.2%\n",
            "Step: 18 ------------ Loss: 11696.91 ------------ Accuracy: 26.2%\n",
            "Step: 19 ------------ Loss: 11679.49 ------------ Accuracy: 26.2%\n",
            "Step: 20 ------------ Loss: 11662.63 ------------ Accuracy: 26.2%\n",
            "Step: 21 ------------ Loss: 11617.6 ------------ Accuracy: 26.2%\n",
            "Step: 22 ------------ Loss: 11614.46 ------------ Accuracy: 26.2%\n",
            "Step: 23 ------------ Loss: 11611.36 ------------ Accuracy: 26.2%\n",
            "Step: 24 ------------ Loss: 11584.2 ------------ Accuracy: 26.2%\n",
            "Step: 25 ------------ Loss: 11580.05 ------------ Accuracy: 26.2%\n",
            "Step: 26 ------------ Loss: 11542.27 ------------ Accuracy: 26.2%\n",
            "Step: 27 ------------ Loss: 11540.16 ------------ Accuracy: 26.2%\n",
            "Step: 28 ------------ Loss: 11538.51 ------------ Accuracy: 26.2%\n",
            "Step: 29 ------------ Loss: 11535.66 ------------ Accuracy: 26.2%\n",
            "Step: 30 ------------ Loss: 11531.33 ------------ Accuracy: 26.2%\n",
            "Step: 31 ------------ Loss: 11499.44 ------------ Accuracy: 26.2%\n",
            "Step: 32 ------------ Loss: 11468.91 ------------ Accuracy: 26.2%\n",
            "Step: 33 ------------ Loss: 11454.44 ------------ Accuracy: 26.2%\n",
            "Step: 34 ------------ Loss: 11449.72 ------------ Accuracy: 26.2%\n",
            "Step: 35 ------------ Loss: 11421.97 ------------ Accuracy: 26.2%\n",
            "Step: 36 ------------ Loss: 11417.15 ------------ Accuracy: 26.2%\n",
            "Step: 37 ------------ Loss: 11414.84 ------------ Accuracy: 26.2%\n",
            "Step: 38 ------------ Loss: 11411.59 ------------ Accuracy: 26.2%\n",
            "Step: 39 ------------ Loss: 11389.46 ------------ Accuracy: 26.2%\n",
            "Step: 40 ------------ Loss: 11378.62 ------------ Accuracy: 26.2%\n",
            "Step: 41 ------------ Loss: 11368.62 ------------ Accuracy: 26.2%\n",
            "Step: 42 ------------ Loss: 11366.23 ------------ Accuracy: 26.2%\n",
            "Step: 43 ------------ Loss: 11364.0 ------------ Accuracy: 26.2%\n",
            "Step: 44 ------------ Loss: 11361.8 ------------ Accuracy: 26.2%\n",
            "Step: 45 ------------ Loss: 11358.29 ------------ Accuracy: 26.2%\n",
            "Step: 46 ------------ Loss: 11332.28 ------------ Accuracy: 26.2%\n",
            "Step: 47 ------------ Loss: 11307.16 ------------ Accuracy: 26.2%\n",
            "Step: 48 ------------ Loss: 11304.75 ------------ Accuracy: 26.2%\n",
            "Step: 49 ------------ Loss: 11296.34 ------------ Accuracy: 26.2%\n",
            "Step: 50 ------------ Loss: 11293.8 ------------ Accuracy: 26.2%\n",
            "Step: 51 ------------ Loss: 11290.04 ------------ Accuracy: 26.2%\n",
            "Step: 52 ------------ Loss: 11287.54 ------------ Accuracy: 26.2%\n",
            "Step: 53 ------------ Loss: 11283.29 ------------ Accuracy: 26.2%\n",
            "Step: 54 ------------ Loss: 11266.41 ------------ Accuracy: 26.2%\n",
            "Step: 55 ------------ Loss: 11261.03 ------------ Accuracy: 26.2%\n",
            "Step: 56 ------------ Loss: 11237.81 ------------ Accuracy: 26.2%\n",
            "Step: 57 ------------ Loss: 11215.81 ------------ Accuracy: 26.2%\n",
            "Step: 58 ------------ Loss: 11198.89 ------------ Accuracy: 26.2%\n",
            "Step: 59 ------------ Loss: 11177.32 ------------ Accuracy: 26.2%\n",
            "Step: 60 ------------ Loss: 11171.48 ------------ Accuracy: 26.2%\n",
            "Step: 61 ------------ Loss: 11168.72 ------------ Accuracy: 26.2%\n",
            "Step: 62 ------------ Loss: 11165.97 ------------ Accuracy: 26.2%\n",
            "Step: 63 ------------ Loss: 11161.74 ------------ Accuracy: 26.2%\n",
            "Step: 64 ------------ Loss: 11146.38 ------------ Accuracy: 26.2%\n",
            "Step: 65 ------------ Loss: 11140.31 ------------ Accuracy: 26.2%\n",
            "Step: 66 ------------ Loss: 11125.45 ------------ Accuracy: 26.2%\n",
            "Step: 67 ------------ Loss: 11122.7 ------------ Accuracy: 26.2%\n",
            "Step: 68 ------------ Loss: 11109.25 ------------ Accuracy: 26.2%\n",
            "Step: 69 ------------ Loss: 11098.45 ------------ Accuracy: 26.2%\n",
            "Step: 70 ------------ Loss: 11093.26 ------------ Accuracy: 26.2%\n",
            "Step: 71 ------------ Loss: 11088.15 ------------ Accuracy: 26.2%\n",
            "Step: 72 ------------ Loss: 11069.3 ------------ Accuracy: 26.2%\n",
            "Step: 73 ------------ Loss: 11053.51 ------------ Accuracy: 26.2%\n",
            "Step: 74 ------------ Loss: 11040.06 ------------ Accuracy: 26.2%\n",
            "Step: 75 ------------ Loss: 11033.64 ------------ Accuracy: 26.2%\n",
            "Step: 76 ------------ Loss: 11016.25 ------------ Accuracy: 26.2%\n",
            "Step: 77 ------------ Loss: 11010.93 ------------ Accuracy: 26.2%\n",
            "Step: 78 ------------ Loss: 10997.99 ------------ Accuracy: 26.2%\n",
            "Step: 79 ------------ Loss: 10980.83 ------------ Accuracy: 26.2%\n",
            "Step: 80 ------------ Loss: 10964.8 ------------ Accuracy: 26.2%\n",
            "Step: 81 ------------ Loss: 10961.76 ------------ Accuracy: 26.2%\n",
            "Step: 82 ------------ Loss: 10945.76 ------------ Accuracy: 26.2%\n",
            "Step: 83 ------------ Loss: 10939.97 ------------ Accuracy: 26.2%\n",
            "Step: 84 ------------ Loss: 10925.61 ------------ Accuracy: 26.2%\n",
            "Step: 85 ------------ Loss: 10919.57 ------------ Accuracy: 26.2%\n",
            "Step: 86 ------------ Loss: 10916.4 ------------ Accuracy: 26.2%\n",
            "Step: 87 ------------ Loss: 10913.83 ------------ Accuracy: 26.2%\n",
            "Step: 88 ------------ Loss: 10902.83 ------------ Accuracy: 26.2%\n",
            "Step: 89 ------------ Loss: 10899.74 ------------ Accuracy: 26.2%\n",
            "Step: 90 ------------ Loss: 10894.45 ------------ Accuracy: 26.2%\n",
            "Step: 91 ------------ Loss: 10889.65 ------------ Accuracy: 26.2%\n",
            "Step: 92 ------------ Loss: 10885.28 ------------ Accuracy: 26.2%\n",
            "Step: 93 ------------ Loss: 10874.9 ------------ Accuracy: 26.2%\n",
            "Step: 94 ------------ Loss: 10860.72 ------------ Accuracy: 26.2%\n",
            "Step: 95 ------------ Loss: 10854.41 ------------ Accuracy: 26.2%\n",
            "Step: 96 ------------ Loss: 10847.57 ------------ Accuracy: 26.2%\n",
            "Step: 97 ------------ Loss: 10838.1 ------------ Accuracy: 26.2%\n",
            "Step: 98 ------------ Loss: 10834.53 ------------ Accuracy: 26.2%\n",
            "Step: 99 ------------ Loss: 10831.02 ------------ Accuracy: 26.2%\n",
            "Step: 100 ------------ Loss: 10823.31 ------------ Accuracy: 26.2%\n",
            "Step: 101 ------------ Loss: 10819.95 ------------ Accuracy: 26.2%\n",
            "Step: 102 ------------ Loss: 10810.68 ------------ Accuracy: 26.2%\n",
            "Step: 103 ------------ Loss: 10806.51 ------------ Accuracy: 26.2%\n",
            "Step: 104 ------------ Loss: 10798.85 ------------ Accuracy: 26.2%\n",
            "Step: 105 ------------ Loss: 10789.76 ------------ Accuracy: 26.2%\n",
            "Step: 106 ------------ Loss: 10784.23 ------------ Accuracy: 26.2%\n",
            "Step: 107 ------------ Loss: 10780.05 ------------ Accuracy: 26.2%\n",
            "Step: 108 ------------ Loss: 10771.49 ------------ Accuracy: 26.2%\n",
            "Step: 109 ------------ Loss: 10765.61 ------------ Accuracy: 26.2%\n",
            "Step: 110 ------------ Loss: 10762.14 ------------ Accuracy: 26.2%\n",
            "Step: 111 ------------ Loss: 10758.08 ------------ Accuracy: 26.2%\n",
            "Step: 112 ------------ Loss: 10752.83 ------------ Accuracy: 26.2%\n",
            "Step: 113 ------------ Loss: 10749.35 ------------ Accuracy: 26.2%\n",
            "Step: 114 ------------ Loss: 10733.11 ------------ Accuracy: 26.2%\n",
            "Step: 115 ------------ Loss: 10724.62 ------------ Accuracy: 26.2%\n",
            "Step: 116 ------------ Loss: 10720.4 ------------ Accuracy: 26.2%\n",
            "Step: 117 ------------ Loss: 10713.9 ------------ Accuracy: 26.2%\n",
            "Step: 118 ------------ Loss: 10711.06 ------------ Accuracy: 26.3%\n",
            "Step: 119 ------------ Loss: 10702.74 ------------ Accuracy: 26.3%\n",
            "Step: 120 ------------ Loss: 10688.59 ------------ Accuracy: 26.3%\n",
            "Step: 121 ------------ Loss: 10676.59 ------------ Accuracy: 26.3%\n",
            "Step: 122 ------------ Loss: 10672.32 ------------ Accuracy: 26.3%\n",
            "Step: 123 ------------ Loss: 10668.84 ------------ Accuracy: 26.3%\n",
            "Step: 124 ------------ Loss: 10667.87 ------------ Accuracy: 26.3%\n",
            "Step: 125 ------------ Loss: 10664.4 ------------ Accuracy: 26.3%\n",
            "Step: 126 ------------ Loss: 10661.07 ------------ Accuracy: 26.3%\n",
            "Step: 127 ------------ Loss: 10660.14 ------------ Accuracy: 26.3%\n",
            "Step: 128 ------------ Loss: 10659.26 ------------ Accuracy: 26.3%\n",
            "Step: 129 ------------ Loss: 10655.81 ------------ Accuracy: 26.3%\n",
            "Step: 130 ------------ Loss: 10647.63 ------------ Accuracy: 26.3%\n",
            "Step: 131 ------------ Loss: 10644.81 ------------ Accuracy: 26.3%\n",
            "Step: 132 ------------ Loss: 10636.95 ------------ Accuracy: 26.3%\n",
            "Step: 133 ------------ Loss: 10633.42 ------------ Accuracy: 26.3%\n",
            "Step: 134 ------------ Loss: 10631.03 ------------ Accuracy: 26.3%\n",
            "Step: 135 ------------ Loss: 10627.19 ------------ Accuracy: 26.3%\n",
            "Step: 136 ------------ Loss: 10619.73 ------------ Accuracy: 26.3%\n",
            "Step: 137 ------------ Loss: 10609.22 ------------ Accuracy: 26.3%\n",
            "Step: 138 ------------ Loss: 10601.09 ------------ Accuracy: 26.3%\n",
            "Step: 139 ------------ Loss: 10595.01 ------------ Accuracy: 26.3%\n",
            "Step: 140 ------------ Loss: 10580.53 ------------ Accuracy: 26.3%\n",
            "Step: 141 ------------ Loss: 10565.16 ------------ Accuracy: 26.3%\n",
            "Step: 142 ------------ Loss: 10554.91 ------------ Accuracy: 26.3%\n",
            "Step: 143 ------------ Loss: 10551.38 ------------ Accuracy: 26.3%\n",
            "Step: 144 ------------ Loss: 10541.61 ------------ Accuracy: 26.3%\n",
            "Step: 145 ------------ Loss: 10538.06 ------------ Accuracy: 26.3%\n",
            "Step: 146 ------------ Loss: 10534.65 ------------ Accuracy: 26.3%\n",
            "Step: 147 ------------ Loss: 10532.82 ------------ Accuracy: 26.3%\n",
            "Step: 148 ------------ Loss: 10526.88 ------------ Accuracy: 26.3%\n",
            "Step: 149 ------------ Loss: 10523.51 ------------ Accuracy: 26.3%\n",
            "Step: 150 ------------ Loss: 10517.68 ------------ Accuracy: 26.3%\n",
            "Step: 151 ------------ Loss: 10506.24 ------------ Accuracy: 26.4%\n",
            "Step: 152 ------------ Loss: 10496.93 ------------ Accuracy: 26.3%\n",
            "Step: 153 ------------ Loss: 10492.49 ------------ Accuracy: 26.3%\n",
            "Step: 154 ------------ Loss: 10488.12 ------------ Accuracy: 26.4%\n",
            "Step: 155 ------------ Loss: 10477.96 ------------ Accuracy: 26.4%\n",
            "Step: 156 ------------ Loss: 10473.65 ------------ Accuracy: 26.4%\n",
            "Step: 157 ------------ Loss: 10464.49 ------------ Accuracy: 26.5%\n",
            "Step: 158 ------------ Loss: 10454.87 ------------ Accuracy: 26.5%\n",
            "Step: 159 ------------ Loss: 10447.98 ------------ Accuracy: 26.5%\n",
            "Step: 160 ------------ Loss: 10439.44 ------------ Accuracy: 26.6%\n",
            "Step: 161 ------------ Loss: 10431.73 ------------ Accuracy: 26.8%\n",
            "Step: 162 ------------ Loss: 10430.26 ------------ Accuracy: 26.8%\n",
            "Step: 163 ------------ Loss: 10426.98 ------------ Accuracy: 26.8%\n",
            "Step: 164 ------------ Loss: 10419.95 ------------ Accuracy: 27.0%\n",
            "Step: 165 ------------ Loss: 10414.01 ------------ Accuracy: 26.9%\n",
            "Step: 166 ------------ Loss: 10403.84 ------------ Accuracy: 26.9%\n",
            "Step: 167 ------------ Loss: 10397.18 ------------ Accuracy: 27.0%\n",
            "Step: 168 ------------ Loss: 10385.0 ------------ Accuracy: 27.0%\n",
            "Step: 169 ------------ Loss: 10381.7 ------------ Accuracy: 27.0%\n",
            "Step: 170 ------------ Loss: 10375.85 ------------ Accuracy: 27.1%\n",
            "Step: 171 ------------ Loss: 10370.07 ------------ Accuracy: 27.2%\n",
            "Step: 172 ------------ Loss: 10358.47 ------------ Accuracy: 27.7%\n",
            "Step: 173 ------------ Loss: 10355.28 ------------ Accuracy: 27.7%\n",
            "Step: 174 ------------ Loss: 10345.31 ------------ Accuracy: 27.7%\n",
            "Step: 175 ------------ Loss: 10340.14 ------------ Accuracy: 27.7%\n",
            "Step: 176 ------------ Loss: 10338.68 ------------ Accuracy: 27.7%\n",
            "Step: 177 ------------ Loss: 10331.37 ------------ Accuracy: 28.0%\n",
            "Step: 178 ------------ Loss: 10327.25 ------------ Accuracy: 28.0%\n",
            "Step: 179 ------------ Loss: 10317.31 ------------ Accuracy: 28.0%\n",
            "Step: 180 ------------ Loss: 10314.29 ------------ Accuracy: 28.0%\n",
            "Step: 181 ------------ Loss: 10304.44 ------------ Accuracy: 27.9%\n",
            "Step: 182 ------------ Loss: 10303.22 ------------ Accuracy: 27.9%\n",
            "Step: 183 ------------ Loss: 10301.51 ------------ Accuracy: 27.8%\n",
            "Step: 184 ------------ Loss: 10295.82 ------------ Accuracy: 27.9%\n",
            "Step: 185 ------------ Loss: 10292.77 ------------ Accuracy: 28.0%\n",
            "Step: 186 ------------ Loss: 10289.61 ------------ Accuracy: 28.0%\n",
            "Step: 187 ------------ Loss: 10282.1 ------------ Accuracy: 28.4%\n",
            "Step: 188 ------------ Loss: 10276.62 ------------ Accuracy: 28.6%\n",
            "Step: 189 ------------ Loss: 10265.62 ------------ Accuracy: 29.2%\n",
            "Step: 190 ------------ Loss: 10255.51 ------------ Accuracy: 29.1%\n",
            "Step: 191 ------------ Loss: 10244.63 ------------ Accuracy: 29.6%\n",
            "Step: 192 ------------ Loss: 10238.32 ------------ Accuracy: 30.0%\n",
            "Step: 193 ------------ Loss: 10233.03 ------------ Accuracy: 30.2%\n",
            "Step: 194 ------------ Loss: 10230.11 ------------ Accuracy: 30.2%\n",
            "Step: 195 ------------ Loss: 10219.65 ------------ Accuracy: 30.0%\n",
            "Step: 196 ------------ Loss: 10216.61 ------------ Accuracy: 30.1%\n",
            "Step: 197 ------------ Loss: 10204.59 ------------ Accuracy: 30.0%\n",
            "Step: 198 ------------ Loss: 10201.65 ------------ Accuracy: 30.0%\n",
            "Step: 199 ------------ Loss: 10196.37 ------------ Accuracy: 30.2%\n",
            "Step: 200 ------------ Loss: 10190.57 ------------ Accuracy: 30.4%\n",
            "Step: 201 ------------ Loss: 10184.86 ------------ Accuracy: 30.7%\n",
            "Step: 202 ------------ Loss: 10174.9 ------------ Accuracy: 30.5%\n",
            "Step: 203 ------------ Loss: 10172.89 ------------ Accuracy: 30.3%\n",
            "Step: 204 ------------ Loss: 10171.7 ------------ Accuracy: 30.3%\n",
            "Step: 205 ------------ Loss: 10160.47 ------------ Accuracy: 30.1%\n",
            "Step: 206 ------------ Loss: 10155.79 ------------ Accuracy: 29.9%\n",
            "Step: 207 ------------ Loss: 10152.81 ------------ Accuracy: 29.9%\n",
            "Step: 208 ------------ Loss: 10149.72 ------------ Accuracy: 29.9%\n",
            "Step: 209 ------------ Loss: 10146.77 ------------ Accuracy: 30.0%\n",
            "Step: 210 ------------ Loss: 10135.71 ------------ Accuracy: 30.7%\n",
            "Step: 211 ------------ Loss: 10132.79 ------------ Accuracy: 30.7%\n",
            "Step: 212 ------------ Loss: 10131.5 ------------ Accuracy: 30.6%\n",
            "Step: 213 ------------ Loss: 10127.53 ------------ Accuracy: 30.6%\n",
            "Step: 214 ------------ Loss: 10124.54 ------------ Accuracy: 30.7%\n",
            "Step: 215 ------------ Loss: 10117.48 ------------ Accuracy: 31.0%\n",
            "Step: 216 ------------ Loss: 10112.47 ------------ Accuracy: 30.8%\n",
            "Step: 217 ------------ Loss: 10107.2 ------------ Accuracy: 30.9%\n",
            "Step: 218 ------------ Loss: 10098.4 ------------ Accuracy: 30.8%\n",
            "Step: 219 ------------ Loss: 10091.36 ------------ Accuracy: 31.2%\n",
            "Step: 220 ------------ Loss: 10086.16 ------------ Accuracy: 31.4%\n",
            "Step: 221 ------------ Loss: 10075.9 ------------ Accuracy: 32.3%\n",
            "Step: 222 ------------ Loss: 10070.77 ------------ Accuracy: 31.9%\n",
            "Step: 223 ------------ Loss: 10066.78 ------------ Accuracy: 32.0%\n",
            "Step: 224 ------------ Loss: 10061.64 ------------ Accuracy: 32.1%\n",
            "Step: 225 ------------ Loss: 10056.02 ------------ Accuracy: 32.5%\n",
            "Step: 226 ------------ Loss: 10049.85 ------------ Accuracy: 32.8%\n",
            "Step: 227 ------------ Loss: 10047.06 ------------ Accuracy: 32.9%\n",
            "Step: 228 ------------ Loss: 10037.45 ------------ Accuracy: 32.8%\n",
            "Step: 229 ------------ Loss: 10036.04 ------------ Accuracy: 32.6%\n",
            "Step: 230 ------------ Loss: 10032.19 ------------ Accuracy: 32.6%\n",
            "Step: 231 ------------ Loss: 10026.69 ------------ Accuracy: 32.9%\n",
            "Step: 232 ------------ Loss: 10015.75 ------------ Accuracy: 32.7%\n",
            "Step: 233 ------------ Loss: 10014.05 ------------ Accuracy: 32.6%\n",
            "Step: 234 ------------ Loss: 10005.35 ------------ Accuracy: 32.5%\n",
            "Step: 235 ------------ Loss: 10001.13 ------------ Accuracy: 32.0%\n",
            "Step: 236 ------------ Loss: 9990.41 ------------ Accuracy: 32.9%\n",
            "Step: 237 ------------ Loss: 9980.43 ------------ Accuracy: 32.7%\n",
            "Step: 238 ------------ Loss: 9973.39 ------------ Accuracy: 33.3%\n",
            "Step: 239 ------------ Loss: 9967.06 ------------ Accuracy: 33.6%\n",
            "Step: 240 ------------ Loss: 9958.43 ------------ Accuracy: 33.5%\n",
            "Step: 241 ------------ Loss: 9949.9 ------------ Accuracy: 33.5%\n",
            "Step: 242 ------------ Loss: 9941.89 ------------ Accuracy: 33.5%\n",
            "Step: 243 ------------ Loss: 9938.9 ------------ Accuracy: 33.5%\n",
            "Step: 244 ------------ Loss: 9938.22 ------------ Accuracy: 33.5%\n",
            "Step: 245 ------------ Loss: 9937.21 ------------ Accuracy: 33.4%\n",
            "Step: 246 ------------ Loss: 9936.12 ------------ Accuracy: 33.3%\n",
            "Step: 247 ------------ Loss: 9932.63 ------------ Accuracy: 33.0%\n",
            "Step: 248 ------------ Loss: 9927.65 ------------ Accuracy: 33.1%\n",
            "Step: 249 ------------ Loss: 9926.69 ------------ Accuracy: 33.0%\n",
            "Step: 250 ------------ Loss: 9923.64 ------------ Accuracy: 33.1%\n",
            "Step: 251 ------------ Loss: 9920.61 ------------ Accuracy: 33.1%\n",
            "Step: 252 ------------ Loss: 9909.93 ------------ Accuracy: 33.7%\n",
            "Step: 253 ------------ Loss: 9908.96 ------------ Accuracy: 33.6%\n",
            "Step: 254 ------------ Loss: 9904.1 ------------ Accuracy: 33.7%\n",
            "Step: 255 ------------ Loss: 9900.12 ------------ Accuracy: 33.7%\n",
            "Step: 256 ------------ Loss: 9890.84 ------------ Accuracy: 33.7%\n",
            "Step: 257 ------------ Loss: 9880.31 ------------ Accuracy: 34.2%\n",
            "Step: 258 ------------ Loss: 9879.73 ------------ Accuracy: 34.2%\n",
            "Step: 259 ------------ Loss: 9872.3 ------------ Accuracy: 34.2%\n",
            "Step: 260 ------------ Loss: 9871.78 ------------ Accuracy: 34.2%\n",
            "Step: 261 ------------ Loss: 9871.31 ------------ Accuracy: 34.2%\n",
            "Step: 262 ------------ Loss: 9870.45 ------------ Accuracy: 34.1%\n",
            "Step: 263 ------------ Loss: 9860.04 ------------ Accuracy: 34.7%\n",
            "Step: 264 ------------ Loss: 9852.5 ------------ Accuracy: 34.4%\n",
            "Step: 265 ------------ Loss: 9845.15 ------------ Accuracy: 34.4%\n",
            "Step: 266 ------------ Loss: 9836.58 ------------ Accuracy: 34.3%\n",
            "Step: 267 ------------ Loss: 9829.68 ------------ Accuracy: 34.3%\n",
            "Step: 268 ------------ Loss: 9821.57 ------------ Accuracy: 34.3%\n",
            "Step: 269 ------------ Loss: 9810.82 ------------ Accuracy: 34.8%\n",
            "Step: 270 ------------ Loss: 9805.35 ------------ Accuracy: 35.0%\n",
            "Step: 271 ------------ Loss: 9804.4 ------------ Accuracy: 34.9%\n",
            "Step: 272 ------------ Loss: 9799.39 ------------ Accuracy: 35.0%\n",
            "Step: 273 ------------ Loss: 9792.73 ------------ Accuracy: 35.0%\n",
            "Step: 274 ------------ Loss: 9789.8 ------------ Accuracy: 35.0%\n",
            "Step: 275 ------------ Loss: 9787.18 ------------ Accuracy: 34.7%\n",
            "Step: 276 ------------ Loss: 9786.4 ------------ Accuracy: 34.6%\n",
            "Step: 277 ------------ Loss: 9785.98 ------------ Accuracy: 34.7%\n",
            "Step: 278 ------------ Loss: 9780.96 ------------ Accuracy: 34.8%\n",
            "Step: 279 ------------ Loss: 9773.12 ------------ Accuracy: 34.7%\n",
            "Step: 280 ------------ Loss: 9770.87 ------------ Accuracy: 34.5%\n",
            "Step: 281 ------------ Loss: 9762.22 ------------ Accuracy: 35.0%\n",
            "Step: 282 ------------ Loss: 9755.84 ------------ Accuracy: 34.9%\n",
            "Step: 283 ------------ Loss: 9747.7 ------------ Accuracy: 35.3%\n",
            "Step: 284 ------------ Loss: 9746.86 ------------ Accuracy: 35.2%\n",
            "Step: 285 ------------ Loss: 9736.57 ------------ Accuracy: 35.7%\n",
            "Step: 286 ------------ Loss: 9728.59 ------------ Accuracy: 35.6%\n",
            "Step: 287 ------------ Loss: 9724.38 ------------ Accuracy: 35.7%\n",
            "Step: 288 ------------ Loss: 9717.37 ------------ Accuracy: 35.6%\n",
            "Step: 289 ------------ Loss: 9712.36 ------------ Accuracy: 35.6%\n",
            "Step: 290 ------------ Loss: 9708.16 ------------ Accuracy: 35.7%\n",
            "Step: 291 ------------ Loss: 9707.5 ------------ Accuracy: 35.7%\n",
            "Step: 292 ------------ Loss: 9704.99 ------------ Accuracy: 35.5%\n",
            "Step: 293 ------------ Loss: 9698.62 ------------ Accuracy: 35.4%\n",
            "Step: 294 ------------ Loss: 9692.45 ------------ Accuracy: 35.4%\n",
            "Step: 295 ------------ Loss: 9686.45 ------------ Accuracy: 35.5%\n",
            "Step: 296 ------------ Loss: 9680.54 ------------ Accuracy: 35.7%\n",
            "Step: 297 ------------ Loss: 9677.66 ------------ Accuracy: 35.7%\n",
            "Step: 298 ------------ Loss: 9677.02 ------------ Accuracy: 35.7%\n",
            "Step: 299 ------------ Loss: 9670.02 ------------ Accuracy: 35.6%\n",
            "Step: 300 ------------ Loss: 9669.47 ------------ Accuracy: 35.6%\n",
            "Step: 301 ------------ Loss: 9664.48 ------------ Accuracy: 35.7%\n",
            "Step: 302 ------------ Loss: 9663.68 ------------ Accuracy: 35.6%\n",
            "Step: 303 ------------ Loss: 9663.14 ------------ Accuracy: 35.6%\n",
            "Step: 304 ------------ Loss: 9660.14 ------------ Accuracy: 35.6%\n",
            "Step: 305 ------------ Loss: 9656.03 ------------ Accuracy: 35.7%\n",
            "Step: 306 ------------ Loss: 9649.93 ------------ Accuracy: 35.7%\n",
            "Step: 307 ------------ Loss: 9647.07 ------------ Accuracy: 35.7%\n",
            "Step: 308 ------------ Loss: 9639.88 ------------ Accuracy: 35.6%\n",
            "Step: 309 ------------ Loss: 9635.8 ------------ Accuracy: 35.7%\n",
            "Step: 310 ------------ Loss: 9635.25 ------------ Accuracy: 35.7%\n",
            "Step: 311 ------------ Loss: 9628.34 ------------ Accuracy: 35.5%\n",
            "Step: 312 ------------ Loss: 9626.34 ------------ Accuracy: 35.4%\n",
            "Step: 313 ------------ Loss: 9617.97 ------------ Accuracy: 35.8%\n",
            "Step: 314 ------------ Loss: 9607.74 ------------ Accuracy: 36.2%\n",
            "Step: 315 ------------ Loss: 9600.52 ------------ Accuracy: 36.1%\n",
            "Step: 316 ------------ Loss: 9595.58 ------------ Accuracy: 36.2%\n",
            "Step: 317 ------------ Loss: 9594.72 ------------ Accuracy: 36.1%\n",
            "Step: 318 ------------ Loss: 9588.69 ------------ Accuracy: 36.2%\n",
            "Step: 319 ------------ Loss: 9578.48 ------------ Accuracy: 36.7%\n",
            "Step: 320 ------------ Loss: 9572.5 ------------ Accuracy: 36.7%\n",
            "Step: 321 ------------ Loss: 9568.41 ------------ Accuracy: 36.8%\n",
            "Step: 322 ------------ Loss: 9568.08 ------------ Accuracy: 36.8%\n",
            "Step: 323 ------------ Loss: 9561.11 ------------ Accuracy: 36.8%\n",
            "Step: 324 ------------ Loss: 9557.02 ------------ Accuracy: 36.9%\n",
            "Step: 325 ------------ Loss: 9550.23 ------------ Accuracy: 36.7%\n",
            "Step: 326 ------------ Loss: 9542.17 ------------ Accuracy: 37.1%\n",
            "Step: 327 ------------ Loss: 9536.3 ------------ Accuracy: 37.1%\n",
            "Step: 328 ------------ Loss: 9532.22 ------------ Accuracy: 37.3%\n",
            "Step: 329 ------------ Loss: 9531.75 ------------ Accuracy: 37.2%\n",
            "Step: 330 ------------ Loss: 9529.7 ------------ Accuracy: 37.0%\n",
            "Step: 331 ------------ Loss: 9523.98 ------------ Accuracy: 37.2%\n",
            "Step: 332 ------------ Loss: 9523.52 ------------ Accuracy: 37.2%\n",
            "Step: 333 ------------ Loss: 9515.87 ------------ Accuracy: 37.4%\n",
            "Step: 334 ------------ Loss: 9509.96 ------------ Accuracy: 37.5%\n",
            "Step: 335 ------------ Loss: 9505.92 ------------ Accuracy: 37.6%\n",
            "Step: 336 ------------ Loss: 9503.14 ------------ Accuracy: 37.7%\n",
            "Step: 337 ------------ Loss: 9502.71 ------------ Accuracy: 37.6%\n",
            "Step: 338 ------------ Loss: 9497.0 ------------ Accuracy: 37.7%\n",
            "Step: 339 ------------ Loss: 9491.96 ------------ Accuracy: 37.8%\n",
            "Step: 340 ------------ Loss: 9488.03 ------------ Accuracy: 37.9%\n",
            "Step: 341 ------------ Loss: 9480.58 ------------ Accuracy: 38.1%\n",
            "Step: 342 ------------ Loss: 9480.31 ------------ Accuracy: 38.1%\n",
            "Step: 343 ------------ Loss: 9471.01 ------------ Accuracy: 38.6%\n",
            "Step: 344 ------------ Loss: 9463.83 ------------ Accuracy: 38.5%\n",
            "Step: 345 ------------ Loss: 9463.42 ------------ Accuracy: 38.4%\n",
            "Step: 346 ------------ Loss: 9458.08 ------------ Accuracy: 38.6%\n",
            "Step: 347 ------------ Loss: 9451.62 ------------ Accuracy: 38.6%\n",
            "Step: 348 ------------ Loss: 9450.65 ------------ Accuracy: 38.6%\n",
            "Step: 349 ------------ Loss: 9444.5 ------------ Accuracy: 38.7%\n",
            "Step: 350 ------------ Loss: 9441.7 ------------ Accuracy: 38.7%\n",
            "Step: 351 ------------ Loss: 9435.75 ------------ Accuracy: 38.8%\n",
            "Step: 352 ------------ Loss: 9429.21 ------------ Accuracy: 38.9%\n",
            "Step: 353 ------------ Loss: 9422.66 ------------ Accuracy: 38.8%\n",
            "Step: 354 ------------ Loss: 9419.85 ------------ Accuracy: 38.8%\n",
            "Step: 355 ------------ Loss: 9412.81 ------------ Accuracy: 38.7%\n",
            "Step: 356 ------------ Loss: 9408.82 ------------ Accuracy: 38.9%\n",
            "Step: 357 ------------ Loss: 9406.34 ------------ Accuracy: 38.8%\n",
            "Step: 358 ------------ Loss: 9401.06 ------------ Accuracy: 38.8%\n",
            "Step: 359 ------------ Loss: 9400.64 ------------ Accuracy: 38.8%\n",
            "Step: 360 ------------ Loss: 9395.82 ------------ Accuracy: 38.9%\n",
            "Step: 361 ------------ Loss: 9393.05 ------------ Accuracy: 38.9%\n",
            "Step: 362 ------------ Loss: 9386.89 ------------ Accuracy: 39.0%\n",
            "Step: 363 ------------ Loss: 9384.21 ------------ Accuracy: 39.0%\n",
            "Step: 364 ------------ Loss: 9377.35 ------------ Accuracy: 38.9%\n",
            "Step: 365 ------------ Loss: 9376.46 ------------ Accuracy: 38.9%\n",
            "Step: 366 ------------ Loss: 9370.61 ------------ Accuracy: 39.0%\n",
            "Step: 367 ------------ Loss: 9367.93 ------------ Accuracy: 39.0%\n",
            "Step: 368 ------------ Loss: 9367.67 ------------ Accuracy: 39.0%\n",
            "Step: 369 ------------ Loss: 9362.47 ------------ Accuracy: 39.1%\n",
            "Step: 370 ------------ Loss: 9359.73 ------------ Accuracy: 39.2%\n",
            "Step: 371 ------------ Loss: 9355.02 ------------ Accuracy: 39.2%\n",
            "Step: 372 ------------ Loss: 9348.6 ------------ Accuracy: 39.0%\n",
            "Step: 373 ------------ Loss: 9342.43 ------------ Accuracy: 39.2%\n",
            "Step: 374 ------------ Loss: 9339.71 ------------ Accuracy: 39.2%\n",
            "Step: 375 ------------ Loss: 9338.77 ------------ Accuracy: 39.2%\n",
            "Step: 376 ------------ Loss: 9334.14 ------------ Accuracy: 39.3%\n",
            "Step: 377 ------------ Loss: 9331.46 ------------ Accuracy: 39.3%\n",
            "Step: 378 ------------ Loss: 9327.17 ------------ Accuracy: 39.4%\n",
            "Step: 379 ------------ Loss: 9318.75 ------------ Accuracy: 39.5%\n",
            "Step: 380 ------------ Loss: 9311.73 ------------ Accuracy: 39.5%\n",
            "Step: 381 ------------ Loss: 9309.14 ------------ Accuracy: 39.5%\n",
            "Step: 382 ------------ Loss: 9300.71 ------------ Accuracy: 39.6%\n",
            "Step: 383 ------------ Loss: 9294.68 ------------ Accuracy: 39.7%\n",
            "Step: 384 ------------ Loss: 9288.55 ------------ Accuracy: 39.6%\n",
            "Step: 385 ------------ Loss: 9282.65 ------------ Accuracy: 39.7%\n",
            "Step: 386 ------------ Loss: 9276.8 ------------ Accuracy: 39.8%\n",
            "Step: 387 ------------ Loss: 9274.11 ------------ Accuracy: 39.8%\n",
            "Step: 388 ------------ Loss: 9271.54 ------------ Accuracy: 39.9%\n",
            "Step: 389 ------------ Loss: 9264.9 ------------ Accuracy: 39.8%\n",
            "Step: 390 ------------ Loss: 9260.01 ------------ Accuracy: 39.9%\n",
            "Step: 391 ------------ Loss: 9257.35 ------------ Accuracy: 39.9%\n",
            "Step: 392 ------------ Loss: 9251.96 ------------ Accuracy: 39.9%\n",
            "Step: 393 ------------ Loss: 9246.17 ------------ Accuracy: 39.9%\n",
            "Step: 394 ------------ Loss: 9240.69 ------------ Accuracy: 39.7%\n",
            "Step: 395 ------------ Loss: 9238.0 ------------ Accuracy: 39.7%\n",
            "Step: 396 ------------ Loss: 9233.23 ------------ Accuracy: 39.7%\n",
            "Step: 397 ------------ Loss: 9230.31 ------------ Accuracy: 39.7%\n",
            "Step: 398 ------------ Loss: 9225.73 ------------ Accuracy: 39.7%\n",
            "Step: 399 ------------ Loss: 9221.2 ------------ Accuracy: 39.8%\n",
            "Step: 400 ------------ Loss: 9214.53 ------------ Accuracy: 39.9%\n",
            "Step: 401 ------------ Loss: 9210.62 ------------ Accuracy: 40.0%\n",
            "Step: 402 ------------ Loss: 9204.2 ------------ Accuracy: 40.1%\n",
            "Step: 403 ------------ Loss: 9199.58 ------------ Accuracy: 40.1%\n",
            "Step: 404 ------------ Loss: 9195.17 ------------ Accuracy: 40.1%\n",
            "Step: 405 ------------ Loss: 9194.79 ------------ Accuracy: 40.2%\n",
            "Step: 406 ------------ Loss: 9190.2 ------------ Accuracy: 40.2%\n",
            "Step: 407 ------------ Loss: 9183.76 ------------ Accuracy: 40.4%\n",
            "Step: 408 ------------ Loss: 9181.29 ------------ Accuracy: 40.4%\n",
            "Step: 409 ------------ Loss: 9174.54 ------------ Accuracy: 40.5%\n",
            "Step: 410 ------------ Loss: 9171.88 ------------ Accuracy: 40.5%\n",
            "Step: 411 ------------ Loss: 9167.03 ------------ Accuracy: 40.4%\n",
            "Step: 412 ------------ Loss: 9164.44 ------------ Accuracy: 40.4%\n",
            "Step: 413 ------------ Loss: 9163.76 ------------ Accuracy: 40.5%\n",
            "Step: 414 ------------ Loss: 9161.27 ------------ Accuracy: 40.5%\n",
            "Step: 415 ------------ Loss: 9155.04 ------------ Accuracy: 40.7%\n",
            "Step: 416 ------------ Loss: 9154.02 ------------ Accuracy: 40.8%\n",
            "Step: 417 ------------ Loss: 9149.41 ------------ Accuracy: 40.8%\n",
            "Step: 418 ------------ Loss: 9149.18 ------------ Accuracy: 40.9%\n",
            "Step: 419 ------------ Loss: 9143.38 ------------ Accuracy: 40.6%\n",
            "Step: 420 ------------ Loss: 9142.35 ------------ Accuracy: 40.7%\n",
            "Step: 421 ------------ Loss: 9138.22 ------------ Accuracy: 40.8%\n",
            "Step: 422 ------------ Loss: 9130.59 ------------ Accuracy: 40.8%\n",
            "Step: 423 ------------ Loss: 9128.15 ------------ Accuracy: 40.8%\n",
            "Step: 424 ------------ Loss: 9123.66 ------------ Accuracy: 40.9%\n",
            "Step: 425 ------------ Loss: 9117.94 ------------ Accuracy: 40.6%\n",
            "Step: 426 ------------ Loss: 9113.67 ------------ Accuracy: 40.7%\n",
            "Step: 427 ------------ Loss: 9107.61 ------------ Accuracy: 41.0%\n",
            "Step: 428 ------------ Loss: 9103.14 ------------ Accuracy: 41.0%\n",
            "Step: 429 ------------ Loss: 9097.26 ------------ Accuracy: 41.3%\n",
            "Step: 430 ------------ Loss: 9093.65 ------------ Accuracy: 41.3%\n",
            "Step: 431 ------------ Loss: 9091.18 ------------ Accuracy: 41.4%\n",
            "Step: 432 ------------ Loss: 9087.63 ------------ Accuracy: 41.5%\n",
            "Step: 433 ------------ Loss: 9081.97 ------------ Accuracy: 41.8%\n",
            "Step: 434 ------------ Loss: 9081.74 ------------ Accuracy: 41.8%\n",
            "Step: 435 ------------ Loss: 9075.8 ------------ Accuracy: 41.6%\n",
            "Step: 436 ------------ Loss: 9071.34 ------------ Accuracy: 41.6%\n",
            "Step: 437 ------------ Loss: 9065.22 ------------ Accuracy: 41.6%\n",
            "Step: 438 ------------ Loss: 9065.0 ------------ Accuracy: 41.7%\n",
            "Step: 439 ------------ Loss: 9059.58 ------------ Accuracy: 42.0%\n",
            "Step: 440 ------------ Loss: 9054.28 ------------ Accuracy: 42.2%\n",
            "Step: 441 ------------ Loss: 9053.83 ------------ Accuracy: 42.2%\n",
            "Step: 442 ------------ Loss: 9049.81 ------------ Accuracy: 42.2%\n",
            "Step: 443 ------------ Loss: 9044.77 ------------ Accuracy: 42.5%\n",
            "Step: 444 ------------ Loss: 9044.05 ------------ Accuracy: 42.6%\n",
            "Step: 445 ------------ Loss: 9042.14 ------------ Accuracy: 42.5%\n",
            "Step: 446 ------------ Loss: 9037.87 ------------ Accuracy: 42.6%\n",
            "Step: 447 ------------ Loss: 9033.07 ------------ Accuracy: 42.8%\n",
            "Step: 448 ------------ Loss: 9030.6 ------------ Accuracy: 42.8%\n",
            "Step: 449 ------------ Loss: 9030.13 ------------ Accuracy: 42.7%\n",
            "Step: 450 ------------ Loss: 9025.52 ------------ Accuracy: 42.9%\n",
            "Step: 451 ------------ Loss: 9021.06 ------------ Accuracy: 43.2%\n",
            "Step: 452 ------------ Loss: 9019.45 ------------ Accuracy: 43.1%\n",
            "Step: 453 ------------ Loss: 9015.95 ------------ Accuracy: 43.1%\n",
            "Step: 454 ------------ Loss: 9011.72 ------------ Accuracy: 43.4%\n",
            "Step: 455 ------------ Loss: 9004.35 ------------ Accuracy: 43.2%\n",
            "Step: 456 ------------ Loss: 9000.36 ------------ Accuracy: 43.3%\n",
            "Step: 457 ------------ Loss: 8999.89 ------------ Accuracy: 43.2%\n",
            "Step: 458 ------------ Loss: 8995.48 ------------ Accuracy: 43.4%\n",
            "Step: 459 ------------ Loss: 8994.94 ------------ Accuracy: 43.5%\n",
            "Step: 460 ------------ Loss: 8993.36 ------------ Accuracy: 43.3%\n",
            "Step: 461 ------------ Loss: 8989.35 ------------ Accuracy: 43.5%\n",
            "Step: 462 ------------ Loss: 8984.26 ------------ Accuracy: 43.5%\n",
            "Step: 463 ------------ Loss: 8979.6 ------------ Accuracy: 43.5%\n",
            "Step: 464 ------------ Loss: 8972.5 ------------ Accuracy: 43.3%\n",
            "Step: 465 ------------ Loss: 8968.57 ------------ Accuracy: 43.4%\n",
            "Step: 466 ------------ Loss: 8960.32 ------------ Accuracy: 43.4%\n",
            "Step: 467 ------------ Loss: 8957.91 ------------ Accuracy: 43.5%\n",
            "Step: 468 ------------ Loss: 8953.38 ------------ Accuracy: 43.7%\n",
            "Step: 469 ------------ Loss: 8950.98 ------------ Accuracy: 43.8%\n",
            "Step: 470 ------------ Loss: 8950.69 ------------ Accuracy: 43.7%\n",
            "Step: 471 ------------ Loss: 8950.13 ------------ Accuracy: 43.7%\n",
            "Step: 472 ------------ Loss: 8942.04 ------------ Accuracy: 43.7%\n",
            "Step: 473 ------------ Loss: 8937.74 ------------ Accuracy: 43.8%\n",
            "Step: 474 ------------ Loss: 8934.42 ------------ Accuracy: 44.0%\n",
            "Step: 475 ------------ Loss: 8933.9 ------------ Accuracy: 43.8%\n",
            "Step: 476 ------------ Loss: 8931.63 ------------ Accuracy: 43.8%\n",
            "Step: 477 ------------ Loss: 8927.04 ------------ Accuracy: 44.1%\n",
            "Step: 478 ------------ Loss: 8926.5 ------------ Accuracy: 44.2%\n",
            "Step: 479 ------------ Loss: 8924.15 ------------ Accuracy: 44.3%\n",
            "Step: 480 ------------ Loss: 8921.91 ------------ Accuracy: 44.3%\n",
            "Step: 481 ------------ Loss: 8916.57 ------------ Accuracy: 44.3%\n",
            "Step: 482 ------------ Loss: 8910.24 ------------ Accuracy: 43.9%\n",
            "Step: 483 ------------ Loss: 8909.97 ------------ Accuracy: 43.9%\n",
            "Step: 484 ------------ Loss: 8908.06 ------------ Accuracy: 43.8%\n",
            "Step: 485 ------------ Loss: 8900.28 ------------ Accuracy: 43.9%\n",
            "Step: 486 ------------ Loss: 8892.77 ------------ Accuracy: 43.9%\n",
            "Step: 487 ------------ Loss: 8885.51 ------------ Accuracy: 44.0%\n",
            "Step: 488 ------------ Loss: 8880.67 ------------ Accuracy: 44.2%\n",
            "Step: 489 ------------ Loss: 8874.74 ------------ Accuracy: 43.8%\n",
            "Step: 490 ------------ Loss: 8874.29 ------------ Accuracy: 43.8%\n",
            "Step: 491 ------------ Loss: 8870.3 ------------ Accuracy: 43.9%\n",
            "Step: 492 ------------ Loss: 8865.25 ------------ Accuracy: 43.7%\n",
            "Step: 493 ------------ Loss: 8858.43 ------------ Accuracy: 43.9%\n",
            "Step: 494 ------------ Loss: 8851.84 ------------ Accuracy: 43.8%\n",
            "Step: 495 ------------ Loss: 8846.61 ------------ Accuracy: 44.1%\n",
            "Step: 496 ------------ Loss: 8844.22 ------------ Accuracy: 44.1%\n",
            "Step: 497 ------------ Loss: 8839.28 ------------ Accuracy: 44.4%\n",
            "Step: 498 ------------ Loss: 8832.53 ------------ Accuracy: 44.4%\n",
            "Step: 499 ------------ Loss: 8828.49 ------------ Accuracy: 44.5%\n",
            "Step: 500 ------------ Loss: 8828.32 ------------ Accuracy: 44.5%\n",
            "Step: 501 ------------ Loss: 8823.41 ------------ Accuracy: 44.8%\n",
            "Step: 502 ------------ Loss: 8822.91 ------------ Accuracy: 44.7%\n",
            "Step: 503 ------------ Loss: 8817.3 ------------ Accuracy: 44.4%\n",
            "Step: 504 ------------ Loss: 8816.88 ------------ Accuracy: 44.4%\n",
            "Step: 505 ------------ Loss: 8816.49 ------------ Accuracy: 44.3%\n",
            "Step: 506 ------------ Loss: 8812.68 ------------ Accuracy: 44.4%\n",
            "Step: 507 ------------ Loss: 8808.56 ------------ Accuracy: 44.4%\n",
            "Step: 508 ------------ Loss: 8808.41 ------------ Accuracy: 44.5%\n",
            "Step: 509 ------------ Loss: 8806.06 ------------ Accuracy: 44.5%\n",
            "Step: 510 ------------ Loss: 8801.46 ------------ Accuracy: 44.3%\n",
            "Step: 511 ------------ Loss: 8796.01 ------------ Accuracy: 44.3%\n",
            "Step: 512 ------------ Loss: 8793.82 ------------ Accuracy: 44.3%\n",
            "Step: 513 ------------ Loss: 8793.7 ------------ Accuracy: 44.4%\n",
            "Step: 514 ------------ Loss: 8788.52 ------------ Accuracy: 44.4%\n",
            "Step: 515 ------------ Loss: 8788.14 ------------ Accuracy: 44.4%\n",
            "Step: 516 ------------ Loss: 8783.5 ------------ Accuracy: 44.7%\n",
            "Step: 517 ------------ Loss: 8778.28 ------------ Accuracy: 44.3%\n",
            "Step: 518 ------------ Loss: 8775.87 ------------ Accuracy: 44.3%\n",
            "Step: 519 ------------ Loss: 8775.54 ------------ Accuracy: 44.3%\n",
            "Step: 520 ------------ Loss: 8773.76 ------------ Accuracy: 44.3%\n",
            "Step: 521 ------------ Loss: 8768.8 ------------ Accuracy: 44.0%\n",
            "Step: 522 ------------ Loss: 8763.8 ------------ Accuracy: 43.9%\n",
            "Step: 523 ------------ Loss: 8761.38 ------------ Accuracy: 44.0%\n",
            "Step: 524 ------------ Loss: 8754.71 ------------ Accuracy: 44.0%\n",
            "Step: 525 ------------ Loss: 8749.74 ------------ Accuracy: 44.4%\n",
            "Step: 526 ------------ Loss: 8744.96 ------------ Accuracy: 44.7%\n",
            "Step: 527 ------------ Loss: 8742.56 ------------ Accuracy: 44.7%\n",
            "Step: 528 ------------ Loss: 8740.17 ------------ Accuracy: 44.7%\n",
            "Step: 529 ------------ Loss: 8735.57 ------------ Accuracy: 44.9%\n",
            "Step: 530 ------------ Loss: 8732.06 ------------ Accuracy: 45.0%\n",
            "Step: 531 ------------ Loss: 8728.26 ------------ Accuracy: 45.2%\n",
            "Step: 532 ------------ Loss: 8727.42 ------------ Accuracy: 45.3%\n",
            "Step: 533 ------------ Loss: 8722.67 ------------ Accuracy: 45.3%\n",
            "Step: 534 ------------ Loss: 8718.06 ------------ Accuracy: 45.3%\n",
            "Step: 535 ------------ Loss: 8717.87 ------------ Accuracy: 45.3%\n",
            "Step: 536 ------------ Loss: 8712.81 ------------ Accuracy: 44.9%\n",
            "Step: 537 ------------ Loss: 8711.31 ------------ Accuracy: 45.0%\n",
            "Step: 538 ------------ Loss: 8707.42 ------------ Accuracy: 45.1%\n",
            "Step: 539 ------------ Loss: 8706.0 ------------ Accuracy: 45.0%\n",
            "Step: 540 ------------ Loss: 8701.67 ------------ Accuracy: 45.1%\n",
            "Step: 541 ------------ Loss: 8697.33 ------------ Accuracy: 45.2%\n",
            "Step: 542 ------------ Loss: 8693.28 ------------ Accuracy: 45.6%\n",
            "Step: 543 ------------ Loss: 8689.36 ------------ Accuracy: 46.0%\n",
            "Step: 544 ------------ Loss: 8684.35 ------------ Accuracy: 45.5%\n",
            "Step: 545 ------------ Loss: 8680.42 ------------ Accuracy: 45.7%\n",
            "Step: 546 ------------ Loss: 8675.62 ------------ Accuracy: 45.2%\n",
            "Step: 547 ------------ Loss: 8671.07 ------------ Accuracy: 44.8%\n",
            "Step: 548 ------------ Loss: 8666.86 ------------ Accuracy: 44.9%\n",
            "Step: 549 ------------ Loss: 8665.64 ------------ Accuracy: 45.0%\n",
            "Step: 550 ------------ Loss: 8664.51 ------------ Accuracy: 45.1%\n",
            "Step: 551 ------------ Loss: 8660.58 ------------ Accuracy: 45.2%\n",
            "Step: 552 ------------ Loss: 8660.12 ------------ Accuracy: 45.3%\n",
            "Step: 553 ------------ Loss: 8654.07 ------------ Accuracy: 45.1%\n",
            "Step: 554 ------------ Loss: 8648.57 ------------ Accuracy: 45.0%\n",
            "Step: 555 ------------ Loss: 8646.28 ------------ Accuracy: 45.1%\n",
            "Step: 556 ------------ Loss: 8643.91 ------------ Accuracy: 45.1%\n",
            "Step: 557 ------------ Loss: 8639.57 ------------ Accuracy: 45.5%\n",
            "Step: 558 ------------ Loss: 8635.39 ------------ Accuracy: 45.9%\n",
            "Step: 559 ------------ Loss: 8633.12 ------------ Accuracy: 46.0%\n",
            "Step: 560 ------------ Loss: 8626.09 ------------ Accuracy: 46.0%\n",
            "Step: 561 ------------ Loss: 8622.59 ------------ Accuracy: 46.2%\n",
            "Step: 562 ------------ Loss: 8621.73 ------------ Accuracy: 46.3%\n",
            "Step: 563 ------------ Loss: 8617.67 ------------ Accuracy: 46.6%\n",
            "Step: 564 ------------ Loss: 8613.77 ------------ Accuracy: 46.9%\n",
            "Step: 565 ------------ Loss: 8609.99 ------------ Accuracy: 47.2%\n",
            "Step: 566 ------------ Loss: 8609.56 ------------ Accuracy: 47.2%\n",
            "Step: 567 ------------ Loss: 8605.37 ------------ Accuracy: 47.3%\n",
            "Step: 568 ------------ Loss: 8603.07 ------------ Accuracy: 47.3%\n",
            "Step: 569 ------------ Loss: 8597.39 ------------ Accuracy: 47.0%\n",
            "Step: 570 ------------ Loss: 8593.48 ------------ Accuracy: 47.3%\n",
            "Step: 571 ------------ Loss: 8586.59 ------------ Accuracy: 47.4%\n",
            "Step: 572 ------------ Loss: 8585.2 ------------ Accuracy: 47.4%\n",
            "Step: 573 ------------ Loss: 8581.85 ------------ Accuracy: 47.6%\n",
            "Step: 574 ------------ Loss: 8580.55 ------------ Accuracy: 47.5%\n",
            "Step: 575 ------------ Loss: 8576.67 ------------ Accuracy: 47.7%\n",
            "Step: 576 ------------ Loss: 8572.93 ------------ Accuracy: 47.9%\n",
            "Step: 577 ------------ Loss: 8569.09 ------------ Accuracy: 48.0%\n",
            "Step: 578 ------------ Loss: 8565.45 ------------ Accuracy: 48.1%\n",
            "Step: 579 ------------ Loss: 8564.84 ------------ Accuracy: 48.2%\n",
            "Step: 580 ------------ Loss: 8564.39 ------------ Accuracy: 48.1%\n",
            "Step: 581 ------------ Loss: 8561.16 ------------ Accuracy: 48.2%\n",
            "Step: 582 ------------ Loss: 8559.93 ------------ Accuracy: 48.2%\n",
            "Step: 583 ------------ Loss: 8556.33 ------------ Accuracy: 48.3%\n",
            "Step: 584 ------------ Loss: 8552.35 ------------ Accuracy: 48.4%\n",
            "Step: 585 ------------ Loss: 8548.28 ------------ Accuracy: 48.4%\n",
            "Step: 586 ------------ Loss: 8544.3 ------------ Accuracy: 48.5%\n",
            "Step: 587 ------------ Loss: 8543.12 ------------ Accuracy: 48.5%\n",
            "Step: 588 ------------ Loss: 8537.81 ------------ Accuracy: 48.2%\n",
            "Step: 589 ------------ Loss: 8534.21 ------------ Accuracy: 48.3%\n",
            "Step: 590 ------------ Loss: 8533.63 ------------ Accuracy: 48.4%\n",
            "Step: 591 ------------ Loss: 8532.55 ------------ Accuracy: 48.3%\n",
            "Step: 592 ------------ Loss: 8526.64 ------------ Accuracy: 48.2%\n",
            "Step: 593 ------------ Loss: 8522.98 ------------ Accuracy: 48.4%\n",
            "Step: 594 ------------ Loss: 8516.0 ------------ Accuracy: 48.5%\n",
            "Step: 595 ------------ Loss: 8510.97 ------------ Accuracy: 48.2%\n",
            "Step: 596 ------------ Loss: 8505.76 ------------ Accuracy: 47.9%\n",
            "Step: 597 ------------ Loss: 8501.02 ------------ Accuracy: 47.7%\n",
            "Step: 598 ------------ Loss: 8497.33 ------------ Accuracy: 47.7%\n",
            "Step: 599 ------------ Loss: 8497.2 ------------ Accuracy: 47.8%\n",
            "Step: 600 ------------ Loss: 8496.78 ------------ Accuracy: 47.9%\n",
            "Step: 601 ------------ Loss: 8492.68 ------------ Accuracy: 48.3%\n",
            "Step: 602 ------------ Loss: 8490.58 ------------ Accuracy: 48.3%\n",
            "Step: 603 ------------ Loss: 8488.49 ------------ Accuracy: 48.3%\n",
            "Step: 604 ------------ Loss: 8484.0 ------------ Accuracy: 48.1%\n",
            "Step: 605 ------------ Loss: 8478.01 ------------ Accuracy: 48.0%\n",
            "Step: 606 ------------ Loss: 8477.59 ------------ Accuracy: 48.0%\n",
            "Step: 607 ------------ Loss: 8473.31 ------------ Accuracy: 48.3%\n",
            "Step: 608 ------------ Loss: 8470.11 ------------ Accuracy: 48.5%\n",
            "Step: 609 ------------ Loss: 8466.0 ------------ Accuracy: 48.7%\n",
            "Step: 610 ------------ Loss: 8465.67 ------------ Accuracy: 48.7%\n",
            "Step: 611 ------------ Loss: 8463.6 ------------ Accuracy: 48.7%\n",
            "Step: 612 ------------ Loss: 8459.7 ------------ Accuracy: 48.9%\n",
            "Step: 613 ------------ Loss: 8456.01 ------------ Accuracy: 49.0%\n",
            "Step: 614 ------------ Loss: 8449.9 ------------ Accuracy: 48.9%\n",
            "Step: 615 ------------ Loss: 8444.89 ------------ Accuracy: 48.7%\n",
            "Step: 616 ------------ Loss: 8440.63 ------------ Accuracy: 48.6%\n",
            "Step: 617 ------------ Loss: 8436.7 ------------ Accuracy: 48.8%\n",
            "Step: 618 ------------ Loss: 8434.63 ------------ Accuracy: 48.9%\n",
            "Step: 619 ------------ Loss: 8428.58 ------------ Accuracy: 48.8%\n",
            "Step: 620 ------------ Loss: 8424.3 ------------ Accuracy: 48.7%\n",
            "Step: 621 ------------ Loss: 8418.67 ------------ Accuracy: 48.7%\n",
            "Step: 622 ------------ Loss: 8418.54 ------------ Accuracy: 48.7%\n",
            "Step: 623 ------------ Loss: 8418.16 ------------ Accuracy: 48.7%\n",
            "Step: 624 ------------ Loss: 8417.29 ------------ Accuracy: 48.8%\n",
            "Step: 625 ------------ Loss: 8415.16 ------------ Accuracy: 48.8%\n",
            "Step: 626 ------------ Loss: 8412.03 ------------ Accuracy: 48.9%\n",
            "Step: 627 ------------ Loss: 8408.19 ------------ Accuracy: 48.8%\n",
            "Step: 628 ------------ Loss: 8403.98 ------------ Accuracy: 49.0%\n",
            "Step: 629 ------------ Loss: 8399.57 ------------ Accuracy: 49.0%\n",
            "Step: 630 ------------ Loss: 8396.05 ------------ Accuracy: 49.2%\n",
            "Step: 631 ------------ Loss: 8394.22 ------------ Accuracy: 49.1%\n",
            "Step: 632 ------------ Loss: 8390.29 ------------ Accuracy: 49.4%\n",
            "Step: 633 ------------ Loss: 8387.18 ------------ Accuracy: 49.5%\n",
            "Step: 634 ------------ Loss: 8383.08 ------------ Accuracy: 49.3%\n",
            "Step: 635 ------------ Loss: 8382.32 ------------ Accuracy: 49.4%\n",
            "Step: 636 ------------ Loss: 8376.78 ------------ Accuracy: 49.4%\n",
            "Step: 637 ------------ Loss: 8376.38 ------------ Accuracy: 49.3%\n",
            "Step: 638 ------------ Loss: 8372.98 ------------ Accuracy: 49.4%\n",
            "Step: 639 ------------ Loss: 8371.1 ------------ Accuracy: 49.4%\n",
            "Step: 640 ------------ Loss: 8369.1 ------------ Accuracy: 49.5%\n",
            "Step: 641 ------------ Loss: 8367.03 ------------ Accuracy: 49.5%\n",
            "Step: 642 ------------ Loss: 8362.19 ------------ Accuracy: 49.2%\n",
            "Step: 643 ------------ Loss: 8357.61 ------------ Accuracy: 48.9%\n",
            "Step: 644 ------------ Loss: 8354.44 ------------ Accuracy: 49.1%\n",
            "Step: 645 ------------ Loss: 8350.94 ------------ Accuracy: 49.1%\n",
            "Step: 646 ------------ Loss: 8346.49 ------------ Accuracy: 48.8%\n",
            "Step: 647 ------------ Loss: 8343.16 ------------ Accuracy: 49.0%\n",
            "Step: 648 ------------ Loss: 8341.4 ------------ Accuracy: 49.0%\n",
            "Step: 649 ------------ Loss: 8337.28 ------------ Accuracy: 49.3%\n",
            "Step: 650 ------------ Loss: 8333.27 ------------ Accuracy: 49.3%\n",
            "Step: 651 ------------ Loss: 8327.62 ------------ Accuracy: 49.2%\n",
            "Step: 652 ------------ Loss: 8323.65 ------------ Accuracy: 49.2%\n",
            "Step: 653 ------------ Loss: 8322.15 ------------ Accuracy: 49.3%\n",
            "Step: 654 ------------ Loss: 8321.73 ------------ Accuracy: 49.3%\n",
            "Step: 655 ------------ Loss: 8320.33 ------------ Accuracy: 49.4%\n",
            "Step: 656 ------------ Loss: 8316.7 ------------ Accuracy: 49.5%\n",
            "Step: 657 ------------ Loss: 8314.61 ------------ Accuracy: 49.5%\n",
            "Step: 658 ------------ Loss: 8311.48 ------------ Accuracy: 49.7%\n",
            "Step: 659 ------------ Loss: 8311.09 ------------ Accuracy: 49.7%\n",
            "Step: 660 ------------ Loss: 8307.38 ------------ Accuracy: 49.8%\n",
            "Step: 661 ------------ Loss: 8305.31 ------------ Accuracy: 49.9%\n",
            "Step: 662 ------------ Loss: 8303.99 ------------ Accuracy: 49.9%\n",
            "Step: 663 ------------ Loss: 8303.85 ------------ Accuracy: 49.9%\n",
            "Step: 664 ------------ Loss: 8297.98 ------------ Accuracy: 49.9%\n",
            "Step: 665 ------------ Loss: 8297.26 ------------ Accuracy: 50.0%\n",
            "Step: 666 ------------ Loss: 8293.71 ------------ Accuracy: 50.2%\n",
            "Step: 667 ------------ Loss: 8290.24 ------------ Accuracy: 50.4%\n",
            "Step: 668 ------------ Loss: 8285.53 ------------ Accuracy: 50.1%\n",
            "Step: 669 ------------ Loss: 8284.85 ------------ Accuracy: 50.2%\n",
            "Step: 670 ------------ Loss: 8284.48 ------------ Accuracy: 50.1%\n",
            "Step: 671 ------------ Loss: 8281.02 ------------ Accuracy: 50.3%\n",
            "Step: 672 ------------ Loss: 8278.97 ------------ Accuracy: 50.3%\n",
            "Step: 673 ------------ Loss: 8275.31 ------------ Accuracy: 50.3%\n",
            "Step: 674 ------------ Loss: 8272.03 ------------ Accuracy: 50.4%\n",
            "Step: 675 ------------ Loss: 8268.62 ------------ Accuracy: 50.6%\n",
            "Step: 676 ------------ Loss: 8265.29 ------------ Accuracy: 50.8%\n",
            "Step: 677 ------------ Loss: 8263.35 ------------ Accuracy: 50.9%\n",
            "Step: 678 ------------ Loss: 8258.59 ------------ Accuracy: 50.7%\n",
            "Step: 679 ------------ Loss: 8258.44 ------------ Accuracy: 50.7%\n",
            "Step: 680 ------------ Loss: 8258.31 ------------ Accuracy: 50.7%\n",
            "Step: 681 ------------ Loss: 8254.98 ------------ Accuracy: 50.9%\n",
            "Step: 682 ------------ Loss: 8252.04 ------------ Accuracy: 51.0%\n",
            "Step: 683 ------------ Loss: 8250.67 ------------ Accuracy: 51.0%\n",
            "Step: 684 ------------ Loss: 8247.52 ------------ Accuracy: 51.1%\n",
            "Step: 685 ------------ Loss: 8246.96 ------------ Accuracy: 51.2%\n",
            "Step: 686 ------------ Loss: 8246.43 ------------ Accuracy: 51.3%\n",
            "Step: 687 ------------ Loss: 8243.17 ------------ Accuracy: 51.4%\n",
            "Step: 688 ------------ Loss: 8239.85 ------------ Accuracy: 51.6%\n",
            "Step: 689 ------------ Loss: 8234.09 ------------ Accuracy: 51.6%\n",
            "Step: 690 ------------ Loss: 8231.07 ------------ Accuracy: 51.7%\n",
            "Step: 691 ------------ Loss: 8229.23 ------------ Accuracy: 51.7%\n",
            "Step: 692 ------------ Loss: 8223.68 ------------ Accuracy: 51.7%\n",
            "Step: 693 ------------ Loss: 8222.11 ------------ Accuracy: 51.7%\n",
            "Step: 694 ------------ Loss: 8218.64 ------------ Accuracy: 51.8%\n",
            "Step: 695 ------------ Loss: 8218.18 ------------ Accuracy: 51.7%\n",
            "Step: 696 ------------ Loss: 8216.26 ------------ Accuracy: 51.7%\n",
            "Step: 697 ------------ Loss: 8215.84 ------------ Accuracy: 51.6%\n",
            "Step: 698 ------------ Loss: 8215.47 ------------ Accuracy: 51.4%\n",
            "Step: 699 ------------ Loss: 8209.9 ------------ Accuracy: 51.5%\n",
            "Step: 700 ------------ Loss: 8209.78 ------------ Accuracy: 51.4%\n",
            "Step: 701 ------------ Loss: 8206.31 ------------ Accuracy: 51.6%\n",
            "Step: 702 ------------ Loss: 8203.29 ------------ Accuracy: 51.9%\n",
            "Step: 703 ------------ Loss: 8200.16 ------------ Accuracy: 52.0%\n",
            "Step: 704 ------------ Loss: 8198.26 ------------ Accuracy: 52.0%\n",
            "Step: 705 ------------ Loss: 8194.13 ------------ Accuracy: 51.7%\n",
            "Step: 706 ------------ Loss: 8189.27 ------------ Accuracy: 51.3%\n",
            "Step: 707 ------------ Loss: 8186.15 ------------ Accuracy: 51.4%\n",
            "Step: 708 ------------ Loss: 8181.51 ------------ Accuracy: 51.0%\n",
            "Step: 709 ------------ Loss: 8177.78 ------------ Accuracy: 51.3%\n",
            "Step: 710 ------------ Loss: 8173.32 ------------ Accuracy: 50.9%\n",
            "Step: 711 ------------ Loss: 8170.12 ------------ Accuracy: 51.0%\n",
            "Step: 712 ------------ Loss: 8167.24 ------------ Accuracy: 51.1%\n",
            "Step: 713 ------------ Loss: 8164.11 ------------ Accuracy: 51.2%\n",
            "Step: 714 ------------ Loss: 8160.32 ------------ Accuracy: 51.2%\n",
            "Step: 715 ------------ Loss: 8157.13 ------------ Accuracy: 51.3%\n",
            "Step: 716 ------------ Loss: 8154.15 ------------ Accuracy: 51.5%\n",
            "Step: 717 ------------ Loss: 8148.96 ------------ Accuracy: 51.3%\n",
            "Step: 718 ------------ Loss: 8146.16 ------------ Accuracy: 51.5%\n",
            "Step: 719 ------------ Loss: 8142.47 ------------ Accuracy: 51.7%\n",
            "Step: 720 ------------ Loss: 8140.69 ------------ Accuracy: 51.8%\n",
            "Step: 721 ------------ Loss: 8138.91 ------------ Accuracy: 51.9%\n",
            "Step: 722 ------------ Loss: 8137.29 ------------ Accuracy: 51.8%\n",
            "Step: 723 ------------ Loss: 8135.51 ------------ Accuracy: 51.9%\n",
            "Step: 724 ------------ Loss: 8135.35 ------------ Accuracy: 51.9%\n",
            "Step: 725 ------------ Loss: 8133.51 ------------ Accuracy: 51.9%\n",
            "Step: 726 ------------ Loss: 8132.9 ------------ Accuracy: 52.0%\n",
            "Step: 727 ------------ Loss: 8131.42 ------------ Accuracy: 52.0%\n",
            "Step: 728 ------------ Loss: 8128.04 ------------ Accuracy: 52.4%\n",
            "Step: 729 ------------ Loss: 8126.2 ------------ Accuracy: 52.5%\n",
            "Step: 730 ------------ Loss: 8121.54 ------------ Accuracy: 51.9%\n",
            "Step: 731 ------------ Loss: 8118.39 ------------ Accuracy: 52.0%\n",
            "Step: 732 ------------ Loss: 8115.66 ------------ Accuracy: 52.2%\n",
            "Step: 733 ------------ Loss: 8112.95 ------------ Accuracy: 52.4%\n",
            "Step: 734 ------------ Loss: 8111.57 ------------ Accuracy: 52.5%\n",
            "Step: 735 ------------ Loss: 8106.14 ------------ Accuracy: 52.3%\n",
            "Step: 736 ------------ Loss: 8103.08 ------------ Accuracy: 52.4%\n",
            "Step: 737 ------------ Loss: 8097.86 ------------ Accuracy: 52.2%\n",
            "Step: 738 ------------ Loss: 8094.15 ------------ Accuracy: 52.1%\n",
            "Step: 739 ------------ Loss: 8091.44 ------------ Accuracy: 52.2%\n",
            "Step: 740 ------------ Loss: 8086.97 ------------ Accuracy: 51.8%\n",
            "Step: 741 ------------ Loss: 8083.3 ------------ Accuracy: 52.1%\n",
            "Step: 742 ------------ Loss: 8080.33 ------------ Accuracy: 52.2%\n",
            "Step: 743 ------------ Loss: 8077.37 ------------ Accuracy: 52.2%\n",
            "Step: 744 ------------ Loss: 8076.72 ------------ Accuracy: 52.4%\n",
            "Step: 745 ------------ Loss: 8073.22 ------------ Accuracy: 52.2%\n",
            "Step: 746 ------------ Loss: 8070.33 ------------ Accuracy: 52.3%\n",
            "Step: 747 ------------ Loss: 8067.14 ------------ Accuracy: 52.2%\n",
            "Step: 748 ------------ Loss: 8064.39 ------------ Accuracy: 52.2%\n",
            "Step: 749 ------------ Loss: 8061.67 ------------ Accuracy: 52.3%\n",
            "Step: 750 ------------ Loss: 8057.73 ------------ Accuracy: 52.5%\n",
            "Step: 751 ------------ Loss: 8055.13 ------------ Accuracy: 52.7%\n",
            "Step: 752 ------------ Loss: 8052.34 ------------ Accuracy: 52.8%\n",
            "Step: 753 ------------ Loss: 8049.79 ------------ Accuracy: 52.9%\n",
            "Step: 754 ------------ Loss: 8045.14 ------------ Accuracy: 52.8%\n",
            "Step: 755 ------------ Loss: 8042.6 ------------ Accuracy: 53.0%\n",
            "Step: 756 ------------ Loss: 8040.91 ------------ Accuracy: 53.1%\n",
            "Step: 757 ------------ Loss: 8037.05 ------------ Accuracy: 53.4%\n",
            "Step: 758 ------------ Loss: 8035.43 ------------ Accuracy: 53.4%\n",
            "Step: 759 ------------ Loss: 8033.82 ------------ Accuracy: 53.5%\n",
            "Step: 760 ------------ Loss: 8033.21 ------------ Accuracy: 53.6%\n",
            "Step: 761 ------------ Loss: 8030.54 ------------ Accuracy: 53.7%\n",
            "Step: 762 ------------ Loss: 8027.9 ------------ Accuracy: 53.7%\n",
            "Step: 763 ------------ Loss: 8024.27 ------------ Accuracy: 53.9%\n",
            "Step: 764 ------------ Loss: 8019.59 ------------ Accuracy: 53.8%\n",
            "Step: 765 ------------ Loss: 8016.4 ------------ Accuracy: 53.5%\n",
            "Step: 766 ------------ Loss: 8013.8 ------------ Accuracy: 53.6%\n",
            "Step: 767 ------------ Loss: 8010.88 ------------ Accuracy: 53.3%\n",
            "Step: 768 ------------ Loss: 8010.53 ------------ Accuracy: 53.2%\n",
            "Step: 769 ------------ Loss: 8009.79 ------------ Accuracy: 53.2%\n",
            "Step: 770 ------------ Loss: 8005.85 ------------ Accuracy: 53.4%\n",
            "Step: 771 ------------ Loss: 8003.8 ------------ Accuracy: 53.5%\n",
            "Step: 772 ------------ Loss: 7999.31 ------------ Accuracy: 53.3%\n",
            "Step: 773 ------------ Loss: 7996.81 ------------ Accuracy: 53.5%\n",
            "Step: 774 ------------ Loss: 7993.02 ------------ Accuracy: 53.7%\n",
            "Step: 775 ------------ Loss: 7991.42 ------------ Accuracy: 53.8%\n",
            "Step: 776 ------------ Loss: 7991.18 ------------ Accuracy: 53.7%\n",
            "Step: 777 ------------ Loss: 7988.63 ------------ Accuracy: 53.8%\n",
            "Step: 778 ------------ Loss: 7986.71 ------------ Accuracy: 53.8%\n",
            "Step: 779 ------------ Loss: 7986.51 ------------ Accuracy: 53.8%\n",
            "Step: 780 ------------ Loss: 7985.93 ------------ Accuracy: 53.9%\n",
            "Step: 781 ------------ Loss: 7982.46 ------------ Accuracy: 54.1%\n",
            "Step: 782 ------------ Loss: 7979.09 ------------ Accuracy: 53.9%\n",
            "Step: 783 ------------ Loss: 7975.58 ------------ Accuracy: 54.1%\n",
            "Step: 784 ------------ Loss: 7973.01 ------------ Accuracy: 54.2%\n",
            "Step: 785 ------------ Loss: 7970.47 ------------ Accuracy: 54.2%\n",
            "Step: 786 ------------ Loss: 7969.88 ------------ Accuracy: 54.1%\n",
            "Step: 787 ------------ Loss: 7966.09 ------------ Accuracy: 54.1%\n",
            "Step: 788 ------------ Loss: 7962.75 ------------ Accuracy: 53.8%\n",
            "Step: 789 ------------ Loss: 7960.18 ------------ Accuracy: 54.0%\n",
            "Step: 790 ------------ Loss: 7956.38 ------------ Accuracy: 53.9%\n",
            "Step: 791 ------------ Loss: 7952.97 ------------ Accuracy: 54.1%\n",
            "Step: 792 ------------ Loss: 7951.33 ------------ Accuracy: 54.0%\n",
            "Step: 793 ------------ Loss: 7948.86 ------------ Accuracy: 54.2%\n",
            "Step: 794 ------------ Loss: 7944.26 ------------ Accuracy: 53.9%\n",
            "Step: 795 ------------ Loss: 7944.09 ------------ Accuracy: 53.9%\n",
            "Step: 796 ------------ Loss: 7941.36 ------------ Accuracy: 54.0%\n",
            "Step: 797 ------------ Loss: 7938.87 ------------ Accuracy: 54.1%\n",
            "Step: 798 ------------ Loss: 7938.35 ------------ Accuracy: 54.3%\n",
            "Step: 799 ------------ Loss: 7937.86 ------------ Accuracy: 54.4%\n",
            "Step: 800 ------------ Loss: 7936.37 ------------ Accuracy: 54.5%\n",
            "Step: 801 ------------ Loss: 7936.2 ------------ Accuracy: 54.4%\n",
            "Step: 802 ------------ Loss: 7933.49 ------------ Accuracy: 54.5%\n",
            "Step: 803 ------------ Loss: 7930.81 ------------ Accuracy: 54.6%\n",
            "Step: 804 ------------ Loss: 7929.38 ------------ Accuracy: 54.7%\n",
            "Step: 805 ------------ Loss: 7928.05 ------------ Accuracy: 54.7%\n",
            "Step: 806 ------------ Loss: 7924.95 ------------ Accuracy: 54.9%\n",
            "Step: 807 ------------ Loss: 7921.92 ------------ Accuracy: 55.0%\n",
            "Step: 808 ------------ Loss: 7918.65 ------------ Accuracy: 54.9%\n",
            "Step: 809 ------------ Loss: 7916.03 ------------ Accuracy: 55.1%\n",
            "Step: 810 ------------ Loss: 7913.3 ------------ Accuracy: 55.3%\n",
            "Step: 811 ------------ Loss: 7912.77 ------------ Accuracy: 55.0%\n",
            "Step: 812 ------------ Loss: 7912.39 ------------ Accuracy: 55.1%\n",
            "Step: 813 ------------ Loss: 7909.82 ------------ Accuracy: 55.3%\n",
            "Step: 814 ------------ Loss: 7909.32 ------------ Accuracy: 55.1%\n",
            "Step: 815 ------------ Loss: 7906.56 ------------ Accuracy: 55.2%\n",
            "Step: 816 ------------ Loss: 7902.55 ------------ Accuracy: 54.9%\n",
            "Step: 817 ------------ Loss: 7902.15 ------------ Accuracy: 55.1%\n",
            "Step: 818 ------------ Loss: 7901.77 ------------ Accuracy: 55.2%\n",
            "Step: 819 ------------ Loss: 7897.15 ------------ Accuracy: 54.9%\n",
            "Step: 820 ------------ Loss: 7894.47 ------------ Accuracy: 54.9%\n",
            "Step: 821 ------------ Loss: 7891.15 ------------ Accuracy: 54.9%\n",
            "Step: 822 ------------ Loss: 7887.92 ------------ Accuracy: 54.8%\n",
            "Step: 823 ------------ Loss: 7884.09 ------------ Accuracy: 54.6%\n",
            "Step: 824 ------------ Loss: 7881.63 ------------ Accuracy: 54.8%\n",
            "Step: 825 ------------ Loss: 7878.97 ------------ Accuracy: 54.9%\n",
            "Step: 826 ------------ Loss: 7877.35 ------------ Accuracy: 54.9%\n",
            "Step: 827 ------------ Loss: 7876.93 ------------ Accuracy: 55.1%\n",
            "Step: 828 ------------ Loss: 7875.32 ------------ Accuracy: 55.1%\n",
            "Step: 829 ------------ Loss: 7872.02 ------------ Accuracy: 55.1%\n",
            "Step: 830 ------------ Loss: 7871.79 ------------ Accuracy: 55.1%\n",
            "Step: 831 ------------ Loss: 7867.44 ------------ Accuracy: 54.7%\n",
            "Step: 832 ------------ Loss: 7864.99 ------------ Accuracy: 54.9%\n",
            "Step: 833 ------------ Loss: 7863.37 ------------ Accuracy: 54.9%\n",
            "Step: 834 ------------ Loss: 7860.69 ------------ Accuracy: 55.0%\n",
            "Step: 835 ------------ Loss: 7859.4 ------------ Accuracy: 55.0%\n",
            "Step: 836 ------------ Loss: 7855.78 ------------ Accuracy: 54.8%\n",
            "Step: 837 ------------ Loss: 7854.48 ------------ Accuracy: 54.9%\n",
            "Step: 838 ------------ Loss: 7851.82 ------------ Accuracy: 55.0%\n",
            "Step: 839 ------------ Loss: 7848.59 ------------ Accuracy: 54.9%\n",
            "Step: 840 ------------ Loss: 7847.04 ------------ Accuracy: 55.0%\n",
            "Step: 841 ------------ Loss: 7842.93 ------------ Accuracy: 54.6%\n",
            "Step: 842 ------------ Loss: 7840.46 ------------ Accuracy: 54.7%\n",
            "Step: 843 ------------ Loss: 7838.92 ------------ Accuracy: 54.8%\n",
            "Step: 844 ------------ Loss: 7835.77 ------------ Accuracy: 55.0%\n",
            "Step: 845 ------------ Loss: 7831.73 ------------ Accuracy: 54.7%\n",
            "Step: 846 ------------ Loss: 7830.59 ------------ Accuracy: 54.7%\n",
            "Step: 847 ------------ Loss: 7827.51 ------------ Accuracy: 55.0%\n",
            "Step: 848 ------------ Loss: 7827.04 ------------ Accuracy: 55.2%\n",
            "Step: 849 ------------ Loss: 7824.28 ------------ Accuracy: 55.3%\n",
            "Step: 850 ------------ Loss: 7820.51 ------------ Accuracy: 55.0%\n",
            "Step: 851 ------------ Loss: 7817.97 ------------ Accuracy: 55.2%\n",
            "Step: 852 ------------ Loss: 7815.34 ------------ Accuracy: 55.3%\n",
            "Step: 853 ------------ Loss: 7812.73 ------------ Accuracy: 55.4%\n",
            "Step: 854 ------------ Loss: 7811.22 ------------ Accuracy: 55.5%\n",
            "Step: 855 ------------ Loss: 7806.44 ------------ Accuracy: 55.3%\n",
            "Step: 856 ------------ Loss: 7804.94 ------------ Accuracy: 55.3%\n",
            "Step: 857 ------------ Loss: 7803.39 ------------ Accuracy: 55.4%\n",
            "Step: 858 ------------ Loss: 7800.24 ------------ Accuracy: 55.5%\n",
            "Step: 859 ------------ Loss: 7796.83 ------------ Accuracy: 55.4%\n",
            "Step: 860 ------------ Loss: 7793.71 ------------ Accuracy: 55.2%\n",
            "Step: 861 ------------ Loss: 7792.26 ------------ Accuracy: 55.2%\n",
            "Step: 862 ------------ Loss: 7790.91 ------------ Accuracy: 55.3%\n",
            "Step: 863 ------------ Loss: 7788.44 ------------ Accuracy: 55.4%\n",
            "Step: 864 ------------ Loss: 7785.23 ------------ Accuracy: 55.6%\n",
            "Step: 865 ------------ Loss: 7783.67 ------------ Accuracy: 55.6%\n",
            "Step: 866 ------------ Loss: 7783.49 ------------ Accuracy: 55.7%\n",
            "Step: 867 ------------ Loss: 7781.06 ------------ Accuracy: 55.8%\n",
            "Step: 868 ------------ Loss: 7776.95 ------------ Accuracy: 55.4%\n",
            "Step: 869 ------------ Loss: 7773.79 ------------ Accuracy: 55.4%\n",
            "Step: 870 ------------ Loss: 7771.21 ------------ Accuracy: 55.5%\n",
            "Step: 871 ------------ Loss: 7770.69 ------------ Accuracy: 55.5%\n",
            "Step: 872 ------------ Loss: 7769.48 ------------ Accuracy: 55.5%\n",
            "Step: 873 ------------ Loss: 7766.9 ------------ Accuracy: 55.6%\n",
            "Step: 874 ------------ Loss: 7764.53 ------------ Accuracy: 55.8%\n",
            "Step: 875 ------------ Loss: 7761.21 ------------ Accuracy: 55.6%\n",
            "Step: 876 ------------ Loss: 7760.7 ------------ Accuracy: 55.5%\n",
            "Step: 877 ------------ Loss: 7759.22 ------------ Accuracy: 55.6%\n",
            "Step: 878 ------------ Loss: 7755.3 ------------ Accuracy: 55.2%\n",
            "Step: 879 ------------ Loss: 7751.58 ------------ Accuracy: 54.7%\n",
            "Step: 880 ------------ Loss: 7750.29 ------------ Accuracy: 54.9%\n",
            "Step: 881 ------------ Loss: 7747.85 ------------ Accuracy: 55.1%\n",
            "Step: 882 ------------ Loss: 7745.25 ------------ Accuracy: 55.2%\n",
            "Step: 883 ------------ Loss: 7742.05 ------------ Accuracy: 55.4%\n",
            "Step: 884 ------------ Loss: 7738.35 ------------ Accuracy: 55.0%\n",
            "Step: 885 ------------ Loss: 7736.78 ------------ Accuracy: 55.1%\n",
            "Step: 886 ------------ Loss: 7735.29 ------------ Accuracy: 55.2%\n",
            "Step: 887 ------------ Loss: 7732.69 ------------ Accuracy: 55.3%\n",
            "Step: 888 ------------ Loss: 7730.23 ------------ Accuracy: 55.4%\n",
            "Step: 889 ------------ Loss: 7728.7 ------------ Accuracy: 55.5%\n",
            "Step: 890 ------------ Loss: 7724.22 ------------ Accuracy: 55.4%\n",
            "Step: 891 ------------ Loss: 7722.7 ------------ Accuracy: 55.5%\n",
            "Step: 892 ------------ Loss: 7720.34 ------------ Accuracy: 55.6%\n",
            "Step: 893 ------------ Loss: 7719.03 ------------ Accuracy: 55.6%\n",
            "Step: 894 ------------ Loss: 7715.83 ------------ Accuracy: 55.7%\n",
            "Step: 895 ------------ Loss: 7712.75 ------------ Accuracy: 56.0%\n",
            "Step: 896 ------------ Loss: 7709.8 ------------ Accuracy: 56.2%\n",
            "Step: 897 ------------ Loss: 7709.62 ------------ Accuracy: 56.2%\n",
            "Step: 898 ------------ Loss: 7706.71 ------------ Accuracy: 56.2%\n",
            "Step: 899 ------------ Loss: 7705.2 ------------ Accuracy: 56.3%\n",
            "Step: 900 ------------ Loss: 7705.02 ------------ Accuracy: 56.3%\n",
            "Step: 901 ------------ Loss: 7702.5 ------------ Accuracy: 56.4%\n",
            "Step: 902 ------------ Loss: 7699.99 ------------ Accuracy: 56.5%\n",
            "Step: 903 ------------ Loss: 7695.4 ------------ Accuracy: 56.4%\n",
            "Step: 904 ------------ Loss: 7693.91 ------------ Accuracy: 56.4%\n",
            "Step: 905 ------------ Loss: 7691.02 ------------ Accuracy: 56.5%\n",
            "Step: 906 ------------ Loss: 7688.58 ------------ Accuracy: 56.6%\n",
            "Step: 907 ------------ Loss: 7687.17 ------------ Accuracy: 56.6%\n",
            "Step: 908 ------------ Loss: 7683.71 ------------ Accuracy: 56.6%\n",
            "Step: 909 ------------ Loss: 7679.38 ------------ Accuracy: 56.4%\n",
            "Step: 910 ------------ Loss: 7676.33 ------------ Accuracy: 56.6%\n",
            "Step: 911 ------------ Loss: 7675.84 ------------ Accuracy: 56.5%\n",
            "Step: 912 ------------ Loss: 7674.43 ------------ Accuracy: 56.6%\n",
            "Step: 913 ------------ Loss: 7673.15 ------------ Accuracy: 56.6%\n",
            "Step: 914 ------------ Loss: 7670.83 ------------ Accuracy: 56.7%\n",
            "Step: 915 ------------ Loss: 7670.36 ------------ Accuracy: 56.8%\n",
            "Step: 916 ------------ Loss: 7668.9 ------------ Accuracy: 56.8%\n",
            "Step: 917 ------------ Loss: 7666.07 ------------ Accuracy: 56.8%\n",
            "Step: 918 ------------ Loss: 7664.9 ------------ Accuracy: 56.8%\n",
            "Step: 919 ------------ Loss: 7660.81 ------------ Accuracy: 56.7%\n",
            "Step: 920 ------------ Loss: 7659.75 ------------ Accuracy: 56.7%\n",
            "Step: 921 ------------ Loss: 7659.26 ------------ Accuracy: 56.6%\n",
            "Step: 922 ------------ Loss: 7656.47 ------------ Accuracy: 56.7%\n",
            "Step: 923 ------------ Loss: 7656.02 ------------ Accuracy: 56.6%\n",
            "Step: 924 ------------ Loss: 7655.85 ------------ Accuracy: 56.6%\n",
            "Step: 925 ------------ Loss: 7653.34 ------------ Accuracy: 56.7%\n",
            "Step: 926 ------------ Loss: 7651.08 ------------ Accuracy: 56.8%\n",
            "Step: 927 ------------ Loss: 7648.3 ------------ Accuracy: 56.7%\n",
            "Step: 928 ------------ Loss: 7647.88 ------------ Accuracy: 56.7%\n",
            "Step: 929 ------------ Loss: 7643.3 ------------ Accuracy: 56.6%\n",
            "Step: 930 ------------ Loss: 7642.91 ------------ Accuracy: 56.6%\n",
            "Step: 931 ------------ Loss: 7640.43 ------------ Accuracy: 56.6%\n",
            "Step: 932 ------------ Loss: 7637.99 ------------ Accuracy: 56.7%\n",
            "Step: 933 ------------ Loss: 7635.59 ------------ Accuracy: 56.8%\n",
            "Step: 934 ------------ Loss: 7635.21 ------------ Accuracy: 56.8%\n",
            "Step: 935 ------------ Loss: 7634.73 ------------ Accuracy: 56.9%\n",
            "Step: 936 ------------ Loss: 7634.38 ------------ Accuracy: 56.8%\n",
            "Step: 937 ------------ Loss: 7632.92 ------------ Accuracy: 56.9%\n",
            "Step: 938 ------------ Loss: 7630.09 ------------ Accuracy: 56.8%\n",
            "Step: 939 ------------ Loss: 7626.19 ------------ Accuracy: 56.6%\n",
            "Step: 940 ------------ Loss: 7623.73 ------------ Accuracy: 56.7%\n",
            "Step: 941 ------------ Loss: 7621.32 ------------ Accuracy: 56.8%\n",
            "Step: 942 ------------ Loss: 7618.91 ------------ Accuracy: 56.8%\n",
            "Step: 943 ------------ Loss: 7617.53 ------------ Accuracy: 56.9%\n",
            "Step: 944 ------------ Loss: 7616.09 ------------ Accuracy: 56.9%\n",
            "Step: 945 ------------ Loss: 7615.74 ------------ Accuracy: 56.9%\n",
            "Step: 946 ------------ Loss: 7612.96 ------------ Accuracy: 56.9%\n",
            "Step: 947 ------------ Loss: 7610.59 ------------ Accuracy: 57.0%\n",
            "Step: 948 ------------ Loss: 7606.18 ------------ Accuracy: 56.9%\n",
            "Step: 949 ------------ Loss: 7604.92 ------------ Accuracy: 56.9%\n",
            "Step: 950 ------------ Loss: 7602.16 ------------ Accuracy: 57.0%\n",
            "Step: 951 ------------ Loss: 7599.51 ------------ Accuracy: 57.2%\n",
            "Step: 952 ------------ Loss: 7596.86 ------------ Accuracy: 57.1%\n",
            "Step: 953 ------------ Loss: 7594.34 ------------ Accuracy: 57.3%\n",
            "Step: 954 ------------ Loss: 7590.57 ------------ Accuracy: 57.1%\n",
            "Step: 955 ------------ Loss: 7587.99 ------------ Accuracy: 57.2%\n",
            "Step: 956 ------------ Loss: 7583.51 ------------ Accuracy: 57.2%\n",
            "Step: 957 ------------ Loss: 7580.94 ------------ Accuracy: 57.2%\n",
            "Step: 958 ------------ Loss: 7580.6 ------------ Accuracy: 57.2%\n",
            "Step: 959 ------------ Loss: 7576.69 ------------ Accuracy: 57.0%\n",
            "Step: 960 ------------ Loss: 7575.23 ------------ Accuracy: 57.0%\n",
            "Step: 961 ------------ Loss: 7571.78 ------------ Accuracy: 56.8%\n",
            "Step: 962 ------------ Loss: 7569.13 ------------ Accuracy: 56.8%\n",
            "Step: 963 ------------ Loss: 7565.53 ------------ Accuracy: 56.6%\n",
            "Step: 964 ------------ Loss: 7563.08 ------------ Accuracy: 56.7%\n",
            "Step: 965 ------------ Loss: 7560.38 ------------ Accuracy: 56.7%\n",
            "Step: 966 ------------ Loss: 7556.12 ------------ Accuracy: 56.7%\n",
            "Step: 967 ------------ Loss: 7553.54 ------------ Accuracy: 56.6%\n",
            "Step: 968 ------------ Loss: 7551.21 ------------ Accuracy: 56.7%\n",
            "Step: 969 ------------ Loss: 7548.9 ------------ Accuracy: 56.8%\n",
            "Step: 970 ------------ Loss: 7547.72 ------------ Accuracy: 57.0%\n",
            "Step: 971 ------------ Loss: 7545.12 ------------ Accuracy: 57.1%\n",
            "Step: 972 ------------ Loss: 7544.79 ------------ Accuracy: 57.2%\n",
            "Step: 973 ------------ Loss: 7544.25 ------------ Accuracy: 57.2%\n",
            "Step: 974 ------------ Loss: 7541.74 ------------ Accuracy: 57.3%\n",
            "Step: 975 ------------ Loss: 7541.54 ------------ Accuracy: 57.3%\n",
            "Step: 976 ------------ Loss: 7539.16 ------------ Accuracy: 57.4%\n",
            "Step: 977 ------------ Loss: 7536.72 ------------ Accuracy: 57.4%\n",
            "Step: 978 ------------ Loss: 7535.34 ------------ Accuracy: 57.5%\n",
            "Step: 979 ------------ Loss: 7533.19 ------------ Accuracy: 57.5%\n",
            "Step: 980 ------------ Loss: 7530.85 ------------ Accuracy: 57.7%\n",
            "Step: 981 ------------ Loss: 7528.52 ------------ Accuracy: 57.8%\n",
            "Step: 982 ------------ Loss: 7527.17 ------------ Accuracy: 57.8%\n",
            "Step: 983 ------------ Loss: 7526.75 ------------ Accuracy: 58.0%\n",
            "Step: 984 ------------ Loss: 7522.98 ------------ Accuracy: 57.8%\n",
            "Step: 985 ------------ Loss: 7522.67 ------------ Accuracy: 57.8%\n",
            "Step: 986 ------------ Loss: 7520.56 ------------ Accuracy: 57.9%\n",
            "Step: 987 ------------ Loss: 7520.36 ------------ Accuracy: 57.9%\n",
            "Step: 988 ------------ Loss: 7519.23 ------------ Accuracy: 57.9%\n",
            "Step: 989 ------------ Loss: 7515.75 ------------ Accuracy: 57.8%\n",
            "Step: 990 ------------ Loss: 7515.46 ------------ Accuracy: 57.8%\n",
            "Step: 991 ------------ Loss: 7513.25 ------------ Accuracy: 57.9%\n",
            "Step: 992 ------------ Loss: 7510.72 ------------ Accuracy: 58.0%\n",
            "Step: 993 ------------ Loss: 7510.44 ------------ Accuracy: 57.9%\n",
            "Step: 994 ------------ Loss: 7509.3 ------------ Accuracy: 57.9%\n",
            "Step: 995 ------------ Loss: 7507.08 ------------ Accuracy: 58.0%\n",
            "Step: 996 ------------ Loss: 7503.72 ------------ Accuracy: 58.0%\n",
            "Step: 997 ------------ Loss: 7501.6 ------------ Accuracy: 58.1%\n",
            "Step: 998 ------------ Loss: 7501.46 ------------ Accuracy: 58.1%\n",
            "Step: 999 ------------ Loss: 7499.19 ------------ Accuracy: 58.2%\n",
            "Step: 1000 ------------ Loss: 7496.64 ------------ Accuracy: 58.3%\n",
            "Step: 1001 ------------ Loss: 7495.31 ------------ Accuracy: 58.3%\n",
            "Step: 1002 ------------ Loss: 7495.01 ------------ Accuracy: 58.3%\n",
            "Step: 1003 ------------ Loss: 7492.77 ------------ Accuracy: 58.3%\n",
            "Step: 1004 ------------ Loss: 7492.37 ------------ Accuracy: 58.5%\n",
            "Step: 1005 ------------ Loss: 7492.08 ------------ Accuracy: 58.5%\n",
            "Step: 1006 ------------ Loss: 7488.87 ------------ Accuracy: 58.3%\n",
            "Step: 1007 ------------ Loss: 7486.27 ------------ Accuracy: 58.4%\n",
            "Step: 1008 ------------ Loss: 7482.14 ------------ Accuracy: 58.3%\n",
            "Step: 1009 ------------ Loss: 7480.81 ------------ Accuracy: 58.4%\n",
            "Step: 1010 ------------ Loss: 7478.74 ------------ Accuracy: 58.5%\n",
            "Step: 1011 ------------ Loss: 7476.03 ------------ Accuracy: 58.4%\n",
            "Step: 1012 ------------ Loss: 7473.81 ------------ Accuracy: 58.5%\n",
            "Step: 1013 ------------ Loss: 7471.29 ------------ Accuracy: 58.6%\n",
            "Step: 1014 ------------ Loss: 7469.93 ------------ Accuracy: 58.7%\n",
            "Step: 1015 ------------ Loss: 7467.3 ------------ Accuracy: 58.5%\n",
            "Step: 1016 ------------ Loss: 7465.11 ------------ Accuracy: 58.7%\n",
            "Step: 1017 ------------ Loss: 7463.89 ------------ Accuracy: 58.7%\n",
            "Step: 1018 ------------ Loss: 7461.67 ------------ Accuracy: 58.8%\n",
            "Step: 1019 ------------ Loss: 7457.52 ------------ Accuracy: 58.7%\n",
            "Step: 1020 ------------ Loss: 7456.17 ------------ Accuracy: 58.8%\n",
            "Step: 1021 ------------ Loss: 7453.57 ------------ Accuracy: 58.7%\n",
            "Step: 1022 ------------ Loss: 7453.17 ------------ Accuracy: 58.8%\n",
            "Step: 1023 ------------ Loss: 7452.85 ------------ Accuracy: 58.7%\n",
            "Step: 1024 ------------ Loss: 7450.68 ------------ Accuracy: 58.8%\n",
            "Step: 1025 ------------ Loss: 7448.51 ------------ Accuracy: 58.9%\n",
            "Step: 1026 ------------ Loss: 7446.44 ------------ Accuracy: 59.0%\n",
            "Step: 1027 ------------ Loss: 7443.86 ------------ Accuracy: 58.9%\n",
            "Step: 1028 ------------ Loss: 7441.72 ------------ Accuracy: 59.1%\n",
            "Step: 1029 ------------ Loss: 7440.45 ------------ Accuracy: 59.1%\n",
            "Step: 1030 ------------ Loss: 7438.49 ------------ Accuracy: 59.3%\n",
            "Step: 1031 ------------ Loss: 7436.38 ------------ Accuracy: 59.4%\n",
            "Step: 1032 ------------ Loss: 7434.29 ------------ Accuracy: 59.6%\n",
            "Step: 1033 ------------ Loss: 7432.23 ------------ Accuracy: 59.6%\n",
            "Step: 1034 ------------ Loss: 7431.0 ------------ Accuracy: 59.7%\n",
            "Step: 1035 ------------ Loss: 7428.96 ------------ Accuracy: 59.7%\n",
            "Step: 1036 ------------ Loss: 7427.69 ------------ Accuracy: 59.8%\n",
            "Step: 1037 ------------ Loss: 7427.28 ------------ Accuracy: 59.7%\n",
            "Step: 1038 ------------ Loss: 7424.11 ------------ Accuracy: 59.4%\n",
            "Step: 1039 ------------ Loss: 7423.75 ------------ Accuracy: 59.4%\n",
            "Step: 1040 ------------ Loss: 7420.84 ------------ Accuracy: 59.3%\n",
            "Step: 1041 ------------ Loss: 7418.16 ------------ Accuracy: 59.3%\n",
            "Step: 1042 ------------ Loss: 7416.13 ------------ Accuracy: 59.4%\n",
            "Step: 1043 ------------ Loss: 7414.85 ------------ Accuracy: 59.5%\n",
            "Step: 1044 ------------ Loss: 7412.84 ------------ Accuracy: 59.6%\n",
            "Step: 1045 ------------ Loss: 7411.63 ------------ Accuracy: 59.6%\n",
            "Step: 1046 ------------ Loss: 7409.65 ------------ Accuracy: 59.7%\n",
            "Step: 1047 ------------ Loss: 7409.25 ------------ Accuracy: 59.7%\n",
            "Step: 1048 ------------ Loss: 7405.6 ------------ Accuracy: 59.5%\n",
            "Step: 1049 ------------ Loss: 7405.34 ------------ Accuracy: 59.5%\n",
            "Step: 1050 ------------ Loss: 7404.96 ------------ Accuracy: 59.4%\n",
            "Step: 1051 ------------ Loss: 7401.18 ------------ Accuracy: 59.1%\n",
            "Step: 1052 ------------ Loss: 7399.15 ------------ Accuracy: 59.2%\n",
            "Step: 1053 ------------ Loss: 7396.34 ------------ Accuracy: 59.4%\n",
            "Step: 1054 ------------ Loss: 7392.66 ------------ Accuracy: 59.0%\n",
            "Step: 1055 ------------ Loss: 7389.88 ------------ Accuracy: 59.2%\n",
            "Step: 1056 ------------ Loss: 7387.15 ------------ Accuracy: 59.2%\n",
            "Step: 1057 ------------ Loss: 7385.86 ------------ Accuracy: 59.3%\n",
            "Step: 1058 ------------ Loss: 7385.57 ------------ Accuracy: 59.2%\n",
            "Step: 1059 ------------ Loss: 7382.98 ------------ Accuracy: 59.3%\n",
            "Step: 1060 ------------ Loss: 7381.58 ------------ Accuracy: 59.2%\n",
            "Step: 1061 ------------ Loss: 7381.38 ------------ Accuracy: 59.2%\n",
            "Step: 1062 ------------ Loss: 7381.12 ------------ Accuracy: 59.1%\n",
            "Step: 1063 ------------ Loss: 7379.04 ------------ Accuracy: 59.3%\n",
            "Step: 1064 ------------ Loss: 7378.59 ------------ Accuracy: 59.5%\n",
            "Step: 1065 ------------ Loss: 7376.64 ------------ Accuracy: 59.7%\n",
            "Step: 1066 ------------ Loss: 7372.89 ------------ Accuracy: 59.3%\n",
            "Step: 1067 ------------ Loss: 7370.38 ------------ Accuracy: 59.4%\n",
            "Step: 1068 ------------ Loss: 7369.95 ------------ Accuracy: 59.5%\n",
            "Step: 1069 ------------ Loss: 7368.0 ------------ Accuracy: 59.7%\n",
            "Step: 1070 ------------ Loss: 7365.95 ------------ Accuracy: 59.8%\n",
            "Step: 1071 ------------ Loss: 7364.73 ------------ Accuracy: 59.8%\n",
            "Step: 1072 ------------ Loss: 7362.7 ------------ Accuracy: 60.0%\n",
            "Step: 1073 ------------ Loss: 7361.44 ------------ Accuracy: 60.0%\n",
            "Step: 1074 ------------ Loss: 7359.04 ------------ Accuracy: 60.1%\n",
            "Step: 1075 ------------ Loss: 7357.16 ------------ Accuracy: 60.3%\n",
            "Step: 1076 ------------ Loss: 7356.81 ------------ Accuracy: 60.3%\n",
            "Step: 1077 ------------ Loss: 7354.96 ------------ Accuracy: 60.4%\n",
            "Step: 1078 ------------ Loss: 7354.69 ------------ Accuracy: 60.3%\n",
            "Step: 1079 ------------ Loss: 7353.5 ------------ Accuracy: 60.4%\n",
            "Step: 1080 ------------ Loss: 7351.67 ------------ Accuracy: 60.6%\n",
            "Step: 1081 ------------ Loss: 7351.33 ------------ Accuracy: 60.5%\n",
            "Step: 1082 ------------ Loss: 7350.03 ------------ Accuracy: 60.3%\n",
            "Step: 1083 ------------ Loss: 7348.05 ------------ Accuracy: 60.5%\n",
            "Step: 1084 ------------ Loss: 7346.06 ------------ Accuracy: 60.7%\n",
            "Step: 1085 ------------ Loss: 7344.09 ------------ Accuracy: 60.8%\n",
            "Step: 1086 ------------ Loss: 7341.77 ------------ Accuracy: 60.9%\n",
            "Step: 1087 ------------ Loss: 7339.52 ------------ Accuracy: 61.0%\n",
            "Step: 1088 ------------ Loss: 7339.16 ------------ Accuracy: 60.9%\n",
            "Step: 1089 ------------ Loss: 7337.99 ------------ Accuracy: 61.0%\n",
            "Step: 1090 ------------ Loss: 7336.19 ------------ Accuracy: 61.1%\n",
            "Step: 1091 ------------ Loss: 7334.22 ------------ Accuracy: 61.3%\n",
            "Step: 1092 ------------ Loss: 7332.94 ------------ Accuracy: 61.1%\n",
            "Step: 1093 ------------ Loss: 7328.89 ------------ Accuracy: 60.7%\n",
            "Step: 1094 ------------ Loss: 7326.66 ------------ Accuracy: 60.8%\n",
            "Step: 1095 ------------ Loss: 7325.49 ------------ Accuracy: 60.9%\n",
            "Step: 1096 ------------ Loss: 7321.37 ------------ Accuracy: 60.8%\n",
            "Step: 1097 ------------ Loss: 7319.39 ------------ Accuracy: 61.0%\n",
            "Step: 1098 ------------ Loss: 7317.43 ------------ Accuracy: 61.2%\n",
            "Step: 1099 ------------ Loss: 7317.17 ------------ Accuracy: 61.0%\n",
            "Step: 1100 ------------ Loss: 7315.31 ------------ Accuracy: 61.3%\n",
            "Step: 1101 ------------ Loss: 7314.09 ------------ Accuracy: 61.1%\n",
            "Step: 1102 ------------ Loss: 7310.12 ------------ Accuracy: 61.1%\n",
            "Step: 1103 ------------ Loss: 7307.83 ------------ Accuracy: 61.2%\n",
            "Step: 1104 ------------ Loss: 7307.5 ------------ Accuracy: 61.3%\n",
            "Step: 1105 ------------ Loss: 7305.56 ------------ Accuracy: 61.5%\n",
            "Step: 1106 ------------ Loss: 7301.65 ------------ Accuracy: 61.4%\n",
            "Step: 1107 ------------ Loss: 7300.43 ------------ Accuracy: 61.2%\n",
            "Step: 1108 ------------ Loss: 7296.57 ------------ Accuracy: 60.8%\n",
            "Step: 1109 ------------ Loss: 7294.28 ------------ Accuracy: 60.9%\n",
            "Step: 1110 ------------ Loss: 7292.04 ------------ Accuracy: 61.0%\n",
            "Step: 1111 ------------ Loss: 7290.98 ------------ Accuracy: 60.9%\n",
            "Step: 1112 ------------ Loss: 7288.7 ------------ Accuracy: 60.8%\n",
            "Step: 1113 ------------ Loss: 7288.49 ------------ Accuracy: 60.8%\n",
            "Step: 1114 ------------ Loss: 7286.57 ------------ Accuracy: 61.0%\n",
            "Step: 1115 ------------ Loss: 7286.37 ------------ Accuracy: 60.9%\n",
            "Step: 1116 ------------ Loss: 7282.66 ------------ Accuracy: 60.5%\n",
            "Step: 1117 ------------ Loss: 7280.64 ------------ Accuracy: 60.6%\n",
            "Step: 1118 ------------ Loss: 7279.46 ------------ Accuracy: 60.7%\n",
            "Step: 1119 ------------ Loss: 7277.22 ------------ Accuracy: 60.6%\n",
            "Step: 1120 ------------ Loss: 7275.04 ------------ Accuracy: 60.8%\n",
            "Step: 1121 ------------ Loss: 7273.11 ------------ Accuracy: 61.0%\n",
            "Step: 1122 ------------ Loss: 7269.49 ------------ Accuracy: 60.5%\n",
            "Step: 1123 ------------ Loss: 7265.56 ------------ Accuracy: 60.5%\n",
            "Step: 1124 ------------ Loss: 7262.16 ------------ Accuracy: 60.2%\n",
            "Step: 1125 ------------ Loss: 7260.12 ------------ Accuracy: 60.3%\n",
            "Step: 1126 ------------ Loss: 7258.94 ------------ Accuracy: 60.4%\n",
            "Step: 1127 ------------ Loss: 7255.68 ------------ Accuracy: 60.0%\n",
            "Step: 1128 ------------ Loss: 7253.64 ------------ Accuracy: 60.2%\n",
            "Step: 1129 ------------ Loss: 7251.68 ------------ Accuracy: 60.4%\n",
            "Step: 1130 ------------ Loss: 7249.66 ------------ Accuracy: 60.6%\n",
            "Step: 1131 ------------ Loss: 7247.68 ------------ Accuracy: 60.6%\n",
            "Step: 1132 ------------ Loss: 7245.33 ------------ Accuracy: 60.7%\n",
            "Step: 1133 ------------ Loss: 7241.6 ------------ Accuracy: 60.7%\n",
            "Step: 1134 ------------ Loss: 7239.63 ------------ Accuracy: 60.8%\n",
            "Step: 1135 ------------ Loss: 7237.67 ------------ Accuracy: 60.9%\n",
            "Step: 1136 ------------ Loss: 7234.37 ------------ Accuracy: 60.7%\n",
            "Step: 1137 ------------ Loss: 7233.87 ------------ Accuracy: 60.8%\n",
            "Step: 1138 ------------ Loss: 7231.51 ------------ Accuracy: 60.9%\n",
            "Step: 1139 ------------ Loss: 7229.55 ------------ Accuracy: 61.1%\n",
            "Step: 1140 ------------ Loss: 7226.27 ------------ Accuracy: 60.7%\n",
            "Step: 1141 ------------ Loss: 7225.07 ------------ Accuracy: 60.8%\n",
            "Step: 1142 ------------ Loss: 7221.95 ------------ Accuracy: 60.5%\n",
            "Step: 1143 ------------ Loss: 7218.37 ------------ Accuracy: 60.3%\n",
            "Step: 1144 ------------ Loss: 7218.1 ------------ Accuracy: 60.5%\n",
            "Step: 1145 ------------ Loss: 7214.63 ------------ Accuracy: 60.4%\n",
            "Step: 1146 ------------ Loss: 7213.5 ------------ Accuracy: 60.5%\n",
            "Step: 1147 ------------ Loss: 7213.3 ------------ Accuracy: 60.6%\n",
            "Step: 1148 ------------ Loss: 7212.76 ------------ Accuracy: 60.8%\n",
            "Step: 1149 ------------ Loss: 7210.85 ------------ Accuracy: 61.0%\n",
            "Step: 1150 ------------ Loss: 7209.81 ------------ Accuracy: 60.9%\n",
            "Step: 1151 ------------ Loss: 7209.67 ------------ Accuracy: 61.1%\n",
            "Step: 1152 ------------ Loss: 7207.76 ------------ Accuracy: 61.2%\n",
            "Step: 1153 ------------ Loss: 7204.61 ------------ Accuracy: 60.9%\n",
            "Step: 1154 ------------ Loss: 7204.1 ------------ Accuracy: 61.0%\n",
            "Step: 1155 ------------ Loss: 7202.9 ------------ Accuracy: 61.1%\n",
            "Step: 1156 ------------ Loss: 7200.45 ------------ Accuracy: 61.3%\n",
            "Step: 1157 ------------ Loss: 7198.11 ------------ Accuracy: 61.4%\n",
            "Step: 1158 ------------ Loss: 7194.53 ------------ Accuracy: 61.4%\n",
            "Step: 1159 ------------ Loss: 7192.19 ------------ Accuracy: 61.5%\n",
            "Step: 1160 ------------ Loss: 7190.04 ------------ Accuracy: 61.4%\n",
            "Step: 1161 ------------ Loss: 7186.49 ------------ Accuracy: 61.4%\n",
            "Step: 1162 ------------ Loss: 7184.6 ------------ Accuracy: 61.6%\n",
            "Step: 1163 ------------ Loss: 7182.69 ------------ Accuracy: 61.7%\n",
            "Step: 1164 ------------ Loss: 7181.55 ------------ Accuracy: 61.7%\n",
            "Step: 1165 ------------ Loss: 7179.3 ------------ Accuracy: 61.8%\n",
            "Step: 1166 ------------ Loss: 7177.45 ------------ Accuracy: 61.9%\n",
            "Step: 1167 ------------ Loss: 7175.63 ------------ Accuracy: 62.1%\n",
            "Step: 1168 ------------ Loss: 7175.22 ------------ Accuracy: 62.2%\n",
            "Step: 1169 ------------ Loss: 7174.76 ------------ Accuracy: 62.1%\n",
            "Step: 1170 ------------ Loss: 7171.4 ------------ Accuracy: 61.9%\n",
            "Step: 1171 ------------ Loss: 7168.6 ------------ Accuracy: 61.7%\n",
            "Step: 1172 ------------ Loss: 7166.25 ------------ Accuracy: 61.9%\n",
            "Step: 1173 ------------ Loss: 7165.82 ------------ Accuracy: 62.0%\n",
            "Step: 1174 ------------ Loss: 7163.11 ------------ Accuracy: 61.9%\n",
            "Step: 1175 ------------ Loss: 7160.79 ------------ Accuracy: 62.1%\n",
            "Step: 1176 ------------ Loss: 7158.92 ------------ Accuracy: 62.1%\n",
            "Step: 1177 ------------ Loss: 7155.68 ------------ Accuracy: 61.8%\n",
            "Step: 1178 ------------ Loss: 7153.37 ------------ Accuracy: 62.0%\n",
            "Step: 1179 ------------ Loss: 7151.52 ------------ Accuracy: 62.1%\n",
            "Step: 1180 ------------ Loss: 7150.5 ------------ Accuracy: 62.0%\n",
            "Step: 1181 ------------ Loss: 7148.62 ------------ Accuracy: 62.1%\n",
            "Step: 1182 ------------ Loss: 7146.8 ------------ Accuracy: 62.3%\n",
            "Step: 1183 ------------ Loss: 7144.94 ------------ Accuracy: 62.3%\n",
            "Step: 1184 ------------ Loss: 7141.53 ------------ Accuracy: 62.3%\n",
            "Step: 1185 ------------ Loss: 7139.71 ------------ Accuracy: 62.3%\n",
            "Step: 1186 ------------ Loss: 7139.57 ------------ Accuracy: 62.4%\n",
            "Step: 1187 ------------ Loss: 7137.78 ------------ Accuracy: 62.5%\n",
            "Step: 1188 ------------ Loss: 7135.99 ------------ Accuracy: 62.6%\n",
            "Step: 1189 ------------ Loss: 7132.7 ------------ Accuracy: 62.5%\n",
            "Step: 1190 ------------ Loss: 7130.93 ------------ Accuracy: 62.7%\n",
            "Step: 1191 ------------ Loss: 7127.74 ------------ Accuracy: 62.6%\n",
            "Step: 1192 ------------ Loss: 7126.66 ------------ Accuracy: 62.7%\n",
            "Step: 1193 ------------ Loss: 7123.36 ------------ Accuracy: 62.3%\n",
            "Step: 1194 ------------ Loss: 7121.57 ------------ Accuracy: 62.5%\n",
            "Step: 1195 ------------ Loss: 7119.76 ------------ Accuracy: 62.5%\n",
            "Step: 1196 ------------ Loss: 7118.0 ------------ Accuracy: 62.7%\n",
            "Step: 1197 ------------ Loss: 7114.91 ------------ Accuracy: 62.7%\n",
            "Step: 1198 ------------ Loss: 7113.15 ------------ Accuracy: 62.9%\n",
            "Step: 1199 ------------ Loss: 7110.79 ------------ Accuracy: 62.7%\n",
            "Step: 1200 ------------ Loss: 7110.63 ------------ Accuracy: 62.8%\n",
            "Step: 1201 ------------ Loss: 7107.59 ------------ Accuracy: 62.7%\n",
            "Step: 1202 ------------ Loss: 7105.81 ------------ Accuracy: 62.9%\n",
            "Step: 1203 ------------ Loss: 7104.7 ------------ Accuracy: 63.0%\n",
            "Step: 1204 ------------ Loss: 7104.53 ------------ Accuracy: 63.0%\n",
            "Step: 1205 ------------ Loss: 7104.01 ------------ Accuracy: 63.0%\n",
            "Step: 1206 ------------ Loss: 7102.24 ------------ Accuracy: 63.1%\n",
            "Step: 1207 ------------ Loss: 7100.49 ------------ Accuracy: 63.2%\n",
            "Step: 1208 ------------ Loss: 7098.12 ------------ Accuracy: 63.1%\n",
            "Step: 1209 ------------ Loss: 7095.11 ------------ Accuracy: 63.0%\n",
            "Step: 1210 ------------ Loss: 7093.44 ------------ Accuracy: 63.1%\n",
            "Step: 1211 ------------ Loss: 7090.21 ------------ Accuracy: 62.9%\n",
            "Step: 1212 ------------ Loss: 7088.44 ------------ Accuracy: 62.9%\n",
            "Step: 1213 ------------ Loss: 7085.92 ------------ Accuracy: 63.0%\n",
            "Step: 1214 ------------ Loss: 7084.22 ------------ Accuracy: 63.2%\n",
            "Step: 1215 ------------ Loss: 7082.5 ------------ Accuracy: 63.3%\n",
            "Step: 1216 ------------ Loss: 7081.42 ------------ Accuracy: 63.3%\n",
            "Step: 1217 ------------ Loss: 7079.72 ------------ Accuracy: 63.4%\n",
            "Step: 1218 ------------ Loss: 7076.76 ------------ Accuracy: 63.4%\n",
            "Step: 1219 ------------ Loss: 7075.06 ------------ Accuracy: 63.5%\n",
            "Step: 1220 ------------ Loss: 7072.69 ------------ Accuracy: 63.4%\n",
            "Step: 1221 ------------ Loss: 7071.36 ------------ Accuracy: 63.4%\n",
            "Step: 1222 ------------ Loss: 7070.28 ------------ Accuracy: 63.4%\n",
            "Step: 1223 ------------ Loss: 7069.03 ------------ Accuracy: 63.4%\n",
            "Step: 1224 ------------ Loss: 7067.36 ------------ Accuracy: 63.5%\n",
            "Step: 1225 ------------ Loss: 7066.33 ------------ Accuracy: 63.7%\n",
            "Step: 1226 ------------ Loss: 7065.8 ------------ Accuracy: 63.7%\n",
            "Step: 1227 ------------ Loss: 7063.46 ------------ Accuracy: 63.7%\n",
            "Step: 1228 ------------ Loss: 7060.38 ------------ Accuracy: 63.7%\n",
            "Step: 1229 ------------ Loss: 7057.14 ------------ Accuracy: 63.3%\n",
            "Step: 1230 ------------ Loss: 7054.07 ------------ Accuracy: 63.0%\n",
            "Step: 1231 ------------ Loss: 7052.38 ------------ Accuracy: 63.1%\n",
            "Step: 1232 ------------ Loss: 7052.19 ------------ Accuracy: 63.2%\n",
            "Step: 1233 ------------ Loss: 7049.99 ------------ Accuracy: 63.1%\n",
            "Step: 1234 ------------ Loss: 7048.28 ------------ Accuracy: 63.3%\n",
            "Step: 1235 ------------ Loss: 7046.6 ------------ Accuracy: 63.4%\n",
            "Step: 1236 ------------ Loss: 7045.57 ------------ Accuracy: 63.5%\n",
            "Step: 1237 ------------ Loss: 7043.39 ------------ Accuracy: 63.4%\n",
            "Step: 1238 ------------ Loss: 7040.42 ------------ Accuracy: 63.1%\n",
            "Step: 1239 ------------ Loss: 7039.92 ------------ Accuracy: 63.2%\n",
            "Step: 1240 ------------ Loss: 7039.38 ------------ Accuracy: 63.3%\n",
            "Step: 1241 ------------ Loss: 7038.34 ------------ Accuracy: 63.4%\n",
            "Step: 1242 ------------ Loss: 7037.84 ------------ Accuracy: 63.4%\n",
            "Step: 1243 ------------ Loss: 7036.76 ------------ Accuracy: 63.5%\n",
            "Step: 1244 ------------ Loss: 7033.72 ------------ Accuracy: 63.4%\n",
            "Step: 1245 ------------ Loss: 7031.38 ------------ Accuracy: 63.6%\n",
            "Step: 1246 ------------ Loss: 7028.38 ------------ Accuracy: 63.6%\n",
            "Step: 1247 ------------ Loss: 7027.91 ------------ Accuracy: 63.7%\n",
            "Step: 1248 ------------ Loss: 7026.18 ------------ Accuracy: 63.8%\n",
            "Step: 1249 ------------ Loss: 7023.93 ------------ Accuracy: 63.7%\n",
            "Step: 1250 ------------ Loss: 7021.01 ------------ Accuracy: 63.3%\n",
            "Step: 1251 ------------ Loss: 7019.96 ------------ Accuracy: 63.4%\n",
            "Step: 1252 ------------ Loss: 7018.27 ------------ Accuracy: 63.6%\n",
            "Step: 1253 ------------ Loss: 7016.59 ------------ Accuracy: 63.7%\n",
            "Step: 1254 ------------ Loss: 7014.95 ------------ Accuracy: 63.7%\n",
            "Step: 1255 ------------ Loss: 7012.47 ------------ Accuracy: 63.9%\n",
            "Step: 1256 ------------ Loss: 7010.35 ------------ Accuracy: 63.8%\n",
            "Step: 1257 ------------ Loss: 7009.29 ------------ Accuracy: 63.8%\n",
            "Step: 1258 ------------ Loss: 7006.85 ------------ Accuracy: 64.0%\n",
            "Step: 1259 ------------ Loss: 7004.65 ------------ Accuracy: 63.9%\n",
            "Step: 1260 ------------ Loss: 7003.02 ------------ Accuracy: 64.0%\n",
            "Step: 1261 ------------ Loss: 7001.38 ------------ Accuracy: 64.0%\n",
            "Step: 1262 ------------ Loss: 6999.05 ------------ Accuracy: 64.1%\n",
            "Step: 1263 ------------ Loss: 6997.43 ------------ Accuracy: 64.3%\n",
            "Step: 1264 ------------ Loss: 6996.97 ------------ Accuracy: 64.4%\n",
            "Step: 1265 ------------ Loss: 6995.93 ------------ Accuracy: 64.5%\n",
            "Step: 1266 ------------ Loss: 6994.9 ------------ Accuracy: 64.6%\n",
            "Step: 1267 ------------ Loss: 6994.71 ------------ Accuracy: 64.6%\n",
            "Step: 1268 ------------ Loss: 6992.54 ------------ Accuracy: 64.5%\n",
            "Step: 1269 ------------ Loss: 6990.42 ------------ Accuracy: 64.4%\n",
            "Step: 1270 ------------ Loss: 6989.39 ------------ Accuracy: 64.5%\n",
            "Step: 1271 ------------ Loss: 6987.05 ------------ Accuracy: 64.4%\n",
            "Step: 1272 ------------ Loss: 6986.01 ------------ Accuracy: 64.5%\n",
            "Step: 1273 ------------ Loss: 6984.42 ------------ Accuracy: 64.6%\n",
            "Step: 1274 ------------ Loss: 6982.11 ------------ Accuracy: 64.7%\n",
            "Step: 1275 ------------ Loss: 6981.68 ------------ Accuracy: 64.6%\n",
            "Step: 1276 ------------ Loss: 6981.5 ------------ Accuracy: 64.6%\n",
            "Step: 1277 ------------ Loss: 6979.87 ------------ Accuracy: 64.7%\n",
            "Step: 1278 ------------ Loss: 6976.9 ------------ Accuracy: 64.7%\n",
            "Step: 1279 ------------ Loss: 6974.02 ------------ Accuracy: 64.6%\n",
            "Step: 1280 ------------ Loss: 6971.85 ------------ Accuracy: 64.6%\n",
            "Step: 1281 ------------ Loss: 6970.86 ------------ Accuracy: 64.6%\n",
            "Step: 1282 ------------ Loss: 6969.22 ------------ Accuracy: 64.7%\n",
            "Step: 1283 ------------ Loss: 6968.78 ------------ Accuracy: 64.7%\n",
            "Step: 1284 ------------ Loss: 6966.57 ------------ Accuracy: 64.7%\n",
            "Step: 1285 ------------ Loss: 6964.99 ------------ Accuracy: 64.9%\n",
            "Step: 1286 ------------ Loss: 6962.73 ------------ Accuracy: 64.7%\n",
            "Step: 1287 ------------ Loss: 6959.92 ------------ Accuracy: 64.7%\n",
            "Step: 1288 ------------ Loss: 6958.94 ------------ Accuracy: 64.8%\n",
            "Step: 1289 ------------ Loss: 6958.5 ------------ Accuracy: 64.7%\n",
            "Step: 1290 ------------ Loss: 6956.88 ------------ Accuracy: 64.9%\n",
            "Step: 1291 ------------ Loss: 6956.69 ------------ Accuracy: 64.9%\n",
            "Step: 1292 ------------ Loss: 6956.23 ------------ Accuracy: 65.0%\n",
            "Step: 1293 ------------ Loss: 6954.97 ------------ Accuracy: 65.0%\n",
            "Step: 1294 ------------ Loss: 6953.36 ------------ Accuracy: 65.1%\n",
            "Step: 1295 ------------ Loss: 6951.81 ------------ Accuracy: 65.3%\n",
            "Step: 1296 ------------ Loss: 6950.6 ------------ Accuracy: 65.3%\n",
            "Step: 1297 ------------ Loss: 6949.59 ------------ Accuracy: 65.3%\n",
            "Step: 1298 ------------ Loss: 6948.04 ------------ Accuracy: 65.5%\n",
            "Step: 1299 ------------ Loss: 6945.83 ------------ Accuracy: 65.5%\n",
            "Step: 1300 ------------ Loss: 6944.71 ------------ Accuracy: 65.6%\n",
            "Step: 1301 ------------ Loss: 6943.1 ------------ Accuracy: 65.7%\n",
            "Step: 1302 ------------ Loss: 6940.98 ------------ Accuracy: 65.7%\n",
            "Step: 1303 ------------ Loss: 6938.93 ------------ Accuracy: 65.5%\n",
            "Step: 1304 ------------ Loss: 6936.91 ------------ Accuracy: 65.6%\n",
            "Step: 1305 ------------ Loss: 6936.59 ------------ Accuracy: 65.7%\n",
            "Step: 1306 ------------ Loss: 6933.31 ------------ Accuracy: 65.4%\n",
            "Step: 1307 ------------ Loss: 6930.23 ------------ Accuracy: 65.4%\n",
            "Step: 1308 ------------ Loss: 6928.66 ------------ Accuracy: 65.5%\n",
            "Step: 1309 ------------ Loss: 6926.65 ------------ Accuracy: 65.6%\n",
            "Step: 1310 ------------ Loss: 6925.09 ------------ Accuracy: 65.7%\n",
            "Step: 1311 ------------ Loss: 6924.13 ------------ Accuracy: 65.7%\n",
            "Step: 1312 ------------ Loss: 6922.16 ------------ Accuracy: 65.6%\n",
            "Step: 1313 ------------ Loss: 6919.1 ------------ Accuracy: 65.5%\n",
            "Step: 1314 ------------ Loss: 6918.94 ------------ Accuracy: 65.5%\n",
            "Step: 1315 ------------ Loss: 6918.79 ------------ Accuracy: 65.5%\n",
            "Step: 1316 ------------ Loss: 6917.22 ------------ Accuracy: 65.7%\n",
            "Step: 1317 ------------ Loss: 6916.86 ------------ Accuracy: 65.8%\n",
            "Step: 1318 ------------ Loss: 6914.91 ------------ Accuracy: 65.9%\n",
            "Step: 1319 ------------ Loss: 6913.92 ------------ Accuracy: 65.8%\n",
            "Step: 1320 ------------ Loss: 6913.48 ------------ Accuracy: 65.7%\n",
            "Step: 1321 ------------ Loss: 6910.32 ------------ Accuracy: 65.4%\n",
            "Step: 1322 ------------ Loss: 6909.3 ------------ Accuracy: 65.5%\n",
            "Step: 1323 ------------ Loss: 6907.72 ------------ Accuracy: 65.6%\n",
            "Step: 1324 ------------ Loss: 6905.82 ------------ Accuracy: 65.5%\n",
            "Step: 1325 ------------ Loss: 6904.85 ------------ Accuracy: 65.6%\n",
            "Step: 1326 ------------ Loss: 6902.93 ------------ Accuracy: 65.7%\n",
            "Step: 1327 ------------ Loss: 6901.3 ------------ Accuracy: 65.8%\n",
            "Step: 1328 ------------ Loss: 6901.13 ------------ Accuracy: 65.8%\n",
            "Step: 1329 ------------ Loss: 6900.74 ------------ Accuracy: 65.8%\n",
            "Step: 1330 ------------ Loss: 6899.74 ------------ Accuracy: 65.8%\n",
            "Step: 1331 ------------ Loss: 6898.82 ------------ Accuracy: 65.8%\n",
            "Step: 1332 ------------ Loss: 6897.81 ------------ Accuracy: 65.9%\n",
            "Step: 1333 ------------ Loss: 6897.67 ------------ Accuracy: 65.9%\n",
            "Step: 1334 ------------ Loss: 6896.71 ------------ Accuracy: 66.0%\n",
            "Step: 1335 ------------ Loss: 6894.84 ------------ Accuracy: 66.0%\n",
            "Step: 1336 ------------ Loss: 6893.29 ------------ Accuracy: 66.2%\n",
            "Step: 1337 ------------ Loss: 6890.61 ------------ Accuracy: 66.0%\n",
            "Step: 1338 ------------ Loss: 6888.71 ------------ Accuracy: 66.1%\n",
            "Step: 1339 ------------ Loss: 6885.59 ------------ Accuracy: 65.8%\n",
            "Step: 1340 ------------ Loss: 6885.22 ------------ Accuracy: 65.8%\n",
            "Step: 1341 ------------ Loss: 6885.09 ------------ Accuracy: 65.9%\n",
            "Step: 1342 ------------ Loss: 6882.13 ------------ Accuracy: 65.6%\n",
            "Step: 1343 ------------ Loss: 6879.74 ------------ Accuracy: 65.5%\n",
            "Step: 1344 ------------ Loss: 6877.7 ------------ Accuracy: 65.6%\n",
            "Step: 1345 ------------ Loss: 6874.9 ------------ Accuracy: 65.4%\n",
            "Step: 1346 ------------ Loss: 6871.94 ------------ Accuracy: 65.3%\n",
            "Step: 1347 ------------ Loss: 6871.59 ------------ Accuracy: 65.4%\n",
            "Step: 1348 ------------ Loss: 6869.52 ------------ Accuracy: 65.5%\n",
            "Step: 1349 ------------ Loss: 6867.84 ------------ Accuracy: 65.7%\n",
            "Step: 1350 ------------ Loss: 6865.84 ------------ Accuracy: 65.8%\n",
            "Step: 1351 ------------ Loss: 6864.92 ------------ Accuracy: 65.7%\n",
            "Step: 1352 ------------ Loss: 6862.13 ------------ Accuracy: 65.5%\n",
            "Step: 1353 ------------ Loss: 6861.14 ------------ Accuracy: 65.5%\n",
            "Step: 1354 ------------ Loss: 6859.37 ------------ Accuracy: 65.4%\n",
            "Step: 1355 ------------ Loss: 6859.22 ------------ Accuracy: 65.5%\n",
            "Step: 1356 ------------ Loss: 6857.48 ------------ Accuracy: 65.4%\n",
            "Step: 1357 ------------ Loss: 6856.48 ------------ Accuracy: 65.5%\n",
            "Step: 1358 ------------ Loss: 6854.81 ------------ Accuracy: 65.6%\n",
            "Step: 1359 ------------ Loss: 6854.47 ------------ Accuracy: 65.7%\n",
            "Step: 1360 ------------ Loss: 6854.33 ------------ Accuracy: 65.7%\n",
            "Step: 1361 ------------ Loss: 6853.92 ------------ Accuracy: 65.8%\n",
            "Step: 1362 ------------ Loss: 6852.89 ------------ Accuracy: 65.9%\n",
            "Step: 1363 ------------ Loss: 6851.25 ------------ Accuracy: 66.0%\n",
            "Step: 1364 ------------ Loss: 6850.94 ------------ Accuracy: 66.0%\n",
            "Step: 1365 ------------ Loss: 6849.06 ------------ Accuracy: 66.1%\n",
            "Step: 1366 ------------ Loss: 6847.23 ------------ Accuracy: 66.2%\n",
            "Step: 1367 ------------ Loss: 6845.64 ------------ Accuracy: 66.3%\n",
            "Step: 1368 ------------ Loss: 6843.88 ------------ Accuracy: 66.4%\n",
            "Step: 1369 ------------ Loss: 6842.91 ------------ Accuracy: 66.4%\n",
            "Step: 1370 ------------ Loss: 6841.2 ------------ Accuracy: 66.5%\n",
            "Step: 1371 ------------ Loss: 6838.44 ------------ Accuracy: 66.4%\n",
            "Step: 1372 ------------ Loss: 6836.88 ------------ Accuracy: 66.6%\n",
            "Step: 1373 ------------ Loss: 6835.26 ------------ Accuracy: 66.7%\n",
            "Step: 1374 ------------ Loss: 6833.65 ------------ Accuracy: 66.8%\n",
            "Step: 1375 ------------ Loss: 6830.57 ------------ Accuracy: 66.7%\n",
            "Step: 1376 ------------ Loss: 6828.8 ------------ Accuracy: 66.8%\n",
            "Step: 1377 ------------ Loss: 6826.26 ------------ Accuracy: 66.7%\n",
            "Step: 1378 ------------ Loss: 6825.3 ------------ Accuracy: 66.6%\n",
            "Step: 1379 ------------ Loss: 6824.35 ------------ Accuracy: 66.7%\n",
            "Step: 1380 ------------ Loss: 6821.95 ------------ Accuracy: 66.6%\n",
            "Step: 1381 ------------ Loss: 6819.07 ------------ Accuracy: 66.6%\n",
            "Step: 1382 ------------ Loss: 6818.97 ------------ Accuracy: 66.6%\n",
            "Step: 1383 ------------ Loss: 6817.97 ------------ Accuracy: 66.7%\n",
            "Step: 1384 ------------ Loss: 6817.61 ------------ Accuracy: 66.8%\n",
            "Step: 1385 ------------ Loss: 6817.26 ------------ Accuracy: 66.9%\n",
            "Step: 1386 ------------ Loss: 6815.39 ------------ Accuracy: 66.7%\n",
            "Step: 1387 ------------ Loss: 6813.17 ------------ Accuracy: 66.7%\n",
            "Step: 1388 ------------ Loss: 6810.4 ------------ Accuracy: 66.5%\n",
            "Step: 1389 ------------ Loss: 6807.72 ------------ Accuracy: 66.4%\n",
            "Step: 1390 ------------ Loss: 6805.81 ------------ Accuracy: 66.3%\n",
            "Step: 1391 ------------ Loss: 6805.39 ------------ Accuracy: 66.4%\n",
            "Step: 1392 ------------ Loss: 6803.59 ------------ Accuracy: 66.4%\n",
            "Step: 1393 ------------ Loss: 6803.47 ------------ Accuracy: 66.4%\n",
            "Step: 1394 ------------ Loss: 6800.76 ------------ Accuracy: 66.0%\n",
            "Step: 1395 ------------ Loss: 6799.78 ------------ Accuracy: 66.0%\n",
            "Step: 1396 ------------ Loss: 6799.66 ------------ Accuracy: 66.2%\n",
            "Step: 1397 ------------ Loss: 6799.21 ------------ Accuracy: 66.3%\n",
            "Step: 1398 ------------ Loss: 6797.61 ------------ Accuracy: 66.5%\n",
            "Step: 1399 ------------ Loss: 6794.94 ------------ Accuracy: 66.0%\n",
            "Step: 1400 ------------ Loss: 6793.97 ------------ Accuracy: 66.1%\n",
            "Step: 1401 ------------ Loss: 6793.57 ------------ Accuracy: 66.1%\n",
            "Step: 1402 ------------ Loss: 6793.2 ------------ Accuracy: 66.3%\n",
            "Step: 1403 ------------ Loss: 6792.11 ------------ Accuracy: 66.3%\n",
            "Step: 1404 ------------ Loss: 6791.09 ------------ Accuracy: 66.4%\n",
            "Step: 1405 ------------ Loss: 6789.54 ------------ Accuracy: 66.4%\n",
            "Step: 1406 ------------ Loss: 6786.94 ------------ Accuracy: 66.1%\n",
            "Step: 1407 ------------ Loss: 6784.35 ------------ Accuracy: 66.0%\n",
            "Step: 1408 ------------ Loss: 6783.34 ------------ Accuracy: 66.1%\n",
            "Step: 1409 ------------ Loss: 6782.88 ------------ Accuracy: 66.2%\n",
            "Step: 1410 ------------ Loss: 6781.95 ------------ Accuracy: 66.2%\n",
            "Step: 1411 ------------ Loss: 6779.44 ------------ Accuracy: 66.0%\n",
            "Step: 1412 ------------ Loss: 6777.82 ------------ Accuracy: 66.1%\n",
            "Step: 1413 ------------ Loss: 6776.21 ------------ Accuracy: 66.2%\n",
            "Step: 1414 ------------ Loss: 6774.62 ------------ Accuracy: 66.3%\n",
            "Step: 1415 ------------ Loss: 6772.5 ------------ Accuracy: 66.5%\n",
            "Step: 1416 ------------ Loss: 6770.69 ------------ Accuracy: 66.5%\n",
            "Step: 1417 ------------ Loss: 6769.72 ------------ Accuracy: 66.5%\n",
            "Step: 1418 ------------ Loss: 6767.05 ------------ Accuracy: 66.3%\n",
            "Step: 1419 ------------ Loss: 6765.43 ------------ Accuracy: 66.4%\n",
            "Step: 1420 ------------ Loss: 6762.94 ------------ Accuracy: 66.1%\n",
            "Step: 1421 ------------ Loss: 6760.8 ------------ Accuracy: 66.2%\n",
            "Step: 1422 ------------ Loss: 6759.04 ------------ Accuracy: 66.2%\n",
            "Step: 1423 ------------ Loss: 6758.63 ------------ Accuracy: 66.3%\n",
            "Step: 1424 ------------ Loss: 6756.99 ------------ Accuracy: 66.5%\n",
            "Step: 1425 ------------ Loss: 6754.98 ------------ Accuracy: 66.6%\n",
            "Step: 1426 ------------ Loss: 6753.27 ------------ Accuracy: 66.5%\n",
            "Step: 1427 ------------ Loss: 6751.38 ------------ Accuracy: 66.7%\n",
            "Step: 1428 ------------ Loss: 6748.64 ------------ Accuracy: 66.5%\n",
            "Step: 1429 ------------ Loss: 6747.78 ------------ Accuracy: 66.6%\n",
            "Step: 1430 ------------ Loss: 6747.39 ------------ Accuracy: 66.8%\n",
            "Step: 1431 ------------ Loss: 6745.53 ------------ Accuracy: 66.9%\n",
            "Step: 1432 ------------ Loss: 6744.57 ------------ Accuracy: 66.9%\n",
            "Step: 1433 ------------ Loss: 6741.81 ------------ Accuracy: 66.7%\n",
            "Step: 1434 ------------ Loss: 6741.0 ------------ Accuracy: 66.8%\n",
            "Step: 1435 ------------ Loss: 6738.4 ------------ Accuracy: 66.6%\n",
            "Step: 1436 ------------ Loss: 6737.43 ------------ Accuracy: 66.6%\n",
            "Step: 1437 ------------ Loss: 6735.82 ------------ Accuracy: 66.8%\n",
            "Step: 1438 ------------ Loss: 6734.86 ------------ Accuracy: 66.9%\n",
            "Step: 1439 ------------ Loss: 6732.35 ------------ Accuracy: 66.5%\n",
            "Step: 1440 ------------ Loss: 6730.46 ------------ Accuracy: 66.8%\n",
            "Step: 1441 ------------ Loss: 6728.85 ------------ Accuracy: 66.8%\n",
            "Step: 1442 ------------ Loss: 6728.72 ------------ Accuracy: 67.0%\n",
            "Step: 1443 ------------ Loss: 6727.14 ------------ Accuracy: 67.0%\n",
            "Step: 1444 ------------ Loss: 6725.31 ------------ Accuracy: 67.1%\n",
            "Step: 1445 ------------ Loss: 6723.74 ------------ Accuracy: 67.2%\n",
            "Step: 1446 ------------ Loss: 6722.19 ------------ Accuracy: 67.2%\n",
            "Step: 1447 ------------ Loss: 6720.66 ------------ Accuracy: 67.3%\n",
            "Step: 1448 ------------ Loss: 6719.69 ------------ Accuracy: 67.4%\n",
            "Step: 1449 ------------ Loss: 6719.58 ------------ Accuracy: 67.5%\n",
            "Step: 1450 ------------ Loss: 6718.06 ------------ Accuracy: 67.7%\n",
            "Step: 1451 ------------ Loss: 6717.14 ------------ Accuracy: 67.7%\n",
            "Step: 1452 ------------ Loss: 6714.41 ------------ Accuracy: 67.6%\n",
            "Step: 1453 ------------ Loss: 6712.73 ------------ Accuracy: 67.5%\n",
            "Step: 1454 ------------ Loss: 6711.94 ------------ Accuracy: 67.6%\n",
            "Step: 1455 ------------ Loss: 6710.19 ------------ Accuracy: 67.6%\n",
            "Step: 1456 ------------ Loss: 6708.48 ------------ Accuracy: 67.7%\n",
            "Step: 1457 ------------ Loss: 6705.74 ------------ Accuracy: 67.4%\n",
            "Step: 1458 ------------ Loss: 6704.05 ------------ Accuracy: 67.4%\n",
            "Step: 1459 ------------ Loss: 6701.41 ------------ Accuracy: 67.3%\n",
            "Step: 1460 ------------ Loss: 6700.7 ------------ Accuracy: 67.2%\n",
            "Step: 1461 ------------ Loss: 6700.57 ------------ Accuracy: 67.3%\n",
            "Step: 1462 ------------ Loss: 6699.01 ------------ Accuracy: 67.3%\n",
            "Step: 1463 ------------ Loss: 6698.07 ------------ Accuracy: 67.4%\n",
            "Step: 1464 ------------ Loss: 6696.47 ------------ Accuracy: 67.6%\n",
            "Step: 1465 ------------ Loss: 6695.79 ------------ Accuracy: 67.6%\n",
            "Step: 1466 ------------ Loss: 6692.98 ------------ Accuracy: 67.6%\n",
            "Step: 1467 ------------ Loss: 6691.38 ------------ Accuracy: 67.7%\n",
            "Step: 1468 ------------ Loss: 6691.03 ------------ Accuracy: 67.7%\n",
            "Step: 1469 ------------ Loss: 6689.51 ------------ Accuracy: 67.9%\n",
            "Step: 1470 ------------ Loss: 6687.83 ------------ Accuracy: 68.0%\n",
            "Step: 1471 ------------ Loss: 6685.15 ------------ Accuracy: 67.7%\n",
            "Step: 1472 ------------ Loss: 6683.62 ------------ Accuracy: 67.7%\n",
            "Step: 1473 ------------ Loss: 6681.93 ------------ Accuracy: 67.8%\n",
            "Step: 1474 ------------ Loss: 6681.01 ------------ Accuracy: 67.9%\n",
            "Step: 1475 ------------ Loss: 6680.34 ------------ Accuracy: 67.9%\n",
            "Step: 1476 ------------ Loss: 6678.83 ------------ Accuracy: 67.7%\n",
            "Step: 1477 ------------ Loss: 6675.98 ------------ Accuracy: 67.7%\n",
            "Step: 1478 ------------ Loss: 6675.86 ------------ Accuracy: 67.8%\n",
            "Step: 1479 ------------ Loss: 6675.22 ------------ Accuracy: 67.8%\n",
            "Step: 1480 ------------ Loss: 6673.59 ------------ Accuracy: 68.0%\n",
            "Step: 1481 ------------ Loss: 6671.98 ------------ Accuracy: 67.9%\n",
            "Step: 1482 ------------ Loss: 6670.44 ------------ Accuracy: 68.1%\n",
            "Step: 1483 ------------ Loss: 6667.74 ------------ Accuracy: 67.7%\n",
            "Step: 1484 ------------ Loss: 6667.14 ------------ Accuracy: 67.7%\n",
            "Step: 1485 ------------ Loss: 6665.59 ------------ Accuracy: 67.8%\n",
            "Step: 1486 ------------ Loss: 6664.04 ------------ Accuracy: 67.9%\n",
            "Step: 1487 ------------ Loss: 6663.09 ------------ Accuracy: 68.0%\n",
            "Step: 1488 ------------ Loss: 6661.49 ------------ Accuracy: 68.1%\n",
            "Step: 1489 ------------ Loss: 6660.58 ------------ Accuracy: 68.2%\n",
            "Step: 1490 ------------ Loss: 6657.92 ------------ Accuracy: 67.8%\n",
            "Step: 1491 ------------ Loss: 6656.31 ------------ Accuracy: 68.0%\n",
            "Step: 1492 ------------ Loss: 6654.72 ------------ Accuracy: 68.1%\n",
            "Step: 1493 ------------ Loss: 6654.58 ------------ Accuracy: 68.2%\n",
            "Step: 1494 ------------ Loss: 6653.07 ------------ Accuracy: 68.3%\n",
            "Step: 1495 ------------ Loss: 6651.61 ------------ Accuracy: 68.2%\n",
            "Step: 1496 ------------ Loss: 6650.71 ------------ Accuracy: 68.2%\n",
            "Step: 1497 ------------ Loss: 6649.22 ------------ Accuracy: 68.3%\n",
            "Step: 1498 ------------ Loss: 6648.74 ------------ Accuracy: 68.4%\n",
            "Step: 1499 ------------ Loss: 6647.26 ------------ Accuracy: 68.5%\n",
            "Step: 1500 ------------ Loss: 6644.6 ------------ Accuracy: 68.2%\n",
            "Step: 1501 ------------ Loss: 6643.17 ------------ Accuracy: 68.1%\n",
            "Step: 1502 ------------ Loss: 6642.27 ------------ Accuracy: 68.1%\n",
            "Step: 1503 ------------ Loss: 6640.71 ------------ Accuracy: 68.3%\n",
            "Step: 1504 ------------ Loss: 6639.78 ------------ Accuracy: 68.3%\n",
            "Step: 1505 ------------ Loss: 6639.44 ------------ Accuracy: 68.4%\n",
            "Step: 1506 ------------ Loss: 6636.86 ------------ Accuracy: 68.4%\n",
            "Step: 1507 ------------ Loss: 6635.38 ------------ Accuracy: 68.5%\n",
            "Step: 1508 ------------ Loss: 6634.96 ------------ Accuracy: 68.5%\n",
            "Step: 1509 ------------ Loss: 6632.4 ------------ Accuracy: 68.3%\n",
            "Step: 1510 ------------ Loss: 6629.97 ------------ Accuracy: 68.0%\n",
            "Step: 1511 ------------ Loss: 6628.3 ------------ Accuracy: 68.1%\n",
            "Step: 1512 ------------ Loss: 6627.4 ------------ Accuracy: 68.1%\n",
            "Step: 1513 ------------ Loss: 6625.9 ------------ Accuracy: 68.2%\n",
            "Step: 1514 ------------ Loss: 6623.49 ------------ Accuracy: 68.0%\n",
            "Step: 1515 ------------ Loss: 6621.92 ------------ Accuracy: 68.1%\n",
            "Step: 1516 ------------ Loss: 6621.53 ------------ Accuracy: 68.2%\n",
            "Step: 1517 ------------ Loss: 6620.11 ------------ Accuracy: 68.2%\n",
            "Step: 1518 ------------ Loss: 6619.22 ------------ Accuracy: 68.2%\n",
            "Step: 1519 ------------ Loss: 6619.01 ------------ Accuracy: 68.3%\n",
            "Step: 1520 ------------ Loss: 6617.52 ------------ Accuracy: 68.4%\n",
            "Step: 1521 ------------ Loss: 6616.04 ------------ Accuracy: 68.6%\n",
            "Step: 1522 ------------ Loss: 6615.87 ------------ Accuracy: 68.7%\n",
            "Step: 1523 ------------ Loss: 6613.55 ------------ Accuracy: 68.6%\n",
            "Step: 1524 ------------ Loss: 6611.17 ------------ Accuracy: 68.4%\n",
            "Step: 1525 ------------ Loss: 6609.44 ------------ Accuracy: 68.5%\n",
            "Step: 1526 ------------ Loss: 6607.13 ------------ Accuracy: 68.3%\n",
            "Step: 1527 ------------ Loss: 6606.72 ------------ Accuracy: 68.3%\n",
            "Step: 1528 ------------ Loss: 6604.47 ------------ Accuracy: 68.1%\n",
            "Step: 1529 ------------ Loss: 6602.33 ------------ Accuracy: 67.9%\n",
            "Step: 1530 ------------ Loss: 6600.52 ------------ Accuracy: 68.0%\n",
            "Step: 1531 ------------ Loss: 6600.07 ------------ Accuracy: 68.1%\n",
            "Step: 1532 ------------ Loss: 6599.86 ------------ Accuracy: 68.2%\n",
            "Step: 1533 ------------ Loss: 6599.18 ------------ Accuracy: 68.3%\n",
            "Step: 1534 ------------ Loss: 6598.77 ------------ Accuracy: 68.4%\n",
            "Step: 1535 ------------ Loss: 6597.2 ------------ Accuracy: 68.5%\n",
            "Step: 1536 ------------ Loss: 6597.05 ------------ Accuracy: 68.6%\n",
            "Step: 1537 ------------ Loss: 6595.54 ------------ Accuracy: 68.7%\n",
            "Step: 1538 ------------ Loss: 6594.0 ------------ Accuracy: 68.8%\n",
            "Step: 1539 ------------ Loss: 6592.33 ------------ Accuracy: 68.9%\n",
            "Step: 1540 ------------ Loss: 6590.84 ------------ Accuracy: 69.0%\n",
            "Step: 1541 ------------ Loss: 6589.38 ------------ Accuracy: 69.2%\n",
            "Step: 1542 ------------ Loss: 6587.2 ------------ Accuracy: 69.1%\n",
            "Step: 1543 ------------ Loss: 6585.49 ------------ Accuracy: 69.1%\n",
            "Step: 1544 ------------ Loss: 6584.04 ------------ Accuracy: 69.2%\n",
            "Step: 1545 ------------ Loss: 6583.94 ------------ Accuracy: 69.3%\n",
            "Step: 1546 ------------ Loss: 6582.5 ------------ Accuracy: 69.4%\n",
            "Step: 1547 ------------ Loss: 6581.07 ------------ Accuracy: 69.5%\n",
            "Step: 1548 ------------ Loss: 6580.73 ------------ Accuracy: 69.5%\n",
            "Step: 1549 ------------ Loss: 6579.31 ------------ Accuracy: 69.6%\n",
            "Step: 1550 ------------ Loss: 6577.91 ------------ Accuracy: 69.8%\n",
            "Step: 1551 ------------ Loss: 6577.59 ------------ Accuracy: 69.8%\n",
            "Step: 1552 ------------ Loss: 6577.3 ------------ Accuracy: 69.7%\n",
            "Step: 1553 ------------ Loss: 6575.67 ------------ Accuracy: 69.8%\n",
            "Step: 1554 ------------ Loss: 6574.26 ------------ Accuracy: 69.8%\n",
            "Step: 1555 ------------ Loss: 6571.64 ------------ Accuracy: 69.8%\n",
            "Step: 1556 ------------ Loss: 6569.11 ------------ Accuracy: 69.5%\n",
            "Step: 1557 ------------ Loss: 6566.7 ------------ Accuracy: 69.3%\n",
            "Step: 1558 ------------ Loss: 6564.77 ------------ Accuracy: 69.2%\n",
            "Step: 1559 ------------ Loss: 6562.99 ------------ Accuracy: 69.3%\n",
            "Step: 1560 ------------ Loss: 6561.53 ------------ Accuracy: 69.4%\n",
            "Step: 1561 ------------ Loss: 6559.98 ------------ Accuracy: 69.3%\n",
            "Step: 1562 ------------ Loss: 6558.56 ------------ Accuracy: 69.4%\n",
            "Step: 1563 ------------ Loss: 6558.44 ------------ Accuracy: 69.5%\n",
            "Step: 1564 ------------ Loss: 6558.16 ------------ Accuracy: 69.5%\n",
            "Step: 1565 ------------ Loss: 6557.3 ------------ Accuracy: 69.5%\n",
            "Step: 1566 ------------ Loss: 6555.85 ------------ Accuracy: 69.6%\n",
            "Step: 1567 ------------ Loss: 6555.51 ------------ Accuracy: 69.7%\n",
            "Step: 1568 ------------ Loss: 6554.13 ------------ Accuracy: 69.9%\n",
            "Step: 1569 ------------ Loss: 6553.87 ------------ Accuracy: 69.9%\n",
            "Step: 1570 ------------ Loss: 6553.75 ------------ Accuracy: 69.9%\n",
            "Step: 1571 ------------ Loss: 6553.5 ------------ Accuracy: 69.9%\n",
            "Step: 1572 ------------ Loss: 6551.06 ------------ Accuracy: 69.7%\n",
            "Step: 1573 ------------ Loss: 6550.21 ------------ Accuracy: 69.7%\n",
            "Step: 1574 ------------ Loss: 6548.5 ------------ Accuracy: 69.8%\n",
            "Step: 1575 ------------ Loss: 6547.07 ------------ Accuracy: 69.9%\n",
            "Step: 1576 ------------ Loss: 6545.53 ------------ Accuracy: 69.8%\n",
            "Step: 1577 ------------ Loss: 6544.13 ------------ Accuracy: 70.0%\n",
            "Step: 1578 ------------ Loss: 6542.76 ------------ Accuracy: 70.2%\n",
            "Step: 1579 ------------ Loss: 6540.77 ------------ Accuracy: 70.0%\n",
            "Step: 1580 ------------ Loss: 6539.07 ------------ Accuracy: 70.1%\n",
            "Step: 1581 ------------ Loss: 6537.7 ------------ Accuracy: 70.2%\n",
            "Step: 1582 ------------ Loss: 6536.81 ------------ Accuracy: 70.3%\n",
            "Step: 1583 ------------ Loss: 6536.7 ------------ Accuracy: 70.2%\n",
            "Step: 1584 ------------ Loss: 6535.33 ------------ Accuracy: 70.2%\n",
            "Step: 1585 ------------ Loss: 6533.93 ------------ Accuracy: 70.4%\n",
            "Step: 1586 ------------ Loss: 6533.09 ------------ Accuracy: 70.4%\n",
            "Step: 1587 ------------ Loss: 6532.99 ------------ Accuracy: 70.3%\n",
            "Step: 1588 ------------ Loss: 6532.16 ------------ Accuracy: 70.4%\n",
            "Step: 1589 ------------ Loss: 6531.87 ------------ Accuracy: 70.5%\n",
            "Step: 1590 ------------ Loss: 6531.09 ------------ Accuracy: 70.4%\n",
            "Step: 1591 ------------ Loss: 6529.69 ------------ Accuracy: 70.5%\n",
            "Step: 1592 ------------ Loss: 6528.34 ------------ Accuracy: 70.6%\n",
            "Step: 1593 ------------ Loss: 6527.52 ------------ Accuracy: 70.6%\n",
            "Step: 1594 ------------ Loss: 6526.18 ------------ Accuracy: 70.7%\n",
            "Step: 1595 ------------ Loss: 6525.37 ------------ Accuracy: 70.7%\n",
            "Step: 1596 ------------ Loss: 6523.76 ------------ Accuracy: 70.7%\n",
            "Step: 1597 ------------ Loss: 6522.91 ------------ Accuracy: 70.8%\n",
            "Step: 1598 ------------ Loss: 6520.34 ------------ Accuracy: 70.8%\n",
            "Step: 1599 ------------ Loss: 6517.84 ------------ Accuracy: 70.8%\n",
            "Step: 1600 ------------ Loss: 6515.42 ------------ Accuracy: 70.7%\n",
            "Step: 1601 ------------ Loss: 6515.13 ------------ Accuracy: 70.8%\n",
            "Step: 1602 ------------ Loss: 6513.49 ------------ Accuracy: 70.9%\n",
            "Step: 1603 ------------ Loss: 6513.23 ------------ Accuracy: 70.9%\n",
            "Step: 1604 ------------ Loss: 6512.42 ------------ Accuracy: 71.0%\n",
            "Step: 1605 ------------ Loss: 6511.13 ------------ Accuracy: 71.0%\n",
            "Step: 1606 ------------ Loss: 6509.56 ------------ Accuracy: 71.2%\n",
            "Step: 1607 ------------ Loss: 6507.1 ------------ Accuracy: 71.0%\n",
            "Step: 1608 ------------ Loss: 6505.15 ------------ Accuracy: 70.9%\n",
            "Step: 1609 ------------ Loss: 6503.52 ------------ Accuracy: 70.8%\n",
            "Step: 1610 ------------ Loss: 6501.18 ------------ Accuracy: 70.7%\n",
            "Step: 1611 ------------ Loss: 6499.51 ------------ Accuracy: 70.8%\n",
            "Step: 1612 ------------ Loss: 6497.88 ------------ Accuracy: 70.9%\n",
            "Step: 1613 ------------ Loss: 6496.56 ------------ Accuracy: 71.0%\n",
            "Step: 1614 ------------ Loss: 6495.01 ------------ Accuracy: 71.1%\n",
            "Step: 1615 ------------ Loss: 6494.18 ------------ Accuracy: 71.1%\n",
            "Step: 1616 ------------ Loss: 6493.81 ------------ Accuracy: 71.0%\n",
            "Step: 1617 ------------ Loss: 6493.55 ------------ Accuracy: 71.1%\n",
            "Step: 1618 ------------ Loss: 6492.76 ------------ Accuracy: 71.1%\n",
            "Step: 1619 ------------ Loss: 6491.48 ------------ Accuracy: 71.3%\n",
            "Step: 1620 ------------ Loss: 6488.77 ------------ Accuracy: 70.9%\n",
            "Step: 1621 ------------ Loss: 6487.89 ------------ Accuracy: 70.9%\n",
            "Step: 1622 ------------ Loss: 6487.64 ------------ Accuracy: 71.0%\n",
            "Step: 1623 ------------ Loss: 6486.83 ------------ Accuracy: 71.0%\n",
            "Step: 1624 ------------ Loss: 6485.49 ------------ Accuracy: 71.1%\n",
            "Step: 1625 ------------ Loss: 6484.69 ------------ Accuracy: 71.1%\n",
            "Step: 1626 ------------ Loss: 6483.89 ------------ Accuracy: 71.2%\n",
            "Step: 1627 ------------ Loss: 6482.37 ------------ Accuracy: 71.2%\n",
            "Step: 1628 ------------ Loss: 6480.29 ------------ Accuracy: 71.1%\n",
            "Step: 1629 ------------ Loss: 6478.76 ------------ Accuracy: 71.0%\n",
            "Step: 1630 ------------ Loss: 6477.43 ------------ Accuracy: 71.1%\n",
            "Step: 1631 ------------ Loss: 6476.64 ------------ Accuracy: 71.2%\n",
            "Step: 1632 ------------ Loss: 6475.1 ------------ Accuracy: 71.2%\n",
            "Step: 1633 ------------ Loss: 6474.88 ------------ Accuracy: 71.3%\n",
            "Step: 1634 ------------ Loss: 6473.62 ------------ Accuracy: 71.4%\n",
            "Step: 1635 ------------ Loss: 6472.36 ------------ Accuracy: 71.5%\n",
            "Step: 1636 ------------ Loss: 6470.88 ------------ Accuracy: 71.6%\n",
            "Step: 1637 ------------ Loss: 6469.59 ------------ Accuracy: 71.7%\n",
            "Step: 1638 ------------ Loss: 6468.82 ------------ Accuracy: 71.7%\n",
            "Step: 1639 ------------ Loss: 6467.31 ------------ Accuracy: 71.6%\n",
            "Step: 1640 ------------ Loss: 6466.95 ------------ Accuracy: 71.7%\n",
            "Step: 1641 ------------ Loss: 6466.17 ------------ Accuracy: 71.7%\n",
            "Step: 1642 ------------ Loss: 6464.93 ------------ Accuracy: 71.8%\n",
            "Step: 1643 ------------ Loss: 6462.78 ------------ Accuracy: 71.7%\n",
            "Step: 1644 ------------ Loss: 6462.46 ------------ Accuracy: 71.7%\n",
            "Step: 1645 ------------ Loss: 6462.25 ------------ Accuracy: 71.7%\n",
            "Step: 1646 ------------ Loss: 6459.62 ------------ Accuracy: 71.4%\n",
            "Step: 1647 ------------ Loss: 6458.37 ------------ Accuracy: 71.5%\n",
            "Step: 1648 ------------ Loss: 6456.86 ------------ Accuracy: 71.5%\n",
            "Step: 1649 ------------ Loss: 6455.6 ------------ Accuracy: 71.7%\n",
            "Step: 1650 ------------ Loss: 6454.76 ------------ Accuracy: 71.6%\n",
            "Step: 1651 ------------ Loss: 6453.98 ------------ Accuracy: 71.7%\n",
            "Step: 1652 ------------ Loss: 6453.18 ------------ Accuracy: 71.7%\n",
            "Step: 1653 ------------ Loss: 6451.89 ------------ Accuracy: 71.8%\n",
            "Step: 1654 ------------ Loss: 6451.13 ------------ Accuracy: 71.8%\n",
            "Step: 1655 ------------ Loss: 6450.34 ------------ Accuracy: 71.9%\n",
            "Step: 1656 ------------ Loss: 6448.31 ------------ Accuracy: 71.8%\n",
            "Step: 1657 ------------ Loss: 6448.1 ------------ Accuracy: 71.8%\n",
            "Step: 1658 ------------ Loss: 6447.95 ------------ Accuracy: 71.8%\n",
            "Step: 1659 ------------ Loss: 6446.42 ------------ Accuracy: 71.9%\n",
            "Step: 1660 ------------ Loss: 6446.1 ------------ Accuracy: 71.9%\n",
            "Step: 1661 ------------ Loss: 6445.81 ------------ Accuracy: 71.8%\n",
            "Step: 1662 ------------ Loss: 6444.53 ------------ Accuracy: 71.9%\n",
            "Step: 1663 ------------ Loss: 6443.3 ------------ Accuracy: 72.0%\n",
            "Step: 1664 ------------ Loss: 6442.51 ------------ Accuracy: 72.0%\n",
            "Step: 1665 ------------ Loss: 6440.99 ------------ Accuracy: 72.0%\n",
            "Step: 1666 ------------ Loss: 6440.14 ------------ Accuracy: 71.9%\n",
            "Step: 1667 ------------ Loss: 6439.34 ------------ Accuracy: 72.0%\n",
            "Step: 1668 ------------ Loss: 6437.88 ------------ Accuracy: 72.0%\n",
            "Step: 1669 ------------ Loss: 6437.08 ------------ Accuracy: 72.0%\n",
            "Step: 1670 ------------ Loss: 6436.29 ------------ Accuracy: 72.0%\n",
            "Step: 1671 ------------ Loss: 6434.88 ------------ Accuracy: 72.0%\n",
            "Step: 1672 ------------ Loss: 6433.51 ------------ Accuracy: 72.1%\n",
            "Step: 1673 ------------ Loss: 6433.33 ------------ Accuracy: 72.0%\n",
            "Step: 1674 ------------ Loss: 6432.58 ------------ Accuracy: 72.1%\n",
            "Step: 1675 ------------ Loss: 6431.79 ------------ Accuracy: 72.1%\n",
            "Step: 1676 ------------ Loss: 6431.04 ------------ Accuracy: 72.1%\n",
            "Step: 1677 ------------ Loss: 6428.45 ------------ Accuracy: 72.1%\n",
            "Step: 1678 ------------ Loss: 6428.26 ------------ Accuracy: 72.2%\n",
            "Step: 1679 ------------ Loss: 6427.0 ------------ Accuracy: 72.2%\n",
            "Step: 1680 ------------ Loss: 6424.31 ------------ Accuracy: 72.1%\n",
            "Step: 1681 ------------ Loss: 6422.9 ------------ Accuracy: 72.2%\n",
            "Step: 1682 ------------ Loss: 6421.63 ------------ Accuracy: 72.2%\n",
            "Step: 1683 ------------ Loss: 6420.21 ------------ Accuracy: 72.2%\n",
            "Step: 1684 ------------ Loss: 6419.46 ------------ Accuracy: 72.2%\n",
            "Step: 1685 ------------ Loss: 6418.2 ------------ Accuracy: 72.3%\n",
            "Step: 1686 ------------ Loss: 6417.0 ------------ Accuracy: 72.4%\n",
            "Step: 1687 ------------ Loss: 6414.81 ------------ Accuracy: 72.3%\n",
            "Step: 1688 ------------ Loss: 6413.4 ------------ Accuracy: 72.3%\n",
            "Step: 1689 ------------ Loss: 6411.98 ------------ Accuracy: 72.3%\n",
            "Step: 1690 ------------ Loss: 6411.21 ------------ Accuracy: 72.3%\n",
            "Step: 1691 ------------ Loss: 6409.84 ------------ Accuracy: 72.4%\n",
            "Step: 1692 ------------ Loss: 6407.64 ------------ Accuracy: 72.3%\n",
            "Step: 1693 ------------ Loss: 6406.9 ------------ Accuracy: 72.4%\n",
            "Step: 1694 ------------ Loss: 6405.66 ------------ Accuracy: 72.4%\n",
            "Step: 1695 ------------ Loss: 6405.46 ------------ Accuracy: 72.4%\n",
            "Step: 1696 ------------ Loss: 6404.26 ------------ Accuracy: 72.5%\n",
            "Step: 1697 ------------ Loss: 6403.04 ------------ Accuracy: 72.6%\n",
            "Step: 1698 ------------ Loss: 6402.7 ------------ Accuracy: 72.5%\n",
            "Step: 1699 ------------ Loss: 6401.94 ------------ Accuracy: 72.5%\n",
            "Step: 1700 ------------ Loss: 6399.32 ------------ Accuracy: 72.4%\n",
            "Step: 1701 ------------ Loss: 6397.9 ------------ Accuracy: 72.4%\n",
            "Step: 1702 ------------ Loss: 6397.14 ------------ Accuracy: 72.4%\n",
            "Step: 1703 ------------ Loss: 6395.93 ------------ Accuracy: 72.5%\n",
            "Step: 1704 ------------ Loss: 6395.63 ------------ Accuracy: 72.5%\n",
            "Step: 1705 ------------ Loss: 6394.24 ------------ Accuracy: 72.6%\n",
            "Step: 1706 ------------ Loss: 6391.66 ------------ Accuracy: 72.4%\n",
            "Step: 1707 ------------ Loss: 6390.26 ------------ Accuracy: 72.4%\n",
            "Step: 1708 ------------ Loss: 6388.18 ------------ Accuracy: 72.4%\n",
            "Step: 1709 ------------ Loss: 6387.34 ------------ Accuracy: 72.3%\n",
            "Step: 1710 ------------ Loss: 6386.6 ------------ Accuracy: 72.4%\n",
            "Step: 1711 ------------ Loss: 6385.35 ------------ Accuracy: 72.4%\n",
            "Step: 1712 ------------ Loss: 6384.62 ------------ Accuracy: 72.5%\n",
            "Step: 1713 ------------ Loss: 6384.33 ------------ Accuracy: 72.5%\n",
            "Step: 1714 ------------ Loss: 6383.6 ------------ Accuracy: 72.5%\n",
            "Step: 1715 ------------ Loss: 6382.78 ------------ Accuracy: 72.5%\n",
            "Step: 1716 ------------ Loss: 6381.4 ------------ Accuracy: 72.5%\n",
            "Step: 1717 ------------ Loss: 6380.15 ------------ Accuracy: 72.5%\n",
            "Step: 1718 ------------ Loss: 6379.86 ------------ Accuracy: 72.5%\n",
            "Step: 1719 ------------ Loss: 6378.5 ------------ Accuracy: 72.5%\n",
            "Step: 1720 ------------ Loss: 6377.27 ------------ Accuracy: 72.5%\n",
            "Step: 1721 ------------ Loss: 6377.01 ------------ Accuracy: 72.4%\n",
            "Step: 1722 ------------ Loss: 6375.78 ------------ Accuracy: 72.5%\n",
            "Step: 1723 ------------ Loss: 6374.41 ------------ Accuracy: 72.6%\n",
            "Step: 1724 ------------ Loss: 6373.07 ------------ Accuracy: 72.6%\n",
            "Step: 1725 ------------ Loss: 6372.81 ------------ Accuracy: 72.5%\n",
            "Step: 1726 ------------ Loss: 6371.61 ------------ Accuracy: 72.6%\n",
            "Step: 1727 ------------ Loss: 6370.39 ------------ Accuracy: 72.7%\n",
            "Step: 1728 ------------ Loss: 6369.57 ------------ Accuracy: 72.6%\n",
            "Step: 1729 ------------ Loss: 6367.45 ------------ Accuracy: 72.6%\n",
            "Step: 1730 ------------ Loss: 6365.03 ------------ Accuracy: 72.3%\n",
            "Step: 1731 ------------ Loss: 6362.61 ------------ Accuracy: 72.4%\n",
            "Step: 1732 ------------ Loss: 6361.26 ------------ Accuracy: 72.3%\n",
            "Step: 1733 ------------ Loss: 6360.02 ------------ Accuracy: 72.4%\n",
            "Step: 1734 ------------ Loss: 6358.59 ------------ Accuracy: 72.4%\n",
            "Step: 1735 ------------ Loss: 6357.38 ------------ Accuracy: 72.5%\n",
            "Step: 1736 ------------ Loss: 6356.62 ------------ Accuracy: 72.5%\n",
            "Step: 1737 ------------ Loss: 6355.43 ------------ Accuracy: 72.5%\n",
            "Step: 1738 ------------ Loss: 6353.46 ------------ Accuracy: 72.5%\n",
            "Step: 1739 ------------ Loss: 6353.22 ------------ Accuracy: 72.6%\n",
            "Step: 1740 ------------ Loss: 6351.78 ------------ Accuracy: 72.6%\n",
            "Step: 1741 ------------ Loss: 6350.58 ------------ Accuracy: 72.7%\n",
            "Step: 1742 ------------ Loss: 6348.2 ------------ Accuracy: 72.7%\n",
            "Step: 1743 ------------ Loss: 6345.88 ------------ Accuracy: 72.6%\n",
            "Step: 1744 ------------ Loss: 6345.72 ------------ Accuracy: 72.7%\n",
            "Step: 1745 ------------ Loss: 6344.88 ------------ Accuracy: 72.7%\n",
            "Step: 1746 ------------ Loss: 6344.09 ------------ Accuracy: 72.6%\n",
            "Step: 1747 ------------ Loss: 6342.87 ------------ Accuracy: 72.7%\n",
            "Step: 1748 ------------ Loss: 6342.57 ------------ Accuracy: 72.8%\n",
            "Step: 1749 ------------ Loss: 6340.27 ------------ Accuracy: 72.7%\n",
            "Step: 1750 ------------ Loss: 6339.99 ------------ Accuracy: 72.7%\n",
            "Step: 1751 ------------ Loss: 6339.87 ------------ Accuracy: 72.7%\n",
            "Step: 1752 ------------ Loss: 6339.14 ------------ Accuracy: 72.7%\n",
            "Step: 1753 ------------ Loss: 6337.95 ------------ Accuracy: 72.8%\n",
            "Step: 1754 ------------ Loss: 6336.75 ------------ Accuracy: 72.9%\n",
            "Step: 1755 ------------ Loss: 6334.5 ------------ Accuracy: 72.9%\n",
            "Step: 1756 ------------ Loss: 6333.75 ------------ Accuracy: 72.9%\n",
            "Step: 1757 ------------ Loss: 6333.46 ------------ Accuracy: 72.9%\n",
            "Step: 1758 ------------ Loss: 6333.35 ------------ Accuracy: 72.9%\n",
            "Step: 1759 ------------ Loss: 6331.16 ------------ Accuracy: 72.8%\n",
            "Step: 1760 ------------ Loss: 6330.3 ------------ Accuracy: 72.8%\n",
            "Step: 1761 ------------ Loss: 6329.08 ------------ Accuracy: 72.9%\n",
            "Step: 1762 ------------ Loss: 6327.65 ------------ Accuracy: 72.9%\n",
            "Step: 1763 ------------ Loss: 6326.25 ------------ Accuracy: 72.8%\n",
            "Step: 1764 ------------ Loss: 6326.15 ------------ Accuracy: 72.9%\n",
            "Step: 1765 ------------ Loss: 6324.41 ------------ Accuracy: 72.7%\n",
            "Step: 1766 ------------ Loss: 6322.91 ------------ Accuracy: 72.8%\n",
            "Step: 1767 ------------ Loss: 6321.22 ------------ Accuracy: 72.7%\n",
            "Step: 1768 ------------ Loss: 6320.93 ------------ Accuracy: 72.8%\n",
            "Step: 1769 ------------ Loss: 6320.67 ------------ Accuracy: 72.7%\n",
            "Step: 1770 ------------ Loss: 6318.42 ------------ Accuracy: 72.4%\n",
            "Step: 1771 ------------ Loss: 6317.21 ------------ Accuracy: 72.5%\n",
            "Step: 1772 ------------ Loss: 6315.66 ------------ Accuracy: 72.5%\n",
            "Step: 1773 ------------ Loss: 6314.88 ------------ Accuracy: 72.5%\n",
            "Step: 1774 ------------ Loss: 6313.43 ------------ Accuracy: 72.5%\n",
            "Step: 1775 ------------ Loss: 6311.76 ------------ Accuracy: 72.6%\n",
            "Step: 1776 ------------ Loss: 6310.51 ------------ Accuracy: 72.6%\n",
            "Step: 1777 ------------ Loss: 6310.2 ------------ Accuracy: 72.7%\n",
            "Step: 1778 ------------ Loss: 6308.61 ------------ Accuracy: 72.8%\n",
            "Step: 1779 ------------ Loss: 6307.45 ------------ Accuracy: 72.8%\n",
            "Step: 1780 ------------ Loss: 6306.28 ------------ Accuracy: 72.9%\n",
            "Step: 1781 ------------ Loss: 6305.07 ------------ Accuracy: 73.0%\n",
            "Step: 1782 ------------ Loss: 6304.35 ------------ Accuracy: 73.0%\n",
            "Step: 1783 ------------ Loss: 6303.16 ------------ Accuracy: 73.1%\n",
            "Step: 1784 ------------ Loss: 6302.45 ------------ Accuracy: 73.1%\n",
            "Step: 1785 ------------ Loss: 6300.93 ------------ Accuracy: 73.1%\n",
            "Step: 1786 ------------ Loss: 6300.22 ------------ Accuracy: 73.2%\n",
            "Step: 1787 ------------ Loss: 6298.13 ------------ Accuracy: 73.1%\n",
            "Step: 1788 ------------ Loss: 6296.96 ------------ Accuracy: 73.2%\n",
            "Step: 1789 ------------ Loss: 6294.62 ------------ Accuracy: 73.0%\n",
            "Step: 1790 ------------ Loss: 6292.39 ------------ Accuracy: 72.8%\n",
            "Step: 1791 ------------ Loss: 6290.39 ------------ Accuracy: 72.7%\n",
            "Step: 1792 ------------ Loss: 6288.29 ------------ Accuracy: 72.6%\n",
            "Step: 1793 ------------ Loss: 6287.57 ------------ Accuracy: 72.6%\n",
            "Step: 1794 ------------ Loss: 6285.93 ------------ Accuracy: 72.7%\n",
            "Step: 1795 ------------ Loss: 6283.98 ------------ Accuracy: 72.7%\n",
            "Step: 1796 ------------ Loss: 6282.77 ------------ Accuracy: 72.7%\n",
            "Step: 1797 ------------ Loss: 6281.16 ------------ Accuracy: 72.7%\n",
            "Step: 1798 ------------ Loss: 6280.83 ------------ Accuracy: 72.8%\n",
            "Step: 1799 ------------ Loss: 6280.54 ------------ Accuracy: 72.9%\n",
            "Step: 1800 ------------ Loss: 6280.27 ------------ Accuracy: 73.0%\n",
            "Step: 1801 ------------ Loss: 6280.02 ------------ Accuracy: 73.0%\n",
            "Step: 1802 ------------ Loss: 6279.87 ------------ Accuracy: 73.0%\n",
            "Step: 1803 ------------ Loss: 6278.34 ------------ Accuracy: 73.1%\n",
            "Step: 1804 ------------ Loss: 6277.14 ------------ Accuracy: 73.3%\n",
            "Step: 1805 ------------ Loss: 6276.92 ------------ Accuracy: 73.3%\n",
            "Step: 1806 ------------ Loss: 6275.76 ------------ Accuracy: 73.3%\n",
            "Step: 1807 ------------ Loss: 6274.58 ------------ Accuracy: 73.4%\n",
            "Step: 1808 ------------ Loss: 6273.12 ------------ Accuracy: 73.4%\n",
            "Step: 1809 ------------ Loss: 6271.72 ------------ Accuracy: 73.5%\n",
            "Step: 1810 ------------ Loss: 6271.57 ------------ Accuracy: 73.5%\n",
            "Step: 1811 ------------ Loss: 6270.65 ------------ Accuracy: 73.4%\n",
            "Step: 1812 ------------ Loss: 6269.94 ------------ Accuracy: 73.5%\n",
            "Step: 1813 ------------ Loss: 6269.72 ------------ Accuracy: 73.5%\n",
            "Step: 1814 ------------ Loss: 6268.98 ------------ Accuracy: 73.6%\n",
            "Step: 1815 ------------ Loss: 6267.81 ------------ Accuracy: 73.7%\n",
            "Step: 1816 ------------ Loss: 6266.67 ------------ Accuracy: 73.7%\n",
            "Step: 1817 ------------ Loss: 6266.46 ------------ Accuracy: 73.8%\n",
            "Step: 1818 ------------ Loss: 6265.1 ------------ Accuracy: 73.8%\n",
            "Step: 1819 ------------ Loss: 6263.96 ------------ Accuracy: 73.9%\n",
            "Step: 1820 ------------ Loss: 6263.76 ------------ Accuracy: 73.9%\n",
            "Step: 1821 ------------ Loss: 6263.03 ------------ Accuracy: 73.9%\n",
            "Step: 1822 ------------ Loss: 6261.26 ------------ Accuracy: 73.8%\n",
            "Step: 1823 ------------ Loss: 6260.1 ------------ Accuracy: 73.9%\n",
            "Step: 1824 ------------ Loss: 6258.95 ------------ Accuracy: 74.0%\n",
            "Step: 1825 ------------ Loss: 6258.23 ------------ Accuracy: 74.0%\n",
            "Step: 1826 ------------ Loss: 6258.03 ------------ Accuracy: 74.1%\n",
            "Step: 1827 ------------ Loss: 6257.34 ------------ Accuracy: 74.1%\n",
            "Step: 1828 ------------ Loss: 6255.21 ------------ Accuracy: 74.0%\n",
            "Step: 1829 ------------ Loss: 6253.6 ------------ Accuracy: 73.9%\n",
            "Step: 1830 ------------ Loss: 6251.59 ------------ Accuracy: 73.9%\n",
            "Step: 1831 ------------ Loss: 6250.57 ------------ Accuracy: 73.8%\n",
            "Step: 1832 ------------ Loss: 6249.47 ------------ Accuracy: 73.9%\n",
            "Step: 1833 ------------ Loss: 6249.2 ------------ Accuracy: 73.9%\n",
            "Step: 1834 ------------ Loss: 6248.47 ------------ Accuracy: 73.9%\n",
            "Step: 1835 ------------ Loss: 6247.37 ------------ Accuracy: 74.0%\n",
            "Step: 1836 ------------ Loss: 6245.06 ------------ Accuracy: 73.8%\n",
            "Step: 1837 ------------ Loss: 6243.9 ------------ Accuracy: 73.9%\n",
            "Step: 1838 ------------ Loss: 6242.47 ------------ Accuracy: 73.8%\n",
            "Step: 1839 ------------ Loss: 6240.47 ------------ Accuracy: 73.8%\n",
            "Step: 1840 ------------ Loss: 6239.33 ------------ Accuracy: 73.9%\n",
            "Step: 1841 ------------ Loss: 6237.83 ------------ Accuracy: 73.9%\n",
            "Step: 1842 ------------ Loss: 6236.43 ------------ Accuracy: 73.8%\n",
            "Step: 1843 ------------ Loss: 6236.17 ------------ Accuracy: 73.9%\n",
            "Step: 1844 ------------ Loss: 6235.45 ------------ Accuracy: 73.9%\n",
            "Step: 1845 ------------ Loss: 6235.2 ------------ Accuracy: 74.0%\n",
            "Step: 1846 ------------ Loss: 6233.83 ------------ Accuracy: 73.9%\n",
            "Step: 1847 ------------ Loss: 6232.92 ------------ Accuracy: 73.8%\n",
            "Step: 1848 ------------ Loss: 6231.53 ------------ Accuracy: 73.9%\n",
            "Step: 1849 ------------ Loss: 6230.39 ------------ Accuracy: 74.0%\n",
            "Step: 1850 ------------ Loss: 6229.04 ------------ Accuracy: 74.1%\n",
            "Step: 1851 ------------ Loss: 6227.94 ------------ Accuracy: 74.2%\n",
            "Step: 1852 ------------ Loss: 6227.73 ------------ Accuracy: 74.2%\n",
            "Step: 1853 ------------ Loss: 6226.62 ------------ Accuracy: 74.3%\n",
            "Step: 1854 ------------ Loss: 6224.5 ------------ Accuracy: 74.2%\n",
            "Step: 1855 ------------ Loss: 6222.82 ------------ Accuracy: 74.2%\n",
            "Step: 1856 ------------ Loss: 6220.53 ------------ Accuracy: 73.9%\n",
            "Step: 1857 ------------ Loss: 6219.01 ------------ Accuracy: 73.9%\n",
            "Step: 1858 ------------ Loss: 6217.9 ------------ Accuracy: 74.0%\n",
            "Step: 1859 ------------ Loss: 6216.8 ------------ Accuracy: 74.0%\n",
            "Step: 1860 ------------ Loss: 6216.09 ------------ Accuracy: 74.0%\n",
            "Step: 1861 ------------ Loss: 6215.0 ------------ Accuracy: 74.2%\n",
            "Step: 1862 ------------ Loss: 6213.53 ------------ Accuracy: 74.2%\n",
            "Step: 1863 ------------ Loss: 6211.56 ------------ Accuracy: 74.1%\n",
            "Step: 1864 ------------ Loss: 6210.88 ------------ Accuracy: 74.2%\n",
            "Step: 1865 ------------ Loss: 6210.21 ------------ Accuracy: 74.2%\n",
            "Step: 1866 ------------ Loss: 6208.82 ------------ Accuracy: 74.1%\n",
            "Step: 1867 ------------ Loss: 6208.59 ------------ Accuracy: 74.1%\n",
            "Step: 1868 ------------ Loss: 6207.68 ------------ Accuracy: 74.1%\n",
            "Step: 1869 ------------ Loss: 6206.82 ------------ Accuracy: 74.1%\n",
            "Step: 1870 ------------ Loss: 6204.61 ------------ Accuracy: 73.9%\n",
            "Step: 1871 ------------ Loss: 6202.63 ------------ Accuracy: 73.9%\n",
            "Step: 1872 ------------ Loss: 6201.31 ------------ Accuracy: 73.8%\n",
            "Step: 1873 ------------ Loss: 6200.23 ------------ Accuracy: 73.9%\n",
            "Step: 1874 ------------ Loss: 6199.07 ------------ Accuracy: 73.9%\n",
            "Step: 1875 ------------ Loss: 6198.4 ------------ Accuracy: 74.0%\n",
            "Step: 1876 ------------ Loss: 6198.16 ------------ Accuracy: 74.0%\n",
            "Step: 1877 ------------ Loss: 6197.46 ------------ Accuracy: 74.1%\n",
            "Step: 1878 ------------ Loss: 6196.15 ------------ Accuracy: 74.0%\n",
            "Step: 1879 ------------ Loss: 6195.83 ------------ Accuracy: 74.0%\n",
            "Step: 1880 ------------ Loss: 6194.31 ------------ Accuracy: 74.1%\n",
            "Step: 1881 ------------ Loss: 6193.24 ------------ Accuracy: 74.1%\n",
            "Step: 1882 ------------ Loss: 6191.82 ------------ Accuracy: 74.0%\n",
            "Step: 1883 ------------ Loss: 6190.33 ------------ Accuracy: 74.1%\n",
            "Step: 1884 ------------ Loss: 6188.86 ------------ Accuracy: 74.2%\n",
            "Step: 1885 ------------ Loss: 6188.63 ------------ Accuracy: 74.2%\n",
            "Step: 1886 ------------ Loss: 6186.7 ------------ Accuracy: 74.2%\n",
            "Step: 1887 ------------ Loss: 6186.47 ------------ Accuracy: 74.2%\n",
            "Step: 1888 ------------ Loss: 6185.04 ------------ Accuracy: 74.3%\n",
            "Step: 1889 ------------ Loss: 6184.0 ------------ Accuracy: 74.3%\n",
            "Step: 1890 ------------ Loss: 6182.63 ------------ Accuracy: 74.4%\n",
            "Step: 1891 ------------ Loss: 6182.49 ------------ Accuracy: 74.4%\n",
            "Step: 1892 ------------ Loss: 6181.38 ------------ Accuracy: 74.4%\n",
            "Step: 1893 ------------ Loss: 6180.03 ------------ Accuracy: 74.5%\n",
            "Step: 1894 ------------ Loss: 6179.84 ------------ Accuracy: 74.6%\n",
            "Step: 1895 ------------ Loss: 6178.53 ------------ Accuracy: 74.7%\n",
            "Step: 1896 ------------ Loss: 6177.48 ------------ Accuracy: 74.7%\n",
            "Step: 1897 ------------ Loss: 6176.4 ------------ Accuracy: 74.8%\n",
            "Step: 1898 ------------ Loss: 6176.09 ------------ Accuracy: 74.8%\n",
            "Step: 1899 ------------ Loss: 6175.94 ------------ Accuracy: 74.8%\n",
            "Step: 1900 ------------ Loss: 6175.12 ------------ Accuracy: 74.7%\n",
            "Step: 1901 ------------ Loss: 6173.82 ------------ Accuracy: 74.7%\n",
            "Step: 1902 ------------ Loss: 6172.73 ------------ Accuracy: 74.8%\n",
            "Step: 1903 ------------ Loss: 6171.49 ------------ Accuracy: 74.8%\n",
            "Step: 1904 ------------ Loss: 6170.4 ------------ Accuracy: 74.9%\n",
            "Step: 1905 ------------ Loss: 6169.33 ------------ Accuracy: 75.0%\n",
            "Step: 1906 ------------ Loss: 6168.13 ------------ Accuracy: 75.0%\n",
            "Step: 1907 ------------ Loss: 6167.97 ------------ Accuracy: 75.0%\n",
            "Step: 1908 ------------ Loss: 6167.67 ------------ Accuracy: 75.0%\n",
            "Step: 1909 ------------ Loss: 6167.01 ------------ Accuracy: 75.1%\n",
            "Step: 1910 ------------ Loss: 6164.62 ------------ Accuracy: 74.8%\n",
            "Step: 1911 ------------ Loss: 6164.48 ------------ Accuracy: 74.7%\n",
            "Step: 1912 ------------ Loss: 6163.25 ------------ Accuracy: 74.8%\n",
            "Step: 1913 ------------ Loss: 6162.18 ------------ Accuracy: 74.9%\n",
            "Step: 1914 ------------ Loss: 6162.01 ------------ Accuracy: 75.0%\n",
            "Step: 1915 ------------ Loss: 6160.81 ------------ Accuracy: 75.0%\n",
            "Step: 1916 ------------ Loss: 6160.13 ------------ Accuracy: 75.0%\n",
            "Step: 1917 ------------ Loss: 6159.08 ------------ Accuracy: 75.1%\n",
            "Step: 1918 ------------ Loss: 6157.84 ------------ Accuracy: 75.0%\n",
            "Step: 1919 ------------ Loss: 6157.19 ------------ Accuracy: 75.0%\n",
            "Step: 1920 ------------ Loss: 6157.02 ------------ Accuracy: 75.0%\n",
            "Step: 1921 ------------ Loss: 6156.37 ------------ Accuracy: 75.0%\n",
            "Step: 1922 ------------ Loss: 6155.21 ------------ Accuracy: 75.1%\n",
            "Step: 1923 ------------ Loss: 6154.12 ------------ Accuracy: 75.1%\n",
            "Step: 1924 ------------ Loss: 6153.96 ------------ Accuracy: 75.2%\n",
            "Step: 1925 ------------ Loss: 6152.83 ------------ Accuracy: 75.2%\n",
            "Step: 1926 ------------ Loss: 6151.78 ------------ Accuracy: 75.3%\n",
            "Step: 1927 ------------ Loss: 6150.69 ------------ Accuracy: 75.4%\n",
            "Step: 1928 ------------ Loss: 6149.64 ------------ Accuracy: 75.4%\n",
            "Step: 1929 ------------ Loss: 6149.45 ------------ Accuracy: 75.4%\n",
            "Step: 1930 ------------ Loss: 6148.41 ------------ Accuracy: 75.4%\n",
            "Step: 1931 ------------ Loss: 6147.74 ------------ Accuracy: 75.4%\n",
            "Step: 1932 ------------ Loss: 6146.65 ------------ Accuracy: 75.5%\n",
            "Step: 1933 ------------ Loss: 6145.59 ------------ Accuracy: 75.5%\n",
            "Step: 1934 ------------ Loss: 6144.57 ------------ Accuracy: 75.6%\n",
            "Step: 1935 ------------ Loss: 6142.38 ------------ Accuracy: 75.5%\n",
            "Step: 1936 ------------ Loss: 6142.2 ------------ Accuracy: 75.5%\n",
            "Step: 1937 ------------ Loss: 6141.56 ------------ Accuracy: 75.5%\n",
            "Step: 1938 ------------ Loss: 6140.55 ------------ Accuracy: 75.6%\n",
            "Step: 1939 ------------ Loss: 6139.54 ------------ Accuracy: 75.6%\n",
            "Step: 1940 ------------ Loss: 6138.44 ------------ Accuracy: 75.7%\n",
            "Step: 1941 ------------ Loss: 6137.36 ------------ Accuracy: 75.8%\n",
            "Step: 1942 ------------ Loss: 6136.32 ------------ Accuracy: 75.8%\n",
            "Step: 1943 ------------ Loss: 6135.51 ------------ Accuracy: 75.7%\n",
            "Step: 1944 ------------ Loss: 6134.49 ------------ Accuracy: 75.7%\n",
            "Step: 1945 ------------ Loss: 6134.1 ------------ Accuracy: 75.6%\n",
            "Step: 1946 ------------ Loss: 6133.45 ------------ Accuracy: 75.6%\n",
            "Step: 1947 ------------ Loss: 6132.4 ------------ Accuracy: 75.7%\n",
            "Step: 1948 ------------ Loss: 6131.35 ------------ Accuracy: 75.8%\n",
            "Step: 1949 ------------ Loss: 6131.2 ------------ Accuracy: 75.9%\n",
            "Step: 1950 ------------ Loss: 6128.98 ------------ Accuracy: 75.8%\n",
            "Step: 1951 ------------ Loss: 6127.99 ------------ Accuracy: 75.9%\n",
            "Step: 1952 ------------ Loss: 6127.19 ------------ Accuracy: 75.8%\n",
            "Step: 1953 ------------ Loss: 6126.19 ------------ Accuracy: 75.9%\n",
            "Step: 1954 ------------ Loss: 6124.18 ------------ Accuracy: 75.7%\n",
            "Step: 1955 ------------ Loss: 6123.43 ------------ Accuracy: 75.6%\n",
            "Step: 1956 ------------ Loss: 6122.33 ------------ Accuracy: 75.6%\n",
            "Step: 1957 ------------ Loss: 6121.71 ------------ Accuracy: 75.7%\n",
            "Step: 1958 ------------ Loss: 6120.49 ------------ Accuracy: 75.7%\n",
            "Step: 1959 ------------ Loss: 6119.48 ------------ Accuracy: 75.7%\n",
            "Step: 1960 ------------ Loss: 6118.42 ------------ Accuracy: 75.7%\n",
            "Step: 1961 ------------ Loss: 6118.23 ------------ Accuracy: 75.7%\n",
            "Step: 1962 ------------ Loss: 6118.05 ------------ Accuracy: 75.7%\n",
            "Step: 1963 ------------ Loss: 6117.89 ------------ Accuracy: 75.6%\n",
            "Step: 1964 ------------ Loss: 6116.87 ------------ Accuracy: 75.7%\n",
            "Step: 1965 ------------ Loss: 6116.5 ------------ Accuracy: 75.6%\n",
            "Step: 1966 ------------ Loss: 6115.49 ------------ Accuracy: 75.7%\n",
            "Step: 1967 ------------ Loss: 6114.47 ------------ Accuracy: 75.8%\n",
            "Step: 1968 ------------ Loss: 6113.85 ------------ Accuracy: 75.8%\n",
            "Step: 1969 ------------ Loss: 6113.23 ------------ Accuracy: 75.9%\n",
            "Step: 1970 ------------ Loss: 6112.23 ------------ Accuracy: 75.9%\n",
            "Step: 1971 ------------ Loss: 6111.19 ------------ Accuracy: 76.0%\n",
            "Step: 1972 ------------ Loss: 6110.11 ------------ Accuracy: 76.0%\n",
            "Step: 1973 ------------ Loss: 6109.12 ------------ Accuracy: 76.1%\n",
            "Step: 1974 ------------ Loss: 6108.1 ------------ Accuracy: 76.2%\n",
            "Step: 1975 ------------ Loss: 6107.95 ------------ Accuracy: 76.1%\n",
            "Step: 1976 ------------ Loss: 6107.57 ------------ Accuracy: 76.1%\n",
            "Step: 1977 ------------ Loss: 6106.35 ------------ Accuracy: 76.0%\n",
            "Step: 1978 ------------ Loss: 6104.19 ------------ Accuracy: 76.0%\n",
            "Step: 1979 ------------ Loss: 6102.09 ------------ Accuracy: 75.9%\n",
            "Step: 1980 ------------ Loss: 6100.04 ------------ Accuracy: 75.9%\n",
            "Step: 1981 ------------ Loss: 6099.88 ------------ Accuracy: 75.9%\n",
            "Step: 1982 ------------ Loss: 6099.27 ------------ Accuracy: 75.9%\n",
            "Step: 1983 ------------ Loss: 6098.29 ------------ Accuracy: 76.0%\n",
            "Step: 1984 ------------ Loss: 6097.16 ------------ Accuracy: 76.0%\n",
            "Step: 1985 ------------ Loss: 6096.53 ------------ Accuracy: 76.0%\n",
            "Step: 1986 ------------ Loss: 6096.18 ------------ Accuracy: 76.0%\n",
            "Step: 1987 ------------ Loss: 6095.39 ------------ Accuracy: 75.9%\n",
            "Step: 1988 ------------ Loss: 6095.23 ------------ Accuracy: 75.9%\n",
            "Step: 1989 ------------ Loss: 6094.59 ------------ Accuracy: 76.0%\n",
            "Step: 1990 ------------ Loss: 6093.6 ------------ Accuracy: 76.0%\n",
            "Step: 1991 ------------ Loss: 6092.61 ------------ Accuracy: 76.1%\n",
            "Step: 1992 ------------ Loss: 6091.5 ------------ Accuracy: 76.1%\n",
            "Step: 1993 ------------ Loss: 6090.52 ------------ Accuracy: 76.3%\n",
            "Step: 1994 ------------ Loss: 6088.04 ------------ Accuracy: 76.0%\n",
            "Step: 1995 ------------ Loss: 6086.0 ------------ Accuracy: 76.0%\n",
            "Step: 1996 ------------ Loss: 6084.88 ------------ Accuracy: 76.0%\n",
            "Step: 1997 ------------ Loss: 6083.9 ------------ Accuracy: 76.1%\n",
            "Step: 1998 ------------ Loss: 6083.74 ------------ Accuracy: 76.1%\n",
            "Step: 1999 ------------ Loss: 6082.54 ------------ Accuracy: 76.0%\n",
            "Step: 2000 ------------ Loss: 6081.91 ------------ Accuracy: 76.1%\n",
            "Step: 2001 ------------ Loss: 6080.89 ------------ Accuracy: 76.1%\n",
            "Step: 2002 ------------ Loss: 6079.93 ------------ Accuracy: 76.2%\n",
            "Step: 2003 ------------ Loss: 6078.95 ------------ Accuracy: 76.3%\n",
            "Step: 2004 ------------ Loss: 6078.36 ------------ Accuracy: 76.3%\n",
            "Step: 2005 ------------ Loss: 6077.4 ------------ Accuracy: 76.3%\n",
            "Step: 2006 ------------ Loss: 6076.61 ------------ Accuracy: 76.2%\n",
            "Step: 2007 ------------ Loss: 6074.76 ------------ Accuracy: 76.3%\n",
            "Step: 2008 ------------ Loss: 6073.76 ------------ Accuracy: 76.3%\n",
            "Step: 2009 ------------ Loss: 6073.15 ------------ Accuracy: 76.3%\n",
            "Step: 2010 ------------ Loss: 6072.56 ------------ Accuracy: 76.3%\n",
            "Step: 2011 ------------ Loss: 6071.57 ------------ Accuracy: 76.3%\n",
            "Step: 2012 ------------ Loss: 6070.61 ------------ Accuracy: 76.4%\n",
            "Step: 2013 ------------ Loss: 6070.03 ------------ Accuracy: 76.4%\n",
            "Step: 2014 ------------ Loss: 6069.25 ------------ Accuracy: 76.3%\n",
            "Step: 2015 ------------ Loss: 6068.3 ------------ Accuracy: 76.4%\n",
            "Step: 2016 ------------ Loss: 6067.91 ------------ Accuracy: 76.4%\n",
            "Step: 2017 ------------ Loss: 6067.16 ------------ Accuracy: 76.4%\n",
            "Step: 2018 ------------ Loss: 6064.8 ------------ Accuracy: 76.2%\n",
            "Step: 2019 ------------ Loss: 6064.65 ------------ Accuracy: 76.2%\n",
            "Step: 2020 ------------ Loss: 6063.64 ------------ Accuracy: 76.2%\n",
            "Step: 2021 ------------ Loss: 6063.49 ------------ Accuracy: 76.2%\n",
            "Step: 2022 ------------ Loss: 6062.48 ------------ Accuracy: 76.3%\n",
            "Step: 2023 ------------ Loss: 6061.32 ------------ Accuracy: 76.3%\n",
            "Step: 2024 ------------ Loss: 6059.59 ------------ Accuracy: 76.3%\n",
            "Step: 2025 ------------ Loss: 6057.63 ------------ Accuracy: 76.2%\n",
            "Step: 2026 ------------ Loss: 6056.91 ------------ Accuracy: 76.2%\n",
            "Step: 2027 ------------ Loss: 6056.8 ------------ Accuracy: 76.2%\n",
            "Step: 2028 ------------ Loss: 6055.83 ------------ Accuracy: 76.3%\n",
            "Step: 2029 ------------ Loss: 6055.23 ------------ Accuracy: 76.3%\n",
            "Step: 2030 ------------ Loss: 6053.31 ------------ Accuracy: 76.3%\n",
            "Step: 2031 ------------ Loss: 6052.09 ------------ Accuracy: 76.3%\n",
            "Step: 2032 ------------ Loss: 6050.87 ------------ Accuracy: 76.2%\n",
            "Step: 2033 ------------ Loss: 6049.7 ------------ Accuracy: 76.3%\n",
            "Step: 2034 ------------ Loss: 6049.58 ------------ Accuracy: 76.3%\n",
            "Step: 2035 ------------ Loss: 6048.41 ------------ Accuracy: 76.3%\n",
            "Step: 2036 ------------ Loss: 6046.73 ------------ Accuracy: 76.2%\n",
            "Step: 2037 ------------ Loss: 6044.53 ------------ Accuracy: 76.0%\n",
            "Step: 2038 ------------ Loss: 6043.93 ------------ Accuracy: 76.0%\n",
            "Step: 2039 ------------ Loss: 6042.94 ------------ Accuracy: 76.1%\n",
            "Step: 2040 ------------ Loss: 6041.74 ------------ Accuracy: 76.2%\n",
            "Step: 2041 ------------ Loss: 6040.77 ------------ Accuracy: 76.2%\n",
            "Step: 2042 ------------ Loss: 6039.75 ------------ Accuracy: 76.3%\n",
            "Step: 2043 ------------ Loss: 6037.86 ------------ Accuracy: 76.2%\n",
            "Step: 2044 ------------ Loss: 6037.16 ------------ Accuracy: 76.2%\n",
            "Step: 2045 ------------ Loss: 6035.97 ------------ Accuracy: 76.2%\n",
            "Step: 2046 ------------ Loss: 6035.8 ------------ Accuracy: 76.3%\n",
            "Step: 2047 ------------ Loss: 6034.83 ------------ Accuracy: 76.3%\n",
            "Step: 2048 ------------ Loss: 6033.83 ------------ Accuracy: 76.4%\n",
            "Step: 2049 ------------ Loss: 6033.15 ------------ Accuracy: 76.4%\n",
            "Step: 2050 ------------ Loss: 6033.04 ------------ Accuracy: 76.4%\n",
            "Step: 2051 ------------ Loss: 6031.87 ------------ Accuracy: 76.4%\n",
            "Step: 2052 ------------ Loss: 6030.92 ------------ Accuracy: 76.4%\n",
            "Step: 2053 ------------ Loss: 6029.98 ------------ Accuracy: 76.5%\n",
            "Step: 2054 ------------ Loss: 6029.34 ------------ Accuracy: 76.4%\n",
            "Step: 2055 ------------ Loss: 6028.35 ------------ Accuracy: 76.5%\n",
            "Step: 2056 ------------ Loss: 6027.23 ------------ Accuracy: 76.5%\n",
            "Step: 2057 ------------ Loss: 6026.62 ------------ Accuracy: 76.4%\n",
            "Step: 2058 ------------ Loss: 6025.47 ------------ Accuracy: 76.4%\n",
            "Step: 2059 ------------ Loss: 6023.72 ------------ Accuracy: 76.3%\n",
            "Step: 2060 ------------ Loss: 6022.59 ------------ Accuracy: 76.4%\n",
            "Step: 2061 ------------ Loss: 6022.0 ------------ Accuracy: 76.4%\n",
            "Step: 2062 ------------ Loss: 6020.9 ------------ Accuracy: 76.4%\n",
            "Step: 2063 ------------ Loss: 6020.78 ------------ Accuracy: 76.4%\n",
            "Step: 2064 ------------ Loss: 6020.37 ------------ Accuracy: 76.4%\n",
            "Step: 2065 ------------ Loss: 6019.78 ------------ Accuracy: 76.4%\n",
            "Step: 2066 ------------ Loss: 6017.58 ------------ Accuracy: 76.2%\n",
            "Step: 2067 ------------ Loss: 6016.59 ------------ Accuracy: 76.2%\n",
            "Step: 2068 ------------ Loss: 6016.04 ------------ Accuracy: 76.2%\n",
            "Step: 2069 ------------ Loss: 6015.44 ------------ Accuracy: 76.2%\n",
            "Step: 2070 ------------ Loss: 6015.34 ------------ Accuracy: 76.3%\n",
            "Step: 2071 ------------ Loss: 6014.36 ------------ Accuracy: 76.3%\n",
            "Step: 2072 ------------ Loss: 6014.19 ------------ Accuracy: 76.4%\n",
            "Step: 2073 ------------ Loss: 6013.59 ------------ Accuracy: 76.4%\n",
            "Step: 2074 ------------ Loss: 6012.49 ------------ Accuracy: 76.3%\n",
            "Step: 2075 ------------ Loss: 6012.38 ------------ Accuracy: 76.3%\n",
            "Step: 2076 ------------ Loss: 6011.27 ------------ Accuracy: 76.3%\n",
            "Step: 2077 ------------ Loss: 6010.23 ------------ Accuracy: 76.4%\n",
            "Step: 2078 ------------ Loss: 6009.14 ------------ Accuracy: 76.4%\n",
            "Step: 2079 ------------ Loss: 6008.74 ------------ Accuracy: 76.4%\n",
            "Step: 2080 ------------ Loss: 6008.59 ------------ Accuracy: 76.5%\n",
            "Step: 2081 ------------ Loss: 6008.04 ------------ Accuracy: 76.5%\n",
            "Step: 2082 ------------ Loss: 6007.06 ------------ Accuracy: 76.5%\n",
            "Step: 2083 ------------ Loss: 6005.04 ------------ Accuracy: 76.5%\n",
            "Step: 2084 ------------ Loss: 6003.08 ------------ Accuracy: 76.4%\n",
            "Step: 2085 ------------ Loss: 6001.98 ------------ Accuracy: 76.3%\n",
            "Step: 2086 ------------ Loss: 6000.9 ------------ Accuracy: 76.3%\n",
            "Step: 2087 ------------ Loss: 5999.89 ------------ Accuracy: 76.3%\n",
            "Step: 2088 ------------ Loss: 5998.87 ------------ Accuracy: 76.4%\n",
            "Step: 2089 ------------ Loss: 5996.93 ------------ Accuracy: 76.4%\n",
            "Step: 2090 ------------ Loss: 5996.76 ------------ Accuracy: 76.4%\n",
            "Step: 2091 ------------ Loss: 5995.81 ------------ Accuracy: 76.5%\n",
            "Step: 2092 ------------ Loss: 5995.65 ------------ Accuracy: 76.5%\n",
            "Step: 2093 ------------ Loss: 5993.75 ------------ Accuracy: 76.5%\n",
            "Step: 2094 ------------ Loss: 5993.14 ------------ Accuracy: 76.5%\n",
            "Step: 2095 ------------ Loss: 5992.18 ------------ Accuracy: 76.5%\n",
            "Step: 2096 ------------ Loss: 5992.03 ------------ Accuracy: 76.5%\n",
            "Step: 2097 ------------ Loss: 5990.93 ------------ Accuracy: 76.6%\n",
            "Step: 2098 ------------ Loss: 5989.98 ------------ Accuracy: 76.7%\n",
            "Step: 2099 ------------ Loss: 5987.77 ------------ Accuracy: 76.4%\n",
            "Step: 2100 ------------ Loss: 5986.79 ------------ Accuracy: 76.6%\n",
            "Step: 2101 ------------ Loss: 5984.92 ------------ Accuracy: 76.5%\n",
            "Step: 2102 ------------ Loss: 5984.76 ------------ Accuracy: 76.6%\n",
            "Step: 2103 ------------ Loss: 5984.37 ------------ Accuracy: 76.6%\n",
            "Step: 2104 ------------ Loss: 5983.38 ------------ Accuracy: 76.6%\n",
            "Step: 2105 ------------ Loss: 5982.39 ------------ Accuracy: 76.7%\n",
            "Step: 2106 ------------ Loss: 5982.24 ------------ Accuracy: 76.7%\n",
            "Step: 2107 ------------ Loss: 5981.66 ------------ Accuracy: 76.7%\n",
            "Step: 2108 ------------ Loss: 5980.75 ------------ Accuracy: 76.8%\n",
            "Step: 2109 ------------ Loss: 5980.16 ------------ Accuracy: 76.8%\n",
            "Step: 2110 ------------ Loss: 5979.2 ------------ Accuracy: 76.8%\n",
            "Step: 2111 ------------ Loss: 5979.07 ------------ Accuracy: 76.9%\n",
            "Step: 2112 ------------ Loss: 5978.12 ------------ Accuracy: 77.0%\n",
            "Step: 2113 ------------ Loss: 5977.53 ------------ Accuracy: 77.0%\n",
            "Step: 2114 ------------ Loss: 5977.14 ------------ Accuracy: 77.0%\n",
            "Step: 2115 ------------ Loss: 5976.56 ------------ Accuracy: 77.0%\n",
            "Step: 2116 ------------ Loss: 5975.61 ------------ Accuracy: 77.0%\n",
            "Step: 2117 ------------ Loss: 5974.52 ------------ Accuracy: 77.1%\n",
            "Step: 2118 ------------ Loss: 5972.64 ------------ Accuracy: 77.0%\n",
            "Step: 2119 ------------ Loss: 5971.56 ------------ Accuracy: 77.1%\n",
            "Step: 2120 ------------ Loss: 5970.51 ------------ Accuracy: 77.1%\n",
            "Step: 2121 ------------ Loss: 5969.62 ------------ Accuracy: 77.2%\n",
            "Step: 2122 ------------ Loss: 5968.73 ------------ Accuracy: 77.3%\n",
            "Step: 2123 ------------ Loss: 5967.59 ------------ Accuracy: 77.2%\n",
            "Step: 2124 ------------ Loss: 5966.66 ------------ Accuracy: 77.2%\n",
            "Step: 2125 ------------ Loss: 5965.54 ------------ Accuracy: 77.1%\n",
            "Step: 2126 ------------ Loss: 5965.41 ------------ Accuracy: 77.1%\n",
            "Step: 2127 ------------ Loss: 5964.86 ------------ Accuracy: 77.2%\n",
            "Step: 2128 ------------ Loss: 5964.47 ------------ Accuracy: 77.2%\n",
            "Step: 2129 ------------ Loss: 5963.58 ------------ Accuracy: 77.2%\n",
            "Step: 2130 ------------ Loss: 5963.01 ------------ Accuracy: 77.2%\n",
            "Step: 2131 ------------ Loss: 5962.1 ------------ Accuracy: 77.3%\n",
            "Step: 2132 ------------ Loss: 5961.98 ------------ Accuracy: 77.3%\n",
            "Step: 2133 ------------ Loss: 5961.41 ------------ Accuracy: 77.3%\n",
            "Step: 2134 ------------ Loss: 5960.39 ------------ Accuracy: 77.4%\n",
            "Step: 2135 ------------ Loss: 5958.46 ------------ Accuracy: 77.3%\n",
            "Step: 2136 ------------ Loss: 5957.9 ------------ Accuracy: 77.4%\n",
            "Step: 2137 ------------ Loss: 5957.35 ------------ Accuracy: 77.4%\n",
            "Step: 2138 ------------ Loss: 5956.23 ------------ Accuracy: 77.3%\n",
            "Step: 2139 ------------ Loss: 5955.34 ------------ Accuracy: 77.4%\n",
            "Step: 2140 ------------ Loss: 5954.43 ------------ Accuracy: 77.4%\n",
            "Step: 2141 ------------ Loss: 5953.67 ------------ Accuracy: 77.3%\n",
            "Step: 2142 ------------ Loss: 5952.75 ------------ Accuracy: 77.4%\n",
            "Step: 2143 ------------ Loss: 5951.85 ------------ Accuracy: 77.5%\n",
            "Step: 2144 ------------ Loss: 5950.85 ------------ Accuracy: 77.6%\n",
            "Step: 2145 ------------ Loss: 5949.97 ------------ Accuracy: 77.6%\n",
            "Step: 2146 ------------ Loss: 5949.42 ------------ Accuracy: 77.7%\n",
            "Step: 2147 ------------ Loss: 5948.57 ------------ Accuracy: 77.7%\n",
            "Step: 2148 ------------ Loss: 5946.75 ------------ Accuracy: 77.5%\n",
            "Step: 2149 ------------ Loss: 5946.54 ------------ Accuracy: 77.5%\n",
            "Step: 2150 ------------ Loss: 5945.68 ------------ Accuracy: 77.6%\n",
            "Step: 2151 ------------ Loss: 5944.84 ------------ Accuracy: 77.6%\n",
            "Step: 2152 ------------ Loss: 5944.44 ------------ Accuracy: 77.6%\n",
            "Step: 2153 ------------ Loss: 5943.56 ------------ Accuracy: 77.7%\n",
            "Step: 2154 ------------ Loss: 5943.01 ------------ Accuracy: 77.7%\n",
            "Step: 2155 ------------ Loss: 5941.97 ------------ Accuracy: 77.8%\n",
            "Step: 2156 ------------ Loss: 5941.13 ------------ Accuracy: 77.8%\n",
            "Step: 2157 ------------ Loss: 5940.25 ------------ Accuracy: 77.9%\n",
            "Step: 2158 ------------ Loss: 5939.24 ------------ Accuracy: 77.9%\n",
            "Step: 2159 ------------ Loss: 5938.37 ------------ Accuracy: 78.0%\n",
            "Step: 2160 ------------ Loss: 5937.39 ------------ Accuracy: 78.0%\n",
            "Step: 2161 ------------ Loss: 5934.94 ------------ Accuracy: 77.8%\n",
            "Step: 2162 ------------ Loss: 5933.04 ------------ Accuracy: 77.7%\n",
            "Step: 2163 ------------ Loss: 5932.2 ------------ Accuracy: 77.8%\n",
            "Step: 2164 ------------ Loss: 5931.67 ------------ Accuracy: 77.8%\n",
            "Step: 2165 ------------ Loss: 5931.44 ------------ Accuracy: 77.8%\n",
            "Step: 2166 ------------ Loss: 5930.9 ------------ Accuracy: 77.8%\n",
            "Step: 2167 ------------ Loss: 5929.77 ------------ Accuracy: 77.7%\n",
            "Step: 2168 ------------ Loss: 5928.89 ------------ Accuracy: 77.8%\n",
            "Step: 2169 ------------ Loss: 5928.35 ------------ Accuracy: 77.8%\n",
            "Step: 2170 ------------ Loss: 5927.81 ------------ Accuracy: 77.9%\n",
            "Step: 2171 ------------ Loss: 5927.27 ------------ Accuracy: 77.9%\n",
            "Step: 2172 ------------ Loss: 5926.45 ------------ Accuracy: 77.9%\n",
            "Step: 2173 ------------ Loss: 5925.6 ------------ Accuracy: 78.0%\n",
            "Step: 2174 ------------ Loss: 5924.48 ------------ Accuracy: 77.9%\n",
            "Step: 2175 ------------ Loss: 5923.65 ------------ Accuracy: 78.0%\n",
            "Step: 2176 ------------ Loss: 5923.13 ------------ Accuracy: 78.0%\n",
            "Step: 2177 ------------ Loss: 5922.88 ------------ Accuracy: 77.9%\n",
            "Step: 2178 ------------ Loss: 5922.1 ------------ Accuracy: 77.9%\n",
            "Step: 2179 ------------ Loss: 5921.26 ------------ Accuracy: 77.9%\n",
            "Step: 2180 ------------ Loss: 5920.53 ------------ Accuracy: 77.8%\n",
            "Step: 2181 ------------ Loss: 5919.51 ------------ Accuracy: 77.9%\n",
            "Step: 2182 ------------ Loss: 5918.67 ------------ Accuracy: 77.9%\n",
            "Step: 2183 ------------ Loss: 5917.83 ------------ Accuracy: 78.0%\n",
            "Step: 2184 ------------ Loss: 5916.84 ------------ Accuracy: 78.0%\n",
            "Step: 2185 ------------ Loss: 5916.32 ------------ Accuracy: 78.0%\n",
            "Step: 2186 ------------ Loss: 5914.39 ------------ Accuracy: 78.0%\n",
            "Step: 2187 ------------ Loss: 5913.56 ------------ Accuracy: 78.0%\n",
            "Step: 2188 ------------ Loss: 5912.75 ------------ Accuracy: 78.0%\n",
            "Step: 2189 ------------ Loss: 5911.64 ------------ Accuracy: 78.0%\n",
            "Step: 2190 ------------ Loss: 5909.29 ------------ Accuracy: 77.9%\n",
            "Step: 2191 ------------ Loss: 5909.08 ------------ Accuracy: 77.9%\n",
            "Step: 2192 ------------ Loss: 5908.67 ------------ Accuracy: 77.9%\n",
            "Step: 2193 ------------ Loss: 5907.67 ------------ Accuracy: 77.9%\n",
            "Step: 2194 ------------ Loss: 5906.83 ------------ Accuracy: 78.0%\n",
            "Step: 2195 ------------ Loss: 5906.69 ------------ Accuracy: 77.9%\n",
            "Step: 2196 ------------ Loss: 5906.49 ------------ Accuracy: 77.9%\n",
            "Step: 2197 ------------ Loss: 5905.49 ------------ Accuracy: 78.0%\n",
            "Step: 2198 ------------ Loss: 5904.52 ------------ Accuracy: 78.0%\n",
            "Step: 2199 ------------ Loss: 5903.67 ------------ Accuracy: 78.0%\n",
            "Step: 2200 ------------ Loss: 5902.84 ------------ Accuracy: 78.0%\n",
            "Step: 2201 ------------ Loss: 5902.31 ------------ Accuracy: 78.0%\n",
            "Step: 2202 ------------ Loss: 5901.47 ------------ Accuracy: 78.0%\n",
            "Step: 2203 ------------ Loss: 5900.64 ------------ Accuracy: 78.1%\n",
            "Step: 2204 ------------ Loss: 5900.23 ------------ Accuracy: 78.1%\n",
            "Step: 2205 ------------ Loss: 5899.4 ------------ Accuracy: 78.1%\n",
            "Step: 2206 ------------ Loss: 5898.57 ------------ Accuracy: 78.2%\n",
            "Step: 2207 ------------ Loss: 5898.45 ------------ Accuracy: 78.2%\n",
            "Step: 2208 ------------ Loss: 5897.63 ------------ Accuracy: 78.2%\n",
            "Step: 2209 ------------ Loss: 5895.81 ------------ Accuracy: 78.2%\n",
            "Step: 2210 ------------ Loss: 5895.29 ------------ Accuracy: 78.2%\n",
            "Step: 2211 ------------ Loss: 5894.78 ------------ Accuracy: 78.2%\n",
            "Step: 2212 ------------ Loss: 5893.97 ------------ Accuracy: 78.3%\n",
            "Step: 2213 ------------ Loss: 5892.99 ------------ Accuracy: 78.3%\n",
            "Step: 2214 ------------ Loss: 5892.5 ------------ Accuracy: 78.3%\n",
            "Step: 2215 ------------ Loss: 5890.14 ------------ Accuracy: 78.1%\n",
            "Step: 2216 ------------ Loss: 5889.33 ------------ Accuracy: 78.1%\n",
            "Step: 2217 ------------ Loss: 5888.34 ------------ Accuracy: 78.1%\n",
            "Step: 2218 ------------ Loss: 5887.97 ------------ Accuracy: 78.1%\n",
            "Step: 2219 ------------ Loss: 5887.84 ------------ Accuracy: 78.1%\n",
            "Step: 2220 ------------ Loss: 5887.03 ------------ Accuracy: 78.2%\n",
            "Step: 2221 ------------ Loss: 5886.21 ------------ Accuracy: 78.3%\n",
            "Step: 2222 ------------ Loss: 5884.48 ------------ Accuracy: 78.2%\n",
            "Step: 2223 ------------ Loss: 5883.38 ------------ Accuracy: 78.1%\n",
            "Step: 2224 ------------ Loss: 5882.3 ------------ Accuracy: 78.0%\n",
            "Step: 2225 ------------ Loss: 5880.65 ------------ Accuracy: 78.0%\n",
            "Step: 2226 ------------ Loss: 5879.82 ------------ Accuracy: 78.0%\n",
            "Step: 2227 ------------ Loss: 5878.79 ------------ Accuracy: 78.0%\n",
            "Step: 2228 ------------ Loss: 5877.79 ------------ Accuracy: 78.1%\n",
            "Step: 2229 ------------ Loss: 5877.56 ------------ Accuracy: 78.1%\n",
            "Step: 2230 ------------ Loss: 5877.06 ------------ Accuracy: 78.1%\n",
            "Step: 2231 ------------ Loss: 5876.56 ------------ Accuracy: 78.1%\n",
            "Step: 2232 ------------ Loss: 5876.06 ------------ Accuracy: 78.2%\n",
            "Step: 2233 ------------ Loss: 5875.08 ------------ Accuracy: 78.2%\n",
            "Step: 2234 ------------ Loss: 5874.27 ------------ Accuracy: 78.2%\n",
            "Step: 2235 ------------ Loss: 5873.44 ------------ Accuracy: 78.3%\n",
            "Step: 2236 ------------ Loss: 5872.48 ------------ Accuracy: 78.4%\n",
            "Step: 2237 ------------ Loss: 5871.68 ------------ Accuracy: 78.4%\n",
            "Step: 2238 ------------ Loss: 5871.43 ------------ Accuracy: 78.3%\n",
            "Step: 2239 ------------ Loss: 5871.07 ------------ Accuracy: 78.3%\n",
            "Step: 2240 ------------ Loss: 5870.27 ------------ Accuracy: 78.4%\n",
            "Step: 2241 ------------ Loss: 5868.41 ------------ Accuracy: 78.3%\n",
            "Step: 2242 ------------ Loss: 5866.6 ------------ Accuracy: 78.3%\n",
            "Step: 2243 ------------ Loss: 5865.6 ------------ Accuracy: 78.4%\n",
            "Step: 2244 ------------ Loss: 5863.82 ------------ Accuracy: 78.3%\n",
            "Step: 2245 ------------ Loss: 5863.68 ------------ Accuracy: 78.3%\n",
            "Step: 2246 ------------ Loss: 5861.93 ------------ Accuracy: 78.2%\n",
            "Step: 2247 ------------ Loss: 5860.23 ------------ Accuracy: 78.2%\n",
            "Step: 2248 ------------ Loss: 5860.04 ------------ Accuracy: 78.2%\n",
            "Step: 2249 ------------ Loss: 5857.87 ------------ Accuracy: 78.0%\n",
            "Step: 2250 ------------ Loss: 5856.8 ------------ Accuracy: 78.1%\n",
            "Step: 2251 ------------ Loss: 5856.3 ------------ Accuracy: 78.1%\n",
            "Step: 2252 ------------ Loss: 5855.97 ------------ Accuracy: 78.0%\n",
            "Step: 2253 ------------ Loss: 5855.67 ------------ Accuracy: 78.1%\n",
            "Step: 2254 ------------ Loss: 5853.62 ------------ Accuracy: 77.9%\n",
            "Step: 2255 ------------ Loss: 5852.77 ------------ Accuracy: 78.0%\n",
            "Step: 2256 ------------ Loss: 5851.9 ------------ Accuracy: 78.0%\n",
            "Step: 2257 ------------ Loss: 5851.39 ------------ Accuracy: 78.0%\n",
            "Step: 2258 ------------ Loss: 5850.34 ------------ Accuracy: 78.1%\n",
            "Step: 2259 ------------ Loss: 5849.28 ------------ Accuracy: 78.1%\n",
            "Step: 2260 ------------ Loss: 5848.26 ------------ Accuracy: 78.1%\n",
            "Step: 2261 ------------ Loss: 5847.26 ------------ Accuracy: 78.2%\n",
            "Step: 2262 ------------ Loss: 5847.06 ------------ Accuracy: 78.2%\n",
            "Step: 2263 ------------ Loss: 5846.53 ------------ Accuracy: 78.2%\n",
            "Step: 2264 ------------ Loss: 5845.69 ------------ Accuracy: 78.3%\n",
            "Step: 2265 ------------ Loss: 5845.41 ------------ Accuracy: 78.3%\n",
            "Step: 2266 ------------ Loss: 5844.43 ------------ Accuracy: 78.3%\n",
            "Step: 2267 ------------ Loss: 5843.65 ------------ Accuracy: 78.3%\n",
            "Step: 2268 ------------ Loss: 5842.69 ------------ Accuracy: 78.3%\n",
            "Step: 2269 ------------ Loss: 5840.92 ------------ Accuracy: 78.3%\n",
            "Step: 2270 ------------ Loss: 5840.41 ------------ Accuracy: 78.4%\n",
            "Step: 2271 ------------ Loss: 5839.59 ------------ Accuracy: 78.4%\n",
            "Step: 2272 ------------ Loss: 5838.64 ------------ Accuracy: 78.4%\n",
            "Step: 2273 ------------ Loss: 5837.71 ------------ Accuracy: 78.4%\n",
            "Step: 2274 ------------ Loss: 5836.94 ------------ Accuracy: 78.3%\n",
            "Step: 2275 ------------ Loss: 5836.03 ------------ Accuracy: 78.3%\n",
            "Step: 2276 ------------ Loss: 5835.19 ------------ Accuracy: 78.4%\n",
            "Step: 2277 ------------ Loss: 5833.41 ------------ Accuracy: 78.4%\n",
            "Step: 2278 ------------ Loss: 5832.5 ------------ Accuracy: 78.4%\n",
            "Step: 2279 ------------ Loss: 5830.75 ------------ Accuracy: 78.4%\n",
            "Step: 2280 ------------ Loss: 5829.9 ------------ Accuracy: 78.4%\n",
            "Step: 2281 ------------ Loss: 5829.08 ------------ Accuracy: 78.5%\n",
            "Step: 2282 ------------ Loss: 5827.43 ------------ Accuracy: 78.5%\n",
            "Step: 2283 ------------ Loss: 5825.88 ------------ Accuracy: 78.3%\n",
            "Step: 2284 ------------ Loss: 5825.72 ------------ Accuracy: 78.3%\n",
            "Step: 2285 ------------ Loss: 5824.92 ------------ Accuracy: 78.4%\n",
            "Step: 2286 ------------ Loss: 5824.12 ------------ Accuracy: 78.4%\n",
            "Step: 2287 ------------ Loss: 5823.36 ------------ Accuracy: 78.4%\n",
            "Step: 2288 ------------ Loss: 5822.5 ------------ Accuracy: 78.4%\n",
            "Step: 2289 ------------ Loss: 5821.65 ------------ Accuracy: 78.4%\n",
            "Step: 2290 ------------ Loss: 5820.92 ------------ Accuracy: 78.4%\n",
            "Step: 2291 ------------ Loss: 5820.1 ------------ Accuracy: 78.4%\n",
            "Step: 2292 ------------ Loss: 5818.64 ------------ Accuracy: 78.3%\n",
            "Step: 2293 ------------ Loss: 5817.84 ------------ Accuracy: 78.4%\n",
            "Step: 2294 ------------ Loss: 5816.77 ------------ Accuracy: 78.3%\n",
            "Step: 2295 ------------ Loss: 5815.39 ------------ Accuracy: 78.2%\n",
            "Step: 2296 ------------ Loss: 5814.53 ------------ Accuracy: 78.3%\n",
            "Step: 2297 ------------ Loss: 5813.66 ------------ Accuracy: 78.3%\n",
            "Step: 2298 ------------ Loss: 5813.34 ------------ Accuracy: 78.3%\n",
            "Step: 2299 ------------ Loss: 5812.27 ------------ Accuracy: 78.2%\n",
            "Step: 2300 ------------ Loss: 5812.14 ------------ Accuracy: 78.2%\n",
            "Step: 2301 ------------ Loss: 5810.83 ------------ Accuracy: 78.3%\n",
            "Step: 2302 ------------ Loss: 5809.74 ------------ Accuracy: 78.2%\n",
            "Step: 2303 ------------ Loss: 5808.68 ------------ Accuracy: 78.3%\n",
            "Step: 2304 ------------ Loss: 5807.81 ------------ Accuracy: 78.3%\n",
            "Step: 2305 ------------ Loss: 5806.79 ------------ Accuracy: 78.4%\n",
            "Step: 2306 ------------ Loss: 5806.65 ------------ Accuracy: 78.4%\n",
            "Step: 2307 ------------ Loss: 5806.51 ------------ Accuracy: 78.4%\n",
            "Step: 2308 ------------ Loss: 5806.38 ------------ Accuracy: 78.4%\n",
            "Step: 2309 ------------ Loss: 5806.26 ------------ Accuracy: 78.5%\n",
            "Step: 2310 ------------ Loss: 5805.46 ------------ Accuracy: 78.5%\n",
            "Step: 2311 ------------ Loss: 5804.93 ------------ Accuracy: 78.5%\n",
            "Step: 2312 ------------ Loss: 5803.32 ------------ Accuracy: 78.5%\n",
            "Step: 2313 ------------ Loss: 5802.62 ------------ Accuracy: 78.4%\n",
            "Step: 2314 ------------ Loss: 5800.62 ------------ Accuracy: 78.3%\n",
            "Step: 2315 ------------ Loss: 5799.34 ------------ Accuracy: 78.2%\n",
            "Step: 2316 ------------ Loss: 5798.68 ------------ Accuracy: 78.2%\n",
            "Step: 2317 ------------ Loss: 5797.59 ------------ Accuracy: 78.3%\n",
            "Step: 2318 ------------ Loss: 5796.78 ------------ Accuracy: 78.2%\n",
            "Step: 2319 ------------ Loss: 5796.15 ------------ Accuracy: 78.2%\n",
            "Step: 2320 ------------ Loss: 5795.27 ------------ Accuracy: 78.3%\n",
            "Step: 2321 ------------ Loss: 5793.36 ------------ Accuracy: 78.1%\n",
            "Step: 2322 ------------ Loss: 5792.82 ------------ Accuracy: 78.1%\n",
            "Step: 2323 ------------ Loss: 5792.0 ------------ Accuracy: 78.1%\n",
            "Step: 2324 ------------ Loss: 5791.85 ------------ Accuracy: 78.1%\n",
            "Step: 2325 ------------ Loss: 5790.96 ------------ Accuracy: 78.2%\n",
            "Step: 2326 ------------ Loss: 5790.07 ------------ Accuracy: 78.3%\n",
            "Step: 2327 ------------ Loss: 5789.04 ------------ Accuracy: 78.2%\n",
            "Step: 2328 ------------ Loss: 5788.53 ------------ Accuracy: 78.2%\n",
            "Step: 2329 ------------ Loss: 5788.43 ------------ Accuracy: 78.3%\n",
            "Step: 2330 ------------ Loss: 5787.92 ------------ Accuracy: 78.3%\n",
            "Step: 2331 ------------ Loss: 5786.05 ------------ Accuracy: 78.2%\n",
            "Step: 2332 ------------ Loss: 5785.24 ------------ Accuracy: 78.2%\n",
            "Step: 2333 ------------ Loss: 5784.43 ------------ Accuracy: 78.2%\n",
            "Step: 2334 ------------ Loss: 5783.55 ------------ Accuracy: 78.2%\n",
            "Step: 2335 ------------ Loss: 5782.31 ------------ Accuracy: 78.3%\n",
            "Step: 2336 ------------ Loss: 5781.68 ------------ Accuracy: 78.2%\n",
            "Step: 2337 ------------ Loss: 5779.9 ------------ Accuracy: 78.1%\n",
            "Step: 2338 ------------ Loss: 5779.0 ------------ Accuracy: 78.1%\n",
            "Step: 2339 ------------ Loss: 5778.49 ------------ Accuracy: 78.1%\n",
            "Step: 2340 ------------ Loss: 5777.58 ------------ Accuracy: 78.1%\n",
            "Step: 2341 ------------ Loss: 5776.69 ------------ Accuracy: 78.2%\n",
            "Step: 2342 ------------ Loss: 5775.81 ------------ Accuracy: 78.3%\n",
            "Step: 2343 ------------ Loss: 5775.02 ------------ Accuracy: 78.3%\n",
            "Step: 2344 ------------ Loss: 5774.16 ------------ Accuracy: 78.3%\n",
            "Step: 2345 ------------ Loss: 5773.79 ------------ Accuracy: 78.4%\n",
            "Step: 2346 ------------ Loss: 5772.0 ------------ Accuracy: 78.3%\n",
            "Step: 2347 ------------ Loss: 5770.86 ------------ Accuracy: 78.2%\n",
            "Step: 2348 ------------ Loss: 5770.73 ------------ Accuracy: 78.3%\n",
            "Step: 2349 ------------ Loss: 5769.94 ------------ Accuracy: 78.3%\n",
            "Step: 2350 ------------ Loss: 5768.75 ------------ Accuracy: 78.4%\n",
            "Step: 2351 ------------ Loss: 5767.27 ------------ Accuracy: 78.3%\n",
            "Step: 2352 ------------ Loss: 5766.19 ------------ Accuracy: 78.3%\n",
            "Step: 2353 ------------ Loss: 5764.5 ------------ Accuracy: 78.1%\n",
            "Step: 2354 ------------ Loss: 5763.28 ------------ Accuracy: 78.2%\n",
            "Step: 2355 ------------ Loss: 5763.16 ------------ Accuracy: 78.3%\n",
            "Step: 2356 ------------ Loss: 5762.65 ------------ Accuracy: 78.3%\n",
            "Step: 2357 ------------ Loss: 5762.11 ------------ Accuracy: 78.3%\n",
            "Step: 2358 ------------ Loss: 5761.27 ------------ Accuracy: 78.3%\n",
            "Step: 2359 ------------ Loss: 5759.85 ------------ Accuracy: 78.3%\n",
            "Step: 2360 ------------ Loss: 5759.01 ------------ Accuracy: 78.3%\n",
            "Step: 2361 ------------ Loss: 5758.11 ------------ Accuracy: 78.4%\n",
            "Step: 2362 ------------ Loss: 5758.0 ------------ Accuracy: 78.4%\n",
            "Step: 2363 ------------ Loss: 5756.29 ------------ Accuracy: 78.2%\n",
            "Step: 2364 ------------ Loss: 5756.18 ------------ Accuracy: 78.3%\n",
            "Step: 2365 ------------ Loss: 5754.96 ------------ Accuracy: 78.4%\n",
            "Step: 2366 ------------ Loss: 5753.8 ------------ Accuracy: 78.4%\n",
            "Step: 2367 ------------ Loss: 5753.01 ------------ Accuracy: 78.5%\n",
            "Step: 2368 ------------ Loss: 5752.83 ------------ Accuracy: 78.5%\n",
            "Step: 2369 ------------ Loss: 5752.04 ------------ Accuracy: 78.5%\n",
            "Step: 2370 ------------ Loss: 5751.52 ------------ Accuracy: 78.5%\n",
            "Step: 2371 ------------ Loss: 5750.75 ------------ Accuracy: 78.5%\n",
            "Step: 2372 ------------ Loss: 5750.23 ------------ Accuracy: 78.5%\n",
            "Step: 2373 ------------ Loss: 5749.72 ------------ Accuracy: 78.6%\n",
            "Step: 2374 ------------ Loss: 5749.04 ------------ Accuracy: 78.5%\n",
            "Step: 2375 ------------ Loss: 5748.95 ------------ Accuracy: 78.6%\n",
            "Step: 2376 ------------ Loss: 5748.46 ------------ Accuracy: 78.6%\n",
            "Step: 2377 ------------ Loss: 5747.02 ------------ Accuracy: 78.5%\n",
            "Step: 2378 ------------ Loss: 5746.52 ------------ Accuracy: 78.6%\n",
            "Step: 2379 ------------ Loss: 5746.01 ------------ Accuracy: 78.6%\n",
            "Step: 2380 ------------ Loss: 5745.14 ------------ Accuracy: 78.6%\n",
            "Step: 2381 ------------ Loss: 5744.08 ------------ Accuracy: 78.6%\n",
            "Step: 2382 ------------ Loss: 5743.57 ------------ Accuracy: 78.6%\n",
            "Step: 2383 ------------ Loss: 5742.53 ------------ Accuracy: 78.5%\n",
            "Step: 2384 ------------ Loss: 5741.39 ------------ Accuracy: 78.5%\n",
            "Step: 2385 ------------ Loss: 5740.74 ------------ Accuracy: 78.5%\n",
            "Step: 2386 ------------ Loss: 5739.92 ------------ Accuracy: 78.5%\n",
            "Step: 2387 ------------ Loss: 5739.4 ------------ Accuracy: 78.5%\n",
            "Step: 2388 ------------ Loss: 5738.37 ------------ Accuracy: 78.5%\n",
            "Step: 2389 ------------ Loss: 5737.37 ------------ Accuracy: 78.4%\n",
            "Step: 2390 ------------ Loss: 5737.19 ------------ Accuracy: 78.4%\n",
            "Step: 2391 ------------ Loss: 5736.07 ------------ Accuracy: 78.5%\n",
            "Step: 2392 ------------ Loss: 5735.98 ------------ Accuracy: 78.5%\n",
            "Step: 2393 ------------ Loss: 5735.89 ------------ Accuracy: 78.6%\n",
            "Step: 2394 ------------ Loss: 5734.9 ------------ Accuracy: 78.6%\n",
            "Step: 2395 ------------ Loss: 5734.74 ------------ Accuracy: 78.6%\n",
            "Step: 2396 ------------ Loss: 5733.76 ------------ Accuracy: 78.5%\n",
            "Step: 2397 ------------ Loss: 5732.9 ------------ Accuracy: 78.6%\n",
            "Step: 2398 ------------ Loss: 5732.75 ------------ Accuracy: 78.6%\n",
            "Step: 2399 ------------ Loss: 5732.66 ------------ Accuracy: 78.6%\n",
            "Step: 2400 ------------ Loss: 5732.29 ------------ Accuracy: 78.7%\n",
            "Step: 2401 ------------ Loss: 5731.24 ------------ Accuracy: 78.7%\n",
            "Step: 2402 ------------ Loss: 5730.43 ------------ Accuracy: 78.7%\n",
            "Step: 2403 ------------ Loss: 5729.84 ------------ Accuracy: 78.7%\n",
            "Step: 2404 ------------ Loss: 5729.49 ------------ Accuracy: 78.7%\n",
            "Step: 2405 ------------ Loss: 5729.35 ------------ Accuracy: 78.7%\n",
            "Step: 2406 ------------ Loss: 5728.49 ------------ Accuracy: 78.8%\n",
            "Step: 2407 ------------ Loss: 5727.21 ------------ Accuracy: 78.8%\n",
            "Step: 2408 ------------ Loss: 5726.88 ------------ Accuracy: 78.9%\n",
            "Step: 2409 ------------ Loss: 5726.58 ------------ Accuracy: 78.8%\n",
            "Step: 2410 ------------ Loss: 5725.57 ------------ Accuracy: 78.9%\n",
            "Step: 2411 ------------ Loss: 5724.33 ------------ Accuracy: 78.8%\n",
            "Step: 2412 ------------ Loss: 5723.46 ------------ Accuracy: 78.8%\n",
            "Step: 2413 ------------ Loss: 5722.65 ------------ Accuracy: 78.9%\n",
            "Step: 2414 ------------ Loss: 5721.67 ------------ Accuracy: 78.9%\n",
            "Step: 2415 ------------ Loss: 5720.89 ------------ Accuracy: 78.9%\n",
            "Step: 2416 ------------ Loss: 5720.37 ------------ Accuracy: 78.9%\n",
            "Step: 2417 ------------ Loss: 5719.88 ------------ Accuracy: 78.9%\n",
            "Step: 2418 ------------ Loss: 5719.11 ------------ Accuracy: 79.0%\n",
            "Step: 2419 ------------ Loss: 5718.1 ------------ Accuracy: 79.0%\n",
            "Step: 2420 ------------ Loss: 5717.59 ------------ Accuracy: 79.0%\n",
            "Step: 2421 ------------ Loss: 5716.07 ------------ Accuracy: 79.0%\n",
            "Step: 2422 ------------ Loss: 5714.25 ------------ Accuracy: 78.8%\n",
            "Step: 2423 ------------ Loss: 5713.6 ------------ Accuracy: 78.8%\n",
            "Step: 2424 ------------ Loss: 5713.1 ------------ Accuracy: 78.9%\n",
            "Step: 2425 ------------ Loss: 5711.92 ------------ Accuracy: 78.8%\n",
            "Step: 2426 ------------ Loss: 5711.82 ------------ Accuracy: 78.8%\n",
            "Step: 2427 ------------ Loss: 5710.71 ------------ Accuracy: 78.8%\n",
            "Step: 2428 ------------ Loss: 5710.19 ------------ Accuracy: 78.8%\n",
            "Step: 2429 ------------ Loss: 5709.35 ------------ Accuracy: 78.9%\n",
            "Step: 2430 ------------ Loss: 5708.83 ------------ Accuracy: 78.9%\n",
            "Step: 2431 ------------ Loss: 5708.74 ------------ Accuracy: 79.0%\n",
            "Step: 2432 ------------ Loss: 5708.25 ------------ Accuracy: 79.0%\n",
            "Step: 2433 ------------ Loss: 5706.83 ------------ Accuracy: 78.9%\n",
            "Step: 2434 ------------ Loss: 5705.13 ------------ Accuracy: 78.7%\n",
            "Step: 2435 ------------ Loss: 5703.77 ------------ Accuracy: 78.7%\n",
            "Step: 2436 ------------ Loss: 5702.8 ------------ Accuracy: 78.6%\n",
            "Step: 2437 ------------ Loss: 5701.88 ------------ Accuracy: 78.6%\n",
            "Step: 2438 ------------ Loss: 5700.98 ------------ Accuracy: 78.8%\n",
            "Step: 2439 ------------ Loss: 5700.87 ------------ Accuracy: 78.8%\n",
            "Step: 2440 ------------ Loss: 5700.77 ------------ Accuracy: 78.8%\n",
            "Step: 2441 ------------ Loss: 5700.68 ------------ Accuracy: 78.8%\n",
            "Step: 2442 ------------ Loss: 5699.79 ------------ Accuracy: 78.9%\n",
            "Step: 2443 ------------ Loss: 5698.97 ------------ Accuracy: 79.0%\n",
            "Step: 2444 ------------ Loss: 5698.89 ------------ Accuracy: 79.0%\n",
            "Step: 2445 ------------ Loss: 5698.39 ------------ Accuracy: 79.0%\n",
            "Step: 2446 ------------ Loss: 5698.19 ------------ Accuracy: 79.0%\n",
            "Step: 2447 ------------ Loss: 5697.44 ------------ Accuracy: 79.0%\n",
            "Step: 2448 ------------ Loss: 5696.57 ------------ Accuracy: 79.1%\n",
            "Step: 2449 ------------ Loss: 5695.26 ------------ Accuracy: 79.1%\n",
            "Step: 2450 ------------ Loss: 5695.18 ------------ Accuracy: 79.1%\n",
            "Step: 2451 ------------ Loss: 5694.44 ------------ Accuracy: 79.2%\n",
            "Step: 2452 ------------ Loss: 5693.64 ------------ Accuracy: 79.2%\n",
            "Step: 2453 ------------ Loss: 5693.45 ------------ Accuracy: 79.2%\n",
            "Step: 2454 ------------ Loss: 5693.07 ------------ Accuracy: 79.2%\n",
            "Step: 2455 ------------ Loss: 5692.13 ------------ Accuracy: 79.2%\n",
            "Step: 2456 ------------ Loss: 5690.94 ------------ Accuracy: 79.2%\n",
            "Step: 2457 ------------ Loss: 5690.01 ------------ Accuracy: 79.2%\n",
            "Step: 2458 ------------ Loss: 5689.5 ------------ Accuracy: 79.2%\n",
            "Step: 2459 ------------ Loss: 5688.31 ------------ Accuracy: 79.2%\n",
            "Step: 2460 ------------ Loss: 5687.02 ------------ Accuracy: 79.2%\n",
            "Step: 2461 ------------ Loss: 5686.83 ------------ Accuracy: 79.1%\n",
            "Step: 2462 ------------ Loss: 5685.97 ------------ Accuracy: 79.2%\n",
            "Step: 2463 ------------ Loss: 5685.48 ------------ Accuracy: 79.3%\n",
            "Step: 2464 ------------ Loss: 5684.4 ------------ Accuracy: 79.2%\n",
            "Step: 2465 ------------ Loss: 5683.61 ------------ Accuracy: 79.2%\n",
            "Step: 2466 ------------ Loss: 5682.69 ------------ Accuracy: 79.2%\n",
            "Step: 2467 ------------ Loss: 5681.83 ------------ Accuracy: 79.2%\n",
            "Step: 2468 ------------ Loss: 5681.65 ------------ Accuracy: 79.2%\n",
            "Step: 2469 ------------ Loss: 5680.49 ------------ Accuracy: 79.3%\n",
            "Step: 2470 ------------ Loss: 5680.0 ------------ Accuracy: 79.3%\n",
            "Step: 2471 ------------ Loss: 5679.07 ------------ Accuracy: 79.2%\n",
            "Step: 2472 ------------ Loss: 5678.72 ------------ Accuracy: 79.2%\n",
            "Step: 2473 ------------ Loss: 5678.24 ------------ Accuracy: 79.2%\n",
            "Step: 2474 ------------ Loss: 5678.07 ------------ Accuracy: 79.3%\n",
            "Step: 2475 ------------ Loss: 5677.23 ------------ Accuracy: 79.3%\n",
            "Step: 2476 ------------ Loss: 5676.75 ------------ Accuracy: 79.3%\n",
            "Step: 2477 ------------ Loss: 5676.27 ------------ Accuracy: 79.4%\n",
            "Step: 2478 ------------ Loss: 5676.11 ------------ Accuracy: 79.4%\n",
            "Step: 2479 ------------ Loss: 5674.98 ------------ Accuracy: 79.5%\n",
            "Step: 2480 ------------ Loss: 5674.66 ------------ Accuracy: 79.4%\n",
            "Step: 2481 ------------ Loss: 5673.88 ------------ Accuracy: 79.5%\n",
            "Step: 2482 ------------ Loss: 5672.82 ------------ Accuracy: 79.4%\n",
            "Step: 2483 ------------ Loss: 5671.48 ------------ Accuracy: 79.4%\n",
            "Step: 2484 ------------ Loss: 5670.65 ------------ Accuracy: 79.5%\n",
            "Step: 2485 ------------ Loss: 5669.89 ------------ Accuracy: 79.5%\n",
            "Step: 2486 ------------ Loss: 5668.58 ------------ Accuracy: 79.4%\n",
            "Step: 2487 ------------ Loss: 5666.8 ------------ Accuracy: 79.2%\n",
            "Step: 2488 ------------ Loss: 5665.76 ------------ Accuracy: 79.1%\n",
            "Step: 2489 ------------ Loss: 5664.09 ------------ Accuracy: 79.0%\n",
            "Step: 2490 ------------ Loss: 5663.78 ------------ Accuracy: 79.1%\n",
            "Step: 2491 ------------ Loss: 5662.18 ------------ Accuracy: 78.9%\n",
            "Step: 2492 ------------ Loss: 5661.89 ------------ Accuracy: 79.0%\n",
            "Step: 2493 ------------ Loss: 5660.91 ------------ Accuracy: 79.0%\n",
            "Step: 2494 ------------ Loss: 5659.62 ------------ Accuracy: 78.9%\n",
            "Step: 2495 ------------ Loss: 5658.82 ------------ Accuracy: 79.0%\n",
            "Step: 2496 ------------ Loss: 5657.7 ------------ Accuracy: 79.0%\n",
            "Step: 2497 ------------ Loss: 5656.95 ------------ Accuracy: 79.1%\n",
            "Step: 2498 ------------ Loss: 5655.67 ------------ Accuracy: 79.0%\n",
            "Step: 2499 ------------ Loss: 5654.8 ------------ Accuracy: 79.1%\n",
            "Step: 2500 ------------ Loss: 5653.94 ------------ Accuracy: 79.1%\n",
            "Step: 2501 ------------ Loss: 5653.18 ------------ Accuracy: 79.1%\n",
            "Step: 2502 ------------ Loss: 5652.21 ------------ Accuracy: 79.0%\n",
            "Step: 2503 ------------ Loss: 5651.41 ------------ Accuracy: 79.1%\n",
            "Step: 2504 ------------ Loss: 5650.46 ------------ Accuracy: 79.0%\n",
            "Step: 2505 ------------ Loss: 5649.38 ------------ Accuracy: 79.1%\n",
            "Step: 2506 ------------ Loss: 5648.34 ------------ Accuracy: 79.2%\n",
            "Step: 2507 ------------ Loss: 5647.32 ------------ Accuracy: 79.2%\n",
            "Step: 2508 ------------ Loss: 5646.33 ------------ Accuracy: 79.3%\n",
            "Step: 2509 ------------ Loss: 5645.38 ------------ Accuracy: 79.3%\n",
            "Step: 2510 ------------ Loss: 5644.44 ------------ Accuracy: 79.4%\n",
            "Step: 2511 ------------ Loss: 5644.32 ------------ Accuracy: 79.4%\n",
            "Step: 2512 ------------ Loss: 5644.17 ------------ Accuracy: 79.4%\n",
            "Step: 2513 ------------ Loss: 5643.35 ------------ Accuracy: 79.4%\n",
            "Step: 2514 ------------ Loss: 5642.85 ------------ Accuracy: 79.5%\n",
            "Step: 2515 ------------ Loss: 5642.04 ------------ Accuracy: 79.5%\n",
            "Step: 2516 ------------ Loss: 5641.92 ------------ Accuracy: 79.6%\n",
            "Step: 2517 ------------ Loss: 5641.27 ------------ Accuracy: 79.6%\n",
            "Step: 2518 ------------ Loss: 5639.5 ------------ Accuracy: 79.4%\n",
            "Step: 2519 ------------ Loss: 5638.62 ------------ Accuracy: 79.3%\n",
            "Step: 2520 ------------ Loss: 5637.44 ------------ Accuracy: 79.3%\n",
            "Step: 2521 ------------ Loss: 5636.62 ------------ Accuracy: 79.3%\n",
            "Step: 2522 ------------ Loss: 5636.35 ------------ Accuracy: 79.4%\n",
            "Step: 2523 ------------ Loss: 5635.72 ------------ Accuracy: 79.4%\n",
            "Step: 2524 ------------ Loss: 5634.77 ------------ Accuracy: 79.5%\n",
            "Step: 2525 ------------ Loss: 5634.26 ------------ Accuracy: 79.5%\n",
            "Step: 2526 ------------ Loss: 5633.5 ------------ Accuracy: 79.4%\n",
            "Step: 2527 ------------ Loss: 5632.9 ------------ Accuracy: 79.4%\n",
            "Step: 2528 ------------ Loss: 5632.63 ------------ Accuracy: 79.5%\n",
            "Step: 2529 ------------ Loss: 5631.83 ------------ Accuracy: 79.5%\n",
            "Step: 2530 ------------ Loss: 5630.4 ------------ Accuracy: 79.5%\n",
            "Step: 2531 ------------ Loss: 5629.46 ------------ Accuracy: 79.5%\n",
            "Step: 2532 ------------ Loss: 5628.86 ------------ Accuracy: 79.5%\n",
            "Step: 2533 ------------ Loss: 5628.07 ------------ Accuracy: 79.6%\n",
            "Step: 2534 ------------ Loss: 5627.94 ------------ Accuracy: 79.6%\n",
            "Step: 2535 ------------ Loss: 5627.37 ------------ Accuracy: 79.5%\n",
            "Step: 2536 ------------ Loss: 5626.47 ------------ Accuracy: 79.6%\n",
            "Step: 2537 ------------ Loss: 5624.74 ------------ Accuracy: 79.4%\n",
            "Step: 2538 ------------ Loss: 5623.94 ------------ Accuracy: 79.4%\n",
            "Step: 2539 ------------ Loss: 5623.44 ------------ Accuracy: 79.4%\n",
            "Step: 2540 ------------ Loss: 5622.59 ------------ Accuracy: 79.4%\n",
            "Step: 2541 ------------ Loss: 5621.69 ------------ Accuracy: 79.5%\n",
            "Step: 2542 ------------ Loss: 5620.86 ------------ Accuracy: 79.5%\n",
            "Step: 2543 ------------ Loss: 5620.07 ------------ Accuracy: 79.6%\n",
            "Step: 2544 ------------ Loss: 5619.59 ------------ Accuracy: 79.6%\n",
            "Step: 2545 ------------ Loss: 5619.31 ------------ Accuracy: 79.6%\n",
            "Step: 2546 ------------ Loss: 5619.21 ------------ Accuracy: 79.6%\n",
            "Step: 2547 ------------ Loss: 5618.34 ------------ Accuracy: 79.7%\n",
            "Step: 2548 ------------ Loss: 5617.79 ------------ Accuracy: 79.7%\n",
            "Step: 2549 ------------ Loss: 5617.02 ------------ Accuracy: 79.7%\n",
            "Step: 2550 ------------ Loss: 5616.94 ------------ Accuracy: 79.8%\n",
            "Step: 2551 ------------ Loss: 5615.45 ------------ Accuracy: 79.7%\n",
            "Step: 2552 ------------ Loss: 5615.17 ------------ Accuracy: 79.7%\n",
            "Step: 2553 ------------ Loss: 5615.09 ------------ Accuracy: 79.7%\n",
            "Step: 2554 ------------ Loss: 5614.33 ------------ Accuracy: 79.8%\n",
            "Step: 2555 ------------ Loss: 5613.51 ------------ Accuracy: 79.8%\n",
            "Step: 2556 ------------ Loss: 5612.63 ------------ Accuracy: 79.8%\n",
            "Step: 2557 ------------ Loss: 5611.88 ------------ Accuracy: 79.9%\n",
            "Step: 2558 ------------ Loss: 5610.12 ------------ Accuracy: 79.7%\n",
            "Step: 2559 ------------ Loss: 5608.91 ------------ Accuracy: 79.7%\n",
            "Step: 2560 ------------ Loss: 5607.99 ------------ Accuracy: 79.7%\n",
            "Step: 2561 ------------ Loss: 5607.44 ------------ Accuracy: 79.7%\n",
            "Step: 2562 ------------ Loss: 5607.3 ------------ Accuracy: 79.8%\n",
            "Step: 2563 ------------ Loss: 5606.42 ------------ Accuracy: 79.8%\n",
            "Step: 2564 ------------ Loss: 5606.35 ------------ Accuracy: 79.8%\n",
            "Step: 2565 ------------ Loss: 5605.5 ------------ Accuracy: 79.7%\n",
            "Step: 2566 ------------ Loss: 5605.02 ------------ Accuracy: 79.8%\n",
            "Step: 2567 ------------ Loss: 5604.52 ------------ Accuracy: 79.8%\n",
            "Step: 2568 ------------ Loss: 5603.76 ------------ Accuracy: 79.8%\n",
            "Step: 2569 ------------ Loss: 5602.97 ------------ Accuracy: 79.8%\n",
            "Step: 2570 ------------ Loss: 5602.48 ------------ Accuracy: 79.9%\n",
            "Step: 2571 ------------ Loss: 5601.64 ------------ Accuracy: 79.8%\n",
            "Step: 2572 ------------ Loss: 5600.79 ------------ Accuracy: 79.8%\n",
            "Step: 2573 ------------ Loss: 5600.01 ------------ Accuracy: 79.8%\n",
            "Step: 2574 ------------ Loss: 5599.73 ------------ Accuracy: 79.9%\n",
            "Step: 2575 ------------ Loss: 5599.61 ------------ Accuracy: 79.9%\n",
            "Step: 2576 ------------ Loss: 5599.13 ------------ Accuracy: 79.9%\n",
            "Step: 2577 ------------ Loss: 5598.31 ------------ Accuracy: 79.9%\n",
            "Step: 2578 ------------ Loss: 5597.56 ------------ Accuracy: 79.9%\n",
            "Step: 2579 ------------ Loss: 5597.09 ------------ Accuracy: 79.9%\n",
            "Step: 2580 ------------ Loss: 5596.33 ------------ Accuracy: 80.0%\n",
            "Step: 2581 ------------ Loss: 5595.77 ------------ Accuracy: 80.0%\n",
            "Step: 2582 ------------ Loss: 5594.96 ------------ Accuracy: 80.0%\n",
            "Step: 2583 ------------ Loss: 5594.5 ------------ Accuracy: 80.1%\n",
            "Step: 2584 ------------ Loss: 5594.39 ------------ Accuracy: 80.0%\n",
            "Step: 2585 ------------ Loss: 5593.6 ------------ Accuracy: 80.0%\n",
            "Step: 2586 ------------ Loss: 5592.77 ------------ Accuracy: 80.0%\n",
            "Step: 2587 ------------ Loss: 5591.4 ------------ Accuracy: 80.0%\n",
            "Step: 2588 ------------ Loss: 5590.57 ------------ Accuracy: 79.9%\n",
            "Step: 2589 ------------ Loss: 5589.77 ------------ Accuracy: 80.0%\n",
            "Step: 2590 ------------ Loss: 5588.97 ------------ Accuracy: 80.0%\n",
            "Step: 2591 ------------ Loss: 5588.19 ------------ Accuracy: 80.0%\n",
            "Step: 2592 ------------ Loss: 5587.38 ------------ Accuracy: 80.0%\n",
            "Step: 2593 ------------ Loss: 5586.59 ------------ Accuracy: 80.0%\n",
            "Step: 2594 ------------ Loss: 5585.22 ------------ Accuracy: 80.0%\n",
            "Step: 2595 ------------ Loss: 5584.76 ------------ Accuracy: 80.0%\n",
            "Step: 2596 ------------ Loss: 5583.47 ------------ Accuracy: 80.0%\n",
            "Step: 2597 ------------ Loss: 5582.74 ------------ Accuracy: 80.1%\n",
            "Step: 2598 ------------ Loss: 5581.96 ------------ Accuracy: 80.1%\n",
            "Step: 2599 ------------ Loss: 5581.12 ------------ Accuracy: 80.0%\n",
            "Step: 2600 ------------ Loss: 5579.41 ------------ Accuracy: 79.9%\n",
            "Step: 2601 ------------ Loss: 5579.29 ------------ Accuracy: 80.0%\n",
            "Step: 2602 ------------ Loss: 5578.49 ------------ Accuracy: 80.0%\n",
            "Step: 2603 ------------ Loss: 5578.38 ------------ Accuracy: 80.0%\n",
            "Step: 2604 ------------ Loss: 5577.62 ------------ Accuracy: 80.0%\n",
            "Step: 2605 ------------ Loss: 5576.18 ------------ Accuracy: 80.0%\n",
            "Step: 2606 ------------ Loss: 5575.42 ------------ Accuracy: 80.1%\n",
            "Step: 2607 ------------ Loss: 5574.71 ------------ Accuracy: 80.1%\n",
            "Step: 2608 ------------ Loss: 5573.3 ------------ Accuracy: 80.1%\n",
            "Step: 2609 ------------ Loss: 5573.2 ------------ Accuracy: 80.2%\n",
            "Step: 2610 ------------ Loss: 5572.32 ------------ Accuracy: 80.1%\n",
            "Step: 2611 ------------ Loss: 5571.86 ------------ Accuracy: 80.1%\n",
            "Step: 2612 ------------ Loss: 5571.77 ------------ Accuracy: 80.2%\n",
            "Step: 2613 ------------ Loss: 5571.06 ------------ Accuracy: 80.2%\n",
            "Step: 2614 ------------ Loss: 5570.18 ------------ Accuracy: 80.2%\n",
            "Step: 2615 ------------ Loss: 5568.79 ------------ Accuracy: 80.2%\n",
            "Step: 2616 ------------ Loss: 5568.32 ------------ Accuracy: 80.2%\n",
            "Step: 2617 ------------ Loss: 5567.85 ------------ Accuracy: 80.2%\n",
            "Step: 2618 ------------ Loss: 5567.26 ------------ Accuracy: 80.2%\n",
            "Step: 2619 ------------ Loss: 5566.49 ------------ Accuracy: 80.2%\n",
            "Step: 2620 ------------ Loss: 5566.04 ------------ Accuracy: 80.2%\n",
            "Step: 2621 ------------ Loss: 5565.3 ------------ Accuracy: 80.2%\n",
            "Step: 2622 ------------ Loss: 5564.57 ------------ Accuracy: 80.3%\n",
            "Step: 2623 ------------ Loss: 5564.26 ------------ Accuracy: 80.3%\n",
            "Step: 2624 ------------ Loss: 5563.41 ------------ Accuracy: 80.3%\n",
            "Step: 2625 ------------ Loss: 5562.65 ------------ Accuracy: 80.4%\n",
            "Step: 2626 ------------ Loss: 5562.06 ------------ Accuracy: 80.3%\n",
            "Step: 2627 ------------ Loss: 5561.6 ------------ Accuracy: 80.3%\n",
            "Step: 2628 ------------ Loss: 5560.38 ------------ Accuracy: 80.3%\n",
            "Step: 2629 ------------ Loss: 5558.66 ------------ Accuracy: 80.3%\n",
            "Step: 2630 ------------ Loss: 5557.92 ------------ Accuracy: 80.3%\n",
            "Step: 2631 ------------ Loss: 5557.18 ------------ Accuracy: 80.3%\n",
            "Step: 2632 ------------ Loss: 5556.42 ------------ Accuracy: 80.3%\n",
            "Step: 2633 ------------ Loss: 5555.72 ------------ Accuracy: 80.4%\n",
            "Step: 2634 ------------ Loss: 5554.83 ------------ Accuracy: 80.4%\n",
            "Step: 2635 ------------ Loss: 5554.14 ------------ Accuracy: 80.4%\n",
            "Step: 2636 ------------ Loss: 5553.7 ------------ Accuracy: 80.4%\n",
            "Step: 2637 ------------ Loss: 5553.02 ------------ Accuracy: 80.5%\n",
            "Step: 2638 ------------ Loss: 5552.15 ------------ Accuracy: 80.5%\n",
            "Step: 2639 ------------ Loss: 5551.71 ------------ Accuracy: 80.5%\n",
            "Step: 2640 ------------ Loss: 5551.61 ------------ Accuracy: 80.5%\n",
            "Step: 2641 ------------ Loss: 5550.78 ------------ Accuracy: 80.5%\n",
            "Step: 2642 ------------ Loss: 5549.96 ------------ Accuracy: 80.6%\n",
            "Step: 2643 ------------ Loss: 5549.25 ------------ Accuracy: 80.6%\n",
            "Step: 2644 ------------ Loss: 5548.55 ------------ Accuracy: 80.6%\n",
            "Step: 2645 ------------ Loss: 5548.46 ------------ Accuracy: 80.6%\n",
            "Step: 2646 ------------ Loss: 5546.62 ------------ Accuracy: 80.5%\n",
            "Step: 2647 ------------ Loss: 5546.19 ------------ Accuracy: 80.5%\n",
            "Step: 2648 ------------ Loss: 5545.51 ------------ Accuracy: 80.5%\n",
            "Step: 2649 ------------ Loss: 5544.69 ------------ Accuracy: 80.5%\n",
            "Step: 2650 ------------ Loss: 5542.9 ------------ Accuracy: 80.4%\n",
            "Step: 2651 ------------ Loss: 5541.69 ------------ Accuracy: 80.5%\n",
            "Step: 2652 ------------ Loss: 5541.25 ------------ Accuracy: 80.5%\n",
            "Step: 2653 ------------ Loss: 5541.13 ------------ Accuracy: 80.5%\n",
            "Step: 2654 ------------ Loss: 5540.45 ------------ Accuracy: 80.5%\n",
            "Step: 2655 ------------ Loss: 5539.71 ------------ Accuracy: 80.6%\n",
            "Step: 2656 ------------ Loss: 5538.96 ------------ Accuracy: 80.6%\n",
            "Step: 2657 ------------ Loss: 5538.22 ------------ Accuracy: 80.6%\n",
            "Step: 2658 ------------ Loss: 5537.8 ------------ Accuracy: 80.6%\n",
            "Step: 2659 ------------ Loss: 5537.07 ------------ Accuracy: 80.7%\n",
            "Step: 2660 ------------ Loss: 5536.34 ------------ Accuracy: 80.7%\n",
            "Step: 2661 ------------ Loss: 5536.21 ------------ Accuracy: 80.7%\n",
            "Step: 2662 ------------ Loss: 5535.77 ------------ Accuracy: 80.7%\n",
            "Step: 2663 ------------ Loss: 5534.9 ------------ Accuracy: 80.6%\n",
            "Step: 2664 ------------ Loss: 5534.48 ------------ Accuracy: 80.7%\n",
            "Step: 2665 ------------ Loss: 5533.3 ------------ Accuracy: 80.7%\n",
            "Step: 2666 ------------ Loss: 5533.18 ------------ Accuracy: 80.7%\n",
            "Step: 2667 ------------ Loss: 5532.45 ------------ Accuracy: 80.7%\n",
            "Step: 2668 ------------ Loss: 5531.72 ------------ Accuracy: 80.8%\n",
            "Step: 2669 ------------ Loss: 5531.61 ------------ Accuracy: 80.7%\n",
            "Step: 2670 ------------ Loss: 5530.91 ------------ Accuracy: 80.8%\n",
            "Step: 2671 ------------ Loss: 5530.2 ------------ Accuracy: 80.8%\n",
            "Step: 2672 ------------ Loss: 5529.76 ------------ Accuracy: 80.8%\n",
            "Step: 2673 ------------ Loss: 5528.41 ------------ Accuracy: 80.9%\n",
            "Step: 2674 ------------ Loss: 5527.54 ------------ Accuracy: 80.8%\n",
            "Step: 2675 ------------ Loss: 5526.91 ------------ Accuracy: 80.8%\n",
            "Step: 2676 ------------ Loss: 5526.23 ------------ Accuracy: 80.8%\n",
            "Step: 2677 ------------ Loss: 5526.13 ------------ Accuracy: 80.8%\n",
            "Step: 2678 ------------ Loss: 5525.79 ------------ Accuracy: 80.8%\n",
            "Step: 2679 ------------ Loss: 5524.91 ------------ Accuracy: 80.7%\n",
            "Step: 2680 ------------ Loss: 5524.81 ------------ Accuracy: 80.8%\n",
            "Step: 2681 ------------ Loss: 5524.12 ------------ Accuracy: 80.8%\n",
            "Step: 2682 ------------ Loss: 5523.68 ------------ Accuracy: 80.8%\n",
            "Step: 2683 ------------ Loss: 5522.82 ------------ Accuracy: 80.8%\n",
            "Step: 2684 ------------ Loss: 5521.66 ------------ Accuracy: 80.8%\n",
            "Step: 2685 ------------ Loss: 5521.01 ------------ Accuracy: 80.9%\n",
            "Step: 2686 ------------ Loss: 5520.13 ------------ Accuracy: 80.8%\n",
            "Step: 2687 ------------ Loss: 5519.02 ------------ Accuracy: 80.8%\n",
            "Step: 2688 ------------ Loss: 5518.36 ------------ Accuracy: 80.8%\n",
            "Step: 2689 ------------ Loss: 5517.92 ------------ Accuracy: 80.9%\n",
            "Step: 2690 ------------ Loss: 5517.04 ------------ Accuracy: 80.8%\n",
            "Step: 2691 ------------ Loss: 5516.62 ------------ Accuracy: 80.8%\n",
            "Step: 2692 ------------ Loss: 5516.32 ------------ Accuracy: 80.8%\n",
            "Step: 2693 ------------ Loss: 5515.26 ------------ Accuracy: 80.8%\n",
            "Step: 2694 ------------ Loss: 5514.27 ------------ Accuracy: 80.8%\n",
            "Step: 2695 ------------ Loss: 5513.63 ------------ Accuracy: 80.8%\n",
            "Step: 2696 ------------ Loss: 5512.75 ------------ Accuracy: 80.7%\n",
            "Step: 2697 ------------ Loss: 5512.16 ------------ Accuracy: 80.7%\n",
            "Step: 2698 ------------ Loss: 5511.3 ------------ Accuracy: 80.6%\n",
            "Step: 2699 ------------ Loss: 5510.75 ------------ Accuracy: 80.5%\n",
            "Step: 2700 ------------ Loss: 5510.03 ------------ Accuracy: 80.6%\n",
            "Step: 2701 ------------ Loss: 5509.31 ------------ Accuracy: 80.7%\n",
            "Step: 2702 ------------ Loss: 5508.57 ------------ Accuracy: 80.7%\n",
            "Step: 2703 ------------ Loss: 5507.86 ------------ Accuracy: 80.7%\n",
            "Step: 2704 ------------ Loss: 5507.16 ------------ Accuracy: 80.7%\n",
            "Step: 2705 ------------ Loss: 5507.07 ------------ Accuracy: 80.7%\n",
            "Step: 2706 ------------ Loss: 5506.41 ------------ Accuracy: 80.8%\n",
            "Step: 2707 ------------ Loss: 5505.11 ------------ Accuracy: 80.8%\n",
            "Step: 2708 ------------ Loss: 5504.56 ------------ Accuracy: 80.7%\n",
            "Step: 2709 ------------ Loss: 5503.28 ------------ Accuracy: 80.7%\n",
            "Step: 2710 ------------ Loss: 5502.42 ------------ Accuracy: 80.7%\n",
            "Step: 2711 ------------ Loss: 5501.48 ------------ Accuracy: 80.7%\n",
            "Step: 2712 ------------ Loss: 5500.46 ------------ Accuracy: 80.7%\n",
            "Step: 2713 ------------ Loss: 5499.79 ------------ Accuracy: 80.7%\n",
            "Step: 2714 ------------ Loss: 5499.25 ------------ Accuracy: 80.7%\n",
            "Step: 2715 ------------ Loss: 5498.0 ------------ Accuracy: 80.7%\n",
            "Step: 2716 ------------ Loss: 5497.26 ------------ Accuracy: 80.7%\n",
            "Step: 2717 ------------ Loss: 5496.81 ------------ Accuracy: 80.7%\n",
            "Step: 2718 ------------ Loss: 5495.86 ------------ Accuracy: 80.8%\n",
            "Step: 2719 ------------ Loss: 5495.1 ------------ Accuracy: 80.8%\n",
            "Step: 2720 ------------ Loss: 5494.25 ------------ Accuracy: 80.8%\n",
            "Step: 2721 ------------ Loss: 5493.55 ------------ Accuracy: 80.8%\n",
            "Step: 2722 ------------ Loss: 5492.7 ------------ Accuracy: 80.8%\n",
            "Step: 2723 ------------ Loss: 5491.12 ------------ Accuracy: 80.7%\n",
            "Step: 2724 ------------ Loss: 5490.59 ------------ Accuracy: 80.6%\n",
            "Step: 2725 ------------ Loss: 5490.17 ------------ Accuracy: 80.6%\n",
            "Step: 2726 ------------ Loss: 5489.24 ------------ Accuracy: 80.6%\n",
            "Step: 2727 ------------ Loss: 5487.7 ------------ Accuracy: 80.5%\n",
            "Step: 2728 ------------ Loss: 5487.2 ------------ Accuracy: 80.5%\n",
            "Step: 2729 ------------ Loss: 5486.17 ------------ Accuracy: 80.5%\n",
            "Step: 2730 ------------ Loss: 5485.23 ------------ Accuracy: 80.5%\n",
            "Step: 2731 ------------ Loss: 5484.87 ------------ Accuracy: 80.6%\n",
            "Step: 2732 ------------ Loss: 5484.44 ------------ Accuracy: 80.6%\n",
            "Step: 2733 ------------ Loss: 5484.3 ------------ Accuracy: 80.6%\n",
            "Step: 2734 ------------ Loss: 5483.29 ------------ Accuracy: 80.6%\n",
            "Step: 2735 ------------ Loss: 5482.37 ------------ Accuracy: 80.6%\n",
            "Step: 2736 ------------ Loss: 5481.65 ------------ Accuracy: 80.7%\n",
            "Step: 2737 ------------ Loss: 5480.73 ------------ Accuracy: 80.7%\n",
            "Step: 2738 ------------ Loss: 5479.93 ------------ Accuracy: 80.7%\n",
            "Step: 2739 ------------ Loss: 5479.81 ------------ Accuracy: 80.7%\n",
            "Step: 2740 ------------ Loss: 5478.53 ------------ Accuracy: 80.7%\n",
            "Step: 2741 ------------ Loss: 5477.64 ------------ Accuracy: 80.7%\n",
            "Step: 2742 ------------ Loss: 5476.38 ------------ Accuracy: 80.7%\n",
            "Step: 2743 ------------ Loss: 5475.63 ------------ Accuracy: 80.8%\n",
            "Step: 2744 ------------ Loss: 5474.9 ------------ Accuracy: 80.8%\n",
            "Step: 2745 ------------ Loss: 5474.78 ------------ Accuracy: 80.8%\n",
            "Step: 2746 ------------ Loss: 5473.92 ------------ Accuracy: 80.8%\n",
            "Step: 2747 ------------ Loss: 5472.66 ------------ Accuracy: 80.8%\n",
            "Step: 2748 ------------ Loss: 5472.12 ------------ Accuracy: 80.8%\n",
            "Step: 2749 ------------ Loss: 5471.09 ------------ Accuracy: 80.8%\n",
            "Step: 2750 ------------ Loss: 5470.33 ------------ Accuracy: 80.9%\n",
            "Step: 2751 ------------ Loss: 5469.63 ------------ Accuracy: 80.9%\n",
            "Step: 2752 ------------ Loss: 5468.74 ------------ Accuracy: 80.9%\n",
            "Step: 2753 ------------ Loss: 5468.21 ------------ Accuracy: 80.9%\n",
            "Step: 2754 ------------ Loss: 5467.34 ------------ Accuracy: 80.9%\n",
            "Step: 2755 ------------ Loss: 5466.83 ------------ Accuracy: 80.9%\n",
            "Step: 2756 ------------ Loss: 5465.24 ------------ Accuracy: 80.7%\n",
            "Step: 2757 ------------ Loss: 5463.72 ------------ Accuracy: 80.6%\n",
            "Step: 2758 ------------ Loss: 5462.85 ------------ Accuracy: 80.6%\n",
            "Step: 2759 ------------ Loss: 5461.98 ------------ Accuracy: 80.6%\n",
            "Step: 2760 ------------ Loss: 5461.25 ------------ Accuracy: 80.6%\n",
            "Step: 2761 ------------ Loss: 5460.2 ------------ Accuracy: 80.7%\n",
            "Step: 2762 ------------ Loss: 5459.71 ------------ Accuracy: 80.6%\n",
            "Step: 2763 ------------ Loss: 5459.37 ------------ Accuracy: 80.7%\n",
            "Step: 2764 ------------ Loss: 5458.12 ------------ Accuracy: 80.7%\n",
            "Step: 2765 ------------ Loss: 5457.99 ------------ Accuracy: 80.7%\n",
            "Step: 2766 ------------ Loss: 5457.27 ------------ Accuracy: 80.8%\n",
            "Step: 2767 ------------ Loss: 5456.78 ------------ Accuracy: 80.7%\n",
            "Step: 2768 ------------ Loss: 5456.34 ------------ Accuracy: 80.8%\n",
            "Step: 2769 ------------ Loss: 5454.84 ------------ Accuracy: 80.6%\n",
            "Step: 2770 ------------ Loss: 5454.41 ------------ Accuracy: 80.7%\n",
            "Step: 2771 ------------ Loss: 5453.94 ------------ Accuracy: 80.6%\n",
            "Step: 2772 ------------ Loss: 5453.58 ------------ Accuracy: 80.7%\n",
            "Step: 2773 ------------ Loss: 5452.85 ------------ Accuracy: 80.7%\n",
            "Step: 2774 ------------ Loss: 5452.79 ------------ Accuracy: 80.8%\n",
            "Step: 2775 ------------ Loss: 5452.46 ------------ Accuracy: 80.9%\n",
            "Step: 2776 ------------ Loss: 5452.33 ------------ Accuracy: 80.9%\n",
            "Step: 2777 ------------ Loss: 5451.88 ------------ Accuracy: 80.9%\n",
            "Step: 2778 ------------ Loss: 5451.11 ------------ Accuracy: 80.9%\n",
            "Step: 2779 ------------ Loss: 5450.35 ------------ Accuracy: 81.0%\n",
            "Step: 2780 ------------ Loss: 5449.9 ------------ Accuracy: 81.0%\n",
            "Step: 2781 ------------ Loss: 5449.13 ------------ Accuracy: 80.9%\n",
            "Step: 2782 ------------ Loss: 5448.29 ------------ Accuracy: 80.9%\n",
            "Step: 2783 ------------ Loss: 5447.58 ------------ Accuracy: 80.9%\n",
            "Step: 2784 ------------ Loss: 5447.14 ------------ Accuracy: 80.9%\n",
            "Step: 2785 ------------ Loss: 5446.66 ------------ Accuracy: 81.0%\n",
            "Step: 2786 ------------ Loss: 5445.95 ------------ Accuracy: 81.0%\n",
            "Step: 2787 ------------ Loss: 5445.13 ------------ Accuracy: 81.0%\n",
            "Step: 2788 ------------ Loss: 5445.06 ------------ Accuracy: 81.1%\n",
            "Step: 2789 ------------ Loss: 5443.5 ------------ Accuracy: 80.9%\n",
            "Step: 2790 ------------ Loss: 5443.05 ------------ Accuracy: 80.9%\n",
            "Step: 2791 ------------ Loss: 5441.76 ------------ Accuracy: 80.9%\n",
            "Step: 2792 ------------ Loss: 5441.64 ------------ Accuracy: 80.9%\n",
            "Step: 2793 ------------ Loss: 5441.32 ------------ Accuracy: 81.0%\n",
            "Step: 2794 ------------ Loss: 5440.58 ------------ Accuracy: 81.0%\n",
            "Step: 2795 ------------ Loss: 5439.91 ------------ Accuracy: 81.0%\n",
            "Step: 2796 ------------ Loss: 5439.62 ------------ Accuracy: 81.0%\n",
            "Step: 2797 ------------ Loss: 5438.86 ------------ Accuracy: 81.0%\n",
            "Step: 2798 ------------ Loss: 5438.44 ------------ Accuracy: 81.0%\n",
            "Step: 2799 ------------ Loss: 5436.94 ------------ Accuracy: 80.8%\n",
            "Step: 2800 ------------ Loss: 5436.68 ------------ Accuracy: 80.9%\n",
            "Step: 2801 ------------ Loss: 5435.96 ------------ Accuracy: 80.9%\n",
            "Step: 2802 ------------ Loss: 5434.69 ------------ Accuracy: 80.9%\n",
            "Step: 2803 ------------ Loss: 5433.69 ------------ Accuracy: 80.9%\n",
            "Step: 2804 ------------ Loss: 5432.75 ------------ Accuracy: 80.9%\n",
            "Step: 2805 ------------ Loss: 5431.98 ------------ Accuracy: 80.9%\n",
            "Step: 2806 ------------ Loss: 5431.08 ------------ Accuracy: 80.9%\n",
            "Step: 2807 ------------ Loss: 5429.69 ------------ Accuracy: 80.8%\n",
            "Step: 2808 ------------ Loss: 5428.8 ------------ Accuracy: 80.7%\n",
            "Step: 2809 ------------ Loss: 5428.71 ------------ Accuracy: 80.8%\n",
            "Step: 2810 ------------ Loss: 5428.02 ------------ Accuracy: 80.9%\n",
            "Step: 2811 ------------ Loss: 5427.3 ------------ Accuracy: 80.9%\n",
            "Step: 2812 ------------ Loss: 5426.56 ------------ Accuracy: 80.9%\n",
            "Step: 2813 ------------ Loss: 5425.81 ------------ Accuracy: 80.9%\n",
            "Step: 2814 ------------ Loss: 5424.95 ------------ Accuracy: 80.9%\n",
            "Step: 2815 ------------ Loss: 5424.71 ------------ Accuracy: 81.0%\n",
            "Step: 2816 ------------ Loss: 5423.98 ------------ Accuracy: 81.0%\n",
            "Step: 2817 ------------ Loss: 5423.27 ------------ Accuracy: 81.0%\n",
            "Step: 2818 ------------ Loss: 5422.45 ------------ Accuracy: 81.1%\n",
            "Step: 2819 ------------ Loss: 5421.78 ------------ Accuracy: 81.1%\n",
            "Step: 2820 ------------ Loss: 5420.98 ------------ Accuracy: 81.1%\n",
            "Step: 2821 ------------ Loss: 5420.54 ------------ Accuracy: 81.1%\n",
            "Step: 2822 ------------ Loss: 5419.81 ------------ Accuracy: 81.1%\n",
            "Step: 2823 ------------ Loss: 5418.75 ------------ Accuracy: 81.1%\n",
            "Step: 2824 ------------ Loss: 5418.08 ------------ Accuracy: 81.1%\n",
            "Step: 2825 ------------ Loss: 5417.29 ------------ Accuracy: 81.1%\n",
            "Step: 2826 ------------ Loss: 5416.51 ------------ Accuracy: 81.1%\n",
            "Step: 2827 ------------ Loss: 5415.78 ------------ Accuracy: 81.1%\n",
            "Step: 2828 ------------ Loss: 5415.09 ------------ Accuracy: 81.2%\n",
            "Step: 2829 ------------ Loss: 5414.52 ------------ Accuracy: 81.2%\n",
            "Step: 2830 ------------ Loss: 5413.25 ------------ Accuracy: 81.2%\n",
            "Step: 2831 ------------ Loss: 5413.02 ------------ Accuracy: 81.2%\n",
            "Step: 2832 ------------ Loss: 5411.51 ------------ Accuracy: 81.0%\n",
            "Step: 2833 ------------ Loss: 5410.94 ------------ Accuracy: 81.1%\n",
            "Step: 2834 ------------ Loss: 5410.22 ------------ Accuracy: 81.0%\n",
            "Step: 2835 ------------ Loss: 5409.19 ------------ Accuracy: 81.0%\n",
            "Step: 2836 ------------ Loss: 5408.48 ------------ Accuracy: 81.1%\n",
            "Step: 2837 ------------ Loss: 5408.06 ------------ Accuracy: 81.1%\n",
            "Step: 2838 ------------ Loss: 5407.97 ------------ Accuracy: 81.1%\n",
            "Step: 2839 ------------ Loss: 5407.22 ------------ Accuracy: 81.1%\n",
            "Step: 2840 ------------ Loss: 5406.42 ------------ Accuracy: 81.2%\n",
            "Step: 2841 ------------ Loss: 5405.19 ------------ Accuracy: 81.1%\n",
            "Step: 2842 ------------ Loss: 5404.4 ------------ Accuracy: 81.2%\n",
            "Step: 2843 ------------ Loss: 5404.17 ------------ Accuracy: 81.2%\n",
            "Step: 2844 ------------ Loss: 5403.5 ------------ Accuracy: 81.2%\n",
            "Step: 2845 ------------ Loss: 5403.06 ------------ Accuracy: 81.2%\n",
            "Step: 2846 ------------ Loss: 5402.29 ------------ Accuracy: 81.2%\n",
            "Step: 2847 ------------ Loss: 5401.85 ------------ Accuracy: 81.2%\n",
            "Step: 2848 ------------ Loss: 5401.43 ------------ Accuracy: 81.2%\n",
            "Step: 2849 ------------ Loss: 5400.39 ------------ Accuracy: 81.2%\n",
            "Step: 2850 ------------ Loss: 5399.74 ------------ Accuracy: 81.3%\n",
            "Step: 2851 ------------ Loss: 5398.76 ------------ Accuracy: 81.2%\n",
            "Step: 2852 ------------ Loss: 5398.67 ------------ Accuracy: 81.3%\n",
            "Step: 2853 ------------ Loss: 5397.75 ------------ Accuracy: 81.3%\n",
            "Step: 2854 ------------ Loss: 5396.61 ------------ Accuracy: 81.2%\n",
            "Step: 2855 ------------ Loss: 5395.18 ------------ Accuracy: 81.1%\n",
            "Step: 2856 ------------ Loss: 5395.03 ------------ Accuracy: 81.1%\n",
            "Step: 2857 ------------ Loss: 5394.28 ------------ Accuracy: 81.1%\n",
            "Step: 2858 ------------ Loss: 5392.89 ------------ Accuracy: 81.0%\n",
            "Step: 2859 ------------ Loss: 5392.3 ------------ Accuracy: 81.0%\n",
            "Step: 2860 ------------ Loss: 5391.87 ------------ Accuracy: 81.0%\n",
            "Step: 2861 ------------ Loss: 5390.98 ------------ Accuracy: 81.1%\n",
            "Step: 2862 ------------ Loss: 5390.26 ------------ Accuracy: 81.1%\n",
            "Step: 2863 ------------ Loss: 5388.89 ------------ Accuracy: 81.0%\n",
            "Step: 2864 ------------ Loss: 5388.44 ------------ Accuracy: 81.0%\n",
            "Step: 2865 ------------ Loss: 5388.19 ------------ Accuracy: 81.1%\n",
            "Step: 2866 ------------ Loss: 5387.48 ------------ Accuracy: 81.2%\n",
            "Step: 2867 ------------ Loss: 5386.9 ------------ Accuracy: 81.1%\n",
            "Step: 2868 ------------ Loss: 5386.46 ------------ Accuracy: 81.1%\n",
            "Step: 2869 ------------ Loss: 5385.71 ------------ Accuracy: 81.1%\n",
            "Step: 2870 ------------ Loss: 5384.96 ------------ Accuracy: 81.2%\n",
            "Step: 2871 ------------ Loss: 5384.09 ------------ Accuracy: 81.1%\n",
            "Step: 2872 ------------ Loss: 5383.39 ------------ Accuracy: 81.2%\n",
            "Step: 2873 ------------ Loss: 5382.69 ------------ Accuracy: 81.2%\n",
            "Step: 2874 ------------ Loss: 5381.33 ------------ Accuracy: 81.1%\n",
            "Step: 2875 ------------ Loss: 5380.63 ------------ Accuracy: 81.1%\n",
            "Step: 2876 ------------ Loss: 5379.81 ------------ Accuracy: 81.2%\n",
            "Step: 2877 ------------ Loss: 5379.23 ------------ Accuracy: 81.2%\n",
            "Step: 2878 ------------ Loss: 5378.67 ------------ Accuracy: 81.2%\n",
            "Step: 2879 ------------ Loss: 5377.56 ------------ Accuracy: 81.2%\n",
            "Step: 2880 ------------ Loss: 5377.03 ------------ Accuracy: 81.2%\n",
            "Step: 2881 ------------ Loss: 5376.3 ------------ Accuracy: 81.3%\n",
            "Step: 2882 ------------ Loss: 5375.38 ------------ Accuracy: 81.2%\n",
            "Step: 2883 ------------ Loss: 5374.04 ------------ Accuracy: 81.1%\n",
            "Step: 2884 ------------ Loss: 5373.29 ------------ Accuracy: 81.1%\n",
            "Step: 2885 ------------ Loss: 5372.87 ------------ Accuracy: 81.1%\n",
            "Step: 2886 ------------ Loss: 5372.43 ------------ Accuracy: 81.1%\n",
            "Step: 2887 ------------ Loss: 5371.72 ------------ Accuracy: 81.1%\n",
            "Step: 2888 ------------ Loss: 5370.83 ------------ Accuracy: 81.1%\n",
            "Step: 2889 ------------ Loss: 5370.13 ------------ Accuracy: 81.2%\n",
            "Step: 2890 ------------ Loss: 5369.99 ------------ Accuracy: 81.2%\n",
            "Step: 2891 ------------ Loss: 5368.86 ------------ Accuracy: 81.2%\n",
            "Step: 2892 ------------ Loss: 5368.72 ------------ Accuracy: 81.2%\n",
            "Step: 2893 ------------ Loss: 5368.42 ------------ Accuracy: 81.2%\n",
            "Step: 2894 ------------ Loss: 5367.57 ------------ Accuracy: 81.3%\n",
            "Step: 2895 ------------ Loss: 5367.3 ------------ Accuracy: 81.3%\n",
            "Step: 2896 ------------ Loss: 5366.43 ------------ Accuracy: 81.3%\n",
            "Step: 2897 ------------ Loss: 5366.36 ------------ Accuracy: 81.3%\n",
            "Step: 2898 ------------ Loss: 5365.25 ------------ Accuracy: 81.3%\n",
            "Step: 2899 ------------ Loss: 5364.5 ------------ Accuracy: 81.3%\n",
            "Step: 2900 ------------ Loss: 5363.77 ------------ Accuracy: 81.3%\n",
            "Step: 2901 ------------ Loss: 5363.33 ------------ Accuracy: 81.3%\n",
            "Step: 2902 ------------ Loss: 5362.24 ------------ Accuracy: 81.3%\n",
            "Step: 2903 ------------ Loss: 5361.54 ------------ Accuracy: 81.4%\n",
            "Step: 2904 ------------ Loss: 5360.74 ------------ Accuracy: 81.4%\n",
            "Step: 2905 ------------ Loss: 5360.31 ------------ Accuracy: 81.4%\n",
            "Step: 2906 ------------ Loss: 5360.04 ------------ Accuracy: 81.5%\n",
            "Step: 2907 ------------ Loss: 5358.68 ------------ Accuracy: 81.4%\n",
            "Step: 2908 ------------ Loss: 5358.26 ------------ Accuracy: 81.4%\n",
            "Step: 2909 ------------ Loss: 5357.22 ------------ Accuracy: 81.4%\n",
            "Step: 2910 ------------ Loss: 5356.47 ------------ Accuracy: 81.4%\n",
            "Step: 2911 ------------ Loss: 5356.31 ------------ Accuracy: 81.4%\n",
            "Step: 2912 ------------ Loss: 5355.42 ------------ Accuracy: 81.4%\n",
            "Step: 2913 ------------ Loss: 5354.82 ------------ Accuracy: 81.4%\n",
            "Step: 2914 ------------ Loss: 5353.76 ------------ Accuracy: 81.4%\n",
            "Step: 2915 ------------ Loss: 5353.03 ------------ Accuracy: 81.4%\n",
            "Step: 2916 ------------ Loss: 5351.99 ------------ Accuracy: 81.4%\n",
            "Step: 2917 ------------ Loss: 5351.31 ------------ Accuracy: 81.4%\n",
            "Step: 2918 ------------ Loss: 5351.24 ------------ Accuracy: 81.4%\n",
            "Step: 2919 ------------ Loss: 5350.95 ------------ Accuracy: 81.5%\n",
            "Step: 2920 ------------ Loss: 5350.54 ------------ Accuracy: 81.5%\n",
            "Step: 2921 ------------ Loss: 5349.81 ------------ Accuracy: 81.5%\n",
            "Step: 2922 ------------ Loss: 5348.78 ------------ Accuracy: 81.4%\n",
            "Step: 2923 ------------ Loss: 5348.37 ------------ Accuracy: 81.4%\n",
            "Step: 2924 ------------ Loss: 5347.7 ------------ Accuracy: 81.5%\n",
            "Step: 2925 ------------ Loss: 5347.27 ------------ Accuracy: 81.5%\n",
            "Step: 2926 ------------ Loss: 5347.0 ------------ Accuracy: 81.6%\n",
            "Step: 2927 ------------ Loss: 5345.98 ------------ Accuracy: 81.5%\n",
            "Step: 2928 ------------ Loss: 5345.71 ------------ Accuracy: 81.6%\n",
            "Step: 2929 ------------ Loss: 5345.07 ------------ Accuracy: 81.6%\n",
            "Step: 2930 ------------ Loss: 5344.34 ------------ Accuracy: 81.6%\n",
            "Step: 2931 ------------ Loss: 5343.92 ------------ Accuracy: 81.6%\n",
            "Step: 2932 ------------ Loss: 5343.16 ------------ Accuracy: 81.6%\n",
            "Step: 2933 ------------ Loss: 5343.01 ------------ Accuracy: 81.6%\n",
            "Step: 2934 ------------ Loss: 5342.12 ------------ Accuracy: 81.7%\n",
            "Step: 2935 ------------ Loss: 5341.69 ------------ Accuracy: 81.7%\n",
            "Step: 2936 ------------ Loss: 5341.56 ------------ Accuracy: 81.7%\n",
            "Step: 2937 ------------ Loss: 5340.75 ------------ Accuracy: 81.7%\n",
            "Step: 2938 ------------ Loss: 5339.96 ------------ Accuracy: 81.6%\n",
            "Step: 2939 ------------ Loss: 5338.92 ------------ Accuracy: 81.5%\n",
            "Step: 2940 ------------ Loss: 5338.5 ------------ Accuracy: 81.6%\n",
            "Step: 2941 ------------ Loss: 5337.78 ------------ Accuracy: 81.7%\n",
            "Step: 2942 ------------ Loss: 5336.76 ------------ Accuracy: 81.6%\n",
            "Step: 2943 ------------ Loss: 5336.09 ------------ Accuracy: 81.7%\n",
            "Step: 2944 ------------ Loss: 5335.33 ------------ Accuracy: 81.6%\n",
            "Step: 2945 ------------ Loss: 5334.65 ------------ Accuracy: 81.6%\n",
            "Step: 2946 ------------ Loss: 5334.51 ------------ Accuracy: 81.6%\n",
            "Step: 2947 ------------ Loss: 5333.63 ------------ Accuracy: 81.7%\n",
            "Step: 2948 ------------ Loss: 5332.99 ------------ Accuracy: 81.7%\n",
            "Step: 2949 ------------ Loss: 5331.59 ------------ Accuracy: 81.5%\n",
            "Step: 2950 ------------ Loss: 5330.71 ------------ Accuracy: 81.6%\n",
            "Step: 2951 ------------ Loss: 5330.29 ------------ Accuracy: 81.7%\n",
            "Step: 2952 ------------ Loss: 5329.87 ------------ Accuracy: 81.7%\n",
            "Step: 2953 ------------ Loss: 5329.21 ------------ Accuracy: 81.7%\n",
            "Step: 2954 ------------ Loss: 5327.84 ------------ Accuracy: 81.6%\n",
            "Step: 2955 ------------ Loss: 5327.09 ------------ Accuracy: 81.6%\n",
            "Step: 2956 ------------ Loss: 5326.66 ------------ Accuracy: 81.6%\n",
            "Step: 2957 ------------ Loss: 5326.24 ------------ Accuracy: 81.6%\n",
            "Step: 2958 ------------ Loss: 5325.63 ------------ Accuracy: 81.6%\n",
            "Step: 2959 ------------ Loss: 5324.9 ------------ Accuracy: 81.5%\n",
            "Step: 2960 ------------ Loss: 5324.3 ------------ Accuracy: 81.6%\n",
            "Step: 2961 ------------ Loss: 5323.89 ------------ Accuracy: 81.6%\n",
            "Step: 2962 ------------ Loss: 5323.21 ------------ Accuracy: 81.6%\n",
            "Step: 2963 ------------ Loss: 5322.54 ------------ Accuracy: 81.7%\n",
            "Step: 2964 ------------ Loss: 5321.6 ------------ Accuracy: 81.7%\n",
            "Step: 2965 ------------ Loss: 5320.7 ------------ Accuracy: 81.7%\n",
            "Step: 2966 ------------ Loss: 5319.99 ------------ Accuracy: 81.7%\n",
            "Step: 2967 ------------ Loss: 5319.71 ------------ Accuracy: 81.8%\n",
            "Step: 2968 ------------ Loss: 5319.29 ------------ Accuracy: 81.8%\n",
            "Step: 2969 ------------ Loss: 5319.03 ------------ Accuracy: 81.8%\n",
            "Step: 2970 ------------ Loss: 5318.78 ------------ Accuracy: 81.8%\n",
            "Step: 2971 ------------ Loss: 5318.15 ------------ Accuracy: 81.8%\n",
            "Step: 2972 ------------ Loss: 5317.37 ------------ Accuracy: 81.8%\n",
            "Step: 2973 ------------ Loss: 5317.24 ------------ Accuracy: 81.8%\n",
            "Step: 2974 ------------ Loss: 5316.42 ------------ Accuracy: 81.8%\n",
            "Step: 2975 ------------ Loss: 5315.36 ------------ Accuracy: 81.8%\n",
            "Step: 2976 ------------ Loss: 5314.96 ------------ Accuracy: 81.8%\n",
            "Step: 2977 ------------ Loss: 5314.55 ------------ Accuracy: 81.8%\n",
            "Step: 2978 ------------ Loss: 5314.31 ------------ Accuracy: 81.8%\n",
            "Step: 2979 ------------ Loss: 5313.64 ------------ Accuracy: 81.9%\n",
            "Step: 2980 ------------ Loss: 5313.04 ------------ Accuracy: 81.9%\n",
            "Step: 2981 ------------ Loss: 5312.26 ------------ Accuracy: 81.9%\n",
            "Step: 2982 ------------ Loss: 5311.48 ------------ Accuracy: 81.8%\n",
            "Step: 2983 ------------ Loss: 5311.38 ------------ Accuracy: 81.9%\n",
            "Step: 2984 ------------ Loss: 5311.15 ------------ Accuracy: 81.9%\n",
            "Step: 2985 ------------ Loss: 5310.94 ------------ Accuracy: 81.9%\n",
            "Step: 2986 ------------ Loss: 5310.75 ------------ Accuracy: 81.9%\n",
            "Step: 2987 ------------ Loss: 5309.99 ------------ Accuracy: 81.9%\n",
            "Step: 2988 ------------ Loss: 5309.32 ------------ Accuracy: 81.9%\n",
            "Step: 2989 ------------ Loss: 5308.26 ------------ Accuracy: 81.9%\n",
            "Step: 2990 ------------ Loss: 5307.51 ------------ Accuracy: 81.9%\n",
            "Step: 2991 ------------ Loss: 5306.71 ------------ Accuracy: 81.9%\n",
            "Step: 2992 ------------ Loss: 5306.29 ------------ Accuracy: 81.9%\n",
            "Step: 2993 ------------ Loss: 5305.49 ------------ Accuracy: 81.9%\n",
            "Step: 2994 ------------ Loss: 5304.78 ------------ Accuracy: 81.9%\n",
            "Step: 2995 ------------ Loss: 5304.38 ------------ Accuracy: 81.9%\n",
            "Step: 2996 ------------ Loss: 5304.27 ------------ Accuracy: 82.0%\n",
            "Step: 2997 ------------ Loss: 5303.64 ------------ Accuracy: 81.9%\n",
            "Step: 2998 ------------ Loss: 5303.51 ------------ Accuracy: 82.0%\n",
            "Step: 2999 ------------ Loss: 5303.43 ------------ Accuracy: 82.0%\n",
            "Step: 3000 ------------ Loss: 5303.35 ------------ Accuracy: 82.0%\n",
            "Step: 3001 ------------ Loss: 5302.78 ------------ Accuracy: 81.9%\n",
            "Step: 3002 ------------ Loss: 5301.99 ------------ Accuracy: 81.9%\n",
            "Step: 3003 ------------ Loss: 5301.29 ------------ Accuracy: 82.0%\n",
            "Step: 3004 ------------ Loss: 5300.22 ------------ Accuracy: 81.9%\n",
            "Step: 3005 ------------ Loss: 5299.82 ------------ Accuracy: 81.9%\n",
            "Step: 3006 ------------ Loss: 5299.13 ------------ Accuracy: 82.0%\n",
            "Step: 3007 ------------ Loss: 5298.36 ------------ Accuracy: 82.0%\n",
            "Step: 3008 ------------ Loss: 5298.29 ------------ Accuracy: 82.0%\n",
            "Step: 3009 ------------ Loss: 5298.06 ------------ Accuracy: 82.0%\n",
            "Step: 3010 ------------ Loss: 5297.45 ------------ Accuracy: 82.0%\n",
            "Step: 3011 ------------ Loss: 5296.39 ------------ Accuracy: 82.0%\n",
            "Step: 3012 ------------ Loss: 5295.97 ------------ Accuracy: 82.0%\n",
            "Step: 3013 ------------ Loss: 5295.33 ------------ Accuracy: 82.0%\n",
            "Step: 3014 ------------ Loss: 5294.57 ------------ Accuracy: 82.1%\n",
            "Step: 3015 ------------ Loss: 5294.35 ------------ Accuracy: 82.2%\n",
            "Step: 3016 ------------ Loss: 5293.67 ------------ Accuracy: 82.2%\n",
            "Step: 3017 ------------ Loss: 5293.27 ------------ Accuracy: 82.2%\n",
            "Step: 3018 ------------ Loss: 5292.87 ------------ Accuracy: 82.2%\n",
            "Step: 3019 ------------ Loss: 5292.12 ------------ Accuracy: 82.2%\n",
            "Step: 3020 ------------ Loss: 5291.73 ------------ Accuracy: 82.2%\n",
            "Step: 3021 ------------ Loss: 5291.01 ------------ Accuracy: 82.2%\n",
            "Step: 3022 ------------ Loss: 5290.26 ------------ Accuracy: 82.1%\n",
            "Step: 3023 ------------ Loss: 5289.56 ------------ Accuracy: 82.2%\n",
            "Step: 3024 ------------ Loss: 5289.45 ------------ Accuracy: 82.2%\n",
            "Step: 3025 ------------ Loss: 5287.95 ------------ Accuracy: 82.1%\n",
            "Step: 3026 ------------ Loss: 5286.85 ------------ Accuracy: 82.1%\n",
            "Step: 3027 ------------ Loss: 5286.44 ------------ Accuracy: 82.1%\n",
            "Step: 3028 ------------ Loss: 5285.02 ------------ Accuracy: 82.0%\n",
            "Step: 3029 ------------ Loss: 5284.82 ------------ Accuracy: 82.0%\n",
            "Step: 3030 ------------ Loss: 5284.14 ------------ Accuracy: 82.0%\n",
            "Step: 3031 ------------ Loss: 5283.46 ------------ Accuracy: 82.1%\n",
            "Step: 3032 ------------ Loss: 5282.74 ------------ Accuracy: 82.1%\n",
            "Step: 3033 ------------ Loss: 5282.08 ------------ Accuracy: 82.1%\n",
            "Step: 3034 ------------ Loss: 5281.43 ------------ Accuracy: 82.2%\n",
            "Step: 3035 ------------ Loss: 5280.01 ------------ Accuracy: 82.0%\n",
            "Step: 3036 ------------ Loss: 5279.62 ------------ Accuracy: 82.0%\n",
            "Step: 3037 ------------ Loss: 5278.26 ------------ Accuracy: 81.9%\n",
            "Step: 3038 ------------ Loss: 5276.96 ------------ Accuracy: 81.9%\n",
            "Step: 3039 ------------ Loss: 5276.33 ------------ Accuracy: 81.9%\n",
            "Step: 3040 ------------ Loss: 5275.68 ------------ Accuracy: 81.9%\n",
            "Step: 3041 ------------ Loss: 5275.01 ------------ Accuracy: 81.9%\n",
            "Step: 3042 ------------ Loss: 5274.32 ------------ Accuracy: 82.0%\n",
            "Step: 3043 ------------ Loss: 5273.64 ------------ Accuracy: 81.9%\n",
            "Step: 3044 ------------ Loss: 5273.03 ------------ Accuracy: 82.0%\n",
            "Step: 3045 ------------ Loss: 5272.28 ------------ Accuracy: 82.0%\n",
            "Step: 3046 ------------ Loss: 5271.7 ------------ Accuracy: 82.0%\n",
            "Step: 3047 ------------ Loss: 5271.31 ------------ Accuracy: 82.0%\n",
            "Step: 3048 ------------ Loss: 5270.66 ------------ Accuracy: 82.0%\n",
            "Step: 3049 ------------ Loss: 5270.26 ------------ Accuracy: 82.0%\n",
            "Step: 3050 ------------ Loss: 5269.85 ------------ Accuracy: 82.0%\n",
            "Step: 3051 ------------ Loss: 5269.3 ------------ Accuracy: 82.0%\n",
            "Step: 3052 ------------ Loss: 5267.99 ------------ Accuracy: 82.0%\n",
            "Step: 3053 ------------ Loss: 5267.47 ------------ Accuracy: 81.9%\n",
            "Step: 3054 ------------ Loss: 5266.72 ------------ Accuracy: 82.0%\n",
            "Step: 3055 ------------ Loss: 5266.32 ------------ Accuracy: 82.0%\n",
            "Step: 3056 ------------ Loss: 5265.92 ------------ Accuracy: 82.0%\n",
            "Step: 3057 ------------ Loss: 5265.43 ------------ Accuracy: 81.9%\n",
            "Step: 3058 ------------ Loss: 5265.31 ------------ Accuracy: 82.0%\n",
            "Step: 3059 ------------ Loss: 5264.66 ------------ Accuracy: 82.0%\n",
            "Step: 3060 ------------ Loss: 5263.53 ------------ Accuracy: 82.0%\n",
            "Step: 3061 ------------ Loss: 5262.91 ------------ Accuracy: 82.0%\n",
            "Step: 3062 ------------ Loss: 5262.31 ------------ Accuracy: 82.1%\n",
            "Step: 3063 ------------ Loss: 5261.59 ------------ Accuracy: 82.1%\n",
            "Step: 3064 ------------ Loss: 5261.21 ------------ Accuracy: 82.1%\n",
            "Step: 3065 ------------ Loss: 5260.61 ------------ Accuracy: 82.1%\n",
            "Step: 3066 ------------ Loss: 5259.91 ------------ Accuracy: 82.1%\n",
            "Step: 3067 ------------ Loss: 5259.31 ------------ Accuracy: 82.2%\n",
            "Step: 3068 ------------ Loss: 5258.66 ------------ Accuracy: 82.2%\n",
            "Step: 3069 ------------ Loss: 5258.57 ------------ Accuracy: 82.2%\n",
            "Step: 3070 ------------ Loss: 5258.19 ------------ Accuracy: 82.2%\n",
            "Step: 3071 ------------ Loss: 5257.6 ------------ Accuracy: 82.2%\n",
            "Step: 3072 ------------ Loss: 5256.96 ------------ Accuracy: 82.2%\n",
            "Step: 3073 ------------ Loss: 5256.28 ------------ Accuracy: 82.2%\n",
            "Step: 3074 ------------ Loss: 5255.16 ------------ Accuracy: 82.2%\n",
            "Step: 3075 ------------ Loss: 5254.46 ------------ Accuracy: 82.2%\n",
            "Step: 3076 ------------ Loss: 5254.09 ------------ Accuracy: 82.2%\n",
            "Step: 3077 ------------ Loss: 5253.44 ------------ Accuracy: 82.3%\n",
            "Step: 3078 ------------ Loss: 5253.35 ------------ Accuracy: 82.2%\n",
            "Step: 3079 ------------ Loss: 5252.25 ------------ Accuracy: 82.2%\n",
            "Step: 3080 ------------ Loss: 5250.84 ------------ Accuracy: 82.1%\n",
            "Step: 3081 ------------ Loss: 5250.18 ------------ Accuracy: 82.1%\n",
            "Step: 3082 ------------ Loss: 5249.46 ------------ Accuracy: 82.1%\n",
            "Step: 3083 ------------ Loss: 5248.81 ------------ Accuracy: 82.1%\n",
            "Step: 3084 ------------ Loss: 5248.13 ------------ Accuracy: 82.1%\n",
            "Step: 3085 ------------ Loss: 5247.45 ------------ Accuracy: 82.1%\n",
            "Step: 3086 ------------ Loss: 5247.2 ------------ Accuracy: 82.2%\n",
            "Step: 3087 ------------ Loss: 5246.08 ------------ Accuracy: 82.2%\n",
            "Step: 3088 ------------ Loss: 5245.98 ------------ Accuracy: 82.2%\n",
            "Step: 3089 ------------ Loss: 5245.48 ------------ Accuracy: 82.1%\n",
            "Step: 3090 ------------ Loss: 5244.82 ------------ Accuracy: 82.1%\n",
            "Step: 3091 ------------ Loss: 5244.16 ------------ Accuracy: 82.2%\n",
            "Step: 3092 ------------ Loss: 5243.67 ------------ Accuracy: 82.2%\n",
            "Step: 3093 ------------ Loss: 5243.04 ------------ Accuracy: 82.2%\n",
            "Step: 3094 ------------ Loss: 5242.39 ------------ Accuracy: 82.2%\n",
            "Step: 3095 ------------ Loss: 5242.12 ------------ Accuracy: 82.3%\n",
            "Step: 3096 ------------ Loss: 5241.73 ------------ Accuracy: 82.3%\n",
            "Step: 3097 ------------ Loss: 5241.48 ------------ Accuracy: 82.3%\n",
            "Step: 3098 ------------ Loss: 5240.84 ------------ Accuracy: 82.3%\n",
            "Step: 3099 ------------ Loss: 5240.19 ------------ Accuracy: 82.3%\n",
            "Step: 3100 ------------ Loss: 5239.18 ------------ Accuracy: 82.3%\n",
            "Step: 3101 ------------ Loss: 5238.53 ------------ Accuracy: 82.3%\n",
            "Step: 3102 ------------ Loss: 5238.15 ------------ Accuracy: 82.4%\n",
            "Step: 3103 ------------ Loss: 5237.56 ------------ Accuracy: 82.4%\n",
            "Step: 3104 ------------ Loss: 5236.92 ------------ Accuracy: 82.4%\n",
            "Step: 3105 ------------ Loss: 5236.82 ------------ Accuracy: 82.4%\n",
            "Step: 3106 ------------ Loss: 5236.16 ------------ Accuracy: 82.3%\n",
            "Step: 3107 ------------ Loss: 5234.74 ------------ Accuracy: 82.3%\n",
            "Step: 3108 ------------ Loss: 5234.37 ------------ Accuracy: 82.3%\n",
            "Step: 3109 ------------ Loss: 5233.24 ------------ Accuracy: 82.3%\n",
            "Step: 3110 ------------ Loss: 5232.61 ------------ Accuracy: 82.3%\n",
            "Step: 3111 ------------ Loss: 5231.98 ------------ Accuracy: 82.3%\n",
            "Step: 3112 ------------ Loss: 5231.6 ------------ Accuracy: 82.3%\n",
            "Step: 3113 ------------ Loss: 5230.94 ------------ Accuracy: 82.3%\n",
            "Step: 3114 ------------ Loss: 5229.94 ------------ Accuracy: 82.3%\n",
            "Step: 3115 ------------ Loss: 5229.72 ------------ Accuracy: 82.3%\n",
            "Step: 3116 ------------ Loss: 5229.35 ------------ Accuracy: 82.4%\n",
            "Step: 3117 ------------ Loss: 5228.72 ------------ Accuracy: 82.4%\n",
            "Step: 3118 ------------ Loss: 5228.07 ------------ Accuracy: 82.4%\n",
            "Step: 3119 ------------ Loss: 5226.7 ------------ Accuracy: 82.3%\n",
            "Step: 3120 ------------ Loss: 5226.05 ------------ Accuracy: 82.4%\n",
            "Step: 3121 ------------ Loss: 5225.94 ------------ Accuracy: 82.3%\n",
            "Step: 3122 ------------ Loss: 5224.99 ------------ Accuracy: 82.3%\n",
            "Step: 3123 ------------ Loss: 5224.62 ------------ Accuracy: 82.3%\n",
            "Step: 3124 ------------ Loss: 5223.97 ------------ Accuracy: 82.4%\n",
            "Step: 3125 ------------ Loss: 5223.34 ------------ Accuracy: 82.4%\n",
            "Step: 3126 ------------ Loss: 5222.73 ------------ Accuracy: 82.5%\n",
            "Step: 3127 ------------ Loss: 5222.63 ------------ Accuracy: 82.5%\n",
            "Step: 3128 ------------ Loss: 5221.95 ------------ Accuracy: 82.5%\n",
            "Step: 3129 ------------ Loss: 5221.3 ------------ Accuracy: 82.5%\n",
            "Step: 3130 ------------ Loss: 5220.93 ------------ Accuracy: 82.5%\n",
            "Step: 3131 ------------ Loss: 5220.73 ------------ Accuracy: 82.5%\n",
            "Step: 3132 ------------ Loss: 5220.63 ------------ Accuracy: 82.6%\n",
            "Step: 3133 ------------ Loss: 5219.97 ------------ Accuracy: 82.5%\n",
            "Step: 3134 ------------ Loss: 5219.87 ------------ Accuracy: 82.5%\n",
            "Step: 3135 ------------ Loss: 5219.28 ------------ Accuracy: 82.5%\n",
            "Step: 3136 ------------ Loss: 5218.67 ------------ Accuracy: 82.7%\n",
            "Step: 3137 ------------ Loss: 5218.14 ------------ Accuracy: 82.6%\n",
            "Step: 3138 ------------ Loss: 5217.92 ------------ Accuracy: 82.7%\n",
            "Step: 3139 ------------ Loss: 5217.41 ------------ Accuracy: 82.5%\n",
            "Step: 3140 ------------ Loss: 5217.2 ------------ Accuracy: 82.6%\n",
            "Step: 3141 ------------ Loss: 5216.56 ------------ Accuracy: 82.6%\n",
            "Step: 3142 ------------ Loss: 5215.93 ------------ Accuracy: 82.6%\n",
            "Step: 3143 ------------ Loss: 5215.32 ------------ Accuracy: 82.7%\n",
            "Step: 3144 ------------ Loss: 5214.18 ------------ Accuracy: 82.6%\n",
            "Step: 3145 ------------ Loss: 5214.08 ------------ Accuracy: 82.7%\n",
            "Step: 3146 ------------ Loss: 5213.47 ------------ Accuracy: 82.7%\n",
            "Step: 3147 ------------ Loss: 5212.89 ------------ Accuracy: 82.8%\n",
            "Step: 3148 ------------ Loss: 5212.26 ------------ Accuracy: 82.8%\n",
            "Step: 3149 ------------ Loss: 5211.66 ------------ Accuracy: 82.8%\n",
            "Step: 3150 ------------ Loss: 5210.64 ------------ Accuracy: 82.8%\n",
            "Step: 3151 ------------ Loss: 5210.07 ------------ Accuracy: 82.9%\n",
            "Step: 3152 ------------ Loss: 5208.63 ------------ Accuracy: 82.7%\n",
            "Step: 3153 ------------ Loss: 5208.11 ------------ Accuracy: 82.7%\n",
            "Step: 3154 ------------ Loss: 5207.75 ------------ Accuracy: 82.7%\n",
            "Step: 3155 ------------ Loss: 5207.11 ------------ Accuracy: 82.5%\n",
            "Step: 3156 ------------ Loss: 5206.72 ------------ Accuracy: 82.6%\n",
            "Step: 3157 ------------ Loss: 5205.61 ------------ Accuracy: 82.5%\n",
            "Step: 3158 ------------ Loss: 5205.25 ------------ Accuracy: 82.5%\n",
            "Step: 3159 ------------ Loss: 5204.88 ------------ Accuracy: 82.5%\n",
            "Step: 3160 ------------ Loss: 5204.79 ------------ Accuracy: 82.6%\n",
            "Step: 3161 ------------ Loss: 5203.44 ------------ Accuracy: 82.5%\n",
            "Step: 3162 ------------ Loss: 5202.78 ------------ Accuracy: 82.5%\n",
            "Step: 3163 ------------ Loss: 5202.67 ------------ Accuracy: 82.5%\n",
            "Step: 3164 ------------ Loss: 5202.02 ------------ Accuracy: 82.5%\n",
            "Step: 3165 ------------ Loss: 5201.92 ------------ Accuracy: 82.6%\n",
            "Step: 3166 ------------ Loss: 5201.29 ------------ Accuracy: 82.6%\n",
            "Step: 3167 ------------ Loss: 5201.07 ------------ Accuracy: 82.6%\n",
            "Step: 3168 ------------ Loss: 5200.98 ------------ Accuracy: 82.7%\n",
            "Step: 3169 ------------ Loss: 5200.61 ------------ Accuracy: 82.7%\n",
            "Step: 3170 ------------ Loss: 5199.97 ------------ Accuracy: 82.8%\n",
            "Step: 3171 ------------ Loss: 5198.86 ------------ Accuracy: 82.8%\n",
            "Step: 3172 ------------ Loss: 5198.36 ------------ Accuracy: 82.7%\n",
            "Step: 3173 ------------ Loss: 5197.75 ------------ Accuracy: 82.7%\n",
            "Step: 3174 ------------ Loss: 5197.12 ------------ Accuracy: 82.7%\n",
            "Step: 3175 ------------ Loss: 5195.76 ------------ Accuracy: 82.5%\n",
            "Step: 3176 ------------ Loss: 5194.84 ------------ Accuracy: 82.5%\n",
            "Step: 3177 ------------ Loss: 5194.25 ------------ Accuracy: 82.5%\n",
            "Step: 3178 ------------ Loss: 5193.19 ------------ Accuracy: 82.5%\n",
            "Step: 3179 ------------ Loss: 5192.34 ------------ Accuracy: 82.6%\n",
            "Step: 3180 ------------ Loss: 5191.7 ------------ Accuracy: 82.6%\n",
            "Step: 3181 ------------ Loss: 5191.04 ------------ Accuracy: 82.7%\n",
            "Step: 3182 ------------ Loss: 5189.77 ------------ Accuracy: 82.5%\n",
            "Step: 3183 ------------ Loss: 5189.4 ------------ Accuracy: 82.5%\n",
            "Step: 3184 ------------ Loss: 5188.78 ------------ Accuracy: 82.5%\n",
            "Step: 3185 ------------ Loss: 5188.67 ------------ Accuracy: 82.6%\n",
            "Step: 3186 ------------ Loss: 5187.86 ------------ Accuracy: 82.6%\n",
            "Step: 3187 ------------ Loss: 5187.14 ------------ Accuracy: 82.7%\n",
            "Step: 3188 ------------ Loss: 5186.49 ------------ Accuracy: 82.7%\n",
            "Step: 3189 ------------ Loss: 5185.7 ------------ Accuracy: 82.7%\n",
            "Step: 3190 ------------ Loss: 5185.04 ------------ Accuracy: 82.6%\n",
            "Step: 3191 ------------ Loss: 5184.39 ------------ Accuracy: 82.5%\n",
            "Step: 3192 ------------ Loss: 5183.88 ------------ Accuracy: 82.6%\n",
            "Step: 3193 ------------ Loss: 5182.88 ------------ Accuracy: 82.6%\n",
            "Step: 3194 ------------ Loss: 5182.15 ------------ Accuracy: 82.6%\n",
            "Step: 3195 ------------ Loss: 5181.91 ------------ Accuracy: 82.6%\n",
            "Step: 3196 ------------ Loss: 5181.27 ------------ Accuracy: 82.5%\n",
            "Step: 3197 ------------ Loss: 5180.69 ------------ Accuracy: 82.6%\n",
            "Step: 3198 ------------ Loss: 5179.9 ------------ Accuracy: 82.6%\n",
            "Step: 3199 ------------ Loss: 5179.26 ------------ Accuracy: 82.5%\n",
            "Step: 3200 ------------ Loss: 5178.55 ------------ Accuracy: 82.6%\n",
            "Step: 3201 ------------ Loss: 5178.33 ------------ Accuracy: 82.6%\n",
            "Step: 3202 ------------ Loss: 5177.55 ------------ Accuracy: 82.7%\n",
            "Step: 3203 ------------ Loss: 5176.92 ------------ Accuracy: 82.7%\n",
            "Step: 3204 ------------ Loss: 5176.72 ------------ Accuracy: 82.7%\n",
            "Step: 3205 ------------ Loss: 5176.08 ------------ Accuracy: 82.7%\n",
            "Step: 3206 ------------ Loss: 5175.38 ------------ Accuracy: 82.7%\n",
            "Step: 3207 ------------ Loss: 5174.72 ------------ Accuracy: 82.7%\n",
            "Step: 3208 ------------ Loss: 5174.04 ------------ Accuracy: 82.8%\n",
            "Step: 3209 ------------ Loss: 5173.41 ------------ Accuracy: 82.8%\n",
            "Step: 3210 ------------ Loss: 5173.31 ------------ Accuracy: 82.9%\n",
            "Step: 3211 ------------ Loss: 5172.78 ------------ Accuracy: 82.8%\n",
            "Step: 3212 ------------ Loss: 5172.28 ------------ Accuracy: 82.9%\n",
            "Step: 3213 ------------ Loss: 5171.7 ------------ Accuracy: 82.9%\n",
            "Step: 3214 ------------ Loss: 5171.12 ------------ Accuracy: 82.9%\n",
            "Step: 3215 ------------ Loss: 5170.91 ------------ Accuracy: 83.0%\n",
            "Step: 3216 ------------ Loss: 5170.84 ------------ Accuracy: 82.9%\n",
            "Step: 3217 ------------ Loss: 5169.56 ------------ Accuracy: 82.8%\n",
            "Step: 3218 ------------ Loss: 5169.49 ------------ Accuracy: 82.8%\n",
            "Step: 3219 ------------ Loss: 5168.7 ------------ Accuracy: 82.8%\n",
            "Step: 3220 ------------ Loss: 5168.03 ------------ Accuracy: 82.8%\n",
            "Step: 3221 ------------ Loss: 5167.28 ------------ Accuracy: 82.9%\n",
            "Step: 3222 ------------ Loss: 5166.55 ------------ Accuracy: 82.9%\n",
            "Step: 3223 ------------ Loss: 5165.57 ------------ Accuracy: 82.9%\n",
            "Step: 3224 ------------ Loss: 5164.92 ------------ Accuracy: 82.8%\n",
            "Step: 3225 ------------ Loss: 5164.34 ------------ Accuracy: 82.8%\n",
            "Step: 3226 ------------ Loss: 5163.61 ------------ Accuracy: 82.9%\n",
            "Step: 3227 ------------ Loss: 5163.03 ------------ Accuracy: 82.9%\n",
            "Step: 3228 ------------ Loss: 5162.38 ------------ Accuracy: 82.9%\n",
            "Step: 3229 ------------ Loss: 5161.68 ------------ Accuracy: 82.8%\n",
            "Step: 3230 ------------ Loss: 5161.01 ------------ Accuracy: 82.9%\n",
            "Step: 3231 ------------ Loss: 5160.44 ------------ Accuracy: 82.9%\n",
            "Step: 3232 ------------ Loss: 5160.37 ------------ Accuracy: 83.0%\n",
            "Step: 3233 ------------ Loss: 5159.75 ------------ Accuracy: 83.0%\n",
            "Step: 3234 ------------ Loss: 5159.08 ------------ Accuracy: 83.0%\n",
            "Step: 3235 ------------ Loss: 5158.52 ------------ Accuracy: 83.0%\n",
            "Step: 3236 ------------ Loss: 5157.31 ------------ Accuracy: 82.8%\n",
            "Step: 3237 ------------ Loss: 5156.56 ------------ Accuracy: 82.9%\n",
            "Step: 3238 ------------ Loss: 5155.39 ------------ Accuracy: 82.8%\n",
            "Step: 3239 ------------ Loss: 5154.76 ------------ Accuracy: 82.8%\n",
            "Step: 3240 ------------ Loss: 5154.53 ------------ Accuracy: 82.8%\n",
            "Step: 3241 ------------ Loss: 5154.32 ------------ Accuracy: 82.9%\n",
            "Step: 3242 ------------ Loss: 5153.69 ------------ Accuracy: 82.8%\n",
            "Step: 3243 ------------ Loss: 5152.75 ------------ Accuracy: 82.8%\n",
            "Step: 3244 ------------ Loss: 5152.01 ------------ Accuracy: 82.8%\n",
            "Step: 3245 ------------ Loss: 5151.39 ------------ Accuracy: 82.8%\n",
            "Step: 3246 ------------ Loss: 5150.78 ------------ Accuracy: 82.7%\n",
            "Step: 3247 ------------ Loss: 5150.19 ------------ Accuracy: 82.7%\n",
            "Step: 3248 ------------ Loss: 5149.46 ------------ Accuracy: 82.8%\n",
            "Step: 3249 ------------ Loss: 5148.74 ------------ Accuracy: 82.8%\n",
            "Step: 3250 ------------ Loss: 5148.03 ------------ Accuracy: 82.8%\n",
            "Step: 3251 ------------ Loss: 5147.64 ------------ Accuracy: 82.9%\n",
            "Step: 3252 ------------ Loss: 5147.54 ------------ Accuracy: 82.9%\n",
            "Step: 3253 ------------ Loss: 5146.81 ------------ Accuracy: 82.9%\n",
            "Step: 3254 ------------ Loss: 5146.15 ------------ Accuracy: 82.9%\n",
            "Step: 3255 ------------ Loss: 5146.07 ------------ Accuracy: 83.0%\n",
            "Step: 3256 ------------ Loss: 5145.54 ------------ Accuracy: 83.0%\n",
            "Step: 3257 ------------ Loss: 5145.49 ------------ Accuracy: 83.0%\n",
            "Step: 3258 ------------ Loss: 5144.29 ------------ Accuracy: 82.9%\n",
            "Step: 3259 ------------ Loss: 5143.36 ------------ Accuracy: 82.9%\n",
            "Step: 3260 ------------ Loss: 5142.69 ------------ Accuracy: 82.8%\n",
            "Step: 3261 ------------ Loss: 5142.31 ------------ Accuracy: 82.9%\n",
            "Step: 3262 ------------ Loss: 5141.66 ------------ Accuracy: 82.9%\n",
            "Step: 3263 ------------ Loss: 5141.53 ------------ Accuracy: 83.0%\n",
            "Step: 3264 ------------ Loss: 5140.38 ------------ Accuracy: 82.8%\n",
            "Step: 3265 ------------ Loss: 5139.7 ------------ Accuracy: 82.9%\n",
            "Step: 3266 ------------ Loss: 5138.94 ------------ Accuracy: 82.9%\n",
            "Step: 3267 ------------ Loss: 5138.22 ------------ Accuracy: 82.9%\n",
            "Step: 3268 ------------ Loss: 5138.09 ------------ Accuracy: 83.0%\n",
            "Step: 3269 ------------ Loss: 5137.71 ------------ Accuracy: 83.0%\n",
            "Step: 3270 ------------ Loss: 5137.1 ------------ Accuracy: 83.0%\n",
            "Step: 3271 ------------ Loss: 5136.46 ------------ Accuracy: 83.0%\n",
            "Step: 3272 ------------ Loss: 5135.85 ------------ Accuracy: 83.1%\n",
            "Step: 3273 ------------ Loss: 5135.47 ------------ Accuracy: 83.1%\n",
            "Step: 3274 ------------ Loss: 5134.82 ------------ Accuracy: 83.1%\n",
            "Step: 3275 ------------ Loss: 5134.17 ------------ Accuracy: 83.2%\n",
            "Step: 3276 ------------ Loss: 5133.57 ------------ Accuracy: 83.2%\n",
            "Step: 3277 ------------ Loss: 5133.21 ------------ Accuracy: 83.2%\n",
            "Step: 3278 ------------ Loss: 5132.61 ------------ Accuracy: 83.2%\n",
            "Step: 3279 ------------ Loss: 5132.24 ------------ Accuracy: 83.2%\n",
            "Step: 3280 ------------ Loss: 5131.88 ------------ Accuracy: 83.2%\n",
            "Step: 3281 ------------ Loss: 5131.35 ------------ Accuracy: 83.2%\n",
            "Step: 3282 ------------ Loss: 5130.74 ------------ Accuracy: 83.2%\n",
            "Step: 3283 ------------ Loss: 5130.16 ------------ Accuracy: 83.3%\n",
            "Step: 3284 ------------ Loss: 5129.48 ------------ Accuracy: 83.2%\n",
            "Step: 3285 ------------ Loss: 5128.9 ------------ Accuracy: 83.2%\n",
            "Step: 3286 ------------ Loss: 5128.83 ------------ Accuracy: 83.3%\n",
            "Step: 3287 ------------ Loss: 5128.18 ------------ Accuracy: 83.2%\n",
            "Step: 3288 ------------ Loss: 5126.92 ------------ Accuracy: 83.2%\n",
            "Step: 3289 ------------ Loss: 5125.72 ------------ Accuracy: 83.1%\n",
            "Step: 3290 ------------ Loss: 5125.11 ------------ Accuracy: 83.0%\n",
            "Step: 3291 ------------ Loss: 5125.02 ------------ Accuracy: 83.1%\n",
            "Step: 3292 ------------ Loss: 5124.32 ------------ Accuracy: 83.1%\n",
            "Step: 3293 ------------ Loss: 5123.77 ------------ Accuracy: 83.1%\n",
            "Step: 3294 ------------ Loss: 5123.13 ------------ Accuracy: 83.2%\n",
            "Step: 3295 ------------ Loss: 5122.46 ------------ Accuracy: 83.1%\n",
            "Step: 3296 ------------ Loss: 5121.91 ------------ Accuracy: 83.2%\n",
            "Step: 3297 ------------ Loss: 5121.14 ------------ Accuracy: 83.2%\n",
            "Step: 3298 ------------ Loss: 5120.59 ------------ Accuracy: 83.2%\n",
            "Step: 3299 ------------ Loss: 5119.92 ------------ Accuracy: 83.2%\n",
            "Step: 3300 ------------ Loss: 5119.55 ------------ Accuracy: 83.2%\n",
            "Step: 3301 ------------ Loss: 5119.45 ------------ Accuracy: 83.2%\n",
            "Step: 3302 ------------ Loss: 5118.22 ------------ Accuracy: 83.2%\n",
            "Step: 3303 ------------ Loss: 5117.63 ------------ Accuracy: 83.2%\n",
            "Step: 3304 ------------ Loss: 5117.04 ------------ Accuracy: 83.3%\n",
            "Step: 3305 ------------ Loss: 5116.44 ------------ Accuracy: 83.3%\n",
            "Step: 3306 ------------ Loss: 5116.09 ------------ Accuracy: 83.3%\n",
            "Step: 3307 ------------ Loss: 5115.58 ------------ Accuracy: 83.2%\n",
            "Step: 3308 ------------ Loss: 5114.98 ------------ Accuracy: 83.3%\n",
            "Step: 3309 ------------ Loss: 5114.62 ------------ Accuracy: 83.3%\n",
            "Step: 3310 ------------ Loss: 5114.14 ------------ Accuracy: 83.2%\n",
            "Step: 3311 ------------ Loss: 5113.52 ------------ Accuracy: 83.2%\n",
            "Step: 3312 ------------ Loss: 5113.45 ------------ Accuracy: 83.2%\n",
            "Step: 3313 ------------ Loss: 5113.0 ------------ Accuracy: 83.2%\n",
            "Step: 3314 ------------ Loss: 5112.39 ------------ Accuracy: 83.2%\n",
            "Step: 3315 ------------ Loss: 5111.61 ------------ Accuracy: 83.2%\n",
            "Step: 3316 ------------ Loss: 5110.39 ------------ Accuracy: 83.2%\n",
            "Step: 3317 ------------ Loss: 5110.02 ------------ Accuracy: 83.2%\n",
            "Step: 3318 ------------ Loss: 5109.65 ------------ Accuracy: 83.2%\n",
            "Step: 3319 ------------ Loss: 5109.03 ------------ Accuracy: 83.2%\n",
            "Step: 3320 ------------ Loss: 5108.93 ------------ Accuracy: 83.2%\n",
            "Step: 3321 ------------ Loss: 5108.39 ------------ Accuracy: 83.3%\n",
            "Step: 3322 ------------ Loss: 5107.86 ------------ Accuracy: 83.3%\n",
            "Step: 3323 ------------ Loss: 5107.8 ------------ Accuracy: 83.3%\n",
            "Step: 3324 ------------ Loss: 5107.27 ------------ Accuracy: 83.3%\n",
            "Step: 3325 ------------ Loss: 5106.66 ------------ Accuracy: 83.3%\n",
            "Step: 3326 ------------ Loss: 5105.98 ------------ Accuracy: 83.3%\n",
            "Step: 3327 ------------ Loss: 5105.31 ------------ Accuracy: 83.4%\n",
            "Step: 3328 ------------ Loss: 5104.65 ------------ Accuracy: 83.4%\n",
            "Step: 3329 ------------ Loss: 5104.12 ------------ Accuracy: 83.4%\n",
            "Step: 3330 ------------ Loss: 5103.6 ------------ Accuracy: 83.5%\n",
            "Step: 3331 ------------ Loss: 5103.26 ------------ Accuracy: 83.5%\n",
            "Step: 3332 ------------ Loss: 5101.96 ------------ Accuracy: 83.3%\n",
            "Step: 3333 ------------ Loss: 5100.72 ------------ Accuracy: 83.3%\n",
            "Step: 3334 ------------ Loss: 5099.53 ------------ Accuracy: 83.2%\n",
            "Step: 3335 ------------ Loss: 5098.39 ------------ Accuracy: 83.1%\n",
            "Step: 3336 ------------ Loss: 5097.8 ------------ Accuracy: 83.1%\n",
            "Step: 3337 ------------ Loss: 5096.72 ------------ Accuracy: 83.0%\n",
            "Step: 3338 ------------ Loss: 5095.68 ------------ Accuracy: 82.9%\n",
            "Step: 3339 ------------ Loss: 5095.12 ------------ Accuracy: 83.0%\n",
            "Step: 3340 ------------ Loss: 5094.37 ------------ Accuracy: 83.0%\n",
            "Step: 3341 ------------ Loss: 5093.64 ------------ Accuracy: 83.0%\n",
            "Step: 3342 ------------ Loss: 5093.29 ------------ Accuracy: 83.0%\n",
            "Step: 3343 ------------ Loss: 5092.82 ------------ Accuracy: 83.0%\n",
            "Step: 3344 ------------ Loss: 5092.12 ------------ Accuracy: 83.1%\n",
            "Step: 3345 ------------ Loss: 5091.52 ------------ Accuracy: 83.1%\n",
            "Step: 3346 ------------ Loss: 5091.17 ------------ Accuracy: 83.1%\n",
            "Step: 3347 ------------ Loss: 5090.83 ------------ Accuracy: 83.1%\n",
            "Step: 3348 ------------ Loss: 5089.74 ------------ Accuracy: 83.0%\n",
            "Step: 3349 ------------ Loss: 5089.05 ------------ Accuracy: 83.0%\n",
            "Step: 3350 ------------ Loss: 5088.38 ------------ Accuracy: 83.0%\n",
            "Step: 3351 ------------ Loss: 5087.94 ------------ Accuracy: 83.1%\n",
            "Step: 3352 ------------ Loss: 5087.32 ------------ Accuracy: 83.1%\n",
            "Step: 3353 ------------ Loss: 5086.96 ------------ Accuracy: 83.1%\n",
            "Step: 3354 ------------ Loss: 5086.84 ------------ Accuracy: 83.2%\n",
            "Step: 3355 ------------ Loss: 5086.23 ------------ Accuracy: 83.2%\n",
            "Step: 3356 ------------ Loss: 5085.11 ------------ Accuracy: 83.1%\n",
            "Step: 3357 ------------ Loss: 5084.55 ------------ Accuracy: 83.1%\n",
            "Step: 3358 ------------ Loss: 5084.21 ------------ Accuracy: 83.2%\n",
            "Step: 3359 ------------ Loss: 5084.09 ------------ Accuracy: 83.1%\n",
            "Step: 3360 ------------ Loss: 5083.29 ------------ Accuracy: 83.2%\n",
            "Step: 3361 ------------ Loss: 5082.2 ------------ Accuracy: 83.1%\n",
            "Step: 3362 ------------ Loss: 5081.51 ------------ Accuracy: 83.1%\n",
            "Step: 3363 ------------ Loss: 5080.88 ------------ Accuracy: 83.2%\n",
            "Step: 3364 ------------ Loss: 5080.6 ------------ Accuracy: 83.3%\n",
            "Step: 3365 ------------ Loss: 5080.05 ------------ Accuracy: 83.2%\n",
            "Step: 3366 ------------ Loss: 5079.8 ------------ Accuracy: 83.3%\n",
            "Step: 3367 ------------ Loss: 5079.69 ------------ Accuracy: 83.3%\n",
            "Step: 3368 ------------ Loss: 5078.6 ------------ Accuracy: 83.3%\n",
            "Step: 3369 ------------ Loss: 5078.0 ------------ Accuracy: 83.3%\n",
            "Step: 3370 ------------ Loss: 5077.45 ------------ Accuracy: 83.3%\n",
            "Step: 3371 ------------ Loss: 5077.32 ------------ Accuracy: 83.3%\n",
            "Step: 3372 ------------ Loss: 5076.96 ------------ Accuracy: 83.3%\n",
            "Step: 3373 ------------ Loss: 5076.5 ------------ Accuracy: 83.3%\n",
            "Step: 3374 ------------ Loss: 5075.9 ------------ Accuracy: 83.4%\n",
            "Step: 3375 ------------ Loss: 5075.31 ------------ Accuracy: 83.4%\n",
            "Step: 3376 ------------ Loss: 5075.06 ------------ Accuracy: 83.4%\n",
            "Step: 3377 ------------ Loss: 5074.84 ------------ Accuracy: 83.5%\n",
            "Step: 3378 ------------ Loss: 5074.37 ------------ Accuracy: 83.4%\n",
            "Step: 3379 ------------ Loss: 5073.73 ------------ Accuracy: 83.4%\n",
            "Step: 3380 ------------ Loss: 5073.11 ------------ Accuracy: 83.5%\n",
            "Step: 3381 ------------ Loss: 5072.5 ------------ Accuracy: 83.5%\n",
            "Step: 3382 ------------ Loss: 5071.92 ------------ Accuracy: 83.5%\n",
            "Step: 3383 ------------ Loss: 5071.08 ------------ Accuracy: 83.5%\n",
            "Step: 3384 ------------ Loss: 5069.92 ------------ Accuracy: 83.5%\n",
            "Step: 3385 ------------ Loss: 5069.31 ------------ Accuracy: 83.5%\n",
            "Step: 3386 ------------ Loss: 5069.1 ------------ Accuracy: 83.5%\n",
            "Step: 3387 ------------ Loss: 5069.01 ------------ Accuracy: 83.5%\n",
            "Step: 3388 ------------ Loss: 5068.41 ------------ Accuracy: 83.5%\n",
            "Step: 3389 ------------ Loss: 5068.22 ------------ Accuracy: 83.5%\n",
            "Step: 3390 ------------ Loss: 5068.04 ------------ Accuracy: 83.5%\n",
            "Step: 3391 ------------ Loss: 5067.49 ------------ Accuracy: 83.6%\n",
            "Step: 3392 ------------ Loss: 5067.39 ------------ Accuracy: 83.6%\n",
            "Step: 3393 ------------ Loss: 5066.82 ------------ Accuracy: 83.6%\n",
            "Step: 3394 ------------ Loss: 5066.24 ------------ Accuracy: 83.6%\n",
            "Step: 3395 ------------ Loss: 5065.44 ------------ Accuracy: 83.6%\n",
            "Step: 3396 ------------ Loss: 5064.85 ------------ Accuracy: 83.6%\n",
            "Step: 3397 ------------ Loss: 5064.31 ------------ Accuracy: 83.6%\n",
            "Step: 3398 ------------ Loss: 5063.72 ------------ Accuracy: 83.6%\n",
            "Step: 3399 ------------ Loss: 5063.1 ------------ Accuracy: 83.7%\n",
            "Step: 3400 ------------ Loss: 5062.12 ------------ Accuracy: 83.7%\n",
            "Step: 3401 ------------ Loss: 5062.04 ------------ Accuracy: 83.7%\n",
            "Step: 3402 ------------ Loss: 5061.44 ------------ Accuracy: 83.7%\n",
            "Step: 3403 ------------ Loss: 5061.09 ------------ Accuracy: 83.7%\n",
            "Step: 3404 ------------ Loss: 5060.91 ------------ Accuracy: 83.7%\n",
            "Step: 3405 ------------ Loss: 5060.75 ------------ Accuracy: 83.7%\n",
            "Step: 3406 ------------ Loss: 5059.56 ------------ Accuracy: 83.6%\n",
            "Step: 3407 ------------ Loss: 5059.21 ------------ Accuracy: 83.6%\n",
            "Step: 3408 ------------ Loss: 5058.88 ------------ Accuracy: 83.6%\n",
            "Step: 3409 ------------ Loss: 5058.72 ------------ Accuracy: 83.6%\n",
            "Step: 3410 ------------ Loss: 5057.57 ------------ Accuracy: 83.5%\n",
            "Step: 3411 ------------ Loss: 5056.99 ------------ Accuracy: 83.5%\n",
            "Step: 3412 ------------ Loss: 5056.88 ------------ Accuracy: 83.5%\n",
            "Step: 3413 ------------ Loss: 5056.25 ------------ Accuracy: 83.5%\n",
            "Step: 3414 ------------ Loss: 5055.11 ------------ Accuracy: 83.5%\n",
            "Step: 3415 ------------ Loss: 5054.77 ------------ Accuracy: 83.5%\n",
            "Step: 3416 ------------ Loss: 5054.03 ------------ Accuracy: 83.6%\n",
            "Step: 3417 ------------ Loss: 5053.67 ------------ Accuracy: 83.6%\n",
            "Step: 3418 ------------ Loss: 5053.57 ------------ Accuracy: 83.6%\n",
            "Step: 3419 ------------ Loss: 5052.63 ------------ Accuracy: 83.6%\n",
            "Step: 3420 ------------ Loss: 5052.06 ------------ Accuracy: 83.7%\n",
            "Step: 3421 ------------ Loss: 5051.41 ------------ Accuracy: 83.6%\n",
            "Step: 3422 ------------ Loss: 5050.76 ------------ Accuracy: 83.6%\n",
            "Step: 3423 ------------ Loss: 5050.19 ------------ Accuracy: 83.6%\n",
            "Step: 3424 ------------ Loss: 5049.66 ------------ Accuracy: 83.7%\n",
            "Step: 3425 ------------ Loss: 5049.1 ------------ Accuracy: 83.7%\n",
            "Step: 3426 ------------ Loss: 5048.52 ------------ Accuracy: 83.7%\n",
            "Step: 3427 ------------ Loss: 5047.37 ------------ Accuracy: 83.6%\n",
            "Step: 3428 ------------ Loss: 5047.02 ------------ Accuracy: 83.6%\n",
            "Step: 3429 ------------ Loss: 5046.44 ------------ Accuracy: 83.6%\n",
            "Step: 3430 ------------ Loss: 5045.71 ------------ Accuracy: 83.6%\n",
            "Step: 3431 ------------ Loss: 5044.63 ------------ Accuracy: 83.6%\n",
            "Step: 3432 ------------ Loss: 5044.53 ------------ Accuracy: 83.6%\n",
            "Step: 3433 ------------ Loss: 5043.99 ------------ Accuracy: 83.6%\n",
            "Step: 3434 ------------ Loss: 5043.4 ------------ Accuracy: 83.6%\n",
            "Step: 3435 ------------ Loss: 5042.83 ------------ Accuracy: 83.6%\n",
            "Step: 3436 ------------ Loss: 5042.49 ------------ Accuracy: 83.6%\n",
            "Step: 3437 ------------ Loss: 5041.92 ------------ Accuracy: 83.5%\n",
            "Step: 3438 ------------ Loss: 5041.79 ------------ Accuracy: 83.5%\n",
            "Step: 3439 ------------ Loss: 5041.29 ------------ Accuracy: 83.6%\n",
            "Step: 3440 ------------ Loss: 5040.94 ------------ Accuracy: 83.6%\n",
            "Step: 3441 ------------ Loss: 5040.28 ------------ Accuracy: 83.6%\n",
            "Step: 3442 ------------ Loss: 5039.75 ------------ Accuracy: 83.6%\n",
            "Step: 3443 ------------ Loss: 5039.21 ------------ Accuracy: 83.6%\n",
            "Step: 3444 ------------ Loss: 5038.65 ------------ Accuracy: 83.7%\n",
            "Step: 3445 ------------ Loss: 5037.92 ------------ Accuracy: 83.7%\n",
            "Step: 3446 ------------ Loss: 5037.81 ------------ Accuracy: 83.7%\n",
            "Step: 3447 ------------ Loss: 5037.17 ------------ Accuracy: 83.7%\n",
            "Step: 3448 ------------ Loss: 5036.62 ------------ Accuracy: 83.7%\n",
            "Step: 3449 ------------ Loss: 5035.69 ------------ Accuracy: 83.7%\n",
            "Step: 3450 ------------ Loss: 5035.05 ------------ Accuracy: 83.7%\n",
            "Step: 3451 ------------ Loss: 5034.71 ------------ Accuracy: 83.7%\n",
            "Step: 3452 ------------ Loss: 5033.58 ------------ Accuracy: 83.6%\n",
            "Step: 3453 ------------ Loss: 5032.49 ------------ Accuracy: 83.6%\n",
            "Step: 3454 ------------ Loss: 5032.28 ------------ Accuracy: 83.6%\n",
            "Step: 3455 ------------ Loss: 5032.17 ------------ Accuracy: 83.6%\n",
            "Step: 3456 ------------ Loss: 5031.82 ------------ Accuracy: 83.6%\n",
            "Step: 3457 ------------ Loss: 5031.25 ------------ Accuracy: 83.6%\n",
            "Step: 3458 ------------ Loss: 5030.18 ------------ Accuracy: 83.6%\n",
            "Step: 3459 ------------ Loss: 5029.15 ------------ Accuracy: 83.5%\n",
            "Step: 3460 ------------ Loss: 5028.26 ------------ Accuracy: 83.6%\n",
            "Step: 3461 ------------ Loss: 5027.7 ------------ Accuracy: 83.5%\n",
            "Step: 3462 ------------ Loss: 5027.16 ------------ Accuracy: 83.5%\n",
            "Step: 3463 ------------ Loss: 5026.49 ------------ Accuracy: 83.5%\n",
            "Step: 3464 ------------ Loss: 5025.91 ------------ Accuracy: 83.5%\n",
            "Step: 3465 ------------ Loss: 5025.78 ------------ Accuracy: 83.5%\n",
            "Step: 3466 ------------ Loss: 5025.43 ------------ Accuracy: 83.5%\n",
            "Step: 3467 ------------ Loss: 5024.72 ------------ Accuracy: 83.6%\n",
            "Step: 3468 ------------ Loss: 5024.38 ------------ Accuracy: 83.6%\n",
            "Step: 3469 ------------ Loss: 5023.87 ------------ Accuracy: 83.6%\n",
            "Step: 3470 ------------ Loss: 5023.75 ------------ Accuracy: 83.6%\n",
            "Step: 3471 ------------ Loss: 5023.06 ------------ Accuracy: 83.6%\n",
            "Step: 3472 ------------ Loss: 5022.19 ------------ Accuracy: 83.6%\n",
            "Step: 3473 ------------ Loss: 5021.84 ------------ Accuracy: 83.6%\n",
            "Step: 3474 ------------ Loss: 5021.61 ------------ Accuracy: 83.6%\n",
            "Step: 3475 ------------ Loss: 5020.75 ------------ Accuracy: 83.6%\n",
            "Step: 3476 ------------ Loss: 5020.66 ------------ Accuracy: 83.6%\n",
            "Step: 3477 ------------ Loss: 5019.97 ------------ Accuracy: 83.7%\n",
            "Step: 3478 ------------ Loss: 5019.31 ------------ Accuracy: 83.7%\n",
            "Step: 3479 ------------ Loss: 5019.2 ------------ Accuracy: 83.7%\n",
            "Step: 3480 ------------ Loss: 5018.99 ------------ Accuracy: 83.7%\n",
            "Step: 3481 ------------ Loss: 5018.49 ------------ Accuracy: 83.7%\n",
            "Step: 3482 ------------ Loss: 5018.14 ------------ Accuracy: 83.7%\n",
            "Step: 3483 ------------ Loss: 5017.49 ------------ Accuracy: 83.8%\n",
            "Step: 3484 ------------ Loss: 5017.3 ------------ Accuracy: 83.7%\n",
            "Step: 3485 ------------ Loss: 5016.2 ------------ Accuracy: 83.7%\n",
            "Step: 3486 ------------ Loss: 5015.52 ------------ Accuracy: 83.7%\n",
            "Step: 3487 ------------ Loss: 5015.17 ------------ Accuracy: 83.7%\n",
            "Step: 3488 ------------ Loss: 5014.58 ------------ Accuracy: 83.7%\n",
            "Step: 3489 ------------ Loss: 5013.93 ------------ Accuracy: 83.7%\n",
            "Step: 3490 ------------ Loss: 5013.3 ------------ Accuracy: 83.7%\n",
            "Step: 3491 ------------ Loss: 5013.13 ------------ Accuracy: 83.7%\n",
            "Step: 3492 ------------ Loss: 5012.78 ------------ Accuracy: 83.7%\n",
            "Step: 3493 ------------ Loss: 5012.43 ------------ Accuracy: 83.7%\n",
            "Step: 3494 ------------ Loss: 5011.91 ------------ Accuracy: 83.8%\n",
            "Step: 3495 ------------ Loss: 5011.35 ------------ Accuracy: 83.8%\n",
            "Step: 3496 ------------ Loss: 5011.27 ------------ Accuracy: 83.8%\n",
            "Step: 3497 ------------ Loss: 5010.8 ------------ Accuracy: 83.8%\n",
            "Step: 3498 ------------ Loss: 5010.2 ------------ Accuracy: 83.8%\n",
            "Step: 3499 ------------ Loss: 5009.67 ------------ Accuracy: 83.8%\n",
            "Step: 3500 ------------ Loss: 5009.14 ------------ Accuracy: 83.8%\n",
            "Step: 3501 ------------ Loss: 5009.09 ------------ Accuracy: 83.9%\n",
            "Step: 3502 ------------ Loss: 5008.53 ------------ Accuracy: 83.9%\n",
            "Step: 3503 ------------ Loss: 5007.4 ------------ Accuracy: 83.8%\n",
            "Step: 3504 ------------ Loss: 5007.34 ------------ Accuracy: 83.8%\n",
            "Step: 3505 ------------ Loss: 5006.99 ------------ Accuracy: 83.8%\n",
            "Step: 3506 ------------ Loss: 5006.43 ------------ Accuracy: 83.9%\n",
            "Step: 3507 ------------ Loss: 5005.33 ------------ Accuracy: 83.8%\n",
            "Step: 3508 ------------ Loss: 5004.78 ------------ Accuracy: 83.7%\n",
            "Step: 3509 ------------ Loss: 5003.74 ------------ Accuracy: 83.7%\n",
            "Step: 3510 ------------ Loss: 5002.74 ------------ Accuracy: 83.6%\n",
            "Step: 3511 ------------ Loss: 5002.08 ------------ Accuracy: 83.6%\n",
            "Step: 3512 ------------ Loss: 5001.56 ------------ Accuracy: 83.6%\n",
            "Step: 3513 ------------ Loss: 5000.92 ------------ Accuracy: 83.6%\n",
            "Step: 3514 ------------ Loss: 5000.41 ------------ Accuracy: 83.6%\n",
            "Step: 3515 ------------ Loss: 4999.92 ------------ Accuracy: 83.6%\n",
            "Step: 3516 ------------ Loss: 4999.43 ------------ Accuracy: 83.6%\n",
            "Step: 3517 ------------ Loss: 4999.21 ------------ Accuracy: 83.6%\n",
            "Step: 3518 ------------ Loss: 4998.85 ------------ Accuracy: 83.6%\n",
            "Step: 3519 ------------ Loss: 4998.09 ------------ Accuracy: 83.6%\n",
            "Step: 3520 ------------ Loss: 4997.74 ------------ Accuracy: 83.6%\n",
            "Step: 3521 ------------ Loss: 4997.13 ------------ Accuracy: 83.6%\n",
            "Step: 3522 ------------ Loss: 4996.78 ------------ Accuracy: 83.6%\n",
            "Step: 3523 ------------ Loss: 4996.04 ------------ Accuracy: 83.6%\n",
            "Step: 3524 ------------ Loss: 4995.43 ------------ Accuracy: 83.7%\n",
            "Step: 3525 ------------ Loss: 4994.45 ------------ Accuracy: 83.6%\n",
            "Step: 3526 ------------ Loss: 4994.11 ------------ Accuracy: 83.6%\n",
            "Step: 3527 ------------ Loss: 4993.16 ------------ Accuracy: 83.6%\n",
            "Step: 3528 ------------ Loss: 4992.25 ------------ Accuracy: 83.5%\n",
            "Step: 3529 ------------ Loss: 4991.69 ------------ Accuracy: 83.6%\n",
            "Step: 3530 ------------ Loss: 4990.82 ------------ Accuracy: 83.6%\n",
            "Step: 3531 ------------ Loss: 4990.15 ------------ Accuracy: 83.6%\n",
            "Step: 3532 ------------ Loss: 4989.25 ------------ Accuracy: 83.5%\n",
            "Step: 3533 ------------ Loss: 4988.4 ------------ Accuracy: 83.5%\n",
            "Step: 3534 ------------ Loss: 4988.2 ------------ Accuracy: 83.5%\n",
            "Step: 3535 ------------ Loss: 4987.53 ------------ Accuracy: 83.5%\n",
            "Step: 3536 ------------ Loss: 4987.27 ------------ Accuracy: 83.6%\n",
            "Step: 3537 ------------ Loss: 4986.64 ------------ Accuracy: 83.6%\n",
            "Step: 3538 ------------ Loss: 4985.79 ------------ Accuracy: 83.6%\n",
            "Step: 3539 ------------ Loss: 4985.43 ------------ Accuracy: 83.6%\n",
            "Step: 3540 ------------ Loss: 4984.79 ------------ Accuracy: 83.6%\n",
            "Step: 3541 ------------ Loss: 4984.19 ------------ Accuracy: 83.6%\n",
            "Step: 3542 ------------ Loss: 4983.67 ------------ Accuracy: 83.6%\n",
            "Step: 3543 ------------ Loss: 4982.83 ------------ Accuracy: 83.6%\n",
            "Step: 3544 ------------ Loss: 4982.22 ------------ Accuracy: 83.6%\n",
            "Step: 3545 ------------ Loss: 4981.96 ------------ Accuracy: 83.6%\n",
            "Step: 3546 ------------ Loss: 4981.76 ------------ Accuracy: 83.6%\n",
            "Step: 3547 ------------ Loss: 4981.17 ------------ Accuracy: 83.6%\n",
            "Step: 3548 ------------ Loss: 4980.54 ------------ Accuracy: 83.6%\n",
            "Step: 3549 ------------ Loss: 4980.4 ------------ Accuracy: 83.7%\n",
            "Step: 3550 ------------ Loss: 4979.7 ------------ Accuracy: 83.7%\n",
            "Step: 3551 ------------ Loss: 4979.5 ------------ Accuracy: 83.7%\n",
            "Step: 3552 ------------ Loss: 4979.34 ------------ Accuracy: 83.7%\n",
            "Step: 3553 ------------ Loss: 4978.77 ------------ Accuracy: 83.8%\n",
            "Step: 3554 ------------ Loss: 4978.19 ------------ Accuracy: 83.8%\n",
            "Step: 3555 ------------ Loss: 4977.59 ------------ Accuracy: 83.9%\n",
            "Step: 3556 ------------ Loss: 4976.77 ------------ Accuracy: 83.9%\n",
            "Step: 3557 ------------ Loss: 4976.41 ------------ Accuracy: 83.9%\n",
            "Step: 3558 ------------ Loss: 4976.31 ------------ Accuracy: 83.8%\n",
            "Step: 3559 ------------ Loss: 4976.23 ------------ Accuracy: 83.8%\n",
            "Step: 3560 ------------ Loss: 4975.27 ------------ Accuracy: 83.9%\n",
            "Step: 3561 ------------ Loss: 4974.71 ------------ Accuracy: 83.8%\n",
            "Step: 3562 ------------ Loss: 4973.91 ------------ Accuracy: 83.8%\n",
            "Step: 3563 ------------ Loss: 4973.36 ------------ Accuracy: 83.7%\n",
            "Step: 3564 ------------ Loss: 4972.56 ------------ Accuracy: 83.7%\n",
            "Step: 3565 ------------ Loss: 4971.94 ------------ Accuracy: 83.8%\n",
            "Step: 3566 ------------ Loss: 4971.79 ------------ Accuracy: 83.8%\n",
            "Step: 3567 ------------ Loss: 4971.7 ------------ Accuracy: 83.8%\n",
            "Step: 3568 ------------ Loss: 4971.11 ------------ Accuracy: 83.8%\n",
            "Step: 3569 ------------ Loss: 4970.33 ------------ Accuracy: 83.8%\n",
            "Step: 3570 ------------ Loss: 4969.56 ------------ Accuracy: 83.8%\n",
            "Step: 3571 ------------ Loss: 4969.03 ------------ Accuracy: 83.8%\n",
            "Step: 3572 ------------ Loss: 4968.88 ------------ Accuracy: 83.8%\n",
            "Step: 3573 ------------ Loss: 4968.17 ------------ Accuracy: 83.8%\n",
            "Step: 3574 ------------ Loss: 4967.65 ------------ Accuracy: 83.8%\n",
            "Step: 3575 ------------ Loss: 4967.52 ------------ Accuracy: 83.8%\n",
            "Step: 3576 ------------ Loss: 4967.29 ------------ Accuracy: 83.9%\n",
            "Step: 3577 ------------ Loss: 4967.07 ------------ Accuracy: 83.9%\n",
            "Step: 3578 ------------ Loss: 4966.51 ------------ Accuracy: 84.0%\n",
            "Step: 3579 ------------ Loss: 4966.31 ------------ Accuracy: 84.0%\n",
            "Step: 3580 ------------ Loss: 4965.79 ------------ Accuracy: 84.0%\n",
            "Step: 3581 ------------ Loss: 4965.28 ------------ Accuracy: 84.0%\n",
            "Step: 3582 ------------ Loss: 4964.62 ------------ Accuracy: 84.0%\n",
            "Step: 3583 ------------ Loss: 4963.82 ------------ Accuracy: 84.0%\n",
            "Step: 3584 ------------ Loss: 4963.48 ------------ Accuracy: 84.0%\n",
            "Step: 3585 ------------ Loss: 4962.97 ------------ Accuracy: 84.0%\n",
            "Step: 3586 ------------ Loss: 4962.86 ------------ Accuracy: 84.0%\n",
            "Step: 3587 ------------ Loss: 4962.3 ------------ Accuracy: 84.0%\n",
            "Step: 3588 ------------ Loss: 4961.74 ------------ Accuracy: 84.1%\n",
            "Step: 3589 ------------ Loss: 4961.64 ------------ Accuracy: 84.1%\n",
            "Step: 3590 ------------ Loss: 4961.06 ------------ Accuracy: 84.0%\n",
            "Step: 3591 ------------ Loss: 4960.5 ------------ Accuracy: 84.0%\n",
            "Step: 3592 ------------ Loss: 4959.96 ------------ Accuracy: 84.0%\n",
            "Step: 3593 ------------ Loss: 4959.76 ------------ Accuracy: 84.1%\n",
            "Step: 3594 ------------ Loss: 4959.19 ------------ Accuracy: 84.0%\n",
            "Step: 3595 ------------ Loss: 4958.39 ------------ Accuracy: 84.0%\n",
            "Step: 3596 ------------ Loss: 4957.76 ------------ Accuracy: 84.0%\n",
            "Step: 3597 ------------ Loss: 4957.18 ------------ Accuracy: 84.1%\n",
            "Step: 3598 ------------ Loss: 4956.57 ------------ Accuracy: 84.0%\n",
            "Step: 3599 ------------ Loss: 4956.24 ------------ Accuracy: 84.1%\n",
            "Step: 3600 ------------ Loss: 4955.61 ------------ Accuracy: 84.1%\n",
            "Step: 3601 ------------ Loss: 4955.01 ------------ Accuracy: 84.1%\n",
            "Step: 3602 ------------ Loss: 4954.43 ------------ Accuracy: 84.1%\n",
            "Step: 3603 ------------ Loss: 4954.09 ------------ Accuracy: 84.1%\n",
            "Step: 3604 ------------ Loss: 4954.0 ------------ Accuracy: 84.1%\n",
            "Step: 3605 ------------ Loss: 4953.21 ------------ Accuracy: 84.2%\n",
            "Step: 3606 ------------ Loss: 4952.44 ------------ Accuracy: 84.2%\n",
            "Step: 3607 ------------ Loss: 4951.89 ------------ Accuracy: 84.2%\n",
            "Step: 3608 ------------ Loss: 4950.83 ------------ Accuracy: 84.0%\n",
            "Step: 3609 ------------ Loss: 4950.49 ------------ Accuracy: 84.0%\n",
            "Step: 3610 ------------ Loss: 4949.74 ------------ Accuracy: 84.0%\n",
            "Step: 3611 ------------ Loss: 4949.25 ------------ Accuracy: 84.1%\n",
            "Step: 3612 ------------ Loss: 4948.6 ------------ Accuracy: 84.1%\n",
            "Step: 3613 ------------ Loss: 4947.57 ------------ Accuracy: 84.0%\n",
            "Step: 3614 ------------ Loss: 4946.83 ------------ Accuracy: 84.0%\n",
            "Step: 3615 ------------ Loss: 4946.49 ------------ Accuracy: 84.0%\n",
            "Step: 3616 ------------ Loss: 4946.0 ------------ Accuracy: 84.0%\n",
            "Step: 3617 ------------ Loss: 4945.35 ------------ Accuracy: 84.0%\n",
            "Step: 3618 ------------ Loss: 4944.69 ------------ Accuracy: 84.0%\n",
            "Step: 3619 ------------ Loss: 4944.06 ------------ Accuracy: 84.1%\n",
            "Step: 3620 ------------ Loss: 4943.58 ------------ Accuracy: 84.1%\n",
            "Step: 3621 ------------ Loss: 4943.38 ------------ Accuracy: 84.1%\n",
            "Step: 3622 ------------ Loss: 4942.75 ------------ Accuracy: 84.1%\n",
            "Step: 3623 ------------ Loss: 4942.16 ------------ Accuracy: 84.1%\n",
            "Step: 3624 ------------ Loss: 4941.39 ------------ Accuracy: 84.1%\n",
            "Step: 3625 ------------ Loss: 4940.87 ------------ Accuracy: 84.2%\n",
            "Step: 3626 ------------ Loss: 4940.53 ------------ Accuracy: 84.2%\n",
            "Step: 3627 ------------ Loss: 4939.93 ------------ Accuracy: 84.2%\n",
            "Step: 3628 ------------ Loss: 4939.32 ------------ Accuracy: 84.2%\n",
            "Step: 3629 ------------ Loss: 4938.58 ------------ Accuracy: 84.2%\n",
            "Step: 3630 ------------ Loss: 4937.98 ------------ Accuracy: 84.2%\n",
            "Step: 3631 ------------ Loss: 4937.5 ------------ Accuracy: 84.3%\n",
            "Step: 3632 ------------ Loss: 4937.41 ------------ Accuracy: 84.3%\n",
            "Step: 3633 ------------ Loss: 4936.88 ------------ Accuracy: 84.3%\n",
            "Step: 3634 ------------ Loss: 4936.3 ------------ Accuracy: 84.3%\n",
            "Step: 3635 ------------ Loss: 4935.73 ------------ Accuracy: 84.2%\n",
            "Step: 3636 ------------ Loss: 4935.63 ------------ Accuracy: 84.3%\n",
            "Step: 3637 ------------ Loss: 4935.44 ------------ Accuracy: 84.2%\n",
            "Step: 3638 ------------ Loss: 4934.84 ------------ Accuracy: 84.3%\n",
            "Step: 3639 ------------ Loss: 4934.76 ------------ Accuracy: 84.3%\n",
            "Step: 3640 ------------ Loss: 4934.16 ------------ Accuracy: 84.3%\n",
            "Step: 3641 ------------ Loss: 4933.98 ------------ Accuracy: 84.3%\n",
            "Step: 3642 ------------ Loss: 4933.41 ------------ Accuracy: 84.2%\n",
            "Step: 3643 ------------ Loss: 4933.25 ------------ Accuracy: 84.3%\n",
            "Step: 3644 ------------ Loss: 4933.16 ------------ Accuracy: 84.3%\n",
            "Step: 3645 ------------ Loss: 4933.06 ------------ Accuracy: 84.3%\n",
            "Step: 3646 ------------ Loss: 4932.72 ------------ Accuracy: 84.3%\n",
            "Step: 3647 ------------ Loss: 4932.17 ------------ Accuracy: 84.3%\n",
            "Step: 3648 ------------ Loss: 4931.64 ------------ Accuracy: 84.3%\n",
            "Step: 3649 ------------ Loss: 4931.08 ------------ Accuracy: 84.3%\n",
            "Step: 3650 ------------ Loss: 4930.52 ------------ Accuracy: 84.3%\n",
            "Step: 3651 ------------ Loss: 4930.45 ------------ Accuracy: 84.3%\n",
            "Step: 3652 ------------ Loss: 4929.82 ------------ Accuracy: 84.3%\n",
            "Step: 3653 ------------ Loss: 4929.49 ------------ Accuracy: 84.3%\n",
            "Step: 3654 ------------ Loss: 4928.98 ------------ Accuracy: 84.3%\n",
            "Step: 3655 ------------ Loss: 4928.49 ------------ Accuracy: 84.3%\n",
            "Step: 3656 ------------ Loss: 4928.41 ------------ Accuracy: 84.3%\n",
            "Step: 3657 ------------ Loss: 4928.08 ------------ Accuracy: 84.3%\n",
            "Step: 3658 ------------ Loss: 4927.74 ------------ Accuracy: 84.3%\n",
            "Step: 3659 ------------ Loss: 4927.18 ------------ Accuracy: 84.4%\n",
            "Step: 3660 ------------ Loss: 4926.09 ------------ Accuracy: 84.3%\n",
            "Step: 3661 ------------ Loss: 4925.5 ------------ Accuracy: 84.3%\n",
            "Step: 3662 ------------ Loss: 4925.3 ------------ Accuracy: 84.3%\n",
            "Step: 3663 ------------ Loss: 4925.24 ------------ Accuracy: 84.3%\n",
            "Step: 3664 ------------ Loss: 4924.75 ------------ Accuracy: 84.3%\n",
            "Step: 3665 ------------ Loss: 4924.19 ------------ Accuracy: 84.3%\n",
            "Step: 3666 ------------ Loss: 4923.86 ------------ Accuracy: 84.3%\n",
            "Step: 3667 ------------ Loss: 4923.77 ------------ Accuracy: 84.3%\n",
            "Step: 3668 ------------ Loss: 4923.22 ------------ Accuracy: 84.3%\n",
            "Step: 3669 ------------ Loss: 4922.64 ------------ Accuracy: 84.3%\n",
            "Step: 3670 ------------ Loss: 4922.1 ------------ Accuracy: 84.2%\n",
            "Step: 3671 ------------ Loss: 4921.48 ------------ Accuracy: 84.3%\n",
            "Step: 3672 ------------ Loss: 4921.0 ------------ Accuracy: 84.3%\n",
            "Step: 3673 ------------ Loss: 4920.94 ------------ Accuracy: 84.3%\n",
            "Step: 3674 ------------ Loss: 4920.35 ------------ Accuracy: 84.3%\n",
            "Step: 3675 ------------ Loss: 4919.33 ------------ Accuracy: 84.2%\n",
            "Step: 3676 ------------ Loss: 4919.13 ------------ Accuracy: 84.2%\n",
            "Step: 3677 ------------ Loss: 4919.03 ------------ Accuracy: 84.2%\n",
            "Step: 3678 ------------ Loss: 4918.53 ------------ Accuracy: 84.3%\n",
            "Step: 3679 ------------ Loss: 4917.92 ------------ Accuracy: 84.3%\n",
            "Step: 3680 ------------ Loss: 4917.73 ------------ Accuracy: 84.3%\n",
            "Step: 3681 ------------ Loss: 4917.2 ------------ Accuracy: 84.2%\n",
            "Step: 3682 ------------ Loss: 4916.85 ------------ Accuracy: 84.2%\n",
            "Step: 3683 ------------ Loss: 4916.76 ------------ Accuracy: 84.3%\n",
            "Step: 3684 ------------ Loss: 4916.19 ------------ Accuracy: 84.3%\n",
            "Step: 3685 ------------ Loss: 4915.16 ------------ Accuracy: 84.1%\n",
            "Step: 3686 ------------ Loss: 4914.36 ------------ Accuracy: 84.1%\n",
            "Step: 3687 ------------ Loss: 4914.29 ------------ Accuracy: 84.2%\n",
            "Step: 3688 ------------ Loss: 4913.76 ------------ Accuracy: 84.1%\n",
            "Step: 3689 ------------ Loss: 4913.19 ------------ Accuracy: 84.1%\n",
            "Step: 3690 ------------ Loss: 4912.62 ------------ Accuracy: 84.1%\n",
            "Step: 3691 ------------ Loss: 4912.29 ------------ Accuracy: 84.1%\n",
            "Step: 3692 ------------ Loss: 4911.73 ------------ Accuracy: 84.2%\n",
            "Step: 3693 ------------ Loss: 4911.64 ------------ Accuracy: 84.2%\n",
            "Step: 3694 ------------ Loss: 4911.1 ------------ Accuracy: 84.3%\n",
            "Step: 3695 ------------ Loss: 4910.55 ------------ Accuracy: 84.3%\n",
            "Step: 3696 ------------ Loss: 4910.22 ------------ Accuracy: 84.3%\n",
            "Step: 3697 ------------ Loss: 4910.14 ------------ Accuracy: 84.3%\n",
            "Step: 3698 ------------ Loss: 4910.06 ------------ Accuracy: 84.4%\n",
            "Step: 3699 ------------ Loss: 4909.0 ------------ Accuracy: 84.2%\n",
            "Step: 3700 ------------ Loss: 4908.83 ------------ Accuracy: 84.3%\n",
            "Step: 3701 ------------ Loss: 4908.74 ------------ Accuracy: 84.3%\n",
            "Step: 3702 ------------ Loss: 4908.66 ------------ Accuracy: 84.3%\n",
            "Step: 3703 ------------ Loss: 4908.5 ------------ Accuracy: 84.3%\n",
            "Step: 3704 ------------ Loss: 4908.0 ------------ Accuracy: 84.3%\n",
            "Step: 3705 ------------ Loss: 4907.93 ------------ Accuracy: 84.4%\n",
            "Step: 3706 ------------ Loss: 4907.86 ------------ Accuracy: 84.4%\n",
            "Step: 3707 ------------ Loss: 4907.52 ------------ Accuracy: 84.4%\n",
            "Step: 3708 ------------ Loss: 4906.96 ------------ Accuracy: 84.4%\n",
            "Step: 3709 ------------ Loss: 4906.64 ------------ Accuracy: 84.4%\n",
            "Step: 3710 ------------ Loss: 4906.11 ------------ Accuracy: 84.4%\n",
            "Step: 3711 ------------ Loss: 4905.58 ------------ Accuracy: 84.4%\n",
            "Step: 3712 ------------ Loss: 4905.05 ------------ Accuracy: 84.4%\n",
            "Step: 3713 ------------ Loss: 4904.21 ------------ Accuracy: 84.4%\n",
            "Step: 3714 ------------ Loss: 4903.7 ------------ Accuracy: 84.4%\n",
            "Step: 3715 ------------ Loss: 4903.38 ------------ Accuracy: 84.4%\n",
            "Step: 3716 ------------ Loss: 4902.83 ------------ Accuracy: 84.4%\n",
            "Step: 3717 ------------ Loss: 4902.28 ------------ Accuracy: 84.4%\n",
            "Step: 3718 ------------ Loss: 4901.76 ------------ Accuracy: 84.4%\n",
            "Step: 3719 ------------ Loss: 4901.25 ------------ Accuracy: 84.4%\n",
            "Step: 3720 ------------ Loss: 4901.09 ------------ Accuracy: 84.4%\n",
            "Step: 3721 ------------ Loss: 4901.02 ------------ Accuracy: 84.4%\n",
            "Step: 3722 ------------ Loss: 4900.51 ------------ Accuracy: 84.4%\n",
            "Step: 3723 ------------ Loss: 4899.8 ------------ Accuracy: 84.4%\n",
            "Step: 3724 ------------ Loss: 4899.29 ------------ Accuracy: 84.4%\n",
            "Step: 3725 ------------ Loss: 4898.79 ------------ Accuracy: 84.5%\n",
            "Step: 3726 ------------ Loss: 4898.65 ------------ Accuracy: 84.5%\n",
            "Step: 3727 ------------ Loss: 4898.56 ------------ Accuracy: 84.4%\n",
            "Step: 3728 ------------ Loss: 4898.07 ------------ Accuracy: 84.5%\n",
            "Step: 3729 ------------ Loss: 4897.75 ------------ Accuracy: 84.5%\n",
            "Step: 3730 ------------ Loss: 4897.67 ------------ Accuracy: 84.5%\n",
            "Step: 3731 ------------ Loss: 4897.14 ------------ Accuracy: 84.5%\n",
            "Step: 3732 ------------ Loss: 4896.82 ------------ Accuracy: 84.5%\n",
            "Step: 3733 ------------ Loss: 4896.5 ------------ Accuracy: 84.5%\n",
            "Step: 3734 ------------ Loss: 4895.98 ------------ Accuracy: 84.5%\n",
            "Step: 3735 ------------ Loss: 4894.84 ------------ Accuracy: 84.5%\n",
            "Step: 3736 ------------ Loss: 4894.74 ------------ Accuracy: 84.4%\n",
            "Step: 3737 ------------ Loss: 4894.25 ------------ Accuracy: 84.5%\n",
            "Step: 3738 ------------ Loss: 4893.77 ------------ Accuracy: 84.5%\n",
            "Step: 3739 ------------ Loss: 4893.7 ------------ Accuracy: 84.5%\n",
            "Step: 3740 ------------ Loss: 4892.57 ------------ Accuracy: 84.4%\n",
            "Step: 3741 ------------ Loss: 4891.7 ------------ Accuracy: 84.4%\n",
            "Step: 3742 ------------ Loss: 4891.19 ------------ Accuracy: 84.5%\n",
            "Step: 3743 ------------ Loss: 4890.48 ------------ Accuracy: 84.5%\n",
            "Step: 3744 ------------ Loss: 4889.97 ------------ Accuracy: 84.4%\n",
            "Step: 3745 ------------ Loss: 4889.13 ------------ Accuracy: 84.4%\n",
            "Step: 3746 ------------ Loss: 4888.59 ------------ Accuracy: 84.5%\n",
            "Step: 3747 ------------ Loss: 4888.09 ------------ Accuracy: 84.5%\n",
            "Step: 3748 ------------ Loss: 4887.25 ------------ Accuracy: 84.4%\n",
            "Step: 3749 ------------ Loss: 4886.94 ------------ Accuracy: 84.4%\n",
            "Step: 3750 ------------ Loss: 4886.62 ------------ Accuracy: 84.4%\n",
            "Step: 3751 ------------ Loss: 4886.12 ------------ Accuracy: 84.5%\n",
            "Step: 3752 ------------ Loss: 4886.05 ------------ Accuracy: 84.5%\n",
            "Step: 3753 ------------ Loss: 4885.98 ------------ Accuracy: 84.5%\n",
            "Step: 3754 ------------ Loss: 4885.47 ------------ Accuracy: 84.5%\n",
            "Step: 3755 ------------ Loss: 4884.98 ------------ Accuracy: 84.5%\n",
            "Step: 3756 ------------ Loss: 4884.27 ------------ Accuracy: 84.5%\n",
            "Step: 3757 ------------ Loss: 4883.96 ------------ Accuracy: 84.5%\n",
            "Step: 3758 ------------ Loss: 4883.43 ------------ Accuracy: 84.5%\n",
            "Step: 3759 ------------ Loss: 4882.91 ------------ Accuracy: 84.5%\n",
            "Step: 3760 ------------ Loss: 4882.08 ------------ Accuracy: 84.5%\n",
            "Step: 3761 ------------ Loss: 4881.77 ------------ Accuracy: 84.5%\n",
            "Step: 3762 ------------ Loss: 4880.65 ------------ Accuracy: 84.5%\n",
            "Step: 3763 ------------ Loss: 4880.34 ------------ Accuracy: 84.5%\n",
            "Step: 3764 ------------ Loss: 4880.25 ------------ Accuracy: 84.5%\n",
            "Step: 3765 ------------ Loss: 4879.75 ------------ Accuracy: 84.5%\n",
            "Step: 3766 ------------ Loss: 4879.25 ------------ Accuracy: 84.5%\n",
            "Step: 3767 ------------ Loss: 4878.76 ------------ Accuracy: 84.6%\n",
            "Step: 3768 ------------ Loss: 4878.6 ------------ Accuracy: 84.5%\n",
            "Step: 3769 ------------ Loss: 4878.1 ------------ Accuracy: 84.6%\n",
            "Step: 3770 ------------ Loss: 4878.03 ------------ Accuracy: 84.6%\n",
            "Step: 3771 ------------ Loss: 4877.35 ------------ Accuracy: 84.5%\n",
            "Step: 3772 ------------ Loss: 4876.82 ------------ Accuracy: 84.5%\n",
            "Step: 3773 ------------ Loss: 4876.51 ------------ Accuracy: 84.5%\n",
            "Step: 3774 ------------ Loss: 4876.37 ------------ Accuracy: 84.6%\n",
            "Step: 3775 ------------ Loss: 4875.89 ------------ Accuracy: 84.6%\n",
            "Step: 3776 ------------ Loss: 4875.37 ------------ Accuracy: 84.5%\n",
            "Step: 3777 ------------ Loss: 4875.04 ------------ Accuracy: 84.5%\n",
            "Step: 3778 ------------ Loss: 4874.96 ------------ Accuracy: 84.5%\n",
            "Step: 3779 ------------ Loss: 4874.15 ------------ Accuracy: 84.5%\n",
            "Step: 3780 ------------ Loss: 4873.64 ------------ Accuracy: 84.5%\n",
            "Step: 3781 ------------ Loss: 4873.32 ------------ Accuracy: 84.5%\n",
            "Step: 3782 ------------ Loss: 4872.83 ------------ Accuracy: 84.5%\n",
            "Step: 3783 ------------ Loss: 4872.3 ------------ Accuracy: 84.5%\n",
            "Step: 3784 ------------ Loss: 4872.0 ------------ Accuracy: 84.5%\n",
            "Step: 3785 ------------ Loss: 4871.69 ------------ Accuracy: 84.5%\n",
            "Step: 3786 ------------ Loss: 4871.03 ------------ Accuracy: 84.5%\n",
            "Step: 3787 ------------ Loss: 4870.53 ------------ Accuracy: 84.5%\n",
            "Step: 3788 ------------ Loss: 4870.02 ------------ Accuracy: 84.6%\n",
            "Step: 3789 ------------ Loss: 4869.71 ------------ Accuracy: 84.6%\n",
            "Step: 3790 ------------ Loss: 4869.2 ------------ Accuracy: 84.6%\n",
            "Step: 3791 ------------ Loss: 4868.39 ------------ Accuracy: 84.6%\n",
            "Step: 3792 ------------ Loss: 4868.09 ------------ Accuracy: 84.6%\n",
            "Step: 3793 ------------ Loss: 4867.79 ------------ Accuracy: 84.7%\n",
            "Step: 3794 ------------ Loss: 4867.29 ------------ Accuracy: 84.7%\n",
            "Step: 3795 ------------ Loss: 4866.76 ------------ Accuracy: 84.6%\n",
            "Step: 3796 ------------ Loss: 4866.59 ------------ Accuracy: 84.6%\n",
            "Step: 3797 ------------ Loss: 4866.12 ------------ Accuracy: 84.6%\n",
            "Step: 3798 ------------ Loss: 4865.96 ------------ Accuracy: 84.6%\n",
            "Step: 3799 ------------ Loss: 4865.46 ------------ Accuracy: 84.6%\n",
            "Step: 3800 ------------ Loss: 4865.15 ------------ Accuracy: 84.6%\n",
            "Step: 3801 ------------ Loss: 4864.66 ------------ Accuracy: 84.6%\n",
            "Step: 3802 ------------ Loss: 4864.16 ------------ Accuracy: 84.7%\n",
            "Step: 3803 ------------ Loss: 4864.07 ------------ Accuracy: 84.7%\n",
            "Step: 3804 ------------ Loss: 4863.59 ------------ Accuracy: 84.7%\n",
            "Step: 3805 ------------ Loss: 4863.12 ------------ Accuracy: 84.7%\n",
            "Step: 3806 ------------ Loss: 4862.6 ------------ Accuracy: 84.7%\n",
            "Step: 3807 ------------ Loss: 4862.1 ------------ Accuracy: 84.7%\n",
            "Step: 3808 ------------ Loss: 4861.95 ------------ Accuracy: 84.7%\n",
            "Step: 3809 ------------ Loss: 4861.44 ------------ Accuracy: 84.7%\n",
            "Step: 3810 ------------ Loss: 4861.33 ------------ Accuracy: 84.7%\n",
            "Step: 3811 ------------ Loss: 4860.22 ------------ Accuracy: 84.6%\n",
            "Step: 3812 ------------ Loss: 4859.72 ------------ Accuracy: 84.6%\n",
            "Step: 3813 ------------ Loss: 4859.21 ------------ Accuracy: 84.6%\n",
            "Step: 3814 ------------ Loss: 4859.06 ------------ Accuracy: 84.6%\n",
            "Step: 3815 ------------ Loss: 4858.57 ------------ Accuracy: 84.6%\n",
            "Step: 3816 ------------ Loss: 4857.73 ------------ Accuracy: 84.6%\n",
            "Step: 3817 ------------ Loss: 4857.66 ------------ Accuracy: 84.6%\n",
            "Step: 3818 ------------ Loss: 4857.14 ------------ Accuracy: 84.6%\n",
            "Step: 3819 ------------ Loss: 4856.64 ------------ Accuracy: 84.6%\n",
            "Step: 3820 ------------ Loss: 4856.57 ------------ Accuracy: 84.6%\n",
            "Step: 3821 ------------ Loss: 4855.9 ------------ Accuracy: 84.6%\n",
            "Step: 3822 ------------ Loss: 4855.39 ------------ Accuracy: 84.6%\n",
            "Step: 3823 ------------ Loss: 4854.75 ------------ Accuracy: 84.6%\n",
            "Step: 3824 ------------ Loss: 4854.68 ------------ Accuracy: 84.6%\n",
            "Step: 3825 ------------ Loss: 4854.36 ------------ Accuracy: 84.7%\n",
            "Step: 3826 ------------ Loss: 4853.57 ------------ Accuracy: 84.6%\n",
            "Step: 3827 ------------ Loss: 4853.52 ------------ Accuracy: 84.6%\n",
            "Step: 3828 ------------ Loss: 4852.99 ------------ Accuracy: 84.6%\n",
            "Step: 3829 ------------ Loss: 4852.46 ------------ Accuracy: 84.5%\n",
            "Step: 3830 ------------ Loss: 4852.14 ------------ Accuracy: 84.6%\n",
            "Step: 3831 ------------ Loss: 4851.62 ------------ Accuracy: 84.6%\n",
            "Step: 3832 ------------ Loss: 4851.1 ------------ Accuracy: 84.6%\n",
            "Step: 3833 ------------ Loss: 4850.93 ------------ Accuracy: 84.7%\n",
            "Step: 3834 ------------ Loss: 4850.47 ------------ Accuracy: 84.7%\n",
            "Step: 3835 ------------ Loss: 4849.95 ------------ Accuracy: 84.6%\n",
            "Step: 3836 ------------ Loss: 4849.45 ------------ Accuracy: 84.6%\n",
            "Step: 3837 ------------ Loss: 4848.96 ------------ Accuracy: 84.7%\n",
            "Step: 3838 ------------ Loss: 4848.48 ------------ Accuracy: 84.7%\n",
            "Step: 3839 ------------ Loss: 4848.18 ------------ Accuracy: 84.7%\n",
            "Step: 3840 ------------ Loss: 4847.7 ------------ Accuracy: 84.7%\n",
            "Step: 3841 ------------ Loss: 4847.2 ------------ Accuracy: 84.6%\n",
            "Step: 3842 ------------ Loss: 4846.72 ------------ Accuracy: 84.6%\n",
            "Step: 3843 ------------ Loss: 4846.23 ------------ Accuracy: 84.6%\n",
            "Step: 3844 ------------ Loss: 4845.72 ------------ Accuracy: 84.6%\n",
            "Step: 3845 ------------ Loss: 4845.56 ------------ Accuracy: 84.7%\n",
            "Step: 3846 ------------ Loss: 4845.25 ------------ Accuracy: 84.7%\n",
            "Step: 3847 ------------ Loss: 4844.78 ------------ Accuracy: 84.6%\n",
            "Step: 3848 ------------ Loss: 4844.27 ------------ Accuracy: 84.7%\n",
            "Step: 3849 ------------ Loss: 4843.76 ------------ Accuracy: 84.7%\n",
            "Step: 3850 ------------ Loss: 4843.28 ------------ Accuracy: 84.7%\n",
            "Step: 3851 ------------ Loss: 4843.21 ------------ Accuracy: 84.7%\n",
            "Step: 3852 ------------ Loss: 4842.75 ------------ Accuracy: 84.7%\n",
            "Step: 3853 ------------ Loss: 4842.24 ------------ Accuracy: 84.7%\n",
            "Step: 3854 ------------ Loss: 4841.76 ------------ Accuracy: 84.7%\n",
            "Step: 3855 ------------ Loss: 4841.3 ------------ Accuracy: 84.8%\n",
            "Step: 3856 ------------ Loss: 4840.81 ------------ Accuracy: 84.8%\n",
            "Step: 3857 ------------ Loss: 4840.5 ------------ Accuracy: 84.8%\n",
            "Step: 3858 ------------ Loss: 4840.33 ------------ Accuracy: 84.7%\n",
            "Step: 3859 ------------ Loss: 4839.88 ------------ Accuracy: 84.8%\n",
            "Step: 3860 ------------ Loss: 4839.43 ------------ Accuracy: 84.8%\n",
            "Step: 3861 ------------ Loss: 4838.95 ------------ Accuracy: 84.8%\n",
            "Step: 3862 ------------ Loss: 4838.51 ------------ Accuracy: 84.8%\n",
            "Step: 3863 ------------ Loss: 4838.34 ------------ Accuracy: 84.8%\n",
            "Step: 3864 ------------ Loss: 4838.04 ------------ Accuracy: 84.8%\n",
            "Step: 3865 ------------ Loss: 4837.74 ------------ Accuracy: 84.8%\n",
            "Step: 3866 ------------ Loss: 4837.27 ------------ Accuracy: 84.7%\n",
            "Step: 3867 ------------ Loss: 4836.98 ------------ Accuracy: 84.8%\n",
            "Step: 3868 ------------ Loss: 4836.49 ------------ Accuracy: 84.8%\n",
            "Step: 3869 ------------ Loss: 4836.31 ------------ Accuracy: 84.8%\n",
            "Step: 3870 ------------ Loss: 4835.83 ------------ Accuracy: 84.8%\n",
            "Step: 3871 ------------ Loss: 4835.54 ------------ Accuracy: 84.8%\n",
            "Step: 3872 ------------ Loss: 4835.38 ------------ Accuracy: 84.8%\n",
            "Step: 3873 ------------ Loss: 4835.24 ------------ Accuracy: 84.8%\n",
            "Step: 3874 ------------ Loss: 4834.78 ------------ Accuracy: 84.9%\n",
            "Step: 3875 ------------ Loss: 4834.34 ------------ Accuracy: 84.9%\n",
            "Step: 3876 ------------ Loss: 4834.06 ------------ Accuracy: 84.9%\n",
            "Step: 3877 ------------ Loss: 4833.63 ------------ Accuracy: 84.9%\n",
            "Step: 3878 ------------ Loss: 4833.52 ------------ Accuracy: 84.9%\n",
            "Step: 3879 ------------ Loss: 4833.04 ------------ Accuracy: 84.9%\n",
            "Step: 3880 ------------ Loss: 4831.9 ------------ Accuracy: 84.8%\n",
            "Step: 3881 ------------ Loss: 4831.79 ------------ Accuracy: 84.8%\n",
            "Step: 3882 ------------ Loss: 4831.3 ------------ Accuracy: 84.8%\n",
            "Step: 3883 ------------ Loss: 4830.42 ------------ Accuracy: 84.8%\n",
            "Step: 3884 ------------ Loss: 4829.56 ------------ Accuracy: 84.8%\n",
            "Step: 3885 ------------ Loss: 4828.84 ------------ Accuracy: 84.7%\n",
            "Step: 3886 ------------ Loss: 4828.77 ------------ Accuracy: 84.8%\n",
            "Step: 3887 ------------ Loss: 4828.31 ------------ Accuracy: 84.8%\n",
            "Step: 3888 ------------ Loss: 4828.16 ------------ Accuracy: 84.9%\n",
            "Step: 3889 ------------ Loss: 4827.68 ------------ Accuracy: 84.8%\n",
            "Step: 3890 ------------ Loss: 4827.59 ------------ Accuracy: 84.8%\n",
            "Step: 3891 ------------ Loss: 4827.09 ------------ Accuracy: 84.8%\n",
            "Step: 3892 ------------ Loss: 4826.63 ------------ Accuracy: 84.8%\n",
            "Step: 3893 ------------ Loss: 4826.5 ------------ Accuracy: 84.9%\n",
            "Step: 3894 ------------ Loss: 4825.41 ------------ Accuracy: 84.8%\n",
            "Step: 3895 ------------ Loss: 4824.92 ------------ Accuracy: 84.8%\n",
            "Step: 3896 ------------ Loss: 4824.09 ------------ Accuracy: 84.8%\n",
            "Step: 3897 ------------ Loss: 4823.79 ------------ Accuracy: 84.8%\n",
            "Step: 3898 ------------ Loss: 4823.3 ------------ Accuracy: 84.7%\n",
            "Step: 3899 ------------ Loss: 4822.62 ------------ Accuracy: 84.7%\n",
            "Step: 3900 ------------ Loss: 4822.54 ------------ Accuracy: 84.7%\n",
            "Step: 3901 ------------ Loss: 4822.4 ------------ Accuracy: 84.8%\n",
            "Step: 3902 ------------ Loss: 4821.89 ------------ Accuracy: 84.8%\n",
            "Step: 3903 ------------ Loss: 4821.42 ------------ Accuracy: 84.8%\n",
            "Step: 3904 ------------ Loss: 4820.97 ------------ Accuracy: 84.8%\n",
            "Step: 3905 ------------ Loss: 4819.95 ------------ Accuracy: 84.7%\n",
            "Step: 3906 ------------ Loss: 4819.89 ------------ Accuracy: 84.7%\n",
            "Step: 3907 ------------ Loss: 4819.47 ------------ Accuracy: 84.7%\n",
            "Step: 3908 ------------ Loss: 4819.42 ------------ Accuracy: 84.7%\n",
            "Step: 3909 ------------ Loss: 4819.35 ------------ Accuracy: 84.7%\n",
            "Step: 3910 ------------ Loss: 4818.87 ------------ Accuracy: 84.7%\n",
            "Step: 3911 ------------ Loss: 4818.37 ------------ Accuracy: 84.7%\n",
            "Step: 3912 ------------ Loss: 4817.87 ------------ Accuracy: 84.7%\n",
            "Step: 3913 ------------ Loss: 4817.58 ------------ Accuracy: 84.7%\n",
            "Step: 3914 ------------ Loss: 4817.39 ------------ Accuracy: 84.7%\n",
            "Step: 3915 ------------ Loss: 4816.9 ------------ Accuracy: 84.8%\n",
            "Step: 3916 ------------ Loss: 4815.89 ------------ Accuracy: 84.7%\n",
            "Step: 3917 ------------ Loss: 4815.25 ------------ Accuracy: 84.7%\n",
            "Step: 3918 ------------ Loss: 4814.29 ------------ Accuracy: 84.6%\n",
            "Step: 3919 ------------ Loss: 4813.51 ------------ Accuracy: 84.6%\n",
            "Step: 3920 ------------ Loss: 4812.98 ------------ Accuracy: 84.7%\n",
            "Step: 3921 ------------ Loss: 4812.22 ------------ Accuracy: 84.7%\n",
            "Step: 3922 ------------ Loss: 4811.31 ------------ Accuracy: 84.5%\n",
            "Step: 3923 ------------ Loss: 4810.88 ------------ Accuracy: 84.6%\n",
            "Step: 3924 ------------ Loss: 4810.33 ------------ Accuracy: 84.6%\n",
            "Step: 3925 ------------ Loss: 4810.02 ------------ Accuracy: 84.6%\n",
            "Step: 3926 ------------ Loss: 4809.48 ------------ Accuracy: 84.6%\n",
            "Step: 3927 ------------ Loss: 4808.95 ------------ Accuracy: 84.7%\n",
            "Step: 3928 ------------ Loss: 4808.49 ------------ Accuracy: 84.6%\n",
            "Step: 3929 ------------ Loss: 4807.72 ------------ Accuracy: 84.6%\n",
            "Step: 3930 ------------ Loss: 4807.42 ------------ Accuracy: 84.6%\n",
            "Step: 3931 ------------ Loss: 4807.36 ------------ Accuracy: 84.7%\n",
            "Step: 3932 ------------ Loss: 4806.84 ------------ Accuracy: 84.6%\n",
            "Step: 3933 ------------ Loss: 4806.53 ------------ Accuracy: 84.6%\n",
            "Step: 3934 ------------ Loss: 4805.92 ------------ Accuracy: 84.7%\n",
            "Step: 3935 ------------ Loss: 4805.18 ------------ Accuracy: 84.7%\n",
            "Step: 3936 ------------ Loss: 4804.88 ------------ Accuracy: 84.7%\n",
            "Step: 3937 ------------ Loss: 4804.34 ------------ Accuracy: 84.7%\n",
            "Step: 3938 ------------ Loss: 4803.76 ------------ Accuracy: 84.7%\n",
            "Step: 3939 ------------ Loss: 4803.56 ------------ Accuracy: 84.8%\n",
            "Step: 3940 ------------ Loss: 4803.25 ------------ Accuracy: 84.8%\n",
            "Step: 3941 ------------ Loss: 4802.73 ------------ Accuracy: 84.8%\n",
            "Step: 3942 ------------ Loss: 4802.21 ------------ Accuracy: 84.8%\n",
            "Step: 3943 ------------ Loss: 4801.78 ------------ Accuracy: 84.8%\n",
            "Step: 3944 ------------ Loss: 4801.37 ------------ Accuracy: 84.8%\n",
            "Step: 3945 ------------ Loss: 4801.33 ------------ Accuracy: 84.7%\n",
            "Step: 3946 ------------ Loss: 4800.74 ------------ Accuracy: 84.8%\n",
            "Step: 3947 ------------ Loss: 4800.28 ------------ Accuracy: 84.8%\n",
            "Step: 3948 ------------ Loss: 4800.07 ------------ Accuracy: 84.8%\n",
            "Step: 3949 ------------ Loss: 4799.88 ------------ Accuracy: 84.9%\n",
            "Step: 3950 ------------ Loss: 4799.37 ------------ Accuracy: 84.9%\n",
            "Step: 3951 ------------ Loss: 4798.85 ------------ Accuracy: 84.9%\n",
            "Step: 3952 ------------ Loss: 4798.36 ------------ Accuracy: 84.8%\n",
            "Step: 3953 ------------ Loss: 4798.05 ------------ Accuracy: 84.8%\n",
            "Step: 3954 ------------ Loss: 4797.29 ------------ Accuracy: 84.9%\n",
            "Step: 3955 ------------ Loss: 4796.31 ------------ Accuracy: 84.8%\n",
            "Step: 3956 ------------ Loss: 4795.84 ------------ Accuracy: 84.8%\n",
            "Step: 3957 ------------ Loss: 4795.41 ------------ Accuracy: 84.7%\n",
            "Step: 3958 ------------ Loss: 4794.88 ------------ Accuracy: 84.8%\n",
            "Step: 3959 ------------ Loss: 4794.29 ------------ Accuracy: 84.8%\n",
            "Step: 3960 ------------ Loss: 4793.98 ------------ Accuracy: 84.9%\n",
            "Step: 3961 ------------ Loss: 4793.48 ------------ Accuracy: 84.9%\n",
            "Step: 3962 ------------ Loss: 4793.3 ------------ Accuracy: 84.9%\n",
            "Step: 3963 ------------ Loss: 4792.73 ------------ Accuracy: 84.9%\n",
            "Step: 3964 ------------ Loss: 4792.25 ------------ Accuracy: 84.8%\n",
            "Step: 3965 ------------ Loss: 4791.52 ------------ Accuracy: 84.8%\n",
            "Step: 3966 ------------ Loss: 4791.01 ------------ Accuracy: 84.9%\n",
            "Step: 3967 ------------ Loss: 4790.49 ------------ Accuracy: 84.9%\n",
            "Step: 3968 ------------ Loss: 4790.03 ------------ Accuracy: 84.9%\n",
            "Step: 3969 ------------ Loss: 4789.51 ------------ Accuracy: 84.9%\n",
            "Step: 3970 ------------ Loss: 4789.0 ------------ Accuracy: 84.9%\n",
            "Step: 3971 ------------ Loss: 4788.51 ------------ Accuracy: 84.9%\n",
            "Step: 3972 ------------ Loss: 4788.04 ------------ Accuracy: 84.9%\n",
            "Step: 3973 ------------ Loss: 4787.53 ------------ Accuracy: 84.9%\n",
            "Step: 3974 ------------ Loss: 4787.03 ------------ Accuracy: 84.9%\n",
            "Step: 3975 ------------ Loss: 4786.53 ------------ Accuracy: 84.9%\n",
            "Step: 3976 ------------ Loss: 4786.24 ------------ Accuracy: 84.9%\n",
            "Step: 3977 ------------ Loss: 4786.17 ------------ Accuracy: 84.9%\n",
            "Step: 3978 ------------ Loss: 4785.67 ------------ Accuracy: 85.0%\n",
            "Step: 3979 ------------ Loss: 4785.59 ------------ Accuracy: 84.9%\n",
            "Step: 3980 ------------ Loss: 4785.12 ------------ Accuracy: 85.0%\n",
            "Step: 3981 ------------ Loss: 4785.06 ------------ Accuracy: 84.9%\n",
            "Step: 3982 ------------ Loss: 4784.58 ------------ Accuracy: 85.0%\n",
            "Step: 3983 ------------ Loss: 4784.08 ------------ Accuracy: 85.0%\n",
            "Step: 3984 ------------ Loss: 4783.61 ------------ Accuracy: 85.0%\n",
            "Step: 3985 ------------ Loss: 4783.55 ------------ Accuracy: 85.0%\n",
            "Step: 3986 ------------ Loss: 4783.06 ------------ Accuracy: 85.0%\n",
            "Step: 3987 ------------ Loss: 4782.6 ------------ Accuracy: 85.0%\n",
            "Step: 3988 ------------ Loss: 4782.11 ------------ Accuracy: 85.1%\n",
            "Step: 3989 ------------ Loss: 4781.05 ------------ Accuracy: 85.0%\n",
            "Step: 3990 ------------ Loss: 4780.88 ------------ Accuracy: 85.0%\n",
            "Step: 3991 ------------ Loss: 4780.42 ------------ Accuracy: 85.0%\n",
            "Step: 3992 ------------ Loss: 4780.27 ------------ Accuracy: 85.0%\n",
            "Step: 3993 ------------ Loss: 4780.2 ------------ Accuracy: 85.1%\n",
            "Step: 3994 ------------ Loss: 4779.76 ------------ Accuracy: 85.0%\n",
            "Step: 3995 ------------ Loss: 4779.62 ------------ Accuracy: 85.1%\n",
            "Step: 3996 ------------ Loss: 4778.59 ------------ Accuracy: 85.0%\n",
            "Step: 3997 ------------ Loss: 4778.1 ------------ Accuracy: 85.1%\n",
            "Step: 3998 ------------ Loss: 4777.64 ------------ Accuracy: 85.0%\n",
            "Step: 3999 ------------ Loss: 4777.01 ------------ Accuracy: 85.0%\n",
            "Step: 4000 ------------ Loss: 4776.52 ------------ Accuracy: 85.1%\n",
            "Step: 4001 ------------ Loss: 4776.02 ------------ Accuracy: 85.1%\n",
            "Step: 4002 ------------ Loss: 4775.58 ------------ Accuracy: 85.1%\n",
            "Step: 4003 ------------ Loss: 4774.98 ------------ Accuracy: 85.0%\n",
            "Step: 4004 ------------ Loss: 4774.24 ------------ Accuracy: 85.0%\n",
            "Step: 4005 ------------ Loss: 4773.94 ------------ Accuracy: 85.0%\n",
            "Step: 4006 ------------ Loss: 4773.48 ------------ Accuracy: 85.1%\n",
            "Step: 4007 ------------ Loss: 4772.98 ------------ Accuracy: 85.1%\n",
            "Step: 4008 ------------ Loss: 4772.84 ------------ Accuracy: 85.1%\n",
            "Step: 4009 ------------ Loss: 4772.11 ------------ Accuracy: 85.1%\n",
            "Step: 4010 ------------ Loss: 4771.38 ------------ Accuracy: 85.1%\n",
            "Step: 4011 ------------ Loss: 4771.3 ------------ Accuracy: 85.1%\n",
            "Step: 4012 ------------ Loss: 4770.82 ------------ Accuracy: 85.1%\n",
            "Step: 4013 ------------ Loss: 4769.83 ------------ Accuracy: 85.0%\n",
            "Step: 4014 ------------ Loss: 4769.69 ------------ Accuracy: 85.1%\n",
            "Step: 4015 ------------ Loss: 4769.17 ------------ Accuracy: 85.1%\n",
            "Step: 4016 ------------ Loss: 4768.69 ------------ Accuracy: 85.0%\n",
            "Step: 4017 ------------ Loss: 4768.39 ------------ Accuracy: 85.0%\n",
            "Step: 4018 ------------ Loss: 4767.92 ------------ Accuracy: 85.0%\n",
            "Step: 4019 ------------ Loss: 4767.63 ------------ Accuracy: 85.0%\n",
            "Step: 4020 ------------ Loss: 4767.34 ------------ Accuracy: 85.1%\n",
            "Step: 4021 ------------ Loss: 4766.39 ------------ Accuracy: 85.1%\n",
            "Step: 4022 ------------ Loss: 4765.68 ------------ Accuracy: 85.0%\n",
            "Step: 4023 ------------ Loss: 4764.77 ------------ Accuracy: 85.0%\n",
            "Step: 4024 ------------ Loss: 4764.28 ------------ Accuracy: 85.0%\n",
            "Step: 4025 ------------ Loss: 4764.2 ------------ Accuracy: 85.0%\n",
            "Step: 4026 ------------ Loss: 4764.03 ------------ Accuracy: 85.0%\n",
            "Step: 4027 ------------ Loss: 4763.87 ------------ Accuracy: 85.0%\n",
            "Step: 4028 ------------ Loss: 4763.17 ------------ Accuracy: 85.0%\n",
            "Step: 4029 ------------ Loss: 4763.07 ------------ Accuracy: 85.0%\n",
            "Step: 4030 ------------ Loss: 4762.38 ------------ Accuracy: 85.0%\n",
            "Step: 4031 ------------ Loss: 4761.7 ------------ Accuracy: 85.0%\n",
            "Step: 4032 ------------ Loss: 4761.61 ------------ Accuracy: 85.1%\n",
            "Step: 4033 ------------ Loss: 4761.13 ------------ Accuracy: 85.0%\n",
            "Step: 4034 ------------ Loss: 4760.65 ------------ Accuracy: 85.0%\n",
            "Step: 4035 ------------ Loss: 4760.47 ------------ Accuracy: 85.0%\n",
            "Step: 4036 ------------ Loss: 4760.4 ------------ Accuracy: 85.0%\n",
            "Step: 4037 ------------ Loss: 4759.92 ------------ Accuracy: 85.0%\n",
            "Step: 4038 ------------ Loss: 4759.42 ------------ Accuracy: 85.0%\n",
            "Step: 4039 ------------ Loss: 4758.95 ------------ Accuracy: 85.1%\n",
            "Step: 4040 ------------ Loss: 4758.45 ------------ Accuracy: 85.1%\n",
            "Step: 4041 ------------ Loss: 4757.98 ------------ Accuracy: 85.1%\n",
            "Step: 4042 ------------ Loss: 4757.9 ------------ Accuracy: 85.1%\n",
            "Step: 4043 ------------ Loss: 4757.47 ------------ Accuracy: 85.1%\n",
            "Step: 4044 ------------ Loss: 4757.17 ------------ Accuracy: 85.1%\n",
            "Step: 4045 ------------ Loss: 4756.74 ------------ Accuracy: 85.1%\n",
            "Step: 4046 ------------ Loss: 4756.68 ------------ Accuracy: 85.2%\n",
            "Step: 4047 ------------ Loss: 4756.22 ------------ Accuracy: 85.1%\n",
            "Step: 4048 ------------ Loss: 4755.72 ------------ Accuracy: 85.1%\n",
            "Step: 4049 ------------ Loss: 4755.29 ------------ Accuracy: 85.1%\n",
            "Step: 4050 ------------ Loss: 4755.24 ------------ Accuracy: 85.1%\n",
            "Step: 4051 ------------ Loss: 4754.75 ------------ Accuracy: 85.1%\n",
            "Step: 4052 ------------ Loss: 4754.32 ------------ Accuracy: 85.1%\n",
            "Step: 4053 ------------ Loss: 4754.26 ------------ Accuracy: 85.1%\n",
            "Step: 4054 ------------ Loss: 4754.21 ------------ Accuracy: 85.1%\n",
            "Step: 4055 ------------ Loss: 4753.93 ------------ Accuracy: 85.1%\n",
            "Step: 4056 ------------ Loss: 4753.43 ------------ Accuracy: 85.2%\n",
            "Step: 4057 ------------ Loss: 4753.24 ------------ Accuracy: 85.2%\n",
            "Step: 4058 ------------ Loss: 4752.94 ------------ Accuracy: 85.2%\n",
            "Step: 4059 ------------ Loss: 4752.24 ------------ Accuracy: 85.2%\n",
            "Step: 4060 ------------ Loss: 4751.75 ------------ Accuracy: 85.1%\n",
            "Step: 4061 ------------ Loss: 4751.7 ------------ Accuracy: 85.1%\n",
            "Step: 4062 ------------ Loss: 4751.21 ------------ Accuracy: 85.1%\n",
            "Step: 4063 ------------ Loss: 4751.16 ------------ Accuracy: 85.2%\n",
            "Step: 4064 ------------ Loss: 4750.73 ------------ Accuracy: 85.1%\n",
            "Step: 4065 ------------ Loss: 4750.04 ------------ Accuracy: 85.1%\n",
            "Step: 4066 ------------ Loss: 4749.55 ------------ Accuracy: 85.2%\n",
            "Step: 4067 ------------ Loss: 4749.25 ------------ Accuracy: 85.2%\n",
            "Step: 4068 ------------ Loss: 4748.26 ------------ Accuracy: 85.1%\n",
            "Step: 4069 ------------ Loss: 4748.07 ------------ Accuracy: 85.1%\n",
            "Step: 4070 ------------ Loss: 4747.79 ------------ Accuracy: 85.1%\n",
            "Step: 4071 ------------ Loss: 4747.73 ------------ Accuracy: 85.1%\n",
            "Step: 4072 ------------ Loss: 4747.31 ------------ Accuracy: 85.1%\n",
            "Step: 4073 ------------ Loss: 4746.83 ------------ Accuracy: 85.2%\n",
            "Step: 4074 ------------ Loss: 4746.15 ------------ Accuracy: 85.2%\n",
            "Step: 4075 ------------ Loss: 4745.19 ------------ Accuracy: 85.1%\n",
            "Step: 4076 ------------ Loss: 4744.68 ------------ Accuracy: 85.1%\n",
            "Step: 4077 ------------ Loss: 4744.15 ------------ Accuracy: 85.1%\n",
            "Step: 4078 ------------ Loss: 4743.63 ------------ Accuracy: 85.2%\n",
            "Step: 4079 ------------ Loss: 4743.56 ------------ Accuracy: 85.2%\n",
            "Step: 4080 ------------ Loss: 4743.05 ------------ Accuracy: 85.2%\n",
            "Step: 4081 ------------ Loss: 4742.98 ------------ Accuracy: 85.2%\n",
            "Step: 4082 ------------ Loss: 4742.7 ------------ Accuracy: 85.2%\n",
            "Step: 4083 ------------ Loss: 4742.28 ------------ Accuracy: 85.2%\n",
            "Step: 4084 ------------ Loss: 4742.21 ------------ Accuracy: 85.2%\n",
            "Step: 4085 ------------ Loss: 4741.92 ------------ Accuracy: 85.2%\n",
            "Step: 4086 ------------ Loss: 4741.86 ------------ Accuracy: 85.2%\n",
            "Step: 4087 ------------ Loss: 4741.81 ------------ Accuracy: 85.2%\n",
            "Step: 4088 ------------ Loss: 4741.75 ------------ Accuracy: 85.2%\n",
            "Step: 4089 ------------ Loss: 4741.26 ------------ Accuracy: 85.2%\n",
            "Step: 4090 ------------ Loss: 4741.2 ------------ Accuracy: 85.2%\n",
            "Step: 4091 ------------ Loss: 4741.14 ------------ Accuracy: 85.2%\n",
            "Step: 4092 ------------ Loss: 4740.69 ------------ Accuracy: 85.2%\n",
            "Step: 4093 ------------ Loss: 4740.0 ------------ Accuracy: 85.2%\n",
            "Step: 4094 ------------ Loss: 4739.57 ------------ Accuracy: 85.2%\n",
            "Step: 4095 ------------ Loss: 4738.89 ------------ Accuracy: 85.2%\n",
            "Step: 4096 ------------ Loss: 4738.83 ------------ Accuracy: 85.2%\n",
            "Step: 4097 ------------ Loss: 4738.36 ------------ Accuracy: 85.2%\n",
            "Step: 4098 ------------ Loss: 4737.83 ------------ Accuracy: 85.2%\n",
            "Step: 4099 ------------ Loss: 4737.78 ------------ Accuracy: 85.2%\n",
            "Step: 4100 ------------ Loss: 4737.28 ------------ Accuracy: 85.2%\n",
            "Step: 4101 ------------ Loss: 4736.76 ------------ Accuracy: 85.2%\n",
            "Step: 4102 ------------ Loss: 4735.79 ------------ Accuracy: 85.2%\n",
            "Step: 4103 ------------ Loss: 4735.26 ------------ Accuracy: 85.2%\n",
            "Step: 4104 ------------ Loss: 4734.32 ------------ Accuracy: 85.2%\n",
            "Step: 4105 ------------ Loss: 4733.8 ------------ Accuracy: 85.2%\n",
            "Step: 4106 ------------ Loss: 4733.3 ------------ Accuracy: 85.2%\n",
            "Step: 4107 ------------ Loss: 4733.01 ------------ Accuracy: 85.2%\n",
            "Step: 4108 ------------ Loss: 4732.49 ------------ Accuracy: 85.2%\n",
            "Step: 4109 ------------ Loss: 4732.43 ------------ Accuracy: 85.2%\n",
            "Step: 4110 ------------ Loss: 4731.78 ------------ Accuracy: 85.2%\n",
            "Step: 4111 ------------ Loss: 4730.86 ------------ Accuracy: 85.2%\n",
            "Step: 4112 ------------ Loss: 4730.37 ------------ Accuracy: 85.2%\n",
            "Step: 4113 ------------ Loss: 4729.84 ------------ Accuracy: 85.2%\n",
            "Step: 4114 ------------ Loss: 4729.36 ------------ Accuracy: 85.2%\n",
            "Step: 4115 ------------ Loss: 4728.45 ------------ Accuracy: 85.1%\n",
            "Step: 4116 ------------ Loss: 4727.98 ------------ Accuracy: 85.2%\n",
            "Step: 4117 ------------ Loss: 4727.11 ------------ Accuracy: 85.1%\n",
            "Step: 4118 ------------ Loss: 4726.67 ------------ Accuracy: 85.1%\n",
            "Step: 4119 ------------ Loss: 4726.06 ------------ Accuracy: 85.1%\n",
            "Step: 4120 ------------ Loss: 4725.77 ------------ Accuracy: 85.1%\n",
            "Step: 4121 ------------ Loss: 4725.48 ------------ Accuracy: 85.1%\n",
            "Step: 4122 ------------ Loss: 4724.92 ------------ Accuracy: 85.2%\n",
            "Step: 4123 ------------ Loss: 4724.45 ------------ Accuracy: 85.1%\n",
            "Step: 4124 ------------ Loss: 4723.98 ------------ Accuracy: 85.1%\n",
            "Step: 4125 ------------ Loss: 4723.52 ------------ Accuracy: 85.1%\n",
            "Step: 4126 ------------ Loss: 4723.04 ------------ Accuracy: 85.1%\n",
            "Step: 4127 ------------ Loss: 4722.49 ------------ Accuracy: 85.1%\n",
            "Step: 4128 ------------ Loss: 4721.95 ------------ Accuracy: 85.1%\n",
            "Step: 4129 ------------ Loss: 4721.49 ------------ Accuracy: 85.1%\n",
            "Step: 4130 ------------ Loss: 4721.0 ------------ Accuracy: 85.1%\n",
            "Step: 4131 ------------ Loss: 4720.52 ------------ Accuracy: 85.2%\n",
            "Step: 4132 ------------ Loss: 4720.06 ------------ Accuracy: 85.1%\n",
            "Step: 4133 ------------ Loss: 4719.43 ------------ Accuracy: 85.1%\n",
            "Step: 4134 ------------ Loss: 4718.95 ------------ Accuracy: 85.1%\n",
            "Step: 4135 ------------ Loss: 4718.67 ------------ Accuracy: 85.1%\n",
            "Step: 4136 ------------ Loss: 4718.21 ------------ Accuracy: 85.1%\n",
            "Step: 4137 ------------ Loss: 4717.92 ------------ Accuracy: 85.1%\n",
            "Step: 4138 ------------ Loss: 4717.62 ------------ Accuracy: 85.1%\n",
            "Step: 4139 ------------ Loss: 4717.18 ------------ Accuracy: 85.1%\n",
            "Step: 4140 ------------ Loss: 4716.7 ------------ Accuracy: 85.1%\n",
            "Step: 4141 ------------ Loss: 4716.42 ------------ Accuracy: 85.1%\n",
            "Step: 4142 ------------ Loss: 4715.8 ------------ Accuracy: 85.1%\n",
            "Step: 4143 ------------ Loss: 4714.97 ------------ Accuracy: 85.1%\n",
            "Step: 4144 ------------ Loss: 4714.51 ------------ Accuracy: 85.0%\n",
            "Step: 4145 ------------ Loss: 4713.72 ------------ Accuracy: 85.0%\n",
            "Step: 4146 ------------ Loss: 4713.62 ------------ Accuracy: 85.0%\n",
            "Step: 4147 ------------ Loss: 4713.05 ------------ Accuracy: 85.1%\n",
            "Step: 4148 ------------ Loss: 4712.96 ------------ Accuracy: 85.1%\n",
            "Step: 4149 ------------ Loss: 4712.42 ------------ Accuracy: 85.1%\n",
            "Step: 4150 ------------ Loss: 4712.12 ------------ Accuracy: 85.1%\n",
            "Step: 4151 ------------ Loss: 4711.7 ------------ Accuracy: 85.1%\n",
            "Step: 4152 ------------ Loss: 4711.18 ------------ Accuracy: 85.1%\n",
            "Step: 4153 ------------ Loss: 4711.12 ------------ Accuracy: 85.1%\n",
            "Step: 4154 ------------ Loss: 4710.68 ------------ Accuracy: 85.1%\n",
            "Step: 4155 ------------ Loss: 4710.14 ------------ Accuracy: 85.1%\n",
            "Step: 4156 ------------ Loss: 4709.85 ------------ Accuracy: 85.1%\n",
            "Step: 4157 ------------ Loss: 4709.37 ------------ Accuracy: 85.1%\n",
            "Step: 4158 ------------ Loss: 4709.08 ------------ Accuracy: 85.1%\n",
            "Step: 4159 ------------ Loss: 4708.58 ------------ Accuracy: 85.2%\n",
            "Step: 4160 ------------ Loss: 4708.51 ------------ Accuracy: 85.1%\n",
            "Step: 4161 ------------ Loss: 4707.98 ------------ Accuracy: 85.2%\n",
            "Step: 4162 ------------ Loss: 4707.53 ------------ Accuracy: 85.2%\n",
            "Step: 4163 ------------ Loss: 4707.46 ------------ Accuracy: 85.2%\n",
            "Step: 4164 ------------ Loss: 4706.95 ------------ Accuracy: 85.2%\n",
            "Step: 4165 ------------ Loss: 4706.66 ------------ Accuracy: 85.2%\n",
            "Step: 4166 ------------ Loss: 4705.78 ------------ Accuracy: 85.1%\n",
            "Step: 4167 ------------ Loss: 4705.72 ------------ Accuracy: 85.2%\n",
            "Step: 4168 ------------ Loss: 4705.5 ------------ Accuracy: 85.2%\n",
            "Step: 4169 ------------ Loss: 4705.03 ------------ Accuracy: 85.2%\n",
            "Step: 4170 ------------ Loss: 4704.63 ------------ Accuracy: 85.1%\n",
            "Step: 4171 ------------ Loss: 4704.16 ------------ Accuracy: 85.2%\n",
            "Step: 4172 ------------ Loss: 4703.65 ------------ Accuracy: 85.2%\n",
            "Step: 4173 ------------ Loss: 4703.2 ------------ Accuracy: 85.2%\n",
            "Step: 4174 ------------ Loss: 4702.56 ------------ Accuracy: 85.1%\n",
            "Step: 4175 ------------ Loss: 4702.27 ------------ Accuracy: 85.2%\n",
            "Step: 4176 ------------ Loss: 4702.22 ------------ Accuracy: 85.2%\n",
            "Step: 4177 ------------ Loss: 4701.74 ------------ Accuracy: 85.2%\n",
            "Step: 4178 ------------ Loss: 4701.22 ------------ Accuracy: 85.2%\n",
            "Step: 4179 ------------ Loss: 4701.0 ------------ Accuracy: 85.2%\n",
            "Step: 4180 ------------ Loss: 4700.8 ------------ Accuracy: 85.2%\n",
            "Step: 4181 ------------ Loss: 4700.62 ------------ Accuracy: 85.3%\n",
            "Step: 4182 ------------ Loss: 4700.17 ------------ Accuracy: 85.3%\n",
            "Step: 4183 ------------ Loss: 4700.09 ------------ Accuracy: 85.3%\n",
            "Step: 4184 ------------ Loss: 4700.03 ------------ Accuracy: 85.2%\n",
            "Step: 4185 ------------ Loss: 4699.59 ------------ Accuracy: 85.2%\n",
            "Step: 4186 ------------ Loss: 4699.16 ------------ Accuracy: 85.2%\n",
            "Step: 4187 ------------ Loss: 4698.74 ------------ Accuracy: 85.2%\n",
            "Step: 4188 ------------ Loss: 4698.7 ------------ Accuracy: 85.2%\n",
            "Step: 4189 ------------ Loss: 4698.31 ------------ Accuracy: 85.2%\n",
            "Step: 4190 ------------ Loss: 4697.87 ------------ Accuracy: 85.2%\n",
            "Step: 4191 ------------ Loss: 4697.8 ------------ Accuracy: 85.2%\n",
            "Step: 4192 ------------ Loss: 4697.36 ------------ Accuracy: 85.2%\n",
            "Step: 4193 ------------ Loss: 4696.94 ------------ Accuracy: 85.2%\n",
            "Step: 4194 ------------ Loss: 4696.47 ------------ Accuracy: 85.2%\n",
            "Step: 4195 ------------ Loss: 4696.01 ------------ Accuracy: 85.2%\n",
            "Step: 4196 ------------ Loss: 4695.53 ------------ Accuracy: 85.2%\n",
            "Step: 4197 ------------ Loss: 4695.05 ------------ Accuracy: 85.2%\n",
            "Step: 4198 ------------ Loss: 4695.01 ------------ Accuracy: 85.2%\n",
            "Step: 4199 ------------ Loss: 4694.52 ------------ Accuracy: 85.2%\n",
            "Step: 4200 ------------ Loss: 4694.05 ------------ Accuracy: 85.2%\n",
            "Step: 4201 ------------ Loss: 4693.58 ------------ Accuracy: 85.2%\n",
            "Step: 4202 ------------ Loss: 4692.64 ------------ Accuracy: 85.2%\n",
            "Step: 4203 ------------ Loss: 4692.35 ------------ Accuracy: 85.2%\n",
            "Step: 4204 ------------ Loss: 4691.91 ------------ Accuracy: 85.2%\n",
            "Step: 4205 ------------ Loss: 4691.37 ------------ Accuracy: 85.2%\n",
            "Step: 4206 ------------ Loss: 4690.99 ------------ Accuracy: 85.2%\n",
            "Step: 4207 ------------ Loss: 4690.52 ------------ Accuracy: 85.2%\n",
            "Step: 4208 ------------ Loss: 4690.06 ------------ Accuracy: 85.2%\n",
            "Step: 4209 ------------ Loss: 4689.38 ------------ Accuracy: 85.2%\n",
            "Step: 4210 ------------ Loss: 4688.85 ------------ Accuracy: 85.2%\n",
            "Step: 4211 ------------ Loss: 4688.38 ------------ Accuracy: 85.2%\n",
            "Step: 4212 ------------ Loss: 4687.48 ------------ Accuracy: 85.2%\n",
            "Step: 4213 ------------ Loss: 4687.19 ------------ Accuracy: 85.2%\n",
            "Step: 4214 ------------ Loss: 4686.71 ------------ Accuracy: 85.2%\n",
            "Step: 4215 ------------ Loss: 4686.28 ------------ Accuracy: 85.2%\n",
            "Step: 4216 ------------ Loss: 4686.24 ------------ Accuracy: 85.2%\n",
            "Step: 4217 ------------ Loss: 4685.72 ------------ Accuracy: 85.2%\n",
            "Step: 4218 ------------ Loss: 4685.23 ------------ Accuracy: 85.2%\n",
            "Step: 4219 ------------ Loss: 4684.73 ------------ Accuracy: 85.2%\n",
            "Step: 4220 ------------ Loss: 4684.25 ------------ Accuracy: 85.2%\n",
            "Step: 4221 ------------ Loss: 4683.61 ------------ Accuracy: 85.2%\n",
            "Step: 4222 ------------ Loss: 4683.0 ------------ Accuracy: 85.2%\n",
            "Step: 4223 ------------ Loss: 4682.78 ------------ Accuracy: 85.3%\n",
            "Step: 4224 ------------ Loss: 4682.74 ------------ Accuracy: 85.2%\n",
            "Step: 4225 ------------ Loss: 4682.26 ------------ Accuracy: 85.3%\n",
            "Step: 4226 ------------ Loss: 4681.97 ------------ Accuracy: 85.3%\n",
            "Step: 4227 ------------ Loss: 4681.47 ------------ Accuracy: 85.3%\n",
            "Step: 4228 ------------ Loss: 4681.44 ------------ Accuracy: 85.3%\n",
            "Step: 4229 ------------ Loss: 4681.24 ------------ Accuracy: 85.3%\n",
            "Step: 4230 ------------ Loss: 4680.35 ------------ Accuracy: 85.2%\n",
            "Step: 4231 ------------ Loss: 4679.85 ------------ Accuracy: 85.3%\n",
            "Step: 4232 ------------ Loss: 4679.4 ------------ Accuracy: 85.3%\n",
            "Step: 4233 ------------ Loss: 4679.11 ------------ Accuracy: 85.3%\n",
            "Step: 4234 ------------ Loss: 4678.92 ------------ Accuracy: 85.4%\n",
            "Step: 4235 ------------ Loss: 4678.43 ------------ Accuracy: 85.4%\n",
            "Step: 4236 ------------ Loss: 4677.82 ------------ Accuracy: 85.4%\n",
            "Step: 4237 ------------ Loss: 4677.34 ------------ Accuracy: 85.4%\n",
            "Step: 4238 ------------ Loss: 4676.85 ------------ Accuracy: 85.5%\n",
            "Step: 4239 ------------ Loss: 4676.8 ------------ Accuracy: 85.5%\n",
            "Step: 4240 ------------ Loss: 4676.19 ------------ Accuracy: 85.5%\n",
            "Step: 4241 ------------ Loss: 4675.68 ------------ Accuracy: 85.5%\n",
            "Step: 4242 ------------ Loss: 4675.39 ------------ Accuracy: 85.5%\n",
            "Step: 4243 ------------ Loss: 4674.92 ------------ Accuracy: 85.4%\n",
            "Step: 4244 ------------ Loss: 4674.85 ------------ Accuracy: 85.4%\n",
            "Step: 4245 ------------ Loss: 4674.38 ------------ Accuracy: 85.4%\n",
            "Step: 4246 ------------ Loss: 4674.32 ------------ Accuracy: 85.4%\n",
            "Step: 4247 ------------ Loss: 4673.83 ------------ Accuracy: 85.4%\n",
            "Step: 4248 ------------ Loss: 4673.39 ------------ Accuracy: 85.4%\n",
            "Step: 4249 ------------ Loss: 4673.2 ------------ Accuracy: 85.4%\n",
            "Step: 4250 ------------ Loss: 4672.74 ------------ Accuracy: 85.5%\n",
            "Step: 4251 ------------ Loss: 4672.27 ------------ Accuracy: 85.5%\n",
            "Step: 4252 ------------ Loss: 4671.79 ------------ Accuracy: 85.5%\n",
            "Step: 4253 ------------ Loss: 4671.51 ------------ Accuracy: 85.5%\n",
            "Step: 4254 ------------ Loss: 4670.6 ------------ Accuracy: 85.4%\n",
            "Step: 4255 ------------ Loss: 4670.55 ------------ Accuracy: 85.4%\n",
            "Step: 4256 ------------ Loss: 4670.09 ------------ Accuracy: 85.4%\n",
            "Step: 4257 ------------ Loss: 4670.04 ------------ Accuracy: 85.4%\n",
            "Step: 4258 ------------ Loss: 4669.62 ------------ Accuracy: 85.4%\n",
            "Step: 4259 ------------ Loss: 4669.13 ------------ Accuracy: 85.4%\n",
            "Step: 4260 ------------ Loss: 4668.65 ------------ Accuracy: 85.4%\n",
            "Step: 4261 ------------ Loss: 4668.18 ------------ Accuracy: 85.4%\n",
            "Step: 4262 ------------ Loss: 4667.78 ------------ Accuracy: 85.4%\n",
            "Step: 4263 ------------ Loss: 4667.72 ------------ Accuracy: 85.4%\n",
            "Step: 4264 ------------ Loss: 4667.27 ------------ Accuracy: 85.4%\n",
            "Step: 4265 ------------ Loss: 4667.08 ------------ Accuracy: 85.4%\n",
            "Step: 4266 ------------ Loss: 4666.64 ------------ Accuracy: 85.4%\n",
            "Step: 4267 ------------ Loss: 4666.35 ------------ Accuracy: 85.4%\n",
            "Step: 4268 ------------ Loss: 4665.96 ------------ Accuracy: 85.4%\n",
            "Step: 4269 ------------ Loss: 4665.49 ------------ Accuracy: 85.5%\n",
            "Step: 4270 ------------ Loss: 4665.01 ------------ Accuracy: 85.5%\n",
            "Step: 4271 ------------ Loss: 4664.96 ------------ Accuracy: 85.5%\n",
            "Step: 4272 ------------ Loss: 4664.52 ------------ Accuracy: 85.5%\n",
            "Step: 4273 ------------ Loss: 4664.14 ------------ Accuracy: 85.5%\n",
            "Step: 4274 ------------ Loss: 4663.86 ------------ Accuracy: 85.5%\n",
            "Step: 4275 ------------ Loss: 4663.43 ------------ Accuracy: 85.5%\n",
            "Step: 4276 ------------ Loss: 4662.48 ------------ Accuracy: 85.4%\n",
            "Step: 4277 ------------ Loss: 4662.43 ------------ Accuracy: 85.4%\n",
            "Step: 4278 ------------ Loss: 4662.01 ------------ Accuracy: 85.4%\n",
            "Step: 4279 ------------ Loss: 4661.34 ------------ Accuracy: 85.4%\n",
            "Step: 4280 ------------ Loss: 4660.87 ------------ Accuracy: 85.5%\n",
            "Step: 4281 ------------ Loss: 4660.5 ------------ Accuracy: 85.4%\n",
            "Step: 4282 ------------ Loss: 4660.09 ------------ Accuracy: 85.4%\n",
            "Step: 4283 ------------ Loss: 4659.62 ------------ Accuracy: 85.5%\n",
            "Step: 4284 ------------ Loss: 4658.69 ------------ Accuracy: 85.4%\n",
            "Step: 4285 ------------ Loss: 4658.64 ------------ Accuracy: 85.4%\n",
            "Step: 4286 ------------ Loss: 4658.17 ------------ Accuracy: 85.4%\n",
            "Step: 4287 ------------ Loss: 4658.12 ------------ Accuracy: 85.4%\n",
            "Step: 4288 ------------ Loss: 4657.46 ------------ Accuracy: 85.4%\n",
            "Step: 4289 ------------ Loss: 4657.42 ------------ Accuracy: 85.5%\n",
            "Step: 4290 ------------ Loss: 4656.95 ------------ Accuracy: 85.5%\n",
            "Step: 4291 ------------ Loss: 4656.3 ------------ Accuracy: 85.5%\n",
            "Step: 4292 ------------ Loss: 4655.85 ------------ Accuracy: 85.5%\n",
            "Step: 4293 ------------ Loss: 4655.81 ------------ Accuracy: 85.5%\n",
            "Step: 4294 ------------ Loss: 4655.34 ------------ Accuracy: 85.5%\n",
            "Step: 4295 ------------ Loss: 4654.94 ------------ Accuracy: 85.5%\n",
            "Step: 4296 ------------ Loss: 4654.29 ------------ Accuracy: 85.5%\n",
            "Step: 4297 ------------ Loss: 4653.37 ------------ Accuracy: 85.4%\n",
            "Step: 4298 ------------ Loss: 4653.32 ------------ Accuracy: 85.4%\n",
            "Step: 4299 ------------ Loss: 4653.04 ------------ Accuracy: 85.4%\n",
            "Step: 4300 ------------ Loss: 4652.77 ------------ Accuracy: 85.4%\n",
            "Step: 4301 ------------ Loss: 4652.3 ------------ Accuracy: 85.4%\n",
            "Step: 4302 ------------ Loss: 4651.8 ------------ Accuracy: 85.5%\n",
            "Step: 4303 ------------ Loss: 4651.4 ------------ Accuracy: 85.5%\n",
            "Step: 4304 ------------ Loss: 4650.93 ------------ Accuracy: 85.5%\n",
            "Step: 4305 ------------ Loss: 4650.48 ------------ Accuracy: 85.5%\n",
            "Step: 4306 ------------ Loss: 4650.1 ------------ Accuracy: 85.5%\n",
            "Step: 4307 ------------ Loss: 4649.2 ------------ Accuracy: 85.4%\n",
            "Step: 4308 ------------ Loss: 4648.84 ------------ Accuracy: 85.4%\n",
            "Step: 4309 ------------ Loss: 4648.6 ------------ Accuracy: 85.4%\n",
            "Step: 4310 ------------ Loss: 4648.15 ------------ Accuracy: 85.4%\n",
            "Step: 4311 ------------ Loss: 4647.79 ------------ Accuracy: 85.5%\n",
            "Step: 4312 ------------ Loss: 4647.33 ------------ Accuracy: 85.5%\n",
            "Step: 4313 ------------ Loss: 4646.99 ------------ Accuracy: 85.4%\n",
            "Step: 4314 ------------ Loss: 4646.55 ------------ Accuracy: 85.5%\n",
            "Step: 4315 ------------ Loss: 4646.03 ------------ Accuracy: 85.5%\n",
            "Step: 4316 ------------ Loss: 4645.55 ------------ Accuracy: 85.5%\n",
            "Step: 4317 ------------ Loss: 4645.1 ------------ Accuracy: 85.5%\n",
            "Step: 4318 ------------ Loss: 4644.66 ------------ Accuracy: 85.6%\n",
            "Step: 4319 ------------ Loss: 4644.61 ------------ Accuracy: 85.6%\n",
            "Step: 4320 ------------ Loss: 4644.26 ------------ Accuracy: 85.5%\n",
            "Step: 4321 ------------ Loss: 4643.87 ------------ Accuracy: 85.5%\n",
            "Step: 4322 ------------ Loss: 4642.98 ------------ Accuracy: 85.5%\n",
            "Step: 4323 ------------ Loss: 4642.65 ------------ Accuracy: 85.4%\n",
            "Step: 4324 ------------ Loss: 4642.02 ------------ Accuracy: 85.4%\n",
            "Step: 4325 ------------ Loss: 4641.56 ------------ Accuracy: 85.4%\n",
            "Step: 4326 ------------ Loss: 4640.96 ------------ Accuracy: 85.5%\n",
            "Step: 4327 ------------ Loss: 4640.51 ------------ Accuracy: 85.4%\n",
            "Step: 4328 ------------ Loss: 4640.24 ------------ Accuracy: 85.4%\n",
            "Step: 4329 ------------ Loss: 4639.8 ------------ Accuracy: 85.4%\n",
            "Step: 4330 ------------ Loss: 4639.76 ------------ Accuracy: 85.4%\n",
            "Step: 4331 ------------ Loss: 4639.25 ------------ Accuracy: 85.5%\n",
            "Step: 4332 ------------ Loss: 4638.82 ------------ Accuracy: 85.5%\n",
            "Step: 4333 ------------ Loss: 4638.41 ------------ Accuracy: 85.4%\n",
            "Step: 4334 ------------ Loss: 4637.95 ------------ Accuracy: 85.4%\n",
            "Step: 4335 ------------ Loss: 4637.14 ------------ Accuracy: 85.4%\n",
            "Step: 4336 ------------ Loss: 4636.74 ------------ Accuracy: 85.4%\n",
            "Step: 4337 ------------ Loss: 4636.26 ------------ Accuracy: 85.4%\n",
            "Step: 4338 ------------ Loss: 4635.98 ------------ Accuracy: 85.4%\n",
            "Step: 4339 ------------ Loss: 4635.45 ------------ Accuracy: 85.4%\n",
            "Step: 4340 ------------ Loss: 4635.4 ------------ Accuracy: 85.4%\n",
            "Step: 4341 ------------ Loss: 4635.05 ------------ Accuracy: 85.4%\n",
            "Step: 4342 ------------ Loss: 4635.01 ------------ Accuracy: 85.4%\n",
            "Step: 4343 ------------ Loss: 4634.44 ------------ Accuracy: 85.4%\n",
            "Step: 4344 ------------ Loss: 4634.16 ------------ Accuracy: 85.4%\n",
            "Step: 4345 ------------ Loss: 4633.75 ------------ Accuracy: 85.4%\n",
            "Step: 4346 ------------ Loss: 4633.3 ------------ Accuracy: 85.5%\n",
            "Step: 4347 ------------ Loss: 4632.73 ------------ Accuracy: 85.4%\n",
            "Step: 4348 ------------ Loss: 4632.47 ------------ Accuracy: 85.5%\n",
            "Step: 4349 ------------ Loss: 4632.02 ------------ Accuracy: 85.5%\n",
            "Step: 4350 ------------ Loss: 4631.56 ------------ Accuracy: 85.5%\n",
            "Step: 4351 ------------ Loss: 4631.52 ------------ Accuracy: 85.5%\n",
            "Step: 4352 ------------ Loss: 4631.25 ------------ Accuracy: 85.5%\n",
            "Step: 4353 ------------ Loss: 4630.85 ------------ Accuracy: 85.5%\n",
            "Step: 4354 ------------ Loss: 4630.02 ------------ Accuracy: 85.5%\n",
            "Step: 4355 ------------ Loss: 4629.65 ------------ Accuracy: 85.5%\n",
            "Step: 4356 ------------ Loss: 4629.21 ------------ Accuracy: 85.4%\n",
            "Step: 4357 ------------ Loss: 4628.64 ------------ Accuracy: 85.5%\n",
            "Step: 4358 ------------ Loss: 4628.38 ------------ Accuracy: 85.5%\n",
            "Step: 4359 ------------ Loss: 4627.98 ------------ Accuracy: 85.5%\n",
            "Step: 4360 ------------ Loss: 4627.5 ------------ Accuracy: 85.5%\n",
            "Step: 4361 ------------ Loss: 4626.98 ------------ Accuracy: 85.5%\n",
            "Step: 4362 ------------ Loss: 4626.57 ------------ Accuracy: 85.5%\n",
            "Step: 4363 ------------ Loss: 4626.5 ------------ Accuracy: 85.5%\n",
            "Step: 4364 ------------ Loss: 4626.27 ------------ Accuracy: 85.5%\n",
            "Step: 4365 ------------ Loss: 4625.7 ------------ Accuracy: 85.6%\n",
            "Step: 4366 ------------ Loss: 4625.31 ------------ Accuracy: 85.5%\n",
            "Step: 4367 ------------ Loss: 4624.94 ------------ Accuracy: 85.5%\n",
            "Step: 4368 ------------ Loss: 4624.86 ------------ Accuracy: 85.5%\n",
            "Step: 4369 ------------ Loss: 4624.4 ------------ Accuracy: 85.5%\n",
            "Step: 4370 ------------ Loss: 4624.13 ------------ Accuracy: 85.5%\n",
            "Step: 4371 ------------ Loss: 4623.66 ------------ Accuracy: 85.5%\n",
            "Step: 4372 ------------ Loss: 4623.26 ------------ Accuracy: 85.5%\n",
            "Step: 4373 ------------ Loss: 4623.19 ------------ Accuracy: 85.5%\n",
            "Step: 4374 ------------ Loss: 4622.79 ------------ Accuracy: 85.5%\n",
            "Step: 4375 ------------ Loss: 4622.29 ------------ Accuracy: 85.5%\n",
            "Step: 4376 ------------ Loss: 4621.9 ------------ Accuracy: 85.5%\n",
            "Step: 4377 ------------ Loss: 4621.51 ------------ Accuracy: 85.5%\n",
            "Step: 4378 ------------ Loss: 4621.05 ------------ Accuracy: 85.5%\n",
            "Step: 4379 ------------ Loss: 4620.53 ------------ Accuracy: 85.5%\n",
            "Step: 4380 ------------ Loss: 4620.31 ------------ Accuracy: 85.6%\n",
            "Step: 4381 ------------ Loss: 4619.92 ------------ Accuracy: 85.6%\n",
            "Step: 4382 ------------ Loss: 4619.36 ------------ Accuracy: 85.6%\n",
            "Step: 4383 ------------ Loss: 4619.08 ------------ Accuracy: 85.6%\n",
            "Step: 4384 ------------ Loss: 4619.03 ------------ Accuracy: 85.6%\n",
            "Step: 4385 ------------ Loss: 4618.76 ------------ Accuracy: 85.6%\n",
            "Step: 4386 ------------ Loss: 4618.3 ------------ Accuracy: 85.6%\n",
            "Step: 4387 ------------ Loss: 4618.02 ------------ Accuracy: 85.6%\n",
            "Step: 4388 ------------ Loss: 4617.61 ------------ Accuracy: 85.5%\n",
            "Step: 4389 ------------ Loss: 4617.38 ------------ Accuracy: 85.6%\n",
            "Step: 4390 ------------ Loss: 4617.1 ------------ Accuracy: 85.6%\n",
            "Step: 4391 ------------ Loss: 4616.6 ------------ Accuracy: 85.6%\n",
            "Step: 4392 ------------ Loss: 4616.54 ------------ Accuracy: 85.6%\n",
            "Step: 4393 ------------ Loss: 4616.1 ------------ Accuracy: 85.6%\n",
            "Step: 4394 ------------ Loss: 4615.62 ------------ Accuracy: 85.7%\n",
            "Step: 4395 ------------ Loss: 4614.77 ------------ Accuracy: 85.6%\n",
            "Step: 4396 ------------ Loss: 4614.33 ------------ Accuracy: 85.6%\n",
            "Step: 4397 ------------ Loss: 4614.28 ------------ Accuracy: 85.6%\n",
            "Step: 4398 ------------ Loss: 4613.88 ------------ Accuracy: 85.6%\n",
            "Step: 4399 ------------ Loss: 4613.48 ------------ Accuracy: 85.6%\n",
            "Step: 4400 ------------ Loss: 4613.2 ------------ Accuracy: 85.6%\n",
            "Step: 4401 ------------ Loss: 4612.75 ------------ Accuracy: 85.6%\n",
            "Step: 4402 ------------ Loss: 4612.36 ------------ Accuracy: 85.7%\n",
            "Step: 4403 ------------ Loss: 4612.3 ------------ Accuracy: 85.7%\n",
            "Step: 4404 ------------ Loss: 4611.84 ------------ Accuracy: 85.7%\n",
            "Step: 4405 ------------ Loss: 4611.79 ------------ Accuracy: 85.7%\n",
            "Step: 4406 ------------ Loss: 4611.32 ------------ Accuracy: 85.7%\n",
            "Step: 4407 ------------ Loss: 4610.86 ------------ Accuracy: 85.7%\n",
            "Step: 4408 ------------ Loss: 4610.43 ------------ Accuracy: 85.7%\n",
            "Step: 4409 ------------ Loss: 4609.98 ------------ Accuracy: 85.7%\n",
            "Step: 4410 ------------ Loss: 4609.71 ------------ Accuracy: 85.7%\n",
            "Step: 4411 ------------ Loss: 4609.25 ------------ Accuracy: 85.7%\n",
            "Step: 4412 ------------ Loss: 4608.85 ------------ Accuracy: 85.7%\n",
            "Step: 4413 ------------ Loss: 4608.81 ------------ Accuracy: 85.7%\n",
            "Step: 4414 ------------ Loss: 4608.43 ------------ Accuracy: 85.7%\n",
            "Step: 4415 ------------ Loss: 4608.38 ------------ Accuracy: 85.8%\n",
            "Step: 4416 ------------ Loss: 4607.79 ------------ Accuracy: 85.8%\n",
            "Step: 4417 ------------ Loss: 4607.75 ------------ Accuracy: 85.8%\n",
            "Step: 4418 ------------ Loss: 4607.48 ------------ Accuracy: 85.8%\n",
            "Step: 4419 ------------ Loss: 4606.9 ------------ Accuracy: 85.7%\n",
            "Step: 4420 ------------ Loss: 4606.85 ------------ Accuracy: 85.7%\n",
            "Step: 4421 ------------ Loss: 4605.96 ------------ Accuracy: 85.7%\n",
            "Step: 4422 ------------ Loss: 4605.5 ------------ Accuracy: 85.7%\n",
            "Step: 4423 ------------ Loss: 4605.23 ------------ Accuracy: 85.7%\n",
            "Step: 4424 ------------ Loss: 4604.79 ------------ Accuracy: 85.7%\n",
            "Step: 4425 ------------ Loss: 4604.4 ------------ Accuracy: 85.7%\n",
            "Step: 4426 ------------ Loss: 4603.94 ------------ Accuracy: 85.7%\n",
            "Step: 4427 ------------ Loss: 4603.49 ------------ Accuracy: 85.7%\n",
            "Step: 4428 ------------ Loss: 4603.11 ------------ Accuracy: 85.7%\n",
            "Step: 4429 ------------ Loss: 4602.24 ------------ Accuracy: 85.7%\n",
            "Step: 4430 ------------ Loss: 4601.78 ------------ Accuracy: 85.7%\n",
            "Step: 4431 ------------ Loss: 4601.39 ------------ Accuracy: 85.7%\n",
            "Step: 4432 ------------ Loss: 4600.94 ------------ Accuracy: 85.7%\n",
            "Step: 4433 ------------ Loss: 4600.56 ------------ Accuracy: 85.7%\n",
            "Step: 4434 ------------ Loss: 4600.18 ------------ Accuracy: 85.7%\n",
            "Step: 4435 ------------ Loss: 4599.75 ------------ Accuracy: 85.7%\n",
            "Step: 4436 ------------ Loss: 4599.32 ------------ Accuracy: 85.7%\n",
            "Step: 4437 ------------ Loss: 4598.86 ------------ Accuracy: 85.7%\n",
            "Step: 4438 ------------ Loss: 4598.42 ------------ Accuracy: 85.7%\n",
            "Step: 4439 ------------ Loss: 4598.2 ------------ Accuracy: 85.7%\n",
            "Step: 4440 ------------ Loss: 4597.82 ------------ Accuracy: 85.7%\n",
            "Step: 4441 ------------ Loss: 4597.44 ------------ Accuracy: 85.7%\n",
            "Step: 4442 ------------ Loss: 4597.06 ------------ Accuracy: 85.7%\n",
            "Step: 4443 ------------ Loss: 4596.64 ------------ Accuracy: 85.7%\n",
            "Step: 4444 ------------ Loss: 4596.6 ------------ Accuracy: 85.7%\n",
            "Step: 4445 ------------ Loss: 4596.55 ------------ Accuracy: 85.7%\n",
            "Step: 4446 ------------ Loss: 4596.51 ------------ Accuracy: 85.7%\n",
            "Step: 4447 ------------ Loss: 4595.91 ------------ Accuracy: 85.7%\n",
            "Step: 4448 ------------ Loss: 4595.87 ------------ Accuracy: 85.8%\n",
            "Step: 4449 ------------ Loss: 4595.43 ------------ Accuracy: 85.7%\n",
            "Step: 4450 ------------ Loss: 4595.0 ------------ Accuracy: 85.7%\n",
            "Step: 4451 ------------ Loss: 4594.55 ------------ Accuracy: 85.7%\n",
            "Step: 4452 ------------ Loss: 4594.1 ------------ Accuracy: 85.7%\n",
            "Step: 4453 ------------ Loss: 4593.84 ------------ Accuracy: 85.7%\n",
            "Step: 4454 ------------ Loss: 4593.39 ------------ Accuracy: 85.7%\n",
            "Step: 4455 ------------ Loss: 4592.96 ------------ Accuracy: 85.7%\n",
            "Step: 4456 ------------ Loss: 4592.71 ------------ Accuracy: 85.7%\n",
            "Step: 4457 ------------ Loss: 4592.45 ------------ Accuracy: 85.7%\n",
            "Step: 4458 ------------ Loss: 4592.02 ------------ Accuracy: 85.7%\n",
            "Step: 4459 ------------ Loss: 4591.41 ------------ Accuracy: 85.7%\n",
            "Step: 4460 ------------ Loss: 4590.99 ------------ Accuracy: 85.7%\n",
            "Step: 4461 ------------ Loss: 4590.95 ------------ Accuracy: 85.7%\n",
            "Step: 4462 ------------ Loss: 4590.53 ------------ Accuracy: 85.7%\n",
            "Step: 4463 ------------ Loss: 4590.27 ------------ Accuracy: 85.7%\n",
            "Step: 4464 ------------ Loss: 4590.01 ------------ Accuracy: 85.7%\n",
            "Step: 4465 ------------ Loss: 4589.13 ------------ Accuracy: 85.7%\n",
            "Step: 4466 ------------ Loss: 4588.87 ------------ Accuracy: 85.7%\n",
            "Step: 4467 ------------ Loss: 4588.45 ------------ Accuracy: 85.7%\n",
            "Step: 4468 ------------ Loss: 4588.08 ------------ Accuracy: 85.6%\n",
            "Step: 4469 ------------ Loss: 4588.03 ------------ Accuracy: 85.6%\n",
            "Step: 4470 ------------ Loss: 4587.78 ------------ Accuracy: 85.6%\n",
            "Step: 4471 ------------ Loss: 4587.35 ------------ Accuracy: 85.7%\n",
            "Step: 4472 ------------ Loss: 4586.93 ------------ Accuracy: 85.7%\n",
            "Step: 4473 ------------ Loss: 4586.55 ------------ Accuracy: 85.7%\n",
            "Step: 4474 ------------ Loss: 4586.15 ------------ Accuracy: 85.7%\n",
            "Step: 4475 ------------ Loss: 4585.54 ------------ Accuracy: 85.7%\n",
            "Step: 4476 ------------ Loss: 4585.5 ------------ Accuracy: 85.7%\n",
            "Step: 4477 ------------ Loss: 4585.46 ------------ Accuracy: 85.7%\n",
            "Step: 4478 ------------ Loss: 4584.95 ------------ Accuracy: 85.7%\n",
            "Step: 4479 ------------ Loss: 4584.55 ------------ Accuracy: 85.7%\n",
            "Step: 4480 ------------ Loss: 4584.13 ------------ Accuracy: 85.7%\n",
            "Step: 4481 ------------ Loss: 4583.53 ------------ Accuracy: 85.7%\n",
            "Step: 4482 ------------ Loss: 4582.95 ------------ Accuracy: 85.7%\n",
            "Step: 4483 ------------ Loss: 4582.69 ------------ Accuracy: 85.7%\n",
            "Step: 4484 ------------ Loss: 4582.26 ------------ Accuracy: 85.7%\n",
            "Step: 4485 ------------ Loss: 4581.68 ------------ Accuracy: 85.7%\n",
            "Step: 4486 ------------ Loss: 4581.27 ------------ Accuracy: 85.7%\n",
            "Step: 4487 ------------ Loss: 4580.39 ------------ Accuracy: 85.6%\n",
            "Step: 4488 ------------ Loss: 4579.95 ------------ Accuracy: 85.7%\n",
            "Step: 4489 ------------ Loss: 4579.53 ------------ Accuracy: 85.6%\n",
            "Step: 4490 ------------ Loss: 4579.46 ------------ Accuracy: 85.7%\n",
            "Step: 4491 ------------ Loss: 4579.21 ------------ Accuracy: 85.7%\n",
            "Step: 4492 ------------ Loss: 4578.79 ------------ Accuracy: 85.7%\n",
            "Step: 4493 ------------ Loss: 4578.72 ------------ Accuracy: 85.7%\n",
            "Step: 4494 ------------ Loss: 4578.3 ------------ Accuracy: 85.7%\n",
            "Step: 4495 ------------ Loss: 4578.25 ------------ Accuracy: 85.7%\n",
            "Step: 4496 ------------ Loss: 4577.85 ------------ Accuracy: 85.8%\n",
            "Step: 4497 ------------ Loss: 4577.43 ------------ Accuracy: 85.7%\n",
            "Step: 4498 ------------ Loss: 4577.06 ------------ Accuracy: 85.7%\n",
            "Step: 4499 ------------ Loss: 4577.02 ------------ Accuracy: 85.7%\n",
            "Step: 4500 ------------ Loss: 4576.59 ------------ Accuracy: 85.7%\n",
            "Step: 4501 ------------ Loss: 4576.55 ------------ Accuracy: 85.7%\n",
            "Step: 4502 ------------ Loss: 4576.31 ------------ Accuracy: 85.7%\n",
            "Step: 4503 ------------ Loss: 4576.07 ------------ Accuracy: 85.7%\n",
            "Step: 4504 ------------ Loss: 4575.17 ------------ Accuracy: 85.7%\n",
            "Step: 4505 ------------ Loss: 4574.76 ------------ Accuracy: 85.6%\n",
            "Step: 4506 ------------ Loss: 4574.35 ------------ Accuracy: 85.7%\n",
            "Step: 4507 ------------ Loss: 4573.95 ------------ Accuracy: 85.7%\n",
            "Step: 4508 ------------ Loss: 4573.1 ------------ Accuracy: 85.7%\n",
            "Step: 4509 ------------ Loss: 4572.84 ------------ Accuracy: 85.7%\n",
            "Step: 4510 ------------ Loss: 4572.79 ------------ Accuracy: 85.6%\n",
            "Step: 4511 ------------ Loss: 4572.71 ------------ Accuracy: 85.7%\n",
            "Step: 4512 ------------ Loss: 4572.32 ------------ Accuracy: 85.6%\n",
            "Step: 4513 ------------ Loss: 4571.9 ------------ Accuracy: 85.7%\n",
            "Step: 4514 ------------ Loss: 4571.48 ------------ Accuracy: 85.7%\n",
            "Step: 4515 ------------ Loss: 4570.64 ------------ Accuracy: 85.7%\n",
            "Step: 4516 ------------ Loss: 4570.14 ------------ Accuracy: 85.6%\n",
            "Step: 4517 ------------ Loss: 4569.88 ------------ Accuracy: 85.6%\n",
            "Step: 4518 ------------ Loss: 4569.63 ------------ Accuracy: 85.6%\n",
            "Step: 4519 ------------ Loss: 4569.57 ------------ Accuracy: 85.6%\n",
            "Step: 4520 ------------ Loss: 4569.5 ------------ Accuracy: 85.7%\n",
            "Step: 4521 ------------ Loss: 4569.07 ------------ Accuracy: 85.7%\n",
            "Step: 4522 ------------ Loss: 4568.63 ------------ Accuracy: 85.7%\n",
            "Step: 4523 ------------ Loss: 4568.24 ------------ Accuracy: 85.7%\n",
            "Step: 4524 ------------ Loss: 4567.88 ------------ Accuracy: 85.7%\n",
            "Step: 4525 ------------ Loss: 4567.49 ------------ Accuracy: 85.7%\n",
            "Step: 4526 ------------ Loss: 4567.06 ------------ Accuracy: 85.7%\n",
            "Step: 4527 ------------ Loss: 4566.62 ------------ Accuracy: 85.7%\n",
            "Step: 4528 ------------ Loss: 4566.39 ------------ Accuracy: 85.7%\n",
            "Step: 4529 ------------ Loss: 4565.96 ------------ Accuracy: 85.8%\n",
            "Step: 4530 ------------ Loss: 4565.56 ------------ Accuracy: 85.8%\n",
            "Step: 4531 ------------ Loss: 4565.13 ------------ Accuracy: 85.8%\n",
            "Step: 4532 ------------ Loss: 4564.93 ------------ Accuracy: 85.8%\n",
            "Step: 4533 ------------ Loss: 4564.75 ------------ Accuracy: 85.8%\n",
            "Step: 4534 ------------ Loss: 4564.34 ------------ Accuracy: 85.8%\n",
            "Step: 4535 ------------ Loss: 4564.09 ------------ Accuracy: 85.8%\n",
            "Step: 4536 ------------ Loss: 4563.85 ------------ Accuracy: 85.8%\n",
            "Step: 4537 ------------ Loss: 4563.68 ------------ Accuracy: 85.9%\n",
            "Step: 4538 ------------ Loss: 4563.25 ------------ Accuracy: 85.9%\n",
            "Step: 4539 ------------ Loss: 4562.83 ------------ Accuracy: 85.9%\n",
            "Step: 4540 ------------ Loss: 4562.59 ------------ Accuracy: 85.9%\n",
            "Step: 4541 ------------ Loss: 4562.22 ------------ Accuracy: 85.9%\n",
            "Step: 4542 ------------ Loss: 4562.14 ------------ Accuracy: 85.9%\n",
            "Step: 4543 ------------ Loss: 4561.9 ------------ Accuracy: 85.9%\n",
            "Step: 4544 ------------ Loss: 4561.52 ------------ Accuracy: 86.0%\n",
            "Step: 4545 ------------ Loss: 4561.13 ------------ Accuracy: 86.0%\n",
            "Step: 4546 ------------ Loss: 4560.49 ------------ Accuracy: 86.0%\n",
            "Step: 4547 ------------ Loss: 4560.24 ------------ Accuracy: 86.0%\n",
            "Step: 4548 ------------ Loss: 4559.34 ------------ Accuracy: 85.9%\n",
            "Step: 4549 ------------ Loss: 4558.94 ------------ Accuracy: 85.9%\n",
            "Step: 4550 ------------ Loss: 4558.87 ------------ Accuracy: 85.8%\n",
            "Step: 4551 ------------ Loss: 4558.62 ------------ Accuracy: 85.9%\n",
            "Step: 4552 ------------ Loss: 4558.46 ------------ Accuracy: 85.9%\n",
            "Step: 4553 ------------ Loss: 4558.07 ------------ Accuracy: 85.9%\n",
            "Step: 4554 ------------ Loss: 4558.02 ------------ Accuracy: 85.9%\n",
            "Step: 4555 ------------ Loss: 4557.15 ------------ Accuracy: 85.9%\n",
            "Step: 4556 ------------ Loss: 4557.0 ------------ Accuracy: 85.9%\n",
            "Step: 4557 ------------ Loss: 4556.58 ------------ Accuracy: 85.9%\n",
            "Step: 4558 ------------ Loss: 4556.16 ------------ Accuracy: 85.9%\n",
            "Step: 4559 ------------ Loss: 4555.74 ------------ Accuracy: 85.9%\n",
            "Step: 4560 ------------ Loss: 4555.37 ------------ Accuracy: 85.9%\n",
            "Step: 4561 ------------ Loss: 4555.23 ------------ Accuracy: 85.9%\n",
            "Step: 4562 ------------ Loss: 4554.86 ------------ Accuracy: 85.9%\n",
            "Step: 4563 ------------ Loss: 4554.23 ------------ Accuracy: 86.0%\n",
            "Step: 4564 ------------ Loss: 4553.86 ------------ Accuracy: 86.0%\n",
            "Step: 4565 ------------ Loss: 4553.72 ------------ Accuracy: 86.0%\n",
            "Step: 4566 ------------ Loss: 4553.33 ------------ Accuracy: 86.0%\n",
            "Step: 4567 ------------ Loss: 4553.08 ------------ Accuracy: 86.0%\n",
            "Step: 4568 ------------ Loss: 4552.56 ------------ Accuracy: 86.0%\n",
            "Step: 4569 ------------ Loss: 4552.48 ------------ Accuracy: 86.0%\n",
            "Step: 4570 ------------ Loss: 4552.1 ------------ Accuracy: 86.0%\n",
            "Step: 4571 ------------ Loss: 4551.7 ------------ Accuracy: 86.0%\n",
            "Step: 4572 ------------ Loss: 4551.29 ------------ Accuracy: 86.0%\n",
            "Step: 4573 ------------ Loss: 4550.4 ------------ Accuracy: 86.0%\n",
            "Step: 4574 ------------ Loss: 4550.01 ------------ Accuracy: 86.0%\n",
            "Step: 4575 ------------ Loss: 4549.78 ------------ Accuracy: 86.0%\n",
            "Step: 4576 ------------ Loss: 4549.38 ------------ Accuracy: 86.0%\n",
            "Step: 4577 ------------ Loss: 4548.98 ------------ Accuracy: 86.0%\n",
            "Step: 4578 ------------ Loss: 4548.9 ------------ Accuracy: 86.0%\n",
            "Step: 4579 ------------ Loss: 4548.28 ------------ Accuracy: 86.0%\n",
            "Step: 4580 ------------ Loss: 4548.14 ------------ Accuracy: 86.0%\n",
            "Step: 4581 ------------ Loss: 4547.73 ------------ Accuracy: 86.0%\n",
            "Step: 4582 ------------ Loss: 4547.67 ------------ Accuracy: 86.0%\n",
            "Step: 4583 ------------ Loss: 4547.3 ------------ Accuracy: 86.0%\n",
            "Step: 4584 ------------ Loss: 4547.06 ------------ Accuracy: 86.0%\n",
            "Step: 4585 ------------ Loss: 4546.67 ------------ Accuracy: 86.0%\n",
            "Step: 4586 ------------ Loss: 4546.16 ------------ Accuracy: 86.1%\n",
            "Step: 4587 ------------ Loss: 4545.91 ------------ Accuracy: 86.1%\n",
            "Step: 4588 ------------ Loss: 4545.53 ------------ Accuracy: 86.1%\n",
            "Step: 4589 ------------ Loss: 4545.12 ------------ Accuracy: 86.0%\n",
            "Step: 4590 ------------ Loss: 4544.51 ------------ Accuracy: 86.0%\n",
            "Step: 4591 ------------ Loss: 4544.42 ------------ Accuracy: 86.1%\n",
            "Step: 4592 ------------ Loss: 4544.05 ------------ Accuracy: 86.1%\n",
            "Step: 4593 ------------ Loss: 4543.66 ------------ Accuracy: 86.1%\n",
            "Step: 4594 ------------ Loss: 4543.05 ------------ Accuracy: 86.1%\n",
            "Step: 4595 ------------ Loss: 4542.8 ------------ Accuracy: 86.1%\n",
            "Step: 4596 ------------ Loss: 4542.75 ------------ Accuracy: 86.1%\n",
            "Step: 4597 ------------ Loss: 4542.16 ------------ Accuracy: 86.1%\n",
            "Step: 4598 ------------ Loss: 4541.8 ------------ Accuracy: 86.1%\n",
            "Step: 4599 ------------ Loss: 4541.57 ------------ Accuracy: 86.1%\n",
            "Step: 4600 ------------ Loss: 4541.19 ------------ Accuracy: 86.1%\n",
            "Step: 4601 ------------ Loss: 4541.14 ------------ Accuracy: 86.1%\n",
            "Step: 4602 ------------ Loss: 4540.77 ------------ Accuracy: 86.1%\n",
            "Step: 4603 ------------ Loss: 4540.41 ------------ Accuracy: 86.1%\n",
            "Step: 4604 ------------ Loss: 4540.05 ------------ Accuracy: 86.1%\n",
            "Step: 4605 ------------ Loss: 4540.01 ------------ Accuracy: 86.1%\n",
            "Step: 4606 ------------ Loss: 4539.97 ------------ Accuracy: 86.1%\n",
            "Step: 4607 ------------ Loss: 4539.59 ------------ Accuracy: 86.1%\n",
            "Step: 4608 ------------ Loss: 4539.55 ------------ Accuracy: 86.1%\n",
            "Step: 4609 ------------ Loss: 4538.62 ------------ Accuracy: 86.1%\n",
            "Step: 4610 ------------ Loss: 4538.26 ------------ Accuracy: 86.1%\n",
            "Step: 4611 ------------ Loss: 4538.02 ------------ Accuracy: 86.1%\n",
            "Step: 4612 ------------ Loss: 4537.67 ------------ Accuracy: 86.1%\n",
            "Step: 4613 ------------ Loss: 4537.32 ------------ Accuracy: 86.1%\n",
            "Step: 4614 ------------ Loss: 4536.81 ------------ Accuracy: 86.1%\n",
            "Step: 4615 ------------ Loss: 4536.65 ------------ Accuracy: 86.1%\n",
            "Step: 4616 ------------ Loss: 4536.28 ------------ Accuracy: 86.1%\n",
            "Step: 4617 ------------ Loss: 4535.93 ------------ Accuracy: 86.1%\n",
            "Step: 4618 ------------ Loss: 4535.69 ------------ Accuracy: 86.1%\n",
            "Step: 4619 ------------ Loss: 4535.28 ------------ Accuracy: 86.1%\n",
            "Step: 4620 ------------ Loss: 4535.24 ------------ Accuracy: 86.1%\n",
            "Step: 4621 ------------ Loss: 4534.87 ------------ Accuracy: 86.1%\n",
            "Step: 4622 ------------ Loss: 4534.41 ------------ Accuracy: 86.1%\n",
            "Step: 4623 ------------ Loss: 4534.33 ------------ Accuracy: 86.1%\n",
            "Step: 4624 ------------ Loss: 4533.95 ------------ Accuracy: 86.1%\n",
            "Step: 4625 ------------ Loss: 4533.79 ------------ Accuracy: 86.1%\n",
            "Step: 4626 ------------ Loss: 4533.44 ------------ Accuracy: 86.1%\n",
            "Step: 4627 ------------ Loss: 4532.83 ------------ Accuracy: 86.1%\n",
            "Step: 4628 ------------ Loss: 4532.45 ------------ Accuracy: 86.1%\n",
            "Step: 4629 ------------ Loss: 4532.01 ------------ Accuracy: 86.1%\n",
            "Step: 4630 ------------ Loss: 4531.64 ------------ Accuracy: 86.1%\n",
            "Step: 4631 ------------ Loss: 4531.13 ------------ Accuracy: 86.1%\n",
            "Step: 4632 ------------ Loss: 4530.73 ------------ Accuracy: 86.1%\n",
            "Step: 4633 ------------ Loss: 4530.32 ------------ Accuracy: 86.1%\n",
            "Step: 4634 ------------ Loss: 4529.82 ------------ Accuracy: 86.0%\n",
            "Step: 4635 ------------ Loss: 4529.42 ------------ Accuracy: 86.0%\n",
            "Step: 4636 ------------ Loss: 4529.01 ------------ Accuracy: 86.1%\n",
            "Step: 4637 ------------ Loss: 4528.42 ------------ Accuracy: 86.0%\n",
            "Step: 4638 ------------ Loss: 4528.18 ------------ Accuracy: 86.0%\n",
            "Step: 4639 ------------ Loss: 4528.01 ------------ Accuracy: 86.1%\n",
            "Step: 4640 ------------ Loss: 4527.63 ------------ Accuracy: 86.1%\n",
            "Step: 4641 ------------ Loss: 4527.23 ------------ Accuracy: 86.1%\n",
            "Step: 4642 ------------ Loss: 4527.0 ------------ Accuracy: 86.1%\n",
            "Step: 4643 ------------ Loss: 4526.77 ------------ Accuracy: 86.1%\n",
            "Step: 4644 ------------ Loss: 4526.69 ------------ Accuracy: 86.1%\n",
            "Step: 4645 ------------ Loss: 4526.46 ------------ Accuracy: 86.1%\n",
            "Step: 4646 ------------ Loss: 4526.31 ------------ Accuracy: 86.1%\n",
            "Step: 4647 ------------ Loss: 4525.96 ------------ Accuracy: 86.1%\n",
            "Step: 4648 ------------ Loss: 4525.47 ------------ Accuracy: 86.1%\n",
            "Step: 4649 ------------ Loss: 4525.23 ------------ Accuracy: 86.1%\n",
            "Step: 4650 ------------ Loss: 4525.19 ------------ Accuracy: 86.1%\n",
            "Step: 4651 ------------ Loss: 4524.81 ------------ Accuracy: 86.1%\n",
            "Step: 4652 ------------ Loss: 4524.22 ------------ Accuracy: 86.1%\n",
            "Step: 4653 ------------ Loss: 4523.78 ------------ Accuracy: 86.1%\n",
            "Step: 4654 ------------ Loss: 4523.2 ------------ Accuracy: 86.1%\n",
            "Step: 4655 ------------ Loss: 4522.32 ------------ Accuracy: 86.0%\n",
            "Step: 4656 ------------ Loss: 4522.08 ------------ Accuracy: 86.0%\n",
            "Step: 4657 ------------ Loss: 4521.91 ------------ Accuracy: 86.1%\n",
            "Step: 4658 ------------ Loss: 4521.84 ------------ Accuracy: 86.1%\n",
            "Step: 4659 ------------ Loss: 4521.44 ------------ Accuracy: 86.1%\n",
            "Step: 4660 ------------ Loss: 4520.99 ------------ Accuracy: 86.1%\n",
            "Step: 4661 ------------ Loss: 4520.58 ------------ Accuracy: 86.1%\n",
            "Step: 4662 ------------ Loss: 4520.15 ------------ Accuracy: 86.0%\n",
            "Step: 4663 ------------ Loss: 4519.92 ------------ Accuracy: 86.1%\n",
            "Step: 4664 ------------ Loss: 4519.57 ------------ Accuracy: 86.1%\n",
            "Step: 4665 ------------ Loss: 4519.33 ------------ Accuracy: 86.1%\n",
            "Step: 4666 ------------ Loss: 4518.95 ------------ Accuracy: 86.1%\n",
            "Step: 4667 ------------ Loss: 4518.57 ------------ Accuracy: 86.1%\n",
            "Step: 4668 ------------ Loss: 4518.16 ------------ Accuracy: 86.1%\n",
            "Step: 4669 ------------ Loss: 4517.75 ------------ Accuracy: 86.1%\n",
            "Step: 4670 ------------ Loss: 4516.9 ------------ Accuracy: 86.0%\n",
            "Step: 4671 ------------ Loss: 4516.86 ------------ Accuracy: 86.0%\n",
            "Step: 4672 ------------ Loss: 4516.46 ------------ Accuracy: 86.0%\n",
            "Step: 4673 ------------ Loss: 4516.29 ------------ Accuracy: 86.1%\n",
            "Step: 4674 ------------ Loss: 4516.05 ------------ Accuracy: 86.1%\n",
            "Step: 4675 ------------ Loss: 4515.66 ------------ Accuracy: 86.1%\n",
            "Step: 4676 ------------ Loss: 4515.28 ------------ Accuracy: 86.1%\n",
            "Step: 4677 ------------ Loss: 4514.88 ------------ Accuracy: 86.1%\n",
            "Step: 4678 ------------ Loss: 4514.84 ------------ Accuracy: 86.1%\n",
            "Step: 4679 ------------ Loss: 4514.37 ------------ Accuracy: 86.1%\n",
            "Step: 4680 ------------ Loss: 4513.97 ------------ Accuracy: 86.1%\n",
            "Step: 4681 ------------ Loss: 4513.59 ------------ Accuracy: 86.1%\n",
            "Step: 4682 ------------ Loss: 4513.21 ------------ Accuracy: 86.1%\n",
            "Step: 4683 ------------ Loss: 4512.87 ------------ Accuracy: 86.1%\n",
            "Step: 4684 ------------ Loss: 4512.48 ------------ Accuracy: 86.1%\n",
            "Step: 4685 ------------ Loss: 4512.14 ------------ Accuracy: 86.1%\n",
            "Step: 4686 ------------ Loss: 4511.8 ------------ Accuracy: 86.1%\n",
            "Step: 4687 ------------ Loss: 4511.42 ------------ Accuracy: 86.1%\n",
            "Step: 4688 ------------ Loss: 4510.54 ------------ Accuracy: 86.1%\n",
            "Step: 4689 ------------ Loss: 4510.15 ------------ Accuracy: 86.1%\n",
            "Step: 4690 ------------ Loss: 4510.11 ------------ Accuracy: 86.1%\n",
            "Step: 4691 ------------ Loss: 4509.53 ------------ Accuracy: 86.1%\n",
            "Step: 4692 ------------ Loss: 4509.1 ------------ Accuracy: 86.1%\n",
            "Step: 4693 ------------ Loss: 4508.71 ------------ Accuracy: 86.1%\n",
            "Step: 4694 ------------ Loss: 4508.67 ------------ Accuracy: 86.1%\n",
            "Step: 4695 ------------ Loss: 4508.5 ------------ Accuracy: 86.1%\n",
            "Step: 4696 ------------ Loss: 4508.11 ------------ Accuracy: 86.1%\n",
            "Step: 4697 ------------ Loss: 4508.04 ------------ Accuracy: 86.1%\n",
            "Step: 4698 ------------ Loss: 4507.46 ------------ Accuracy: 86.1%\n",
            "Step: 4699 ------------ Loss: 4507.22 ------------ Accuracy: 86.1%\n",
            "Step: 4700 ------------ Loss: 4506.84 ------------ Accuracy: 86.1%\n",
            "Step: 4701 ------------ Loss: 4506.45 ------------ Accuracy: 86.2%\n",
            "Step: 4702 ------------ Loss: 4506.42 ------------ Accuracy: 86.1%\n",
            "Step: 4703 ------------ Loss: 4506.34 ------------ Accuracy: 86.1%\n",
            "Step: 4704 ------------ Loss: 4505.97 ------------ Accuracy: 86.1%\n",
            "Step: 4705 ------------ Loss: 4505.58 ------------ Accuracy: 86.2%\n",
            "Step: 4706 ------------ Loss: 4505.21 ------------ Accuracy: 86.2%\n",
            "Step: 4707 ------------ Loss: 4504.79 ------------ Accuracy: 86.1%\n",
            "Step: 4708 ------------ Loss: 4504.43 ------------ Accuracy: 86.1%\n",
            "Step: 4709 ------------ Loss: 4504.06 ------------ Accuracy: 86.2%\n",
            "Step: 4710 ------------ Loss: 4503.67 ------------ Accuracy: 86.2%\n",
            "Step: 4711 ------------ Loss: 4503.5 ------------ Accuracy: 86.2%\n",
            "Step: 4712 ------------ Loss: 4503.11 ------------ Accuracy: 86.2%\n",
            "Step: 4713 ------------ Loss: 4502.88 ------------ Accuracy: 86.2%\n",
            "Step: 4714 ------------ Loss: 4502.49 ------------ Accuracy: 86.1%\n",
            "Step: 4715 ------------ Loss: 4502.26 ------------ Accuracy: 86.1%\n",
            "Step: 4716 ------------ Loss: 4501.65 ------------ Accuracy: 86.1%\n",
            "Step: 4717 ------------ Loss: 4501.28 ------------ Accuracy: 86.2%\n",
            "Step: 4718 ------------ Loss: 4500.93 ------------ Accuracy: 86.2%\n",
            "Step: 4719 ------------ Loss: 4500.55 ------------ Accuracy: 86.1%\n",
            "Step: 4720 ------------ Loss: 4500.16 ------------ Accuracy: 86.1%\n",
            "Step: 4721 ------------ Loss: 4500.0 ------------ Accuracy: 86.1%\n",
            "Step: 4722 ------------ Loss: 4499.96 ------------ Accuracy: 86.1%\n",
            "Step: 4723 ------------ Loss: 4499.73 ------------ Accuracy: 86.2%\n",
            "Step: 4724 ------------ Loss: 4499.35 ------------ Accuracy: 86.2%\n",
            "Step: 4725 ------------ Loss: 4498.45 ------------ Accuracy: 86.1%\n",
            "Step: 4726 ------------ Loss: 4498.22 ------------ Accuracy: 86.1%\n",
            "Step: 4727 ------------ Loss: 4497.99 ------------ Accuracy: 86.1%\n",
            "Step: 4728 ------------ Loss: 4497.62 ------------ Accuracy: 86.1%\n",
            "Step: 4729 ------------ Loss: 4497.1 ------------ Accuracy: 86.1%\n",
            "Step: 4730 ------------ Loss: 4496.88 ------------ Accuracy: 86.1%\n",
            "Step: 4731 ------------ Loss: 4496.49 ------------ Accuracy: 86.2%\n",
            "Step: 4732 ------------ Loss: 4496.0 ------------ Accuracy: 86.2%\n",
            "Step: 4733 ------------ Loss: 4495.77 ------------ Accuracy: 86.2%\n",
            "Step: 4734 ------------ Loss: 4495.39 ------------ Accuracy: 86.2%\n",
            "Step: 4735 ------------ Loss: 4495.31 ------------ Accuracy: 86.2%\n",
            "Step: 4736 ------------ Loss: 4495.08 ------------ Accuracy: 86.2%\n",
            "Step: 4737 ------------ Loss: 4494.22 ------------ Accuracy: 86.1%\n",
            "Step: 4738 ------------ Loss: 4494.14 ------------ Accuracy: 86.1%\n",
            "Step: 4739 ------------ Loss: 4493.77 ------------ Accuracy: 86.1%\n",
            "Step: 4740 ------------ Loss: 4493.53 ------------ Accuracy: 86.1%\n",
            "Step: 4741 ------------ Loss: 4493.3 ------------ Accuracy: 86.1%\n",
            "Step: 4742 ------------ Loss: 4493.15 ------------ Accuracy: 86.2%\n",
            "Step: 4743 ------------ Loss: 4493.0 ------------ Accuracy: 86.2%\n",
            "Step: 4744 ------------ Loss: 4492.62 ------------ Accuracy: 86.1%\n",
            "Step: 4745 ------------ Loss: 4492.53 ------------ Accuracy: 86.1%\n",
            "Step: 4746 ------------ Loss: 4492.19 ------------ Accuracy: 86.2%\n",
            "Step: 4747 ------------ Loss: 4491.82 ------------ Accuracy: 86.2%\n",
            "Step: 4748 ------------ Loss: 4491.74 ------------ Accuracy: 86.1%\n",
            "Step: 4749 ------------ Loss: 4491.35 ------------ Accuracy: 86.1%\n",
            "Step: 4750 ------------ Loss: 4490.99 ------------ Accuracy: 86.2%\n",
            "Step: 4751 ------------ Loss: 4490.63 ------------ Accuracy: 86.2%\n",
            "Step: 4752 ------------ Loss: 4490.27 ------------ Accuracy: 86.2%\n",
            "Step: 4753 ------------ Loss: 4489.93 ------------ Accuracy: 86.2%\n",
            "Step: 4754 ------------ Loss: 4489.56 ------------ Accuracy: 86.2%\n",
            "Step: 4755 ------------ Loss: 4489.34 ------------ Accuracy: 86.2%\n",
            "Step: 4756 ------------ Loss: 4488.98 ------------ Accuracy: 86.2%\n",
            "Step: 4757 ------------ Loss: 4488.84 ------------ Accuracy: 86.2%\n",
            "Step: 4758 ------------ Loss: 4488.49 ------------ Accuracy: 86.3%\n",
            "Step: 4759 ------------ Loss: 4488.15 ------------ Accuracy: 86.2%\n",
            "Step: 4760 ------------ Loss: 4488.06 ------------ Accuracy: 86.3%\n",
            "Step: 4761 ------------ Loss: 4487.17 ------------ Accuracy: 86.2%\n",
            "Step: 4762 ------------ Loss: 4486.79 ------------ Accuracy: 86.2%\n",
            "Step: 4763 ------------ Loss: 4486.36 ------------ Accuracy: 86.2%\n",
            "Step: 4764 ------------ Loss: 4485.49 ------------ Accuracy: 86.1%\n",
            "Step: 4765 ------------ Loss: 4485.11 ------------ Accuracy: 86.2%\n",
            "Step: 4766 ------------ Loss: 4484.76 ------------ Accuracy: 86.2%\n",
            "Step: 4767 ------------ Loss: 4484.54 ------------ Accuracy: 86.2%\n",
            "Step: 4768 ------------ Loss: 4484.05 ------------ Accuracy: 86.2%\n",
            "Step: 4769 ------------ Loss: 4483.59 ------------ Accuracy: 86.1%\n",
            "Step: 4770 ------------ Loss: 4483.2 ------------ Accuracy: 86.1%\n",
            "Step: 4771 ------------ Loss: 4482.79 ------------ Accuracy: 86.1%\n",
            "Step: 4772 ------------ Loss: 4481.98 ------------ Accuracy: 86.1%\n",
            "Step: 4773 ------------ Loss: 4481.93 ------------ Accuracy: 86.1%\n",
            "Step: 4774 ------------ Loss: 4481.49 ------------ Accuracy: 86.2%\n",
            "Step: 4775 ------------ Loss: 4481.25 ------------ Accuracy: 86.2%\n",
            "Step: 4776 ------------ Loss: 4480.69 ------------ Accuracy: 86.2%\n",
            "Step: 4777 ------------ Loss: 4480.31 ------------ Accuracy: 86.2%\n",
            "Step: 4778 ------------ Loss: 4479.97 ------------ Accuracy: 86.2%\n",
            "Step: 4779 ------------ Loss: 4479.59 ------------ Accuracy: 86.2%\n",
            "Step: 4780 ------------ Loss: 4479.42 ------------ Accuracy: 86.2%\n",
            "Step: 4781 ------------ Loss: 4479.19 ------------ Accuracy: 86.2%\n",
            "Step: 4782 ------------ Loss: 4478.85 ------------ Accuracy: 86.2%\n",
            "Step: 4783 ------------ Loss: 4478.45 ------------ Accuracy: 86.1%\n",
            "Step: 4784 ------------ Loss: 4478.08 ------------ Accuracy: 86.2%\n",
            "Step: 4785 ------------ Loss: 4477.69 ------------ Accuracy: 86.2%\n",
            "Step: 4786 ------------ Loss: 4477.53 ------------ Accuracy: 86.2%\n",
            "Step: 4787 ------------ Loss: 4476.97 ------------ Accuracy: 86.2%\n",
            "Step: 4788 ------------ Loss: 4476.58 ------------ Accuracy: 86.2%\n",
            "Step: 4789 ------------ Loss: 4476.25 ------------ Accuracy: 86.2%\n",
            "Step: 4790 ------------ Loss: 4475.88 ------------ Accuracy: 86.2%\n",
            "Step: 4791 ------------ Loss: 4475.45 ------------ Accuracy: 86.2%\n",
            "Step: 4792 ------------ Loss: 4475.12 ------------ Accuracy: 86.3%\n",
            "Step: 4793 ------------ Loss: 4474.79 ------------ Accuracy: 86.3%\n",
            "Step: 4794 ------------ Loss: 4474.38 ------------ Accuracy: 86.3%\n",
            "Step: 4795 ------------ Loss: 4474.0 ------------ Accuracy: 86.3%\n",
            "Step: 4796 ------------ Loss: 4473.78 ------------ Accuracy: 86.3%\n",
            "Step: 4797 ------------ Loss: 4473.39 ------------ Accuracy: 86.3%\n",
            "Step: 4798 ------------ Loss: 4472.99 ------------ Accuracy: 86.3%\n",
            "Step: 4799 ------------ Loss: 4472.58 ------------ Accuracy: 86.3%\n",
            "Step: 4800 ------------ Loss: 4472.19 ------------ Accuracy: 86.3%\n",
            "Step: 4801 ------------ Loss: 4471.8 ------------ Accuracy: 86.2%\n",
            "Step: 4802 ------------ Loss: 4471.58 ------------ Accuracy: 86.2%\n",
            "Step: 4803 ------------ Loss: 4471.19 ------------ Accuracy: 86.2%\n",
            "Step: 4804 ------------ Loss: 4470.86 ------------ Accuracy: 86.3%\n",
            "Step: 4805 ------------ Loss: 4470.48 ------------ Accuracy: 86.3%\n",
            "Step: 4806 ------------ Loss: 4470.11 ------------ Accuracy: 86.3%\n",
            "Step: 4807 ------------ Loss: 4469.76 ------------ Accuracy: 86.2%\n",
            "Step: 4808 ------------ Loss: 4469.31 ------------ Accuracy: 86.3%\n",
            "Step: 4809 ------------ Loss: 4468.87 ------------ Accuracy: 86.3%\n",
            "Step: 4810 ------------ Loss: 4468.84 ------------ Accuracy: 86.3%\n",
            "Step: 4811 ------------ Loss: 4468.76 ------------ Accuracy: 86.3%\n",
            "Step: 4812 ------------ Loss: 4468.54 ------------ Accuracy: 86.3%\n",
            "Step: 4813 ------------ Loss: 4467.72 ------------ Accuracy: 86.3%\n",
            "Step: 4814 ------------ Loss: 4467.35 ------------ Accuracy: 86.3%\n",
            "Step: 4815 ------------ Loss: 4466.96 ------------ Accuracy: 86.3%\n",
            "Step: 4816 ------------ Loss: 4466.74 ------------ Accuracy: 86.3%\n",
            "Step: 4817 ------------ Loss: 4466.38 ------------ Accuracy: 86.3%\n",
            "Step: 4818 ------------ Loss: 4466.34 ------------ Accuracy: 86.3%\n",
            "Step: 4819 ------------ Loss: 4465.97 ------------ Accuracy: 86.3%\n",
            "Step: 4820 ------------ Loss: 4465.58 ------------ Accuracy: 86.3%\n",
            "Step: 4821 ------------ Loss: 4465.22 ------------ Accuracy: 86.3%\n",
            "Step: 4822 ------------ Loss: 4464.84 ------------ Accuracy: 86.3%\n",
            "Step: 4823 ------------ Loss: 4464.8 ------------ Accuracy: 86.3%\n",
            "Step: 4824 ------------ Loss: 4464.42 ------------ Accuracy: 86.2%\n",
            "Step: 4825 ------------ Loss: 4464.04 ------------ Accuracy: 86.3%\n",
            "Step: 4826 ------------ Loss: 4463.87 ------------ Accuracy: 86.3%\n",
            "Step: 4827 ------------ Loss: 4463.42 ------------ Accuracy: 86.3%\n",
            "Step: 4828 ------------ Loss: 4463.07 ------------ Accuracy: 86.3%\n",
            "Step: 4829 ------------ Loss: 4463.03 ------------ Accuracy: 86.3%\n",
            "Step: 4830 ------------ Loss: 4462.95 ------------ Accuracy: 86.3%\n",
            "Step: 4831 ------------ Loss: 4462.56 ------------ Accuracy: 86.3%\n",
            "Step: 4832 ------------ Loss: 4462.53 ------------ Accuracy: 86.3%\n",
            "Step: 4833 ------------ Loss: 4462.12 ------------ Accuracy: 86.3%\n",
            "Step: 4834 ------------ Loss: 4461.55 ------------ Accuracy: 86.3%\n",
            "Step: 4835 ------------ Loss: 4461.33 ------------ Accuracy: 86.3%\n",
            "Step: 4836 ------------ Loss: 4461.15 ------------ Accuracy: 86.3%\n",
            "Step: 4837 ------------ Loss: 4460.77 ------------ Accuracy: 86.3%\n",
            "Step: 4838 ------------ Loss: 4460.39 ------------ Accuracy: 86.3%\n",
            "Step: 4839 ------------ Loss: 4460.02 ------------ Accuracy: 86.3%\n",
            "Step: 4840 ------------ Loss: 4459.7 ------------ Accuracy: 86.3%\n",
            "Step: 4841 ------------ Loss: 4459.67 ------------ Accuracy: 86.3%\n",
            "Step: 4842 ------------ Loss: 4459.31 ------------ Accuracy: 86.3%\n",
            "Step: 4843 ------------ Loss: 4458.95 ------------ Accuracy: 86.3%\n",
            "Step: 4844 ------------ Loss: 4458.57 ------------ Accuracy: 86.3%\n",
            "Step: 4845 ------------ Loss: 4457.72 ------------ Accuracy: 86.2%\n",
            "Step: 4846 ------------ Loss: 4457.69 ------------ Accuracy: 86.3%\n",
            "Step: 4847 ------------ Loss: 4457.33 ------------ Accuracy: 86.3%\n",
            "Step: 4848 ------------ Loss: 4456.98 ------------ Accuracy: 86.3%\n",
            "Step: 4849 ------------ Loss: 4456.57 ------------ Accuracy: 86.3%\n",
            "Step: 4850 ------------ Loss: 4456.35 ------------ Accuracy: 86.3%\n",
            "Step: 4851 ------------ Loss: 4455.98 ------------ Accuracy: 86.3%\n",
            "Step: 4852 ------------ Loss: 4455.4 ------------ Accuracy: 86.3%\n",
            "Step: 4853 ------------ Loss: 4454.92 ------------ Accuracy: 86.3%\n",
            "Step: 4854 ------------ Loss: 4454.36 ------------ Accuracy: 86.3%\n",
            "Step: 4855 ------------ Loss: 4454.14 ------------ Accuracy: 86.3%\n",
            "Step: 4856 ------------ Loss: 4453.77 ------------ Accuracy: 86.3%\n",
            "Step: 4857 ------------ Loss: 4453.4 ------------ Accuracy: 86.3%\n",
            "Step: 4858 ------------ Loss: 4453.04 ------------ Accuracy: 86.4%\n",
            "Step: 4859 ------------ Loss: 4452.66 ------------ Accuracy: 86.3%\n",
            "Step: 4860 ------------ Loss: 4452.44 ------------ Accuracy: 86.3%\n",
            "Step: 4861 ------------ Loss: 4452.09 ------------ Accuracy: 86.3%\n",
            "Step: 4862 ------------ Loss: 4451.77 ------------ Accuracy: 86.4%\n",
            "Step: 4863 ------------ Loss: 4451.69 ------------ Accuracy: 86.3%\n",
            "Step: 4864 ------------ Loss: 4451.32 ------------ Accuracy: 86.3%\n",
            "Step: 4865 ------------ Loss: 4451.25 ------------ Accuracy: 86.3%\n",
            "Step: 4866 ------------ Loss: 4450.88 ------------ Accuracy: 86.4%\n",
            "Step: 4867 ------------ Loss: 4450.02 ------------ Accuracy: 86.3%\n",
            "Step: 4868 ------------ Loss: 4449.65 ------------ Accuracy: 86.3%\n",
            "Step: 4869 ------------ Loss: 4449.29 ------------ Accuracy: 86.3%\n",
            "Step: 4870 ------------ Loss: 4449.22 ------------ Accuracy: 86.3%\n",
            "Step: 4871 ------------ Loss: 4448.86 ------------ Accuracy: 86.3%\n",
            "Step: 4872 ------------ Loss: 4448.47 ------------ Accuracy: 86.3%\n",
            "Step: 4873 ------------ Loss: 4448.09 ------------ Accuracy: 86.4%\n",
            "Step: 4874 ------------ Loss: 4447.88 ------------ Accuracy: 86.4%\n",
            "Step: 4875 ------------ Loss: 4447.51 ------------ Accuracy: 86.4%\n",
            "Step: 4876 ------------ Loss: 4447.45 ------------ Accuracy: 86.4%\n",
            "Step: 4877 ------------ Loss: 4447.24 ------------ Accuracy: 86.4%\n",
            "Step: 4878 ------------ Loss: 4446.87 ------------ Accuracy: 86.4%\n",
            "Step: 4879 ------------ Loss: 4446.55 ------------ Accuracy: 86.4%\n",
            "Step: 4880 ------------ Loss: 4446.17 ------------ Accuracy: 86.4%\n",
            "Step: 4881 ------------ Loss: 4445.82 ------------ Accuracy: 86.4%\n",
            "Step: 4882 ------------ Loss: 4444.96 ------------ Accuracy: 86.3%\n",
            "Step: 4883 ------------ Loss: 4444.13 ------------ Accuracy: 86.3%\n",
            "Step: 4884 ------------ Loss: 4443.76 ------------ Accuracy: 86.3%\n",
            "Step: 4885 ------------ Loss: 4443.4 ------------ Accuracy: 86.3%\n",
            "Step: 4886 ------------ Loss: 4443.04 ------------ Accuracy: 86.3%\n",
            "Step: 4887 ------------ Loss: 4443.01 ------------ Accuracy: 86.3%\n",
            "Step: 4888 ------------ Loss: 4442.65 ------------ Accuracy: 86.3%\n",
            "Step: 4889 ------------ Loss: 4442.28 ------------ Accuracy: 86.3%\n",
            "Step: 4890 ------------ Loss: 4441.92 ------------ Accuracy: 86.3%\n",
            "Step: 4891 ------------ Loss: 4441.75 ------------ Accuracy: 86.3%\n",
            "Step: 4892 ------------ Loss: 4441.4 ------------ Accuracy: 86.3%\n",
            "Step: 4893 ------------ Loss: 4441.03 ------------ Accuracy: 86.4%\n",
            "Step: 4894 ------------ Loss: 4440.44 ------------ Accuracy: 86.4%\n",
            "Step: 4895 ------------ Loss: 4440.1 ------------ Accuracy: 86.4%\n",
            "Step: 4896 ------------ Loss: 4439.73 ------------ Accuracy: 86.4%\n",
            "Step: 4897 ------------ Loss: 4439.37 ------------ Accuracy: 86.4%\n",
            "Step: 4898 ------------ Loss: 4439.02 ------------ Accuracy: 86.4%\n",
            "Step: 4899 ------------ Loss: 4438.61 ------------ Accuracy: 86.4%\n",
            "Step: 4900 ------------ Loss: 4438.25 ------------ Accuracy: 86.4%\n",
            "Step: 4901 ------------ Loss: 4437.67 ------------ Accuracy: 86.4%\n",
            "Step: 4902 ------------ Loss: 4437.33 ------------ Accuracy: 86.4%\n",
            "Step: 4903 ------------ Loss: 4436.94 ------------ Accuracy: 86.3%\n",
            "Step: 4904 ------------ Loss: 4436.36 ------------ Accuracy: 86.3%\n",
            "Step: 4905 ------------ Loss: 4435.79 ------------ Accuracy: 86.3%\n",
            "Step: 4906 ------------ Loss: 4435.58 ------------ Accuracy: 86.3%\n",
            "Step: 4907 ------------ Loss: 4435.39 ------------ Accuracy: 86.3%\n",
            "Step: 4908 ------------ Loss: 4435.23 ------------ Accuracy: 86.3%\n",
            "Step: 4909 ------------ Loss: 4434.66 ------------ Accuracy: 86.3%\n",
            "Step: 4910 ------------ Loss: 4434.11 ------------ Accuracy: 86.3%\n",
            "Step: 4911 ------------ Loss: 4433.75 ------------ Accuracy: 86.3%\n",
            "Step: 4912 ------------ Loss: 4433.43 ------------ Accuracy: 86.3%\n",
            "Step: 4913 ------------ Loss: 4433.07 ------------ Accuracy: 86.3%\n",
            "Step: 4914 ------------ Loss: 4432.71 ------------ Accuracy: 86.3%\n",
            "Step: 4915 ------------ Loss: 4432.37 ------------ Accuracy: 86.3%\n",
            "Step: 4916 ------------ Loss: 4432.04 ------------ Accuracy: 86.4%\n",
            "Step: 4917 ------------ Loss: 4431.71 ------------ Accuracy: 86.4%\n",
            "Step: 4918 ------------ Loss: 4431.21 ------------ Accuracy: 86.3%\n",
            "Step: 4919 ------------ Loss: 4430.39 ------------ Accuracy: 86.3%\n",
            "Step: 4920 ------------ Loss: 4430.03 ------------ Accuracy: 86.3%\n",
            "Step: 4921 ------------ Loss: 4429.68 ------------ Accuracy: 86.3%\n",
            "Step: 4922 ------------ Loss: 4429.47 ------------ Accuracy: 86.4%\n",
            "Step: 4923 ------------ Loss: 4429.31 ------------ Accuracy: 86.4%\n",
            "Step: 4924 ------------ Loss: 4429.27 ------------ Accuracy: 86.4%\n",
            "Step: 4925 ------------ Loss: 4428.92 ------------ Accuracy: 86.4%\n",
            "Step: 4926 ------------ Loss: 4428.45 ------------ Accuracy: 86.4%\n",
            "Step: 4927 ------------ Loss: 4428.11 ------------ Accuracy: 86.4%\n",
            "Step: 4928 ------------ Loss: 4428.07 ------------ Accuracy: 86.4%\n",
            "Step: 4929 ------------ Loss: 4427.86 ------------ Accuracy: 86.4%\n",
            "Step: 4930 ------------ Loss: 4427.65 ------------ Accuracy: 86.4%\n",
            "Step: 4931 ------------ Loss: 4427.33 ------------ Accuracy: 86.4%\n",
            "Step: 4932 ------------ Loss: 4426.97 ------------ Accuracy: 86.4%\n",
            "Step: 4933 ------------ Loss: 4426.62 ------------ Accuracy: 86.4%\n",
            "Step: 4934 ------------ Loss: 4426.54 ------------ Accuracy: 86.4%\n",
            "Step: 4935 ------------ Loss: 4426.17 ------------ Accuracy: 86.5%\n",
            "Step: 4936 ------------ Loss: 4425.8 ------------ Accuracy: 86.5%\n",
            "Step: 4937 ------------ Loss: 4425.59 ------------ Accuracy: 86.5%\n",
            "Step: 4938 ------------ Loss: 4425.03 ------------ Accuracy: 86.5%\n",
            "Step: 4939 ------------ Loss: 4424.69 ------------ Accuracy: 86.5%\n",
            "Step: 4940 ------------ Loss: 4423.86 ------------ Accuracy: 86.4%\n",
            "Step: 4941 ------------ Loss: 4423.32 ------------ Accuracy: 86.4%\n",
            "Step: 4942 ------------ Loss: 4422.91 ------------ Accuracy: 86.4%\n",
            "Step: 4943 ------------ Loss: 4422.55 ------------ Accuracy: 86.4%\n",
            "Step: 4944 ------------ Loss: 4422.48 ------------ Accuracy: 86.4%\n",
            "Step: 4945 ------------ Loss: 4422.31 ------------ Accuracy: 86.4%\n",
            "Step: 4946 ------------ Loss: 4421.93 ------------ Accuracy: 86.4%\n",
            "Step: 4947 ------------ Loss: 4421.59 ------------ Accuracy: 86.4%\n",
            "Step: 4948 ------------ Loss: 4421.25 ------------ Accuracy: 86.4%\n",
            "Step: 4949 ------------ Loss: 4420.71 ------------ Accuracy: 86.4%\n",
            "Step: 4950 ------------ Loss: 4420.64 ------------ Accuracy: 86.4%\n",
            "Step: 4951 ------------ Loss: 4420.19 ------------ Accuracy: 86.4%\n",
            "Step: 4952 ------------ Loss: 4419.82 ------------ Accuracy: 86.4%\n",
            "Step: 4953 ------------ Loss: 4419.46 ------------ Accuracy: 86.4%\n",
            "Step: 4954 ------------ Loss: 4419.14 ------------ Accuracy: 86.4%\n",
            "Step: 4955 ------------ Loss: 4418.79 ------------ Accuracy: 86.4%\n",
            "Step: 4956 ------------ Loss: 4418.43 ------------ Accuracy: 86.4%\n",
            "Step: 4957 ------------ Loss: 4418.39 ------------ Accuracy: 86.4%\n",
            "Step: 4958 ------------ Loss: 4418.24 ------------ Accuracy: 86.4%\n",
            "Step: 4959 ------------ Loss: 4418.09 ------------ Accuracy: 86.4%\n",
            "Step: 4960 ------------ Loss: 4417.77 ------------ Accuracy: 86.5%\n",
            "Step: 4961 ------------ Loss: 4417.35 ------------ Accuracy: 86.4%\n",
            "Step: 4962 ------------ Loss: 4416.9 ------------ Accuracy: 86.4%\n",
            "Step: 4963 ------------ Loss: 4416.53 ------------ Accuracy: 86.5%\n",
            "Step: 4964 ------------ Loss: 4416.09 ------------ Accuracy: 86.4%\n",
            "Step: 4965 ------------ Loss: 4415.68 ------------ Accuracy: 86.5%\n",
            "Step: 4966 ------------ Loss: 4415.53 ------------ Accuracy: 86.5%\n",
            "Step: 4967 ------------ Loss: 4415.17 ------------ Accuracy: 86.5%\n",
            "Step: 4968 ------------ Loss: 4414.82 ------------ Accuracy: 86.5%\n",
            "Step: 4969 ------------ Loss: 4414.59 ------------ Accuracy: 86.5%\n",
            "Step: 4970 ------------ Loss: 4414.37 ------------ Accuracy: 86.5%\n",
            "Step: 4971 ------------ Loss: 4414.05 ------------ Accuracy: 86.5%\n",
            "Step: 4972 ------------ Loss: 4413.92 ------------ Accuracy: 86.5%\n",
            "Step: 4973 ------------ Loss: 4413.38 ------------ Accuracy: 86.5%\n",
            "Step: 4974 ------------ Loss: 4413.03 ------------ Accuracy: 86.5%\n",
            "Step: 4975 ------------ Loss: 4412.67 ------------ Accuracy: 86.5%\n",
            "Step: 4976 ------------ Loss: 4412.6 ------------ Accuracy: 86.6%\n",
            "Step: 4977 ------------ Loss: 4412.23 ------------ Accuracy: 86.6%\n",
            "Step: 4978 ------------ Loss: 4411.85 ------------ Accuracy: 86.5%\n",
            "Step: 4979 ------------ Loss: 4411.51 ------------ Accuracy: 86.5%\n",
            "Step: 4980 ------------ Loss: 4411.3 ------------ Accuracy: 86.5%\n",
            "Step: 4981 ------------ Loss: 4410.87 ------------ Accuracy: 86.6%\n",
            "Step: 4982 ------------ Loss: 4410.52 ------------ Accuracy: 86.6%\n",
            "Step: 4983 ------------ Loss: 4410.09 ------------ Accuracy: 86.6%\n",
            "Step: 4984 ------------ Loss: 4409.67 ------------ Accuracy: 86.6%\n",
            "Step: 4985 ------------ Loss: 4409.53 ------------ Accuracy: 86.6%\n",
            "Step: 4986 ------------ Loss: 4409.16 ------------ Accuracy: 86.6%\n",
            "Step: 4987 ------------ Loss: 4408.84 ------------ Accuracy: 86.6%\n",
            "Step: 4988 ------------ Loss: 4408.71 ------------ Accuracy: 86.6%\n",
            "Step: 4989 ------------ Loss: 4408.36 ------------ Accuracy: 86.6%\n",
            "Step: 4990 ------------ Loss: 4408.04 ------------ Accuracy: 86.6%\n",
            "Step: 4991 ------------ Loss: 4407.23 ------------ Accuracy: 86.5%\n",
            "Step: 4992 ------------ Loss: 4406.86 ------------ Accuracy: 86.5%\n",
            "Step: 4993 ------------ Loss: 4406.64 ------------ Accuracy: 86.5%\n",
            "Step: 4994 ------------ Loss: 4406.6 ------------ Accuracy: 86.5%\n",
            "Step: 4995 ------------ Loss: 4406.25 ------------ Accuracy: 86.6%\n",
            "Step: 4996 ------------ Loss: 4405.45 ------------ Accuracy: 86.5%\n",
            "Step: 4997 ------------ Loss: 4405.1 ------------ Accuracy: 86.5%\n",
            "Step: 4998 ------------ Loss: 4404.73 ------------ Accuracy: 86.5%\n",
            "Step: 4999 ------------ Loss: 4404.36 ------------ Accuracy: 86.5%\n",
            "Step: 5000 ------------ Loss: 4404.28 ------------ Accuracy: 86.5%\n",
            "\n",
            " Time taken: 1446.33 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "# fit model\n",
        "model.fit(X_train, Y_train, type=\"BCGD_R\", alpha=0.0001, max_iter=5000, threshold=100)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"\\n Time taken: {np.round(end_time - start_time,2)} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pyS8vJVhpTQn",
        "outputId": "f2799786-6de0-45e2-a706-6224e273d340"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Produce plots\n",
        "args = [\"Loss\", \"Accuracy\", \"CPU\"]\n",
        "for a in args: model.plot(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "02Ilumg4pTck",
        "outputId": "864813e8-6bd0-42cb-f8f6-8a6d42dcfa9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score on test set: 87.15\n"
          ]
        }
      ],
      "source": [
        "# check accuracy on test set\n",
        "print(f\"Accuracy score on test set: {np.round(np.sum(model.predict(X_test) == Y_test) / X_test.shape[0] * 100,2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ua1D6_xKv1ah"
      },
      "outputs": [],
      "source": [
        "# save the data for later comparison\n",
        "df_random = model.backup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJBEsMFoqpiR"
      },
      "source": [
        "## 4) BCGD GS Rule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XniD9wWpqpZw"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "# fit model\n",
        "model.fit(X_train, Y_train, type=\"BCGD_GS\", alpha=0.0001, max_iter=5000, threshold=100)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"\\n Time taken: {np.round(end_time - start_time,2)} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xUdyDcIrqqkp",
        "outputId": "9c7f4675-1c53-4f23-ff05-8cbeac95bd59"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Produce plots\n",
        "args = [\"Loss\", \"Accuracy\", \"CPU\"]\n",
        "for a in args: model.plot(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XwuZupEmqrBw",
        "outputId": "db55d6b2-6a55-442e-da3d-ffbaee75f61c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score on test set: 88.56\n"
          ]
        }
      ],
      "source": [
        "# check accuracy on test set\n",
        "print(f\"Accuracy score on test set: {np.round(np.sum(model.predict(X_test) == Y_test) / X_test.shape[0] * 100,2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mxHHyYPzv3rJ"
      },
      "outputs": [],
      "source": [
        "# save the data for later comparison\n",
        "df_gs = model.backup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgjJkenNvkav"
      },
      "source": [
        "## 5) Final Comparision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A76a5b9KvjQV"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.plot(df_gd['step'], df_gd['loss'], label='Classic GD')\n",
        "plt.plot(df_random['step'], df_random['loss'], label='BCGD Randomized')\n",
        "plt.plot(df_gs['step'], df_gs['loss'], label='BCGD GS')\n",
        "\n",
        "plt.title('Loss comparison ')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3aljH36PyE9"
      },
      "source": [
        "# **2Â° Real Dataset**\n",
        "\n",
        "(https://www.kaggle.com/datasets/sayansh001/microbes-dataset)\n",
        "\n",
        "The dataset consists of 30,527 observations, each detailing 26 features related to microorganisms, which are to be classified into various microbe classes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my-QT4EOi4Ty"
      },
      "source": [
        "## 1) Data Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMPMvjMYPxle"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"microbes.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YD2HtxL8Zt5e"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Mg5MW4uahhq"
      },
      "outputs": [],
      "source": [
        "# shuffle rows to prevent imbalanced splitting\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df['microorganisms']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_1r9mMQahef"
      },
      "outputs": [],
      "source": [
        "# reduce the dataset size\n",
        "df = df[:20000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T45TVxpsaha5"
      },
      "outputs": [],
      "source": [
        "print(f\"Q: Do we have any missing value in the train set? A: {df.isna().any().any()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSeiGhbBahWo"
      },
      "outputs": [],
      "source": [
        "# drop first column since it's useless\n",
        "del df['Unnamed: 0']\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poCsfrqaahQ8"
      },
      "outputs": [],
      "source": [
        "# labels (#10)\n",
        "labels = df['microorganisms'].unique().tolist()\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UJmC1Lgaoxb"
      },
      "outputs": [],
      "source": [
        "# check if dataset is balanced\n",
        "df['microorganisms'].value_counts() # frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZNrxWwHaovF"
      },
      "outputs": [],
      "source": [
        "# make labels as numbers\n",
        "Y = df[\"microorganisms\"]\n",
        "\n",
        "# Step 1: Create a mapping of each unique word to a unique number\n",
        "word_to_number = {word: index for index, word in enumerate(labels)}\n",
        "\n",
        "# Step 2: Replace each word in the original list with its corresponding number\n",
        "Y_as_number = [word_to_number[word] for word in Y]\n",
        "\n",
        "Y = np.asarray(Y_as_number)\n",
        "print(Y[:12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJPNlvKFaos_"
      },
      "outputs": [],
      "source": [
        "word_to_number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QCU3XpCaoqh"
      },
      "outputs": [],
      "source": [
        "# takes al columns but last one (class)\n",
        "X = df.iloc[:, :-1]\n",
        "\n",
        "X.tail() #(8000, 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugIp9wcxaon_"
      },
      "outputs": [],
      "source": [
        "# min-max scaler to avoid overflow issues\n",
        "X = (X-X.min())/(X.max()-X.min())\n",
        "print(X.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtF587ufaolb"
      },
      "outputs": [],
      "source": [
        "# Split into train (80%) and test set (20%)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "     X, Y, test_size=0.20, random_state=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SP0jhk0VaxFr"
      },
      "outputs": [],
      "source": [
        "# convert dataset into numpy array\n",
        "X_train = X_train.to_numpy()\n",
        "X_test = X_test.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk9AbH_oiv5V"
      },
      "source": [
        "## 2) Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJRDcm4baxDH",
        "collapsed": true,
        "outputId": "30d7322d-a88c-48be-e89a-7cd5510df161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mOutput streaming troncato alle ultime 5000 righe.\u001b[0m\n",
            "Step: 3 ------------ Loss: 12149.13 ------------ Accuracy: 35.5%\n",
            "Step: 4 ------------ Loss: 12030.13 ------------ Accuracy: 41.1%\n",
            "Step: 5 ------------ Loss: 11919.06 ------------ Accuracy: 44.0%\n",
            "Step: 6 ------------ Loss: 11814.91 ------------ Accuracy: 47.3%\n",
            "Step: 7 ------------ Loss: 11716.99 ------------ Accuracy: 49.5%\n",
            "Step: 8 ------------ Loss: 11624.75 ------------ Accuracy: 50.5%\n",
            "Step: 9 ------------ Loss: 11537.7 ------------ Accuracy: 51.4%\n",
            "Step: 10 ------------ Loss: 11455.41 ------------ Accuracy: 52.1%\n",
            "Step: 11 ------------ Loss: 11377.49 ------------ Accuracy: 52.6%\n",
            "Step: 12 ------------ Loss: 11303.6 ------------ Accuracy: 52.6%\n",
            "Step: 13 ------------ Loss: 11233.44 ------------ Accuracy: 52.7%\n",
            "Step: 14 ------------ Loss: 11166.71 ------------ Accuracy: 53.0%\n",
            "Step: 15 ------------ Loss: 11103.16 ------------ Accuracy: 52.9%\n",
            "Step: 16 ------------ Loss: 11042.57 ------------ Accuracy: 53.1%\n",
            "Step: 17 ------------ Loss: 10984.74 ------------ Accuracy: 53.1%\n",
            "Step: 18 ------------ Loss: 10929.46 ------------ Accuracy: 53.2%\n",
            "Step: 19 ------------ Loss: 10876.57 ------------ Accuracy: 53.5%\n",
            "Step: 20 ------------ Loss: 10825.91 ------------ Accuracy: 53.7%\n",
            "Step: 21 ------------ Loss: 10777.34 ------------ Accuracy: 53.5%\n",
            "Step: 22 ------------ Loss: 10730.72 ------------ Accuracy: 53.5%\n",
            "Step: 23 ------------ Loss: 10685.94 ------------ Accuracy: 53.5%\n",
            "Step: 24 ------------ Loss: 10642.89 ------------ Accuracy: 53.5%\n",
            "Step: 25 ------------ Loss: 10601.45 ------------ Accuracy: 53.6%\n",
            "Step: 26 ------------ Loss: 10561.55 ------------ Accuracy: 53.6%\n",
            "Step: 27 ------------ Loss: 10523.08 ------------ Accuracy: 53.6%\n",
            "Step: 28 ------------ Loss: 10485.97 ------------ Accuracy: 53.5%\n",
            "Step: 29 ------------ Loss: 10450.15 ------------ Accuracy: 53.5%\n",
            "Step: 30 ------------ Loss: 10415.54 ------------ Accuracy: 53.7%\n",
            "Step: 31 ------------ Loss: 10382.08 ------------ Accuracy: 53.9%\n",
            "Step: 32 ------------ Loss: 10349.71 ------------ Accuracy: 53.9%\n",
            "Step: 33 ------------ Loss: 10318.37 ------------ Accuracy: 54.0%\n",
            "Step: 34 ------------ Loss: 10288.02 ------------ Accuracy: 54.0%\n",
            "Step: 35 ------------ Loss: 10258.6 ------------ Accuracy: 54.2%\n",
            "Step: 36 ------------ Loss: 10230.07 ------------ Accuracy: 54.4%\n",
            "Step: 37 ------------ Loss: 10202.38 ------------ Accuracy: 54.3%\n",
            "Step: 38 ------------ Loss: 10175.5 ------------ Accuracy: 54.3%\n",
            "Step: 39 ------------ Loss: 10149.38 ------------ Accuracy: 54.3%\n",
            "Step: 40 ------------ Loss: 10124.0 ------------ Accuracy: 54.3%\n",
            "Step: 41 ------------ Loss: 10099.31 ------------ Accuracy: 54.3%\n",
            "Step: 42 ------------ Loss: 10075.3 ------------ Accuracy: 54.4%\n",
            "Step: 43 ------------ Loss: 10051.92 ------------ Accuracy: 54.5%\n",
            "Step: 44 ------------ Loss: 10029.15 ------------ Accuracy: 54.5%\n",
            "Step: 45 ------------ Loss: 10006.97 ------------ Accuracy: 54.5%\n",
            "Step: 46 ------------ Loss: 9985.35 ------------ Accuracy: 54.5%\n",
            "Step: 47 ------------ Loss: 9964.27 ------------ Accuracy: 54.5%\n",
            "Step: 48 ------------ Loss: 9943.7 ------------ Accuracy: 54.5%\n",
            "Step: 49 ------------ Loss: 9923.62 ------------ Accuracy: 54.5%\n",
            "Step: 50 ------------ Loss: 9904.03 ------------ Accuracy: 54.6%\n",
            "Step: 51 ------------ Loss: 9884.89 ------------ Accuracy: 54.6%\n",
            "Step: 52 ------------ Loss: 9866.18 ------------ Accuracy: 54.6%\n",
            "Step: 53 ------------ Loss: 9847.91 ------------ Accuracy: 54.6%\n",
            "Step: 54 ------------ Loss: 9830.03 ------------ Accuracy: 54.8%\n",
            "Step: 55 ------------ Loss: 9812.55 ------------ Accuracy: 54.8%\n",
            "Step: 56 ------------ Loss: 9795.45 ------------ Accuracy: 54.7%\n",
            "Step: 57 ------------ Loss: 9778.71 ------------ Accuracy: 54.7%\n",
            "Step: 58 ------------ Loss: 9762.32 ------------ Accuracy: 54.7%\n",
            "Step: 59 ------------ Loss: 9746.27 ------------ Accuracy: 54.7%\n",
            "Step: 60 ------------ Loss: 9730.54 ------------ Accuracy: 54.7%\n",
            "Step: 61 ------------ Loss: 9715.13 ------------ Accuracy: 54.7%\n",
            "Step: 62 ------------ Loss: 9700.03 ------------ Accuracy: 54.9%\n",
            "Step: 63 ------------ Loss: 9685.21 ------------ Accuracy: 54.9%\n",
            "Step: 64 ------------ Loss: 9670.69 ------------ Accuracy: 55.0%\n",
            "Step: 65 ------------ Loss: 9656.44 ------------ Accuracy: 55.0%\n",
            "Step: 66 ------------ Loss: 9642.45 ------------ Accuracy: 55.0%\n",
            "Step: 67 ------------ Loss: 9628.72 ------------ Accuracy: 55.1%\n",
            "Step: 68 ------------ Loss: 9615.25 ------------ Accuracy: 55.1%\n",
            "Step: 69 ------------ Loss: 9602.01 ------------ Accuracy: 55.1%\n",
            "Step: 70 ------------ Loss: 9589.01 ------------ Accuracy: 55.1%\n",
            "Step: 71 ------------ Loss: 9576.24 ------------ Accuracy: 55.1%\n",
            "Step: 72 ------------ Loss: 9563.68 ------------ Accuracy: 55.0%\n",
            "Step: 73 ------------ Loss: 9551.34 ------------ Accuracy: 55.0%\n",
            "Step: 74 ------------ Loss: 9539.21 ------------ Accuracy: 55.1%\n",
            "Step: 75 ------------ Loss: 9527.28 ------------ Accuracy: 55.1%\n",
            "Step: 76 ------------ Loss: 9515.54 ------------ Accuracy: 55.1%\n",
            "Step: 77 ------------ Loss: 9503.99 ------------ Accuracy: 55.1%\n",
            "Step: 78 ------------ Loss: 9492.63 ------------ Accuracy: 55.3%\n",
            "Step: 79 ------------ Loss: 9481.45 ------------ Accuracy: 55.3%\n",
            "Step: 80 ------------ Loss: 9470.44 ------------ Accuracy: 55.3%\n",
            "Step: 81 ------------ Loss: 9459.6 ------------ Accuracy: 55.3%\n",
            "Step: 82 ------------ Loss: 9448.93 ------------ Accuracy: 55.3%\n",
            "Step: 83 ------------ Loss: 9438.42 ------------ Accuracy: 55.3%\n",
            "Step: 84 ------------ Loss: 9428.06 ------------ Accuracy: 55.4%\n",
            "Step: 85 ------------ Loss: 9417.85 ------------ Accuracy: 55.4%\n",
            "Step: 86 ------------ Loss: 9407.8 ------------ Accuracy: 55.3%\n",
            "Step: 87 ------------ Loss: 9397.88 ------------ Accuracy: 55.3%\n",
            "Step: 88 ------------ Loss: 9388.11 ------------ Accuracy: 55.3%\n",
            "Step: 89 ------------ Loss: 9378.47 ------------ Accuracy: 55.3%\n",
            "Step: 90 ------------ Loss: 9368.97 ------------ Accuracy: 55.3%\n",
            "Step: 91 ------------ Loss: 9359.6 ------------ Accuracy: 55.3%\n",
            "Step: 92 ------------ Loss: 9350.35 ------------ Accuracy: 55.3%\n",
            "Step: 93 ------------ Loss: 9341.23 ------------ Accuracy: 55.4%\n",
            "Step: 94 ------------ Loss: 9332.23 ------------ Accuracy: 55.4%\n",
            "Step: 95 ------------ Loss: 9323.35 ------------ Accuracy: 55.4%\n",
            "Step: 96 ------------ Loss: 9314.58 ------------ Accuracy: 55.4%\n",
            "Step: 97 ------------ Loss: 9305.92 ------------ Accuracy: 55.4%\n",
            "Step: 98 ------------ Loss: 9297.38 ------------ Accuracy: 55.4%\n",
            "Step: 99 ------------ Loss: 9288.94 ------------ Accuracy: 55.5%\n",
            "Step: 100 ------------ Loss: 9280.61 ------------ Accuracy: 55.5%\n",
            "Step: 101 ------------ Loss: 9272.37 ------------ Accuracy: 55.5%\n",
            "Step: 102 ------------ Loss: 9264.24 ------------ Accuracy: 56.1%\n",
            "Step: 103 ------------ Loss: 9256.21 ------------ Accuracy: 56.1%\n",
            "Step: 104 ------------ Loss: 9248.27 ------------ Accuracy: 56.1%\n",
            "Step: 105 ------------ Loss: 9240.42 ------------ Accuracy: 56.0%\n",
            "Step: 106 ------------ Loss: 9232.67 ------------ Accuracy: 56.0%\n",
            "Step: 107 ------------ Loss: 9225.0 ------------ Accuracy: 56.1%\n",
            "Step: 108 ------------ Loss: 9217.43 ------------ Accuracy: 56.0%\n",
            "Step: 109 ------------ Loss: 9209.94 ------------ Accuracy: 56.1%\n",
            "Step: 110 ------------ Loss: 9202.53 ------------ Accuracy: 56.2%\n",
            "Step: 111 ------------ Loss: 9195.2 ------------ Accuracy: 56.2%\n",
            "Step: 112 ------------ Loss: 9187.96 ------------ Accuracy: 56.2%\n",
            "Step: 113 ------------ Loss: 9180.79 ------------ Accuracy: 56.2%\n",
            "Step: 114 ------------ Loss: 9173.7 ------------ Accuracy: 56.2%\n",
            "Step: 115 ------------ Loss: 9166.69 ------------ Accuracy: 56.2%\n",
            "Step: 116 ------------ Loss: 9159.75 ------------ Accuracy: 56.2%\n",
            "Step: 117 ------------ Loss: 9152.88 ------------ Accuracy: 56.3%\n",
            "Step: 118 ------------ Loss: 9146.09 ------------ Accuracy: 56.2%\n",
            "Step: 119 ------------ Loss: 9139.36 ------------ Accuracy: 56.3%\n",
            "Step: 120 ------------ Loss: 9132.7 ------------ Accuracy: 56.5%\n",
            "Step: 121 ------------ Loss: 9126.11 ------------ Accuracy: 56.5%\n",
            "Step: 122 ------------ Loss: 9119.58 ------------ Accuracy: 56.5%\n",
            "Step: 123 ------------ Loss: 9113.12 ------------ Accuracy: 56.5%\n",
            "Step: 124 ------------ Loss: 9106.73 ------------ Accuracy: 56.5%\n",
            "Step: 125 ------------ Loss: 9100.39 ------------ Accuracy: 56.6%\n",
            "Step: 126 ------------ Loss: 9094.12 ------------ Accuracy: 56.6%\n",
            "Step: 127 ------------ Loss: 9087.9 ------------ Accuracy: 56.6%\n",
            "Step: 128 ------------ Loss: 9081.74 ------------ Accuracy: 56.6%\n",
            "Step: 129 ------------ Loss: 9075.65 ------------ Accuracy: 56.7%\n",
            "Step: 130 ------------ Loss: 9069.6 ------------ Accuracy: 56.7%\n",
            "Step: 131 ------------ Loss: 9063.62 ------------ Accuracy: 56.7%\n",
            "Step: 132 ------------ Loss: 9057.69 ------------ Accuracy: 56.8%\n",
            "Step: 133 ------------ Loss: 9051.81 ------------ Accuracy: 56.8%\n",
            "Step: 134 ------------ Loss: 9045.98 ------------ Accuracy: 56.8%\n",
            "Step: 135 ------------ Loss: 9040.21 ------------ Accuracy: 56.9%\n",
            "Step: 136 ------------ Loss: 9034.49 ------------ Accuracy: 56.9%\n",
            "Step: 137 ------------ Loss: 9028.81 ------------ Accuracy: 57.0%\n",
            "Step: 138 ------------ Loss: 9023.19 ------------ Accuracy: 57.0%\n",
            "Step: 139 ------------ Loss: 9017.61 ------------ Accuracy: 57.2%\n",
            "Step: 140 ------------ Loss: 9012.09 ------------ Accuracy: 57.3%\n",
            "Step: 141 ------------ Loss: 9006.61 ------------ Accuracy: 57.3%\n",
            "Step: 142 ------------ Loss: 9001.17 ------------ Accuracy: 57.4%\n",
            "Step: 143 ------------ Loss: 8995.78 ------------ Accuracy: 57.3%\n",
            "Step: 144 ------------ Loss: 8990.43 ------------ Accuracy: 57.3%\n",
            "Step: 145 ------------ Loss: 8985.13 ------------ Accuracy: 57.3%\n",
            "Step: 146 ------------ Loss: 8979.87 ------------ Accuracy: 57.3%\n",
            "Step: 147 ------------ Loss: 8974.66 ------------ Accuracy: 57.3%\n",
            "Step: 148 ------------ Loss: 8969.48 ------------ Accuracy: 57.3%\n",
            "Step: 149 ------------ Loss: 8964.35 ------------ Accuracy: 57.3%\n",
            "Step: 150 ------------ Loss: 8959.25 ------------ Accuracy: 57.3%\n",
            "Step: 151 ------------ Loss: 8954.2 ------------ Accuracy: 57.3%\n",
            "Step: 152 ------------ Loss: 8949.19 ------------ Accuracy: 57.2%\n",
            "Step: 153 ------------ Loss: 8944.21 ------------ Accuracy: 57.2%\n",
            "Step: 154 ------------ Loss: 8939.27 ------------ Accuracy: 57.3%\n",
            "Step: 155 ------------ Loss: 8934.37 ------------ Accuracy: 57.4%\n",
            "Step: 156 ------------ Loss: 8929.51 ------------ Accuracy: 57.2%\n",
            "Step: 157 ------------ Loss: 8924.68 ------------ Accuracy: 57.3%\n",
            "Step: 158 ------------ Loss: 8919.89 ------------ Accuracy: 57.4%\n",
            "Step: 159 ------------ Loss: 8915.13 ------------ Accuracy: 57.5%\n",
            "Step: 160 ------------ Loss: 8910.41 ------------ Accuracy: 57.5%\n",
            "Step: 161 ------------ Loss: 8905.72 ------------ Accuracy: 57.5%\n",
            "Step: 162 ------------ Loss: 8901.06 ------------ Accuracy: 57.5%\n",
            "Step: 163 ------------ Loss: 8896.44 ------------ Accuracy: 57.6%\n",
            "Step: 164 ------------ Loss: 8891.85 ------------ Accuracy: 57.7%\n",
            "Step: 165 ------------ Loss: 8887.3 ------------ Accuracy: 57.7%\n",
            "Step: 166 ------------ Loss: 8882.77 ------------ Accuracy: 57.7%\n",
            "Step: 167 ------------ Loss: 8878.28 ------------ Accuracy: 57.7%\n",
            "Step: 168 ------------ Loss: 8873.81 ------------ Accuracy: 57.6%\n",
            "Step: 169 ------------ Loss: 8869.38 ------------ Accuracy: 57.5%\n",
            "Step: 170 ------------ Loss: 8864.98 ------------ Accuracy: 57.3%\n",
            "Step: 171 ------------ Loss: 8860.61 ------------ Accuracy: 57.4%\n",
            "Step: 172 ------------ Loss: 8856.26 ------------ Accuracy: 57.4%\n",
            "Step: 173 ------------ Loss: 8851.95 ------------ Accuracy: 57.4%\n",
            "Step: 174 ------------ Loss: 8847.66 ------------ Accuracy: 57.4%\n",
            "Step: 175 ------------ Loss: 8843.4 ------------ Accuracy: 57.4%\n",
            "Step: 176 ------------ Loss: 8839.17 ------------ Accuracy: 57.5%\n",
            "Step: 177 ------------ Loss: 8834.97 ------------ Accuracy: 57.5%\n",
            "Step: 178 ------------ Loss: 8830.79 ------------ Accuracy: 57.6%\n",
            "Step: 179 ------------ Loss: 8826.65 ------------ Accuracy: 57.6%\n",
            "Step: 180 ------------ Loss: 8822.52 ------------ Accuracy: 57.6%\n",
            "Step: 181 ------------ Loss: 8818.42 ------------ Accuracy: 57.6%\n",
            "Step: 182 ------------ Loss: 8814.35 ------------ Accuracy: 57.6%\n",
            "Step: 183 ------------ Loss: 8810.31 ------------ Accuracy: 57.6%\n",
            "Step: 184 ------------ Loss: 8806.28 ------------ Accuracy: 57.6%\n",
            "Step: 185 ------------ Loss: 8802.29 ------------ Accuracy: 57.8%\n",
            "Step: 186 ------------ Loss: 8798.32 ------------ Accuracy: 57.8%\n",
            "Step: 187 ------------ Loss: 8794.37 ------------ Accuracy: 57.9%\n",
            "Step: 188 ------------ Loss: 8790.44 ------------ Accuracy: 58.0%\n",
            "Step: 189 ------------ Loss: 8786.54 ------------ Accuracy: 58.0%\n",
            "Step: 190 ------------ Loss: 8782.66 ------------ Accuracy: 58.0%\n",
            "Step: 191 ------------ Loss: 8778.81 ------------ Accuracy: 58.0%\n",
            "Step: 192 ------------ Loss: 8774.97 ------------ Accuracy: 58.1%\n",
            "Step: 193 ------------ Loss: 8771.16 ------------ Accuracy: 58.1%\n",
            "Step: 194 ------------ Loss: 8767.37 ------------ Accuracy: 58.1%\n",
            "Step: 195 ------------ Loss: 8763.61 ------------ Accuracy: 57.9%\n",
            "Step: 196 ------------ Loss: 8759.86 ------------ Accuracy: 57.9%\n",
            "Step: 197 ------------ Loss: 8756.14 ------------ Accuracy: 57.8%\n",
            "Step: 198 ------------ Loss: 8752.43 ------------ Accuracy: 57.9%\n",
            "Step: 199 ------------ Loss: 8748.75 ------------ Accuracy: 57.9%\n",
            "Step: 200 ------------ Loss: 8745.09 ------------ Accuracy: 57.9%\n",
            "Step: 201 ------------ Loss: 8741.45 ------------ Accuracy: 57.9%\n",
            "Step: 202 ------------ Loss: 8737.83 ------------ Accuracy: 57.8%\n",
            "Step: 203 ------------ Loss: 8734.22 ------------ Accuracy: 57.9%\n",
            "Step: 204 ------------ Loss: 8730.64 ------------ Accuracy: 58.0%\n",
            "Step: 205 ------------ Loss: 8727.08 ------------ Accuracy: 58.0%\n",
            "Step: 206 ------------ Loss: 8723.54 ------------ Accuracy: 58.6%\n",
            "Step: 207 ------------ Loss: 8720.01 ------------ Accuracy: 58.6%\n",
            "Step: 208 ------------ Loss: 8716.51 ------------ Accuracy: 58.6%\n",
            "Step: 209 ------------ Loss: 8713.02 ------------ Accuracy: 58.7%\n",
            "Step: 210 ------------ Loss: 8709.55 ------------ Accuracy: 58.7%\n",
            "Step: 211 ------------ Loss: 8706.1 ------------ Accuracy: 58.7%\n",
            "Step: 212 ------------ Loss: 8702.66 ------------ Accuracy: 58.8%\n",
            "Step: 213 ------------ Loss: 8699.25 ------------ Accuracy: 58.8%\n",
            "Step: 214 ------------ Loss: 8695.85 ------------ Accuracy: 58.8%\n",
            "Step: 215 ------------ Loss: 8692.47 ------------ Accuracy: 58.8%\n",
            "Step: 216 ------------ Loss: 8689.11 ------------ Accuracy: 59.0%\n",
            "Step: 217 ------------ Loss: 8685.76 ------------ Accuracy: 59.0%\n",
            "Step: 218 ------------ Loss: 8682.43 ------------ Accuracy: 59.0%\n",
            "Step: 219 ------------ Loss: 8679.12 ------------ Accuracy: 59.1%\n",
            "Step: 220 ------------ Loss: 8675.82 ------------ Accuracy: 59.2%\n",
            "Step: 221 ------------ Loss: 8672.54 ------------ Accuracy: 59.2%\n",
            "Step: 222 ------------ Loss: 8669.28 ------------ Accuracy: 59.2%\n",
            "Step: 223 ------------ Loss: 8666.03 ------------ Accuracy: 59.2%\n",
            "Step: 224 ------------ Loss: 8662.8 ------------ Accuracy: 59.2%\n",
            "Step: 225 ------------ Loss: 8659.58 ------------ Accuracy: 59.2%\n",
            "Step: 226 ------------ Loss: 8656.38 ------------ Accuracy: 59.2%\n",
            "Step: 227 ------------ Loss: 8653.19 ------------ Accuracy: 59.2%\n",
            "Step: 228 ------------ Loss: 8650.02 ------------ Accuracy: 59.3%\n",
            "Step: 229 ------------ Loss: 8646.86 ------------ Accuracy: 59.3%\n",
            "Step: 230 ------------ Loss: 8643.72 ------------ Accuracy: 59.3%\n",
            "Step: 231 ------------ Loss: 8640.6 ------------ Accuracy: 59.3%\n",
            "Step: 232 ------------ Loss: 8637.48 ------------ Accuracy: 59.3%\n",
            "Step: 233 ------------ Loss: 8634.39 ------------ Accuracy: 59.4%\n",
            "Step: 234 ------------ Loss: 8631.3 ------------ Accuracy: 59.4%\n",
            "Step: 235 ------------ Loss: 8628.23 ------------ Accuracy: 59.4%\n",
            "Step: 236 ------------ Loss: 8625.18 ------------ Accuracy: 59.4%\n",
            "Step: 237 ------------ Loss: 8622.14 ------------ Accuracy: 59.4%\n",
            "Step: 238 ------------ Loss: 8619.11 ------------ Accuracy: 59.4%\n",
            "Step: 239 ------------ Loss: 8616.09 ------------ Accuracy: 60.0%\n",
            "Step: 240 ------------ Loss: 8613.09 ------------ Accuracy: 60.0%\n",
            "Step: 241 ------------ Loss: 8610.11 ------------ Accuracy: 60.0%\n",
            "Step: 242 ------------ Loss: 8607.13 ------------ Accuracy: 60.0%\n",
            "Step: 243 ------------ Loss: 8604.17 ------------ Accuracy: 59.9%\n",
            "Step: 244 ------------ Loss: 8601.22 ------------ Accuracy: 59.9%\n",
            "Step: 245 ------------ Loss: 8598.29 ------------ Accuracy: 59.8%\n",
            "Step: 246 ------------ Loss: 8595.36 ------------ Accuracy: 59.9%\n",
            "Step: 247 ------------ Loss: 8592.45 ------------ Accuracy: 59.7%\n",
            "Step: 248 ------------ Loss: 8589.56 ------------ Accuracy: 59.7%\n",
            "Step: 249 ------------ Loss: 8586.67 ------------ Accuracy: 59.6%\n",
            "Step: 250 ------------ Loss: 8583.8 ------------ Accuracy: 59.6%\n",
            "Step: 251 ------------ Loss: 8580.94 ------------ Accuracy: 59.6%\n",
            "Step: 252 ------------ Loss: 8578.09 ------------ Accuracy: 59.6%\n",
            "Step: 253 ------------ Loss: 8575.25 ------------ Accuracy: 59.6%\n",
            "Step: 254 ------------ Loss: 8572.42 ------------ Accuracy: 59.5%\n",
            "Step: 255 ------------ Loss: 8569.61 ------------ Accuracy: 59.7%\n",
            "Step: 256 ------------ Loss: 8566.81 ------------ Accuracy: 59.7%\n",
            "Step: 257 ------------ Loss: 8564.02 ------------ Accuracy: 59.7%\n",
            "Step: 258 ------------ Loss: 8561.24 ------------ Accuracy: 59.6%\n",
            "Step: 259 ------------ Loss: 8558.47 ------------ Accuracy: 59.6%\n",
            "Step: 260 ------------ Loss: 8555.72 ------------ Accuracy: 59.6%\n",
            "Step: 261 ------------ Loss: 8552.97 ------------ Accuracy: 59.6%\n",
            "Step: 262 ------------ Loss: 8550.23 ------------ Accuracy: 59.5%\n",
            "Step: 263 ------------ Loss: 8547.51 ------------ Accuracy: 59.4%\n",
            "Step: 264 ------------ Loss: 8544.8 ------------ Accuracy: 59.3%\n",
            "Step: 265 ------------ Loss: 8542.1 ------------ Accuracy: 59.3%\n",
            "Step: 266 ------------ Loss: 8539.4 ------------ Accuracy: 59.4%\n",
            "Step: 267 ------------ Loss: 8536.72 ------------ Accuracy: 59.4%\n",
            "Step: 268 ------------ Loss: 8534.05 ------------ Accuracy: 59.4%\n",
            "Step: 269 ------------ Loss: 8531.39 ------------ Accuracy: 59.4%\n",
            "Step: 270 ------------ Loss: 8528.74 ------------ Accuracy: 59.4%\n",
            "Step: 271 ------------ Loss: 8526.1 ------------ Accuracy: 59.4%\n",
            "Step: 272 ------------ Loss: 8523.47 ------------ Accuracy: 59.3%\n",
            "Step: 273 ------------ Loss: 8520.85 ------------ Accuracy: 59.3%\n",
            "Step: 274 ------------ Loss: 8518.24 ------------ Accuracy: 59.3%\n",
            "Step: 275 ------------ Loss: 8515.64 ------------ Accuracy: 59.3%\n",
            "Step: 276 ------------ Loss: 8513.05 ------------ Accuracy: 59.3%\n",
            "Step: 277 ------------ Loss: 8510.47 ------------ Accuracy: 59.3%\n",
            "Step: 278 ------------ Loss: 8507.9 ------------ Accuracy: 59.3%\n",
            "Step: 279 ------------ Loss: 8505.34 ------------ Accuracy: 59.4%\n",
            "Step: 280 ------------ Loss: 8502.79 ------------ Accuracy: 59.4%\n",
            "Step: 281 ------------ Loss: 8500.25 ------------ Accuracy: 59.4%\n",
            "Step: 282 ------------ Loss: 8497.71 ------------ Accuracy: 59.4%\n",
            "Step: 283 ------------ Loss: 8495.19 ------------ Accuracy: 59.5%\n",
            "Step: 284 ------------ Loss: 8492.67 ------------ Accuracy: 59.4%\n",
            "Step: 285 ------------ Loss: 8490.17 ------------ Accuracy: 59.4%\n",
            "Step: 286 ------------ Loss: 8487.67 ------------ Accuracy: 59.4%\n",
            "Step: 287 ------------ Loss: 8485.18 ------------ Accuracy: 59.4%\n",
            "Step: 288 ------------ Loss: 8482.7 ------------ Accuracy: 59.4%\n",
            "Step: 289 ------------ Loss: 8480.23 ------------ Accuracy: 59.4%\n",
            "Step: 290 ------------ Loss: 8477.77 ------------ Accuracy: 59.4%\n",
            "Step: 291 ------------ Loss: 8475.32 ------------ Accuracy: 59.5%\n",
            "Step: 292 ------------ Loss: 8472.88 ------------ Accuracy: 59.5%\n",
            "Step: 293 ------------ Loss: 8470.44 ------------ Accuracy: 59.5%\n",
            "Step: 294 ------------ Loss: 8468.01 ------------ Accuracy: 59.6%\n",
            "Step: 295 ------------ Loss: 8465.59 ------------ Accuracy: 59.6%\n",
            "Step: 296 ------------ Loss: 8463.18 ------------ Accuracy: 59.5%\n",
            "Step: 297 ------------ Loss: 8460.78 ------------ Accuracy: 59.6%\n",
            "Step: 298 ------------ Loss: 8458.39 ------------ Accuracy: 59.6%\n",
            "Step: 299 ------------ Loss: 8456.0 ------------ Accuracy: 59.7%\n",
            "Step: 300 ------------ Loss: 8453.62 ------------ Accuracy: 59.7%\n",
            "Step: 301 ------------ Loss: 8451.25 ------------ Accuracy: 59.7%\n",
            "Step: 302 ------------ Loss: 8448.89 ------------ Accuracy: 59.7%\n",
            "Step: 303 ------------ Loss: 8446.54 ------------ Accuracy: 59.7%\n",
            "Step: 304 ------------ Loss: 8444.19 ------------ Accuracy: 59.7%\n",
            "Step: 305 ------------ Loss: 8441.86 ------------ Accuracy: 59.7%\n",
            "Step: 306 ------------ Loss: 8439.52 ------------ Accuracy: 59.7%\n",
            "Step: 307 ------------ Loss: 8437.2 ------------ Accuracy: 59.7%\n",
            "Step: 308 ------------ Loss: 8434.89 ------------ Accuracy: 59.7%\n",
            "Step: 309 ------------ Loss: 8432.58 ------------ Accuracy: 59.7%\n",
            "Step: 310 ------------ Loss: 8430.28 ------------ Accuracy: 59.7%\n",
            "Step: 311 ------------ Loss: 8427.99 ------------ Accuracy: 59.8%\n",
            "Step: 312 ------------ Loss: 8425.7 ------------ Accuracy: 59.8%\n",
            "Step: 313 ------------ Loss: 8423.42 ------------ Accuracy: 59.8%\n",
            "Step: 314 ------------ Loss: 8421.15 ------------ Accuracy: 60.0%\n",
            "Step: 315 ------------ Loss: 8418.89 ------------ Accuracy: 60.0%\n",
            "Step: 316 ------------ Loss: 8416.63 ------------ Accuracy: 60.0%\n",
            "Step: 317 ------------ Loss: 8414.38 ------------ Accuracy: 60.0%\n",
            "Step: 318 ------------ Loss: 8412.14 ------------ Accuracy: 60.0%\n",
            "Step: 319 ------------ Loss: 8409.91 ------------ Accuracy: 59.9%\n",
            "Step: 320 ------------ Loss: 8407.68 ------------ Accuracy: 59.9%\n",
            "Step: 321 ------------ Loss: 8405.46 ------------ Accuracy: 59.9%\n",
            "Step: 322 ------------ Loss: 8403.25 ------------ Accuracy: 59.9%\n",
            "Step: 323 ------------ Loss: 8401.04 ------------ Accuracy: 59.9%\n",
            "Step: 324 ------------ Loss: 8398.84 ------------ Accuracy: 59.9%\n",
            "Step: 325 ------------ Loss: 8396.64 ------------ Accuracy: 60.0%\n",
            "Step: 326 ------------ Loss: 8394.46 ------------ Accuracy: 59.9%\n",
            "Step: 327 ------------ Loss: 8392.28 ------------ Accuracy: 59.8%\n",
            "Step: 328 ------------ Loss: 8390.1 ------------ Accuracy: 59.8%\n",
            "Step: 329 ------------ Loss: 8387.94 ------------ Accuracy: 59.8%\n",
            "Step: 330 ------------ Loss: 8385.78 ------------ Accuracy: 59.7%\n",
            "Step: 331 ------------ Loss: 8383.62 ------------ Accuracy: 59.7%\n",
            "Step: 332 ------------ Loss: 8381.48 ------------ Accuracy: 59.7%\n",
            "Step: 333 ------------ Loss: 8379.34 ------------ Accuracy: 59.7%\n",
            "Step: 334 ------------ Loss: 8377.2 ------------ Accuracy: 59.7%\n",
            "Step: 335 ------------ Loss: 8375.07 ------------ Accuracy: 59.8%\n",
            "Step: 336 ------------ Loss: 8372.95 ------------ Accuracy: 59.8%\n",
            "Step: 337 ------------ Loss: 8370.83 ------------ Accuracy: 59.8%\n",
            "Step: 338 ------------ Loss: 8368.73 ------------ Accuracy: 59.8%\n",
            "Step: 339 ------------ Loss: 8366.62 ------------ Accuracy: 59.8%\n",
            "Step: 340 ------------ Loss: 8364.52 ------------ Accuracy: 59.8%\n",
            "Step: 341 ------------ Loss: 8362.43 ------------ Accuracy: 59.8%\n",
            "Step: 342 ------------ Loss: 8360.35 ------------ Accuracy: 59.8%\n",
            "Step: 343 ------------ Loss: 8358.27 ------------ Accuracy: 59.8%\n",
            "Step: 344 ------------ Loss: 8356.2 ------------ Accuracy: 59.8%\n",
            "Step: 345 ------------ Loss: 8354.13 ------------ Accuracy: 59.8%\n",
            "Step: 346 ------------ Loss: 8352.07 ------------ Accuracy: 59.8%\n",
            "Step: 347 ------------ Loss: 8350.01 ------------ Accuracy: 59.8%\n",
            "Step: 348 ------------ Loss: 8347.96 ------------ Accuracy: 59.8%\n",
            "Step: 349 ------------ Loss: 8345.92 ------------ Accuracy: 59.8%\n",
            "Step: 350 ------------ Loss: 8343.88 ------------ Accuracy: 59.9%\n",
            "Step: 351 ------------ Loss: 8341.85 ------------ Accuracy: 59.9%\n",
            "Step: 352 ------------ Loss: 8339.82 ------------ Accuracy: 59.9%\n",
            "Step: 353 ------------ Loss: 8337.8 ------------ Accuracy: 59.9%\n",
            "Step: 354 ------------ Loss: 8335.79 ------------ Accuracy: 59.9%\n",
            "Step: 355 ------------ Loss: 8333.78 ------------ Accuracy: 59.9%\n",
            "Step: 356 ------------ Loss: 8331.77 ------------ Accuracy: 59.9%\n",
            "Step: 357 ------------ Loss: 8329.77 ------------ Accuracy: 59.9%\n",
            "Step: 358 ------------ Loss: 8327.78 ------------ Accuracy: 59.9%\n",
            "Step: 359 ------------ Loss: 8325.79 ------------ Accuracy: 60.0%\n",
            "Step: 360 ------------ Loss: 8323.81 ------------ Accuracy: 60.0%\n",
            "Step: 361 ------------ Loss: 8321.83 ------------ Accuracy: 60.0%\n",
            "Step: 362 ------------ Loss: 8319.86 ------------ Accuracy: 60.0%\n",
            "Step: 363 ------------ Loss: 8317.9 ------------ Accuracy: 60.0%\n",
            "Step: 364 ------------ Loss: 8315.93 ------------ Accuracy: 60.0%\n",
            "Step: 365 ------------ Loss: 8313.98 ------------ Accuracy: 60.0%\n",
            "Step: 366 ------------ Loss: 8312.03 ------------ Accuracy: 60.0%\n",
            "Step: 367 ------------ Loss: 8310.08 ------------ Accuracy: 60.0%\n",
            "Step: 368 ------------ Loss: 8308.14 ------------ Accuracy: 60.0%\n",
            "Step: 369 ------------ Loss: 8306.21 ------------ Accuracy: 60.0%\n",
            "Step: 370 ------------ Loss: 8304.28 ------------ Accuracy: 60.0%\n",
            "Step: 371 ------------ Loss: 8302.35 ------------ Accuracy: 60.0%\n",
            "Step: 372 ------------ Loss: 8300.43 ------------ Accuracy: 60.0%\n",
            "Step: 373 ------------ Loss: 8298.52 ------------ Accuracy: 60.1%\n",
            "Step: 374 ------------ Loss: 8296.61 ------------ Accuracy: 60.1%\n",
            "Step: 375 ------------ Loss: 8294.7 ------------ Accuracy: 60.1%\n",
            "Step: 376 ------------ Loss: 8292.8 ------------ Accuracy: 60.1%\n",
            "Step: 377 ------------ Loss: 8290.91 ------------ Accuracy: 60.1%\n",
            "Step: 378 ------------ Loss: 8289.02 ------------ Accuracy: 60.1%\n",
            "Step: 379 ------------ Loss: 8287.13 ------------ Accuracy: 60.1%\n",
            "Step: 380 ------------ Loss: 8285.25 ------------ Accuracy: 60.1%\n",
            "Step: 381 ------------ Loss: 8283.38 ------------ Accuracy: 60.1%\n",
            "Step: 382 ------------ Loss: 8281.51 ------------ Accuracy: 60.1%\n",
            "Step: 383 ------------ Loss: 8279.64 ------------ Accuracy: 60.3%\n",
            "Step: 384 ------------ Loss: 8277.78 ------------ Accuracy: 60.3%\n",
            "Step: 385 ------------ Loss: 8275.92 ------------ Accuracy: 60.3%\n",
            "Step: 386 ------------ Loss: 8274.07 ------------ Accuracy: 60.3%\n",
            "Step: 387 ------------ Loss: 8272.22 ------------ Accuracy: 60.3%\n",
            "Step: 388 ------------ Loss: 8270.38 ------------ Accuracy: 60.4%\n",
            "Step: 389 ------------ Loss: 8268.54 ------------ Accuracy: 60.4%\n",
            "Step: 390 ------------ Loss: 8266.71 ------------ Accuracy: 60.4%\n",
            "Step: 391 ------------ Loss: 8264.88 ------------ Accuracy: 60.4%\n",
            "Step: 392 ------------ Loss: 8263.05 ------------ Accuracy: 60.4%\n",
            "Step: 393 ------------ Loss: 8261.23 ------------ Accuracy: 60.4%\n",
            "Step: 394 ------------ Loss: 8259.42 ------------ Accuracy: 60.4%\n",
            "Step: 395 ------------ Loss: 8257.61 ------------ Accuracy: 60.4%\n",
            "Step: 396 ------------ Loss: 8255.8 ------------ Accuracy: 60.4%\n",
            "Step: 397 ------------ Loss: 8254.0 ------------ Accuracy: 60.4%\n",
            "Step: 398 ------------ Loss: 8252.2 ------------ Accuracy: 60.4%\n",
            "Step: 399 ------------ Loss: 8250.41 ------------ Accuracy: 60.4%\n",
            "Step: 400 ------------ Loss: 8248.62 ------------ Accuracy: 60.4%\n",
            "Step: 401 ------------ Loss: 8246.83 ------------ Accuracy: 60.4%\n",
            "Step: 402 ------------ Loss: 8245.05 ------------ Accuracy: 60.4%\n",
            "Step: 403 ------------ Loss: 8243.28 ------------ Accuracy: 60.3%\n",
            "Step: 404 ------------ Loss: 8241.5 ------------ Accuracy: 60.3%\n",
            "Step: 405 ------------ Loss: 8239.74 ------------ Accuracy: 60.3%\n",
            "Step: 406 ------------ Loss: 8237.97 ------------ Accuracy: 60.3%\n",
            "Step: 407 ------------ Loss: 8236.21 ------------ Accuracy: 60.3%\n",
            "Step: 408 ------------ Loss: 8234.46 ------------ Accuracy: 60.3%\n",
            "Step: 409 ------------ Loss: 8232.71 ------------ Accuracy: 60.3%\n",
            "Step: 410 ------------ Loss: 8230.96 ------------ Accuracy: 60.3%\n",
            "Step: 411 ------------ Loss: 8229.22 ------------ Accuracy: 60.3%\n",
            "Step: 412 ------------ Loss: 8227.48 ------------ Accuracy: 60.3%\n",
            "Step: 413 ------------ Loss: 8225.74 ------------ Accuracy: 60.3%\n",
            "Step: 414 ------------ Loss: 8224.01 ------------ Accuracy: 60.3%\n",
            "Step: 415 ------------ Loss: 8222.29 ------------ Accuracy: 60.3%\n",
            "Step: 416 ------------ Loss: 8220.56 ------------ Accuracy: 60.3%\n",
            "Step: 417 ------------ Loss: 8218.84 ------------ Accuracy: 60.3%\n",
            "Step: 418 ------------ Loss: 8217.13 ------------ Accuracy: 60.3%\n",
            "Step: 419 ------------ Loss: 8215.42 ------------ Accuracy: 60.3%\n",
            "Step: 420 ------------ Loss: 8213.71 ------------ Accuracy: 60.3%\n",
            "Step: 421 ------------ Loss: 8212.01 ------------ Accuracy: 60.3%\n",
            "Step: 422 ------------ Loss: 8210.31 ------------ Accuracy: 60.3%\n",
            "Step: 423 ------------ Loss: 8208.62 ------------ Accuracy: 60.3%\n",
            "Step: 424 ------------ Loss: 8206.92 ------------ Accuracy: 60.3%\n",
            "Step: 425 ------------ Loss: 8205.24 ------------ Accuracy: 60.3%\n",
            "Step: 426 ------------ Loss: 8203.55 ------------ Accuracy: 60.3%\n",
            "Step: 427 ------------ Loss: 8201.87 ------------ Accuracy: 60.3%\n",
            "Step: 428 ------------ Loss: 8200.2 ------------ Accuracy: 60.3%\n",
            "Step: 429 ------------ Loss: 8198.53 ------------ Accuracy: 60.3%\n",
            "Step: 430 ------------ Loss: 8196.86 ------------ Accuracy: 60.3%\n",
            "Step: 431 ------------ Loss: 8195.19 ------------ Accuracy: 60.4%\n",
            "Step: 432 ------------ Loss: 8193.53 ------------ Accuracy: 60.4%\n",
            "Step: 433 ------------ Loss: 8191.87 ------------ Accuracy: 60.4%\n",
            "Step: 434 ------------ Loss: 8190.22 ------------ Accuracy: 60.3%\n",
            "Step: 435 ------------ Loss: 8188.57 ------------ Accuracy: 60.3%\n",
            "Step: 436 ------------ Loss: 8186.92 ------------ Accuracy: 60.3%\n",
            "Step: 437 ------------ Loss: 8185.28 ------------ Accuracy: 60.3%\n",
            "Step: 438 ------------ Loss: 8183.64 ------------ Accuracy: 60.3%\n",
            "Step: 439 ------------ Loss: 8182.01 ------------ Accuracy: 60.3%\n",
            "Step: 440 ------------ Loss: 8180.37 ------------ Accuracy: 60.3%\n",
            "Step: 441 ------------ Loss: 8178.75 ------------ Accuracy: 60.3%\n",
            "Step: 442 ------------ Loss: 8177.12 ------------ Accuracy: 60.3%\n",
            "Step: 443 ------------ Loss: 8175.5 ------------ Accuracy: 60.3%\n",
            "Step: 444 ------------ Loss: 8173.88 ------------ Accuracy: 60.3%\n",
            "Step: 445 ------------ Loss: 8172.27 ------------ Accuracy: 60.3%\n",
            "Step: 446 ------------ Loss: 8170.66 ------------ Accuracy: 60.4%\n",
            "Step: 447 ------------ Loss: 8169.05 ------------ Accuracy: 60.4%\n",
            "Step: 448 ------------ Loss: 8167.45 ------------ Accuracy: 60.5%\n",
            "Step: 449 ------------ Loss: 8165.85 ------------ Accuracy: 60.5%\n",
            "Step: 450 ------------ Loss: 8164.25 ------------ Accuracy: 60.5%\n",
            "Step: 451 ------------ Loss: 8162.66 ------------ Accuracy: 60.4%\n",
            "Step: 452 ------------ Loss: 8161.07 ------------ Accuracy: 60.4%\n",
            "Step: 453 ------------ Loss: 8159.48 ------------ Accuracy: 60.4%\n",
            "Step: 454 ------------ Loss: 8157.9 ------------ Accuracy: 60.4%\n",
            "Step: 455 ------------ Loss: 8156.32 ------------ Accuracy: 60.4%\n",
            "Step: 456 ------------ Loss: 8154.74 ------------ Accuracy: 60.4%\n",
            "Step: 457 ------------ Loss: 8153.17 ------------ Accuracy: 60.3%\n",
            "Step: 458 ------------ Loss: 8151.6 ------------ Accuracy: 60.3%\n",
            "Step: 459 ------------ Loss: 8150.03 ------------ Accuracy: 60.2%\n",
            "Step: 460 ------------ Loss: 8148.47 ------------ Accuracy: 60.2%\n",
            "Step: 461 ------------ Loss: 8146.91 ------------ Accuracy: 60.2%\n",
            "Step: 462 ------------ Loss: 8145.35 ------------ Accuracy: 60.2%\n",
            "Step: 463 ------------ Loss: 8143.8 ------------ Accuracy: 60.2%\n",
            "Step: 464 ------------ Loss: 8142.25 ------------ Accuracy: 60.2%\n",
            "Step: 465 ------------ Loss: 8140.7 ------------ Accuracy: 60.2%\n",
            "Step: 466 ------------ Loss: 8139.16 ------------ Accuracy: 60.3%\n",
            "Step: 467 ------------ Loss: 8137.62 ------------ Accuracy: 60.3%\n",
            "Step: 468 ------------ Loss: 8136.08 ------------ Accuracy: 60.4%\n",
            "Step: 469 ------------ Loss: 8134.55 ------------ Accuracy: 60.4%\n",
            "Step: 470 ------------ Loss: 8133.01 ------------ Accuracy: 60.4%\n",
            "Step: 471 ------------ Loss: 8131.49 ------------ Accuracy: 60.4%\n",
            "Step: 472 ------------ Loss: 8129.96 ------------ Accuracy: 60.4%\n",
            "Step: 473 ------------ Loss: 8128.44 ------------ Accuracy: 60.4%\n",
            "Step: 474 ------------ Loss: 8126.92 ------------ Accuracy: 60.4%\n",
            "Step: 475 ------------ Loss: 8125.41 ------------ Accuracy: 60.4%\n",
            "Step: 476 ------------ Loss: 8123.89 ------------ Accuracy: 60.4%\n",
            "Step: 477 ------------ Loss: 8122.38 ------------ Accuracy: 60.4%\n",
            "Step: 478 ------------ Loss: 8120.88 ------------ Accuracy: 60.4%\n",
            "Step: 479 ------------ Loss: 8119.38 ------------ Accuracy: 60.4%\n",
            "Step: 480 ------------ Loss: 8117.88 ------------ Accuracy: 60.4%\n",
            "Step: 481 ------------ Loss: 8116.38 ------------ Accuracy: 60.4%\n",
            "Step: 482 ------------ Loss: 8114.88 ------------ Accuracy: 60.4%\n",
            "Step: 483 ------------ Loss: 8113.39 ------------ Accuracy: 60.5%\n",
            "Step: 484 ------------ Loss: 8111.91 ------------ Accuracy: 60.5%\n",
            "Step: 485 ------------ Loss: 8110.42 ------------ Accuracy: 60.5%\n",
            "Step: 486 ------------ Loss: 8108.94 ------------ Accuracy: 60.4%\n",
            "Step: 487 ------------ Loss: 8107.46 ------------ Accuracy: 60.4%\n",
            "Step: 488 ------------ Loss: 8105.98 ------------ Accuracy: 60.4%\n",
            "Step: 489 ------------ Loss: 8104.51 ------------ Accuracy: 60.4%\n",
            "Step: 490 ------------ Loss: 8103.04 ------------ Accuracy: 60.4%\n",
            "Step: 491 ------------ Loss: 8101.57 ------------ Accuracy: 60.5%\n",
            "Step: 492 ------------ Loss: 8100.11 ------------ Accuracy: 60.5%\n",
            "Step: 493 ------------ Loss: 8098.65 ------------ Accuracy: 60.5%\n",
            "Step: 494 ------------ Loss: 8097.19 ------------ Accuracy: 60.5%\n",
            "Step: 495 ------------ Loss: 8095.73 ------------ Accuracy: 61.1%\n",
            "Step: 496 ------------ Loss: 8094.28 ------------ Accuracy: 61.1%\n",
            "Step: 497 ------------ Loss: 8092.83 ------------ Accuracy: 61.1%\n",
            "Step: 498 ------------ Loss: 8091.38 ------------ Accuracy: 61.1%\n",
            "Step: 499 ------------ Loss: 8089.94 ------------ Accuracy: 61.1%\n",
            "Step: 500 ------------ Loss: 8088.5 ------------ Accuracy: 61.1%\n",
            "Step: 501 ------------ Loss: 8087.06 ------------ Accuracy: 61.1%\n",
            "Step: 502 ------------ Loss: 8085.62 ------------ Accuracy: 61.1%\n",
            "Step: 503 ------------ Loss: 8084.19 ------------ Accuracy: 61.1%\n",
            "Step: 504 ------------ Loss: 8082.76 ------------ Accuracy: 61.1%\n",
            "Step: 505 ------------ Loss: 8081.33 ------------ Accuracy: 61.1%\n",
            "Step: 506 ------------ Loss: 8079.91 ------------ Accuracy: 61.1%\n",
            "Step: 507 ------------ Loss: 8078.49 ------------ Accuracy: 61.1%\n",
            "Step: 508 ------------ Loss: 8077.07 ------------ Accuracy: 61.2%\n",
            "Step: 509 ------------ Loss: 8075.65 ------------ Accuracy: 61.2%\n",
            "Step: 510 ------------ Loss: 8074.24 ------------ Accuracy: 61.1%\n",
            "Step: 511 ------------ Loss: 8072.83 ------------ Accuracy: 61.1%\n",
            "Step: 512 ------------ Loss: 8071.42 ------------ Accuracy: 61.1%\n",
            "Step: 513 ------------ Loss: 8070.01 ------------ Accuracy: 61.1%\n",
            "Step: 514 ------------ Loss: 8068.61 ------------ Accuracy: 61.1%\n",
            "Step: 515 ------------ Loss: 8067.21 ------------ Accuracy: 61.1%\n",
            "Step: 516 ------------ Loss: 8065.81 ------------ Accuracy: 61.1%\n",
            "Step: 517 ------------ Loss: 8064.42 ------------ Accuracy: 61.1%\n",
            "Step: 518 ------------ Loss: 8063.02 ------------ Accuracy: 61.1%\n",
            "Step: 519 ------------ Loss: 8061.63 ------------ Accuracy: 61.1%\n",
            "Step: 520 ------------ Loss: 8060.25 ------------ Accuracy: 61.1%\n",
            "Step: 521 ------------ Loss: 8058.86 ------------ Accuracy: 61.1%\n",
            "Step: 522 ------------ Loss: 8057.48 ------------ Accuracy: 61.1%\n",
            "Step: 523 ------------ Loss: 8056.1 ------------ Accuracy: 61.1%\n",
            "Step: 524 ------------ Loss: 8054.73 ------------ Accuracy: 61.1%\n",
            "Step: 525 ------------ Loss: 8053.35 ------------ Accuracy: 61.3%\n",
            "Step: 526 ------------ Loss: 8051.98 ------------ Accuracy: 61.3%\n",
            "Step: 527 ------------ Loss: 8050.61 ------------ Accuracy: 61.3%\n",
            "Step: 528 ------------ Loss: 8049.25 ------------ Accuracy: 61.3%\n",
            "Step: 529 ------------ Loss: 8047.88 ------------ Accuracy: 61.3%\n",
            "Step: 530 ------------ Loss: 8046.52 ------------ Accuracy: 61.3%\n",
            "Step: 531 ------------ Loss: 8045.16 ------------ Accuracy: 61.3%\n",
            "Step: 532 ------------ Loss: 8043.81 ------------ Accuracy: 61.5%\n",
            "Step: 533 ------------ Loss: 8042.45 ------------ Accuracy: 61.5%\n",
            "Step: 534 ------------ Loss: 8041.1 ------------ Accuracy: 61.5%\n",
            "Step: 535 ------------ Loss: 8039.75 ------------ Accuracy: 61.6%\n",
            "Step: 536 ------------ Loss: 8038.41 ------------ Accuracy: 61.6%\n",
            "Step: 537 ------------ Loss: 8037.06 ------------ Accuracy: 61.6%\n",
            "Step: 538 ------------ Loss: 8035.72 ------------ Accuracy: 61.6%\n",
            "Step: 539 ------------ Loss: 8034.38 ------------ Accuracy: 61.7%\n",
            "Step: 540 ------------ Loss: 8033.05 ------------ Accuracy: 61.7%\n",
            "Step: 541 ------------ Loss: 8031.71 ------------ Accuracy: 61.7%\n",
            "Step: 542 ------------ Loss: 8030.38 ------------ Accuracy: 61.7%\n",
            "Step: 543 ------------ Loss: 8029.05 ------------ Accuracy: 61.7%\n",
            "Step: 544 ------------ Loss: 8027.73 ------------ Accuracy: 61.7%\n",
            "Step: 545 ------------ Loss: 8026.4 ------------ Accuracy: 61.7%\n",
            "Step: 546 ------------ Loss: 8025.08 ------------ Accuracy: 61.7%\n",
            "Step: 547 ------------ Loss: 8023.76 ------------ Accuracy: 61.7%\n",
            "Step: 548 ------------ Loss: 8022.45 ------------ Accuracy: 61.7%\n",
            "Step: 549 ------------ Loss: 8021.13 ------------ Accuracy: 61.7%\n",
            "Step: 550 ------------ Loss: 8019.82 ------------ Accuracy: 61.7%\n",
            "Step: 551 ------------ Loss: 8018.51 ------------ Accuracy: 61.6%\n",
            "Step: 552 ------------ Loss: 8017.2 ------------ Accuracy: 61.6%\n",
            "Step: 553 ------------ Loss: 8015.9 ------------ Accuracy: 61.7%\n",
            "Step: 554 ------------ Loss: 8014.6 ------------ Accuracy: 61.7%\n",
            "Step: 555 ------------ Loss: 8013.3 ------------ Accuracy: 61.7%\n",
            "Step: 556 ------------ Loss: 8012.0 ------------ Accuracy: 61.7%\n",
            "Step: 557 ------------ Loss: 8010.7 ------------ Accuracy: 61.7%\n",
            "Step: 558 ------------ Loss: 8009.41 ------------ Accuracy: 61.7%\n",
            "Step: 559 ------------ Loss: 8008.12 ------------ Accuracy: 61.7%\n",
            "Step: 560 ------------ Loss: 8006.83 ------------ Accuracy: 61.7%\n",
            "Step: 561 ------------ Loss: 8005.55 ------------ Accuracy: 61.7%\n",
            "Step: 562 ------------ Loss: 8004.26 ------------ Accuracy: 61.7%\n",
            "Step: 563 ------------ Loss: 8002.98 ------------ Accuracy: 61.7%\n",
            "Step: 564 ------------ Loss: 8001.7 ------------ Accuracy: 61.7%\n",
            "Step: 565 ------------ Loss: 8000.42 ------------ Accuracy: 61.7%\n",
            "Step: 566 ------------ Loss: 7999.15 ------------ Accuracy: 61.7%\n",
            "Step: 567 ------------ Loss: 7997.88 ------------ Accuracy: 61.7%\n",
            "Step: 568 ------------ Loss: 7996.61 ------------ Accuracy: 61.7%\n",
            "Step: 569 ------------ Loss: 7995.34 ------------ Accuracy: 61.7%\n",
            "Step: 570 ------------ Loss: 7994.07 ------------ Accuracy: 61.8%\n",
            "Step: 571 ------------ Loss: 7992.81 ------------ Accuracy: 61.8%\n",
            "Step: 572 ------------ Loss: 7991.55 ------------ Accuracy: 61.8%\n",
            "Step: 573 ------------ Loss: 7990.29 ------------ Accuracy: 61.8%\n",
            "Step: 574 ------------ Loss: 7989.03 ------------ Accuracy: 61.8%\n",
            "Step: 575 ------------ Loss: 7987.78 ------------ Accuracy: 61.8%\n",
            "Step: 576 ------------ Loss: 7986.52 ------------ Accuracy: 61.8%\n",
            "Step: 577 ------------ Loss: 7985.27 ------------ Accuracy: 61.8%\n",
            "Step: 578 ------------ Loss: 7984.02 ------------ Accuracy: 61.8%\n",
            "Step: 579 ------------ Loss: 7982.78 ------------ Accuracy: 61.8%\n",
            "Step: 580 ------------ Loss: 7981.53 ------------ Accuracy: 61.8%\n",
            "Step: 581 ------------ Loss: 7980.29 ------------ Accuracy: 61.7%\n",
            "Step: 582 ------------ Loss: 7979.05 ------------ Accuracy: 61.8%\n",
            "Step: 583 ------------ Loss: 7977.82 ------------ Accuracy: 61.8%\n",
            "Step: 584 ------------ Loss: 7976.58 ------------ Accuracy: 61.8%\n",
            "Step: 585 ------------ Loss: 7975.35 ------------ Accuracy: 61.8%\n",
            "Step: 586 ------------ Loss: 7974.12 ------------ Accuracy: 61.8%\n",
            "Step: 587 ------------ Loss: 7972.89 ------------ Accuracy: 61.8%\n",
            "Step: 588 ------------ Loss: 7971.66 ------------ Accuracy: 61.8%\n",
            "Step: 589 ------------ Loss: 7970.44 ------------ Accuracy: 61.8%\n",
            "Step: 590 ------------ Loss: 7969.21 ------------ Accuracy: 61.8%\n",
            "Step: 591 ------------ Loss: 7967.99 ------------ Accuracy: 61.8%\n",
            "Step: 592 ------------ Loss: 7966.78 ------------ Accuracy: 61.8%\n",
            "Step: 593 ------------ Loss: 7965.56 ------------ Accuracy: 61.8%\n",
            "Step: 594 ------------ Loss: 7964.34 ------------ Accuracy: 61.8%\n",
            "Step: 595 ------------ Loss: 7963.13 ------------ Accuracy: 61.8%\n",
            "Step: 596 ------------ Loss: 7961.92 ------------ Accuracy: 61.8%\n",
            "Step: 597 ------------ Loss: 7960.71 ------------ Accuracy: 61.9%\n",
            "Step: 598 ------------ Loss: 7959.51 ------------ Accuracy: 61.9%\n",
            "Step: 599 ------------ Loss: 7958.3 ------------ Accuracy: 61.9%\n",
            "Step: 600 ------------ Loss: 7957.1 ------------ Accuracy: 62.0%\n",
            "Step: 601 ------------ Loss: 7955.9 ------------ Accuracy: 62.0%\n",
            "Step: 602 ------------ Loss: 7954.7 ------------ Accuracy: 62.0%\n",
            "Step: 603 ------------ Loss: 7953.51 ------------ Accuracy: 62.1%\n",
            "Step: 604 ------------ Loss: 7952.31 ------------ Accuracy: 62.1%\n",
            "Step: 605 ------------ Loss: 7951.12 ------------ Accuracy: 62.1%\n",
            "Step: 606 ------------ Loss: 7949.93 ------------ Accuracy: 62.0%\n",
            "Step: 607 ------------ Loss: 7948.74 ------------ Accuracy: 62.0%\n",
            "Step: 608 ------------ Loss: 7947.56 ------------ Accuracy: 62.0%\n",
            "Step: 609 ------------ Loss: 7946.37 ------------ Accuracy: 62.0%\n",
            "Step: 610 ------------ Loss: 7945.19 ------------ Accuracy: 61.9%\n",
            "Step: 611 ------------ Loss: 7944.01 ------------ Accuracy: 62.1%\n",
            "Step: 612 ------------ Loss: 7942.83 ------------ Accuracy: 62.1%\n",
            "Step: 613 ------------ Loss: 7941.66 ------------ Accuracy: 62.1%\n",
            "Step: 614 ------------ Loss: 7940.48 ------------ Accuracy: 62.1%\n",
            "Step: 615 ------------ Loss: 7939.31 ------------ Accuracy: 62.1%\n",
            "Step: 616 ------------ Loss: 7938.14 ------------ Accuracy: 62.1%\n",
            "Step: 617 ------------ Loss: 7936.97 ------------ Accuracy: 62.1%\n",
            "Step: 618 ------------ Loss: 7935.81 ------------ Accuracy: 62.1%\n",
            "Step: 619 ------------ Loss: 7934.64 ------------ Accuracy: 62.1%\n",
            "Step: 620 ------------ Loss: 7933.48 ------------ Accuracy: 62.1%\n",
            "Step: 621 ------------ Loss: 7932.32 ------------ Accuracy: 62.1%\n",
            "Step: 622 ------------ Loss: 7931.16 ------------ Accuracy: 62.2%\n",
            "Step: 623 ------------ Loss: 7930.0 ------------ Accuracy: 62.2%\n",
            "Step: 624 ------------ Loss: 7928.85 ------------ Accuracy: 62.2%\n",
            "Step: 625 ------------ Loss: 7927.7 ------------ Accuracy: 62.2%\n",
            "Step: 626 ------------ Loss: 7926.54 ------------ Accuracy: 62.2%\n",
            "Step: 627 ------------ Loss: 7925.39 ------------ Accuracy: 62.2%\n",
            "Step: 628 ------------ Loss: 7924.25 ------------ Accuracy: 62.2%\n",
            "Step: 629 ------------ Loss: 7923.1 ------------ Accuracy: 62.2%\n",
            "Step: 630 ------------ Loss: 7921.96 ------------ Accuracy: 62.2%\n",
            "Step: 631 ------------ Loss: 7920.82 ------------ Accuracy: 62.2%\n",
            "Step: 632 ------------ Loss: 7919.68 ------------ Accuracy: 62.3%\n",
            "Step: 633 ------------ Loss: 7918.54 ------------ Accuracy: 62.3%\n",
            "Step: 634 ------------ Loss: 7917.4 ------------ Accuracy: 62.3%\n",
            "Step: 635 ------------ Loss: 7916.27 ------------ Accuracy: 62.3%\n",
            "Step: 636 ------------ Loss: 7915.13 ------------ Accuracy: 62.3%\n",
            "Step: 637 ------------ Loss: 7914.0 ------------ Accuracy: 62.3%\n",
            "Step: 638 ------------ Loss: 7912.87 ------------ Accuracy: 62.3%\n",
            "Step: 639 ------------ Loss: 7911.74 ------------ Accuracy: 62.3%\n",
            "Step: 640 ------------ Loss: 7910.62 ------------ Accuracy: 62.4%\n",
            "Step: 641 ------------ Loss: 7909.5 ------------ Accuracy: 62.4%\n",
            "Step: 642 ------------ Loss: 7908.37 ------------ Accuracy: 62.4%\n",
            "Step: 643 ------------ Loss: 7907.25 ------------ Accuracy: 62.4%\n",
            "Step: 644 ------------ Loss: 7906.13 ------------ Accuracy: 62.4%\n",
            "Step: 645 ------------ Loss: 7905.02 ------------ Accuracy: 62.4%\n",
            "Step: 646 ------------ Loss: 7903.9 ------------ Accuracy: 62.4%\n",
            "Step: 647 ------------ Loss: 7902.79 ------------ Accuracy: 62.5%\n",
            "Step: 648 ------------ Loss: 7901.68 ------------ Accuracy: 63.1%\n",
            "Step: 649 ------------ Loss: 7900.57 ------------ Accuracy: 63.7%\n",
            "Step: 650 ------------ Loss: 7899.46 ------------ Accuracy: 63.7%\n",
            "Step: 651 ------------ Loss: 7898.35 ------------ Accuracy: 63.7%\n",
            "Step: 652 ------------ Loss: 7897.25 ------------ Accuracy: 63.8%\n",
            "Step: 653 ------------ Loss: 7896.15 ------------ Accuracy: 63.8%\n",
            "Step: 654 ------------ Loss: 7895.05 ------------ Accuracy: 63.7%\n",
            "Step: 655 ------------ Loss: 7893.95 ------------ Accuracy: 63.7%\n",
            "Step: 656 ------------ Loss: 7892.85 ------------ Accuracy: 63.7%\n",
            "Step: 657 ------------ Loss: 7891.75 ------------ Accuracy: 63.7%\n",
            "Step: 658 ------------ Loss: 7890.66 ------------ Accuracy: 63.7%\n",
            "Step: 659 ------------ Loss: 7889.56 ------------ Accuracy: 63.7%\n",
            "Step: 660 ------------ Loss: 7888.47 ------------ Accuracy: 63.7%\n",
            "Step: 661 ------------ Loss: 7887.38 ------------ Accuracy: 63.8%\n",
            "Step: 662 ------------ Loss: 7886.3 ------------ Accuracy: 63.8%\n",
            "Step: 663 ------------ Loss: 7885.21 ------------ Accuracy: 63.8%\n",
            "Step: 664 ------------ Loss: 7884.13 ------------ Accuracy: 63.8%\n",
            "Step: 665 ------------ Loss: 7883.04 ------------ Accuracy: 63.8%\n",
            "Step: 666 ------------ Loss: 7881.96 ------------ Accuracy: 63.9%\n",
            "Step: 667 ------------ Loss: 7880.88 ------------ Accuracy: 63.9%\n",
            "Step: 668 ------------ Loss: 7879.81 ------------ Accuracy: 63.9%\n",
            "Step: 669 ------------ Loss: 7878.73 ------------ Accuracy: 63.9%\n",
            "Step: 670 ------------ Loss: 7877.66 ------------ Accuracy: 63.9%\n",
            "Step: 671 ------------ Loss: 7876.58 ------------ Accuracy: 63.9%\n",
            "Step: 672 ------------ Loss: 7875.51 ------------ Accuracy: 63.9%\n",
            "Step: 673 ------------ Loss: 7874.44 ------------ Accuracy: 63.9%\n",
            "Step: 674 ------------ Loss: 7873.37 ------------ Accuracy: 63.7%\n",
            "Step: 675 ------------ Loss: 7872.31 ------------ Accuracy: 63.7%\n",
            "Step: 676 ------------ Loss: 7871.24 ------------ Accuracy: 63.7%\n",
            "Step: 677 ------------ Loss: 7870.18 ------------ Accuracy: 63.7%\n",
            "Step: 678 ------------ Loss: 7869.12 ------------ Accuracy: 63.7%\n",
            "Step: 679 ------------ Loss: 7868.06 ------------ Accuracy: 63.7%\n",
            "Step: 680 ------------ Loss: 7867.0 ------------ Accuracy: 63.7%\n",
            "Step: 681 ------------ Loss: 7865.94 ------------ Accuracy: 63.7%\n",
            "Step: 682 ------------ Loss: 7864.89 ------------ Accuracy: 63.7%\n",
            "Step: 683 ------------ Loss: 7863.84 ------------ Accuracy: 63.7%\n",
            "Step: 684 ------------ Loss: 7862.78 ------------ Accuracy: 63.7%\n",
            "Step: 685 ------------ Loss: 7861.73 ------------ Accuracy: 63.7%\n",
            "Step: 686 ------------ Loss: 7860.68 ------------ Accuracy: 63.7%\n",
            "Step: 687 ------------ Loss: 7859.64 ------------ Accuracy: 63.7%\n",
            "Step: 688 ------------ Loss: 7858.59 ------------ Accuracy: 63.7%\n",
            "Step: 689 ------------ Loss: 7857.55 ------------ Accuracy: 63.7%\n",
            "Step: 690 ------------ Loss: 7856.5 ------------ Accuracy: 63.7%\n",
            "Step: 691 ------------ Loss: 7855.46 ------------ Accuracy: 63.7%\n",
            "Step: 692 ------------ Loss: 7854.42 ------------ Accuracy: 63.7%\n",
            "Step: 693 ------------ Loss: 7853.38 ------------ Accuracy: 63.7%\n",
            "Step: 694 ------------ Loss: 7852.35 ------------ Accuracy: 63.7%\n",
            "Step: 695 ------------ Loss: 7851.31 ------------ Accuracy: 63.7%\n",
            "Step: 696 ------------ Loss: 7850.28 ------------ Accuracy: 63.7%\n",
            "Step: 697 ------------ Loss: 7849.25 ------------ Accuracy: 63.7%\n",
            "Step: 698 ------------ Loss: 7848.22 ------------ Accuracy: 63.7%\n",
            "Step: 699 ------------ Loss: 7847.19 ------------ Accuracy: 63.7%\n",
            "Step: 700 ------------ Loss: 7846.16 ------------ Accuracy: 63.7%\n",
            "Step: 701 ------------ Loss: 7845.13 ------------ Accuracy: 63.7%\n",
            "Step: 702 ------------ Loss: 7844.11 ------------ Accuracy: 63.7%\n",
            "Step: 703 ------------ Loss: 7843.09 ------------ Accuracy: 63.7%\n",
            "Step: 704 ------------ Loss: 7842.06 ------------ Accuracy: 63.7%\n",
            "Step: 705 ------------ Loss: 7841.04 ------------ Accuracy: 63.7%\n",
            "Step: 706 ------------ Loss: 7840.02 ------------ Accuracy: 63.7%\n",
            "Step: 707 ------------ Loss: 7839.01 ------------ Accuracy: 63.7%\n",
            "Step: 708 ------------ Loss: 7837.99 ------------ Accuracy: 63.7%\n",
            "Step: 709 ------------ Loss: 7836.98 ------------ Accuracy: 63.7%\n",
            "Step: 710 ------------ Loss: 7835.96 ------------ Accuracy: 63.7%\n",
            "Step: 711 ------------ Loss: 7834.95 ------------ Accuracy: 63.7%\n",
            "Step: 712 ------------ Loss: 7833.94 ------------ Accuracy: 63.7%\n",
            "Step: 713 ------------ Loss: 7832.93 ------------ Accuracy: 63.7%\n",
            "Step: 714 ------------ Loss: 7831.93 ------------ Accuracy: 63.8%\n",
            "Step: 715 ------------ Loss: 7830.92 ------------ Accuracy: 63.8%\n",
            "Step: 716 ------------ Loss: 7829.91 ------------ Accuracy: 63.8%\n",
            "Step: 717 ------------ Loss: 7828.91 ------------ Accuracy: 63.8%\n",
            "Step: 718 ------------ Loss: 7827.91 ------------ Accuracy: 63.8%\n",
            "Step: 719 ------------ Loss: 7826.91 ------------ Accuracy: 63.9%\n",
            "Step: 720 ------------ Loss: 7825.91 ------------ Accuracy: 63.9%\n",
            "Step: 721 ------------ Loss: 7824.91 ------------ Accuracy: 63.9%\n",
            "Step: 722 ------------ Loss: 7823.92 ------------ Accuracy: 63.9%\n",
            "Step: 723 ------------ Loss: 7822.92 ------------ Accuracy: 63.9%\n",
            "Step: 724 ------------ Loss: 7821.93 ------------ Accuracy: 63.9%\n",
            "Step: 725 ------------ Loss: 7820.94 ------------ Accuracy: 63.9%\n",
            "Step: 726 ------------ Loss: 7819.95 ------------ Accuracy: 63.9%\n",
            "Step: 727 ------------ Loss: 7818.96 ------------ Accuracy: 64.1%\n",
            "Step: 728 ------------ Loss: 7817.97 ------------ Accuracy: 64.1%\n",
            "Step: 729 ------------ Loss: 7816.98 ------------ Accuracy: 64.1%\n",
            "Step: 730 ------------ Loss: 7816.0 ------------ Accuracy: 64.1%\n",
            "Step: 731 ------------ Loss: 7815.01 ------------ Accuracy: 64.1%\n",
            "Step: 732 ------------ Loss: 7814.03 ------------ Accuracy: 64.1%\n",
            "Step: 733 ------------ Loss: 7813.05 ------------ Accuracy: 64.2%\n",
            "Step: 734 ------------ Loss: 7812.07 ------------ Accuracy: 64.2%\n",
            "Step: 735 ------------ Loss: 7811.09 ------------ Accuracy: 64.2%\n",
            "Step: 736 ------------ Loss: 7810.12 ------------ Accuracy: 64.2%\n",
            "Step: 737 ------------ Loss: 7809.14 ------------ Accuracy: 64.2%\n",
            "Step: 738 ------------ Loss: 7808.17 ------------ Accuracy: 64.2%\n",
            "Step: 739 ------------ Loss: 7807.19 ------------ Accuracy: 64.2%\n",
            "Step: 740 ------------ Loss: 7806.22 ------------ Accuracy: 64.3%\n",
            "Step: 741 ------------ Loss: 7805.25 ------------ Accuracy: 64.3%\n",
            "Step: 742 ------------ Loss: 7804.28 ------------ Accuracy: 64.3%\n",
            "Step: 743 ------------ Loss: 7803.31 ------------ Accuracy: 64.3%\n",
            "Step: 744 ------------ Loss: 7802.35 ------------ Accuracy: 64.3%\n",
            "Step: 745 ------------ Loss: 7801.38 ------------ Accuracy: 64.3%\n",
            "Step: 746 ------------ Loss: 7800.42 ------------ Accuracy: 64.3%\n",
            "Step: 747 ------------ Loss: 7799.45 ------------ Accuracy: 64.3%\n",
            "Step: 748 ------------ Loss: 7798.49 ------------ Accuracy: 64.3%\n",
            "Step: 749 ------------ Loss: 7797.53 ------------ Accuracy: 64.3%\n",
            "Step: 750 ------------ Loss: 7796.57 ------------ Accuracy: 64.3%\n",
            "Step: 751 ------------ Loss: 7795.62 ------------ Accuracy: 64.3%\n",
            "Step: 752 ------------ Loss: 7794.66 ------------ Accuracy: 64.3%\n",
            "Step: 753 ------------ Loss: 7793.7 ------------ Accuracy: 64.3%\n",
            "Step: 754 ------------ Loss: 7792.75 ------------ Accuracy: 64.1%\n",
            "Step: 755 ------------ Loss: 7791.8 ------------ Accuracy: 64.1%\n",
            "Step: 756 ------------ Loss: 7790.85 ------------ Accuracy: 64.1%\n",
            "Step: 757 ------------ Loss: 7789.9 ------------ Accuracy: 64.1%\n",
            "Step: 758 ------------ Loss: 7788.95 ------------ Accuracy: 64.1%\n",
            "Step: 759 ------------ Loss: 7788.0 ------------ Accuracy: 64.2%\n",
            "Step: 760 ------------ Loss: 7787.05 ------------ Accuracy: 64.2%\n",
            "Step: 761 ------------ Loss: 7786.11 ------------ Accuracy: 64.3%\n",
            "Step: 762 ------------ Loss: 7785.17 ------------ Accuracy: 64.3%\n",
            "Step: 763 ------------ Loss: 7784.22 ------------ Accuracy: 64.4%\n",
            "Step: 764 ------------ Loss: 7783.28 ------------ Accuracy: 64.4%\n",
            "Step: 765 ------------ Loss: 7782.34 ------------ Accuracy: 64.4%\n",
            "Step: 766 ------------ Loss: 7781.4 ------------ Accuracy: 64.4%\n",
            "Step: 767 ------------ Loss: 7780.46 ------------ Accuracy: 64.4%\n",
            "Step: 768 ------------ Loss: 7779.53 ------------ Accuracy: 64.4%\n",
            "Step: 769 ------------ Loss: 7778.59 ------------ Accuracy: 64.4%\n",
            "Step: 770 ------------ Loss: 7777.66 ------------ Accuracy: 64.4%\n",
            "Step: 771 ------------ Loss: 7776.73 ------------ Accuracy: 64.4%\n",
            "Step: 772 ------------ Loss: 7775.79 ------------ Accuracy: 64.4%\n",
            "Step: 773 ------------ Loss: 7774.86 ------------ Accuracy: 64.4%\n",
            "Step: 774 ------------ Loss: 7773.93 ------------ Accuracy: 64.4%\n",
            "Step: 775 ------------ Loss: 7773.01 ------------ Accuracy: 64.4%\n",
            "Step: 776 ------------ Loss: 7772.08 ------------ Accuracy: 64.4%\n",
            "Step: 777 ------------ Loss: 7771.15 ------------ Accuracy: 64.4%\n",
            "Step: 778 ------------ Loss: 7770.23 ------------ Accuracy: 64.4%\n",
            "Step: 779 ------------ Loss: 7769.3 ------------ Accuracy: 64.4%\n",
            "Step: 780 ------------ Loss: 7768.38 ------------ Accuracy: 64.4%\n",
            "Step: 781 ------------ Loss: 7767.46 ------------ Accuracy: 64.4%\n",
            "Step: 782 ------------ Loss: 7766.54 ------------ Accuracy: 64.4%\n",
            "Step: 783 ------------ Loss: 7765.62 ------------ Accuracy: 64.4%\n",
            "Step: 784 ------------ Loss: 7764.7 ------------ Accuracy: 64.4%\n",
            "Step: 785 ------------ Loss: 7763.79 ------------ Accuracy: 64.3%\n",
            "Step: 786 ------------ Loss: 7762.87 ------------ Accuracy: 64.3%\n",
            "Step: 787 ------------ Loss: 7761.96 ------------ Accuracy: 64.3%\n",
            "Step: 788 ------------ Loss: 7761.05 ------------ Accuracy: 64.3%\n",
            "Step: 789 ------------ Loss: 7760.13 ------------ Accuracy: 64.3%\n",
            "Step: 790 ------------ Loss: 7759.22 ------------ Accuracy: 64.3%\n",
            "Step: 791 ------------ Loss: 7758.31 ------------ Accuracy: 64.3%\n",
            "Step: 792 ------------ Loss: 7757.4 ------------ Accuracy: 64.3%\n",
            "Step: 793 ------------ Loss: 7756.5 ------------ Accuracy: 64.3%\n",
            "Step: 794 ------------ Loss: 7755.59 ------------ Accuracy: 64.3%\n",
            "Step: 795 ------------ Loss: 7754.68 ------------ Accuracy: 64.3%\n",
            "Step: 796 ------------ Loss: 7753.78 ------------ Accuracy: 64.3%\n",
            "Step: 797 ------------ Loss: 7752.88 ------------ Accuracy: 64.3%\n",
            "Step: 798 ------------ Loss: 7751.98 ------------ Accuracy: 64.4%\n",
            "Step: 799 ------------ Loss: 7751.07 ------------ Accuracy: 64.4%\n",
            "Step: 800 ------------ Loss: 7750.17 ------------ Accuracy: 64.4%\n",
            "Step: 801 ------------ Loss: 7749.28 ------------ Accuracy: 64.4%\n",
            "Step: 802 ------------ Loss: 7748.38 ------------ Accuracy: 64.4%\n",
            "Step: 803 ------------ Loss: 7747.48 ------------ Accuracy: 64.4%\n",
            "Step: 804 ------------ Loss: 7746.59 ------------ Accuracy: 64.4%\n",
            "Step: 805 ------------ Loss: 7745.69 ------------ Accuracy: 64.2%\n",
            "Step: 806 ------------ Loss: 7744.8 ------------ Accuracy: 64.2%\n",
            "Step: 807 ------------ Loss: 7743.91 ------------ Accuracy: 64.2%\n",
            "Step: 808 ------------ Loss: 7743.02 ------------ Accuracy: 64.2%\n",
            "Step: 809 ------------ Loss: 7742.13 ------------ Accuracy: 64.2%\n",
            "Step: 810 ------------ Loss: 7741.24 ------------ Accuracy: 64.2%\n",
            "Step: 811 ------------ Loss: 7740.35 ------------ Accuracy: 64.2%\n",
            "Step: 812 ------------ Loss: 7739.46 ------------ Accuracy: 64.2%\n",
            "Step: 813 ------------ Loss: 7738.58 ------------ Accuracy: 64.2%\n",
            "Step: 814 ------------ Loss: 7737.69 ------------ Accuracy: 64.2%\n",
            "Step: 815 ------------ Loss: 7736.81 ------------ Accuracy: 64.3%\n",
            "Step: 816 ------------ Loss: 7735.93 ------------ Accuracy: 64.3%\n",
            "Step: 817 ------------ Loss: 7735.04 ------------ Accuracy: 64.3%\n",
            "Step: 818 ------------ Loss: 7734.16 ------------ Accuracy: 64.3%\n",
            "Step: 819 ------------ Loss: 7733.28 ------------ Accuracy: 64.3%\n",
            "Step: 820 ------------ Loss: 7732.41 ------------ Accuracy: 64.3%\n",
            "Step: 821 ------------ Loss: 7731.53 ------------ Accuracy: 64.3%\n",
            "Step: 822 ------------ Loss: 7730.65 ------------ Accuracy: 64.3%\n",
            "Step: 823 ------------ Loss: 7729.78 ------------ Accuracy: 64.3%\n",
            "Step: 824 ------------ Loss: 7728.9 ------------ Accuracy: 64.3%\n",
            "Step: 825 ------------ Loss: 7728.03 ------------ Accuracy: 64.3%\n",
            "Step: 826 ------------ Loss: 7727.16 ------------ Accuracy: 64.3%\n",
            "Step: 827 ------------ Loss: 7726.29 ------------ Accuracy: 64.3%\n",
            "Step: 828 ------------ Loss: 7725.42 ------------ Accuracy: 64.3%\n",
            "Step: 829 ------------ Loss: 7724.55 ------------ Accuracy: 64.3%\n",
            "Step: 830 ------------ Loss: 7723.68 ------------ Accuracy: 64.3%\n",
            "Step: 831 ------------ Loss: 7722.81 ------------ Accuracy: 64.3%\n",
            "Step: 832 ------------ Loss: 7721.94 ------------ Accuracy: 64.3%\n",
            "Step: 833 ------------ Loss: 7721.08 ------------ Accuracy: 64.3%\n",
            "Step: 834 ------------ Loss: 7720.22 ------------ Accuracy: 64.3%\n",
            "Step: 835 ------------ Loss: 7719.35 ------------ Accuracy: 64.3%\n",
            "Step: 836 ------------ Loss: 7718.49 ------------ Accuracy: 64.3%\n",
            "Step: 837 ------------ Loss: 7717.63 ------------ Accuracy: 64.3%\n",
            "Step: 838 ------------ Loss: 7716.77 ------------ Accuracy: 64.3%\n",
            "Step: 839 ------------ Loss: 7715.91 ------------ Accuracy: 64.3%\n",
            "Step: 840 ------------ Loss: 7715.05 ------------ Accuracy: 64.3%\n",
            "Step: 841 ------------ Loss: 7714.19 ------------ Accuracy: 64.3%\n",
            "Step: 842 ------------ Loss: 7713.34 ------------ Accuracy: 64.3%\n",
            "Step: 843 ------------ Loss: 7712.48 ------------ Accuracy: 64.4%\n",
            "Step: 844 ------------ Loss: 7711.63 ------------ Accuracy: 64.4%\n",
            "Step: 845 ------------ Loss: 7710.77 ------------ Accuracy: 64.4%\n",
            "Step: 846 ------------ Loss: 7709.92 ------------ Accuracy: 64.4%\n",
            "Step: 847 ------------ Loss: 7709.07 ------------ Accuracy: 64.4%\n",
            "Step: 848 ------------ Loss: 7708.22 ------------ Accuracy: 64.4%\n",
            "Step: 849 ------------ Loss: 7707.37 ------------ Accuracy: 64.4%\n",
            "Step: 850 ------------ Loss: 7706.52 ------------ Accuracy: 64.4%\n",
            "Step: 851 ------------ Loss: 7705.67 ------------ Accuracy: 64.4%\n",
            "Step: 852 ------------ Loss: 7704.83 ------------ Accuracy: 64.4%\n",
            "Step: 853 ------------ Loss: 7703.98 ------------ Accuracy: 64.4%\n",
            "Step: 854 ------------ Loss: 7703.14 ------------ Accuracy: 64.4%\n",
            "Step: 855 ------------ Loss: 7702.29 ------------ Accuracy: 64.4%\n",
            "Step: 856 ------------ Loss: 7701.45 ------------ Accuracy: 64.4%\n",
            "Step: 857 ------------ Loss: 7700.61 ------------ Accuracy: 64.4%\n",
            "Step: 858 ------------ Loss: 7699.77 ------------ Accuracy: 64.4%\n",
            "Step: 859 ------------ Loss: 7698.93 ------------ Accuracy: 64.4%\n",
            "Step: 860 ------------ Loss: 7698.09 ------------ Accuracy: 64.4%\n",
            "Step: 861 ------------ Loss: 7697.25 ------------ Accuracy: 64.4%\n",
            "Step: 862 ------------ Loss: 7696.41 ------------ Accuracy: 64.4%\n",
            "Step: 863 ------------ Loss: 7695.57 ------------ Accuracy: 64.3%\n",
            "Step: 864 ------------ Loss: 7694.74 ------------ Accuracy: 64.3%\n",
            "Step: 865 ------------ Loss: 7693.9 ------------ Accuracy: 64.3%\n",
            "Step: 866 ------------ Loss: 7693.07 ------------ Accuracy: 64.3%\n",
            "Step: 867 ------------ Loss: 7692.24 ------------ Accuracy: 64.3%\n",
            "Step: 868 ------------ Loss: 7691.4 ------------ Accuracy: 64.3%\n",
            "Step: 869 ------------ Loss: 7690.57 ------------ Accuracy: 64.3%\n",
            "Step: 870 ------------ Loss: 7689.74 ------------ Accuracy: 64.3%\n",
            "Step: 871 ------------ Loss: 7688.91 ------------ Accuracy: 64.3%\n",
            "Step: 872 ------------ Loss: 7688.09 ------------ Accuracy: 64.3%\n",
            "Step: 873 ------------ Loss: 7687.26 ------------ Accuracy: 64.3%\n",
            "Step: 874 ------------ Loss: 7686.43 ------------ Accuracy: 64.3%\n",
            "Step: 875 ------------ Loss: 7685.61 ------------ Accuracy: 64.3%\n",
            "Step: 876 ------------ Loss: 7684.78 ------------ Accuracy: 64.3%\n",
            "Step: 877 ------------ Loss: 7683.96 ------------ Accuracy: 64.3%\n",
            "Step: 878 ------------ Loss: 7683.13 ------------ Accuracy: 64.3%\n",
            "Step: 879 ------------ Loss: 7682.31 ------------ Accuracy: 64.3%\n",
            "Step: 880 ------------ Loss: 7681.49 ------------ Accuracy: 64.3%\n",
            "Step: 881 ------------ Loss: 7680.67 ------------ Accuracy: 64.3%\n",
            "Step: 882 ------------ Loss: 7679.85 ------------ Accuracy: 64.3%\n",
            "Step: 883 ------------ Loss: 7679.03 ------------ Accuracy: 64.3%\n",
            "Step: 884 ------------ Loss: 7678.22 ------------ Accuracy: 64.3%\n",
            "Step: 885 ------------ Loss: 7677.4 ------------ Accuracy: 64.3%\n",
            "Step: 886 ------------ Loss: 7676.58 ------------ Accuracy: 64.3%\n",
            "Step: 887 ------------ Loss: 7675.77 ------------ Accuracy: 64.3%\n",
            "Step: 888 ------------ Loss: 7674.95 ------------ Accuracy: 64.3%\n",
            "Step: 889 ------------ Loss: 7674.14 ------------ Accuracy: 64.3%\n",
            "Step: 890 ------------ Loss: 7673.33 ------------ Accuracy: 64.3%\n",
            "Step: 891 ------------ Loss: 7672.52 ------------ Accuracy: 64.3%\n",
            "Step: 892 ------------ Loss: 7671.7 ------------ Accuracy: 64.3%\n",
            "Step: 893 ------------ Loss: 7670.89 ------------ Accuracy: 64.3%\n",
            "Step: 894 ------------ Loss: 7670.08 ------------ Accuracy: 64.3%\n",
            "Step: 895 ------------ Loss: 7669.28 ------------ Accuracy: 64.3%\n",
            "Step: 896 ------------ Loss: 7668.47 ------------ Accuracy: 64.3%\n",
            "Step: 897 ------------ Loss: 7667.66 ------------ Accuracy: 64.3%\n",
            "Step: 898 ------------ Loss: 7666.86 ------------ Accuracy: 64.4%\n",
            "Step: 899 ------------ Loss: 7666.05 ------------ Accuracy: 64.4%\n",
            "Step: 900 ------------ Loss: 7665.25 ------------ Accuracy: 64.4%\n",
            "Step: 901 ------------ Loss: 7664.44 ------------ Accuracy: 64.4%\n",
            "Step: 902 ------------ Loss: 7663.64 ------------ Accuracy: 64.4%\n",
            "Step: 903 ------------ Loss: 7662.84 ------------ Accuracy: 64.4%\n",
            "Step: 904 ------------ Loss: 7662.04 ------------ Accuracy: 64.4%\n",
            "Step: 905 ------------ Loss: 7661.24 ------------ Accuracy: 64.4%\n",
            "Step: 906 ------------ Loss: 7660.44 ------------ Accuracy: 64.4%\n",
            "Step: 907 ------------ Loss: 7659.64 ------------ Accuracy: 64.4%\n",
            "Step: 908 ------------ Loss: 7658.84 ------------ Accuracy: 64.4%\n",
            "Step: 909 ------------ Loss: 7658.05 ------------ Accuracy: 64.4%\n",
            "Step: 910 ------------ Loss: 7657.25 ------------ Accuracy: 64.4%\n",
            "Step: 911 ------------ Loss: 7656.46 ------------ Accuracy: 64.4%\n",
            "Step: 912 ------------ Loss: 7655.66 ------------ Accuracy: 64.4%\n",
            "Step: 913 ------------ Loss: 7654.87 ------------ Accuracy: 64.4%\n",
            "Step: 914 ------------ Loss: 7654.08 ------------ Accuracy: 64.4%\n",
            "Step: 915 ------------ Loss: 7653.28 ------------ Accuracy: 64.4%\n",
            "Step: 916 ------------ Loss: 7652.49 ------------ Accuracy: 64.4%\n",
            "Step: 917 ------------ Loss: 7651.7 ------------ Accuracy: 64.4%\n",
            "Step: 918 ------------ Loss: 7650.91 ------------ Accuracy: 64.4%\n",
            "Step: 919 ------------ Loss: 7650.12 ------------ Accuracy: 64.4%\n",
            "Step: 920 ------------ Loss: 7649.34 ------------ Accuracy: 64.4%\n",
            "Step: 921 ------------ Loss: 7648.55 ------------ Accuracy: 64.4%\n",
            "Step: 922 ------------ Loss: 7647.76 ------------ Accuracy: 64.4%\n",
            "Step: 923 ------------ Loss: 7646.98 ------------ Accuracy: 64.4%\n",
            "Step: 924 ------------ Loss: 7646.19 ------------ Accuracy: 64.4%\n",
            "Step: 925 ------------ Loss: 7645.41 ------------ Accuracy: 64.4%\n",
            "Step: 926 ------------ Loss: 7644.62 ------------ Accuracy: 64.4%\n",
            "Step: 927 ------------ Loss: 7643.84 ------------ Accuracy: 64.4%\n",
            "Step: 928 ------------ Loss: 7643.06 ------------ Accuracy: 64.4%\n",
            "Step: 929 ------------ Loss: 7642.28 ------------ Accuracy: 64.4%\n",
            "Step: 930 ------------ Loss: 7641.5 ------------ Accuracy: 64.4%\n",
            "Step: 931 ------------ Loss: 7640.72 ------------ Accuracy: 64.4%\n",
            "Step: 932 ------------ Loss: 7639.94 ------------ Accuracy: 64.4%\n",
            "Step: 933 ------------ Loss: 7639.16 ------------ Accuracy: 64.4%\n",
            "Step: 934 ------------ Loss: 7638.39 ------------ Accuracy: 64.4%\n",
            "Step: 935 ------------ Loss: 7637.61 ------------ Accuracy: 64.4%\n",
            "Step: 936 ------------ Loss: 7636.84 ------------ Accuracy: 64.4%\n",
            "Step: 937 ------------ Loss: 7636.06 ------------ Accuracy: 64.4%\n",
            "Step: 938 ------------ Loss: 7635.29 ------------ Accuracy: 64.4%\n",
            "Step: 939 ------------ Loss: 7634.51 ------------ Accuracy: 64.4%\n",
            "Step: 940 ------------ Loss: 7633.74 ------------ Accuracy: 64.4%\n",
            "Step: 941 ------------ Loss: 7632.97 ------------ Accuracy: 64.4%\n",
            "Step: 942 ------------ Loss: 7632.2 ------------ Accuracy: 64.4%\n",
            "Step: 943 ------------ Loss: 7631.43 ------------ Accuracy: 64.4%\n",
            "Step: 944 ------------ Loss: 7630.66 ------------ Accuracy: 64.4%\n",
            "Step: 945 ------------ Loss: 7629.89 ------------ Accuracy: 64.5%\n",
            "Step: 946 ------------ Loss: 7629.12 ------------ Accuracy: 64.5%\n",
            "Step: 947 ------------ Loss: 7628.35 ------------ Accuracy: 64.5%\n",
            "Step: 948 ------------ Loss: 7627.59 ------------ Accuracy: 64.5%\n",
            "Step: 949 ------------ Loss: 7626.82 ------------ Accuracy: 64.5%\n",
            "Step: 950 ------------ Loss: 7626.06 ------------ Accuracy: 64.5%\n",
            "Step: 951 ------------ Loss: 7625.29 ------------ Accuracy: 64.5%\n",
            "Step: 952 ------------ Loss: 7624.53 ------------ Accuracy: 64.5%\n",
            "Step: 953 ------------ Loss: 7623.77 ------------ Accuracy: 64.5%\n",
            "Step: 954 ------------ Loss: 7623.0 ------------ Accuracy: 64.5%\n",
            "Step: 955 ------------ Loss: 7622.24 ------------ Accuracy: 64.5%\n",
            "Step: 956 ------------ Loss: 7621.48 ------------ Accuracy: 64.5%\n",
            "Step: 957 ------------ Loss: 7620.72 ------------ Accuracy: 64.5%\n",
            "Step: 958 ------------ Loss: 7619.96 ------------ Accuracy: 64.5%\n",
            "Step: 959 ------------ Loss: 7619.2 ------------ Accuracy: 64.5%\n",
            "Step: 960 ------------ Loss: 7618.45 ------------ Accuracy: 64.5%\n",
            "Step: 961 ------------ Loss: 7617.69 ------------ Accuracy: 64.5%\n",
            "Step: 962 ------------ Loss: 7616.93 ------------ Accuracy: 64.5%\n",
            "Step: 963 ------------ Loss: 7616.18 ------------ Accuracy: 64.5%\n",
            "Step: 964 ------------ Loss: 7615.42 ------------ Accuracy: 64.5%\n",
            "Step: 965 ------------ Loss: 7614.67 ------------ Accuracy: 64.5%\n",
            "Step: 966 ------------ Loss: 7613.91 ------------ Accuracy: 64.5%\n",
            "Step: 967 ------------ Loss: 7613.16 ------------ Accuracy: 64.5%\n",
            "Step: 968 ------------ Loss: 7612.41 ------------ Accuracy: 64.5%\n",
            "Step: 969 ------------ Loss: 7611.66 ------------ Accuracy: 64.5%\n",
            "Step: 970 ------------ Loss: 7610.91 ------------ Accuracy: 64.5%\n",
            "Step: 971 ------------ Loss: 7610.16 ------------ Accuracy: 64.5%\n",
            "Step: 972 ------------ Loss: 7609.41 ------------ Accuracy: 64.5%\n",
            "Step: 973 ------------ Loss: 7608.66 ------------ Accuracy: 64.5%\n",
            "Step: 974 ------------ Loss: 7607.91 ------------ Accuracy: 64.6%\n",
            "Step: 975 ------------ Loss: 7607.16 ------------ Accuracy: 64.6%\n",
            "Step: 976 ------------ Loss: 7606.42 ------------ Accuracy: 64.6%\n",
            "Step: 977 ------------ Loss: 7605.67 ------------ Accuracy: 64.6%\n",
            "Step: 978 ------------ Loss: 7604.93 ------------ Accuracy: 64.6%\n",
            "Step: 979 ------------ Loss: 7604.18 ------------ Accuracy: 64.6%\n",
            "Step: 980 ------------ Loss: 7603.44 ------------ Accuracy: 64.6%\n",
            "Step: 981 ------------ Loss: 7602.69 ------------ Accuracy: 64.6%\n",
            "Step: 982 ------------ Loss: 7601.95 ------------ Accuracy: 64.6%\n",
            "Step: 983 ------------ Loss: 7601.21 ------------ Accuracy: 64.6%\n",
            "Step: 984 ------------ Loss: 7600.47 ------------ Accuracy: 64.6%\n",
            "Step: 985 ------------ Loss: 7599.73 ------------ Accuracy: 64.6%\n",
            "Step: 986 ------------ Loss: 7598.99 ------------ Accuracy: 64.6%\n",
            "Step: 987 ------------ Loss: 7598.25 ------------ Accuracy: 64.6%\n",
            "Step: 988 ------------ Loss: 7597.51 ------------ Accuracy: 64.6%\n",
            "Step: 989 ------------ Loss: 7596.77 ------------ Accuracy: 64.6%\n",
            "Step: 990 ------------ Loss: 7596.04 ------------ Accuracy: 64.6%\n",
            "Step: 991 ------------ Loss: 7595.3 ------------ Accuracy: 64.6%\n",
            "Step: 992 ------------ Loss: 7594.57 ------------ Accuracy: 64.6%\n",
            "Step: 993 ------------ Loss: 7593.83 ------------ Accuracy: 64.6%\n",
            "Step: 994 ------------ Loss: 7593.1 ------------ Accuracy: 64.6%\n",
            "Step: 995 ------------ Loss: 7592.36 ------------ Accuracy: 64.6%\n",
            "Step: 996 ------------ Loss: 7591.63 ------------ Accuracy: 64.6%\n",
            "Step: 997 ------------ Loss: 7590.9 ------------ Accuracy: 64.6%\n",
            "Step: 998 ------------ Loss: 7590.17 ------------ Accuracy: 64.6%\n",
            "Step: 999 ------------ Loss: 7589.43 ------------ Accuracy: 64.7%\n",
            "Step: 1000 ------------ Loss: 7588.7 ------------ Accuracy: 64.7%\n",
            "Step: 1001 ------------ Loss: 7587.97 ------------ Accuracy: 64.7%\n",
            "Step: 1002 ------------ Loss: 7587.24 ------------ Accuracy: 64.7%\n",
            "Step: 1003 ------------ Loss: 7586.52 ------------ Accuracy: 64.7%\n",
            "Step: 1004 ------------ Loss: 7585.79 ------------ Accuracy: 64.7%\n",
            "Step: 1005 ------------ Loss: 7585.06 ------------ Accuracy: 64.7%\n",
            "Step: 1006 ------------ Loss: 7584.33 ------------ Accuracy: 64.7%\n",
            "Step: 1007 ------------ Loss: 7583.61 ------------ Accuracy: 64.7%\n",
            "Step: 1008 ------------ Loss: 7582.88 ------------ Accuracy: 64.8%\n",
            "Step: 1009 ------------ Loss: 7582.16 ------------ Accuracy: 64.8%\n",
            "Step: 1010 ------------ Loss: 7581.44 ------------ Accuracy: 64.8%\n",
            "Step: 1011 ------------ Loss: 7580.71 ------------ Accuracy: 64.8%\n",
            "Step: 1012 ------------ Loss: 7579.99 ------------ Accuracy: 64.8%\n",
            "Step: 1013 ------------ Loss: 7579.27 ------------ Accuracy: 64.8%\n",
            "Step: 1014 ------------ Loss: 7578.55 ------------ Accuracy: 64.8%\n",
            "Step: 1015 ------------ Loss: 7577.83 ------------ Accuracy: 64.8%\n",
            "Step: 1016 ------------ Loss: 7577.11 ------------ Accuracy: 64.8%\n",
            "Step: 1017 ------------ Loss: 7576.39 ------------ Accuracy: 64.8%\n",
            "Step: 1018 ------------ Loss: 7575.67 ------------ Accuracy: 64.8%\n",
            "Step: 1019 ------------ Loss: 7574.95 ------------ Accuracy: 64.8%\n",
            "Step: 1020 ------------ Loss: 7574.23 ------------ Accuracy: 64.8%\n",
            "Step: 1021 ------------ Loss: 7573.51 ------------ Accuracy: 64.8%\n",
            "Step: 1022 ------------ Loss: 7572.8 ------------ Accuracy: 64.8%\n",
            "Step: 1023 ------------ Loss: 7572.08 ------------ Accuracy: 64.8%\n",
            "Step: 1024 ------------ Loss: 7571.37 ------------ Accuracy: 64.8%\n",
            "Step: 1025 ------------ Loss: 7570.65 ------------ Accuracy: 64.8%\n",
            "Step: 1026 ------------ Loss: 7569.94 ------------ Accuracy: 64.8%\n",
            "Step: 1027 ------------ Loss: 7569.23 ------------ Accuracy: 64.8%\n",
            "Step: 1028 ------------ Loss: 7568.51 ------------ Accuracy: 64.8%\n",
            "Step: 1029 ------------ Loss: 7567.8 ------------ Accuracy: 64.8%\n",
            "Step: 1030 ------------ Loss: 7567.09 ------------ Accuracy: 64.8%\n",
            "Step: 1031 ------------ Loss: 7566.38 ------------ Accuracy: 64.8%\n",
            "Step: 1032 ------------ Loss: 7565.67 ------------ Accuracy: 64.8%\n",
            "Step: 1033 ------------ Loss: 7564.96 ------------ Accuracy: 64.8%\n",
            "Step: 1034 ------------ Loss: 7564.25 ------------ Accuracy: 64.8%\n",
            "Step: 1035 ------------ Loss: 7563.54 ------------ Accuracy: 64.8%\n",
            "Step: 1036 ------------ Loss: 7562.83 ------------ Accuracy: 64.8%\n",
            "Step: 1037 ------------ Loss: 7562.13 ------------ Accuracy: 64.8%\n",
            "Step: 1038 ------------ Loss: 7561.42 ------------ Accuracy: 64.8%\n",
            "Step: 1039 ------------ Loss: 7560.71 ------------ Accuracy: 64.8%\n",
            "Step: 1040 ------------ Loss: 7560.01 ------------ Accuracy: 64.8%\n",
            "Step: 1041 ------------ Loss: 7559.3 ------------ Accuracy: 64.9%\n",
            "Step: 1042 ------------ Loss: 7558.6 ------------ Accuracy: 64.9%\n",
            "Step: 1043 ------------ Loss: 7557.9 ------------ Accuracy: 64.9%\n",
            "Step: 1044 ------------ Loss: 7557.19 ------------ Accuracy: 65.0%\n",
            "Step: 1045 ------------ Loss: 7556.49 ------------ Accuracy: 65.0%\n",
            "Step: 1046 ------------ Loss: 7555.79 ------------ Accuracy: 65.2%\n",
            "Step: 1047 ------------ Loss: 7555.09 ------------ Accuracy: 65.2%\n",
            "Step: 1048 ------------ Loss: 7554.39 ------------ Accuracy: 65.2%\n",
            "Step: 1049 ------------ Loss: 7553.69 ------------ Accuracy: 65.2%\n",
            "Step: 1050 ------------ Loss: 7552.99 ------------ Accuracy: 65.2%\n",
            "Step: 1051 ------------ Loss: 7552.29 ------------ Accuracy: 65.2%\n",
            "Step: 1052 ------------ Loss: 7551.59 ------------ Accuracy: 65.2%\n",
            "Step: 1053 ------------ Loss: 7550.89 ------------ Accuracy: 65.2%\n",
            "Step: 1054 ------------ Loss: 7550.2 ------------ Accuracy: 65.2%\n",
            "Step: 1055 ------------ Loss: 7549.5 ------------ Accuracy: 65.2%\n",
            "Step: 1056 ------------ Loss: 7548.8 ------------ Accuracy: 65.2%\n",
            "Step: 1057 ------------ Loss: 7548.11 ------------ Accuracy: 65.2%\n",
            "Step: 1058 ------------ Loss: 7547.41 ------------ Accuracy: 65.2%\n",
            "Step: 1059 ------------ Loss: 7546.72 ------------ Accuracy: 65.2%\n",
            "Step: 1060 ------------ Loss: 7546.03 ------------ Accuracy: 65.2%\n",
            "Step: 1061 ------------ Loss: 7545.33 ------------ Accuracy: 65.2%\n",
            "Step: 1062 ------------ Loss: 7544.64 ------------ Accuracy: 65.2%\n",
            "Step: 1063 ------------ Loss: 7543.95 ------------ Accuracy: 65.2%\n",
            "Step: 1064 ------------ Loss: 7543.26 ------------ Accuracy: 65.2%\n",
            "Step: 1065 ------------ Loss: 7542.57 ------------ Accuracy: 65.2%\n",
            "Step: 1066 ------------ Loss: 7541.88 ------------ Accuracy: 65.2%\n",
            "Step: 1067 ------------ Loss: 7541.19 ------------ Accuracy: 65.2%\n",
            "Step: 1068 ------------ Loss: 7540.5 ------------ Accuracy: 65.2%\n",
            "Step: 1069 ------------ Loss: 7539.81 ------------ Accuracy: 65.2%\n",
            "Step: 1070 ------------ Loss: 7539.12 ------------ Accuracy: 65.2%\n",
            "Step: 1071 ------------ Loss: 7538.44 ------------ Accuracy: 65.2%\n",
            "Step: 1072 ------------ Loss: 7537.75 ------------ Accuracy: 65.2%\n",
            "Step: 1073 ------------ Loss: 7537.06 ------------ Accuracy: 65.3%\n",
            "Step: 1074 ------------ Loss: 7536.38 ------------ Accuracy: 65.1%\n",
            "Step: 1075 ------------ Loss: 7535.69 ------------ Accuracy: 65.1%\n",
            "Step: 1076 ------------ Loss: 7535.01 ------------ Accuracy: 65.1%\n",
            "Step: 1077 ------------ Loss: 7534.32 ------------ Accuracy: 65.1%\n",
            "Step: 1078 ------------ Loss: 7533.64 ------------ Accuracy: 65.1%\n",
            "Step: 1079 ------------ Loss: 7532.96 ------------ Accuracy: 65.1%\n",
            "Step: 1080 ------------ Loss: 7532.28 ------------ Accuracy: 65.1%\n",
            "Step: 1081 ------------ Loss: 7531.59 ------------ Accuracy: 65.1%\n",
            "Step: 1082 ------------ Loss: 7530.91 ------------ Accuracy: 65.1%\n",
            "Step: 1083 ------------ Loss: 7530.23 ------------ Accuracy: 65.1%\n",
            "Step: 1084 ------------ Loss: 7529.55 ------------ Accuracy: 65.1%\n",
            "Step: 1085 ------------ Loss: 7528.87 ------------ Accuracy: 65.1%\n",
            "Step: 1086 ------------ Loss: 7528.19 ------------ Accuracy: 65.1%\n",
            "Step: 1087 ------------ Loss: 7527.52 ------------ Accuracy: 65.1%\n",
            "Step: 1088 ------------ Loss: 7526.84 ------------ Accuracy: 65.1%\n",
            "Step: 1089 ------------ Loss: 7526.16 ------------ Accuracy: 65.1%\n",
            "Step: 1090 ------------ Loss: 7525.48 ------------ Accuracy: 65.1%\n",
            "Step: 1091 ------------ Loss: 7524.81 ------------ Accuracy: 65.1%\n",
            "Step: 1092 ------------ Loss: 7524.13 ------------ Accuracy: 65.1%\n",
            "Step: 1093 ------------ Loss: 7523.46 ------------ Accuracy: 65.1%\n",
            "Step: 1094 ------------ Loss: 7522.78 ------------ Accuracy: 65.1%\n",
            "Step: 1095 ------------ Loss: 7522.11 ------------ Accuracy: 65.1%\n",
            "Step: 1096 ------------ Loss: 7521.43 ------------ Accuracy: 65.1%\n",
            "Step: 1097 ------------ Loss: 7520.76 ------------ Accuracy: 65.1%\n",
            "Step: 1098 ------------ Loss: 7520.09 ------------ Accuracy: 65.1%\n",
            "Step: 1099 ------------ Loss: 7519.42 ------------ Accuracy: 65.1%\n",
            "Step: 1100 ------------ Loss: 7518.75 ------------ Accuracy: 65.1%\n",
            "Step: 1101 ------------ Loss: 7518.07 ------------ Accuracy: 65.1%\n",
            "Step: 1102 ------------ Loss: 7517.4 ------------ Accuracy: 65.1%\n",
            "Step: 1103 ------------ Loss: 7516.73 ------------ Accuracy: 65.1%\n",
            "Step: 1104 ------------ Loss: 7516.07 ------------ Accuracy: 65.1%\n",
            "Step: 1105 ------------ Loss: 7515.4 ------------ Accuracy: 65.1%\n",
            "Step: 1106 ------------ Loss: 7514.73 ------------ Accuracy: 65.1%\n",
            "Step: 1107 ------------ Loss: 7514.06 ------------ Accuracy: 65.1%\n",
            "Step: 1108 ------------ Loss: 7513.39 ------------ Accuracy: 65.1%\n",
            "Step: 1109 ------------ Loss: 7512.73 ------------ Accuracy: 65.1%\n",
            "Step: 1110 ------------ Loss: 7512.06 ------------ Accuracy: 65.1%\n",
            "Step: 1111 ------------ Loss: 7511.4 ------------ Accuracy: 65.1%\n",
            "Step: 1112 ------------ Loss: 7510.73 ------------ Accuracy: 65.1%\n",
            "Step: 1113 ------------ Loss: 7510.07 ------------ Accuracy: 65.1%\n",
            "Step: 1114 ------------ Loss: 7509.4 ------------ Accuracy: 65.1%\n",
            "Step: 1115 ------------ Loss: 7508.74 ------------ Accuracy: 65.1%\n",
            "Step: 1116 ------------ Loss: 7508.08 ------------ Accuracy: 65.1%\n",
            "Step: 1117 ------------ Loss: 7507.41 ------------ Accuracy: 65.1%\n",
            "Step: 1118 ------------ Loss: 7506.75 ------------ Accuracy: 65.1%\n",
            "Step: 1119 ------------ Loss: 7506.09 ------------ Accuracy: 65.2%\n",
            "Step: 1120 ------------ Loss: 7505.43 ------------ Accuracy: 65.2%\n",
            "Step: 1121 ------------ Loss: 7504.77 ------------ Accuracy: 65.2%\n",
            "Step: 1122 ------------ Loss: 7504.11 ------------ Accuracy: 65.2%\n",
            "Step: 1123 ------------ Loss: 7503.45 ------------ Accuracy: 65.2%\n",
            "Step: 1124 ------------ Loss: 7502.79 ------------ Accuracy: 65.2%\n",
            "Step: 1125 ------------ Loss: 7502.13 ------------ Accuracy: 65.2%\n",
            "Step: 1126 ------------ Loss: 7501.47 ------------ Accuracy: 65.2%\n",
            "Step: 1127 ------------ Loss: 7500.82 ------------ Accuracy: 65.2%\n",
            "Step: 1128 ------------ Loss: 7500.16 ------------ Accuracy: 65.1%\n",
            "Step: 1129 ------------ Loss: 7499.5 ------------ Accuracy: 65.1%\n",
            "Step: 1130 ------------ Loss: 7498.85 ------------ Accuracy: 65.1%\n",
            "Step: 1131 ------------ Loss: 7498.19 ------------ Accuracy: 65.1%\n",
            "Step: 1132 ------------ Loss: 7497.54 ------------ Accuracy: 65.1%\n",
            "Step: 1133 ------------ Loss: 7496.88 ------------ Accuracy: 65.1%\n",
            "Step: 1134 ------------ Loss: 7496.23 ------------ Accuracy: 65.1%\n",
            "Step: 1135 ------------ Loss: 7495.58 ------------ Accuracy: 65.1%\n",
            "Step: 1136 ------------ Loss: 7494.92 ------------ Accuracy: 65.1%\n",
            "Step: 1137 ------------ Loss: 7494.27 ------------ Accuracy: 65.1%\n",
            "Step: 1138 ------------ Loss: 7493.62 ------------ Accuracy: 65.1%\n",
            "Step: 1139 ------------ Loss: 7492.97 ------------ Accuracy: 65.1%\n",
            "Step: 1140 ------------ Loss: 7492.32 ------------ Accuracy: 65.1%\n",
            "Step: 1141 ------------ Loss: 7491.67 ------------ Accuracy: 65.2%\n",
            "Step: 1142 ------------ Loss: 7491.02 ------------ Accuracy: 65.2%\n",
            "Step: 1143 ------------ Loss: 7490.37 ------------ Accuracy: 65.2%\n",
            "Step: 1144 ------------ Loss: 7489.72 ------------ Accuracy: 65.2%\n",
            "Step: 1145 ------------ Loss: 7489.07 ------------ Accuracy: 65.2%\n",
            "Step: 1146 ------------ Loss: 7488.42 ------------ Accuracy: 65.2%\n",
            "Step: 1147 ------------ Loss: 7487.78 ------------ Accuracy: 65.2%\n",
            "Step: 1148 ------------ Loss: 7487.13 ------------ Accuracy: 65.2%\n",
            "Step: 1149 ------------ Loss: 7486.48 ------------ Accuracy: 65.2%\n",
            "Step: 1150 ------------ Loss: 7485.84 ------------ Accuracy: 65.2%\n",
            "Step: 1151 ------------ Loss: 7485.19 ------------ Accuracy: 65.2%\n",
            "Step: 1152 ------------ Loss: 7484.55 ------------ Accuracy: 65.2%\n",
            "Step: 1153 ------------ Loss: 7483.9 ------------ Accuracy: 65.2%\n",
            "Step: 1154 ------------ Loss: 7483.26 ------------ Accuracy: 65.2%\n",
            "Step: 1155 ------------ Loss: 7482.62 ------------ Accuracy: 65.2%\n",
            "Step: 1156 ------------ Loss: 7481.97 ------------ Accuracy: 65.2%\n",
            "Step: 1157 ------------ Loss: 7481.33 ------------ Accuracy: 65.2%\n",
            "Step: 1158 ------------ Loss: 7480.69 ------------ Accuracy: 65.2%\n",
            "Step: 1159 ------------ Loss: 7480.05 ------------ Accuracy: 65.2%\n",
            "Step: 1160 ------------ Loss: 7479.41 ------------ Accuracy: 65.2%\n",
            "Step: 1161 ------------ Loss: 7478.77 ------------ Accuracy: 65.2%\n",
            "Step: 1162 ------------ Loss: 7478.13 ------------ Accuracy: 65.2%\n",
            "Step: 1163 ------------ Loss: 7477.49 ------------ Accuracy: 65.2%\n",
            "Step: 1164 ------------ Loss: 7476.85 ------------ Accuracy: 65.2%\n",
            "Step: 1165 ------------ Loss: 7476.21 ------------ Accuracy: 65.2%\n",
            "Step: 1166 ------------ Loss: 7475.57 ------------ Accuracy: 65.2%\n",
            "Step: 1167 ------------ Loss: 7474.93 ------------ Accuracy: 65.2%\n",
            "Step: 1168 ------------ Loss: 7474.3 ------------ Accuracy: 65.2%\n",
            "Step: 1169 ------------ Loss: 7473.66 ------------ Accuracy: 65.2%\n",
            "Step: 1170 ------------ Loss: 7473.02 ------------ Accuracy: 65.2%\n",
            "Step: 1171 ------------ Loss: 7472.39 ------------ Accuracy: 65.2%\n",
            "Step: 1172 ------------ Loss: 7471.75 ------------ Accuracy: 65.2%\n",
            "Step: 1173 ------------ Loss: 7471.12 ------------ Accuracy: 65.2%\n",
            "Step: 1174 ------------ Loss: 7470.48 ------------ Accuracy: 65.2%\n",
            "Step: 1175 ------------ Loss: 7469.85 ------------ Accuracy: 65.2%\n",
            "Step: 1176 ------------ Loss: 7469.22 ------------ Accuracy: 65.2%\n",
            "Step: 1177 ------------ Loss: 7468.58 ------------ Accuracy: 65.2%\n",
            "Step: 1178 ------------ Loss: 7467.95 ------------ Accuracy: 65.2%\n",
            "Step: 1179 ------------ Loss: 7467.32 ------------ Accuracy: 65.2%\n",
            "Step: 1180 ------------ Loss: 7466.69 ------------ Accuracy: 65.2%\n",
            "Step: 1181 ------------ Loss: 7466.06 ------------ Accuracy: 65.2%\n",
            "Step: 1182 ------------ Loss: 7465.43 ------------ Accuracy: 65.2%\n",
            "Step: 1183 ------------ Loss: 7464.8 ------------ Accuracy: 65.2%\n",
            "Step: 1184 ------------ Loss: 7464.17 ------------ Accuracy: 65.2%\n",
            "Step: 1185 ------------ Loss: 7463.54 ------------ Accuracy: 65.2%\n",
            "Step: 1186 ------------ Loss: 7462.91 ------------ Accuracy: 65.2%\n",
            "Step: 1187 ------------ Loss: 7462.28 ------------ Accuracy: 65.2%\n",
            "Step: 1188 ------------ Loss: 7461.65 ------------ Accuracy: 65.2%\n",
            "Step: 1189 ------------ Loss: 7461.03 ------------ Accuracy: 65.2%\n",
            "Step: 1190 ------------ Loss: 7460.4 ------------ Accuracy: 65.2%\n",
            "Step: 1191 ------------ Loss: 7459.77 ------------ Accuracy: 65.3%\n",
            "Step: 1192 ------------ Loss: 7459.15 ------------ Accuracy: 65.3%\n",
            "Step: 1193 ------------ Loss: 7458.52 ------------ Accuracy: 65.3%\n",
            "Step: 1194 ------------ Loss: 7457.9 ------------ Accuracy: 65.3%\n",
            "Step: 1195 ------------ Loss: 7457.27 ------------ Accuracy: 65.3%\n",
            "Step: 1196 ------------ Loss: 7456.65 ------------ Accuracy: 65.3%\n",
            "Step: 1197 ------------ Loss: 7456.02 ------------ Accuracy: 65.3%\n",
            "Step: 1198 ------------ Loss: 7455.4 ------------ Accuracy: 65.3%\n",
            "Step: 1199 ------------ Loss: 7454.78 ------------ Accuracy: 65.3%\n",
            "Step: 1200 ------------ Loss: 7454.15 ------------ Accuracy: 65.3%\n",
            "Step: 1201 ------------ Loss: 7453.53 ------------ Accuracy: 65.3%\n",
            "Step: 1202 ------------ Loss: 7452.91 ------------ Accuracy: 65.3%\n",
            "Step: 1203 ------------ Loss: 7452.29 ------------ Accuracy: 65.3%\n",
            "Step: 1204 ------------ Loss: 7451.67 ------------ Accuracy: 65.3%\n",
            "Step: 1205 ------------ Loss: 7451.05 ------------ Accuracy: 65.3%\n",
            "Step: 1206 ------------ Loss: 7450.43 ------------ Accuracy: 65.3%\n",
            "Step: 1207 ------------ Loss: 7449.81 ------------ Accuracy: 65.3%\n",
            "Step: 1208 ------------ Loss: 7449.19 ------------ Accuracy: 65.3%\n",
            "Step: 1209 ------------ Loss: 7448.57 ------------ Accuracy: 65.3%\n",
            "Step: 1210 ------------ Loss: 7447.96 ------------ Accuracy: 65.3%\n",
            "Step: 1211 ------------ Loss: 7447.34 ------------ Accuracy: 65.3%\n",
            "Step: 1212 ------------ Loss: 7446.72 ------------ Accuracy: 65.3%\n",
            "Step: 1213 ------------ Loss: 7446.1 ------------ Accuracy: 65.3%\n",
            "Step: 1214 ------------ Loss: 7445.49 ------------ Accuracy: 65.3%\n",
            "Step: 1215 ------------ Loss: 7444.87 ------------ Accuracy: 65.3%\n",
            "Step: 1216 ------------ Loss: 7444.26 ------------ Accuracy: 65.3%\n",
            "Step: 1217 ------------ Loss: 7443.64 ------------ Accuracy: 65.3%\n",
            "Step: 1218 ------------ Loss: 7443.03 ------------ Accuracy: 65.3%\n",
            "Step: 1219 ------------ Loss: 7442.41 ------------ Accuracy: 65.3%\n",
            "Step: 1220 ------------ Loss: 7441.8 ------------ Accuracy: 65.3%\n",
            "Step: 1221 ------------ Loss: 7441.19 ------------ Accuracy: 65.3%\n",
            "Step: 1222 ------------ Loss: 7440.58 ------------ Accuracy: 65.3%\n",
            "Step: 1223 ------------ Loss: 7439.96 ------------ Accuracy: 65.3%\n",
            "Step: 1224 ------------ Loss: 7439.35 ------------ Accuracy: 65.3%\n",
            "Step: 1225 ------------ Loss: 7438.74 ------------ Accuracy: 65.3%\n",
            "Step: 1226 ------------ Loss: 7438.13 ------------ Accuracy: 65.3%\n",
            "Step: 1227 ------------ Loss: 7437.52 ------------ Accuracy: 65.3%\n",
            "Step: 1228 ------------ Loss: 7436.91 ------------ Accuracy: 65.3%\n",
            "Step: 1229 ------------ Loss: 7436.3 ------------ Accuracy: 65.3%\n",
            "Step: 1230 ------------ Loss: 7435.69 ------------ Accuracy: 65.3%\n",
            "Step: 1231 ------------ Loss: 7435.08 ------------ Accuracy: 65.3%\n",
            "Step: 1232 ------------ Loss: 7434.47 ------------ Accuracy: 65.3%\n",
            "Step: 1233 ------------ Loss: 7433.87 ------------ Accuracy: 65.3%\n",
            "Step: 1234 ------------ Loss: 7433.26 ------------ Accuracy: 65.3%\n",
            "Step: 1235 ------------ Loss: 7432.65 ------------ Accuracy: 65.3%\n",
            "Step: 1236 ------------ Loss: 7432.05 ------------ Accuracy: 65.3%\n",
            "Step: 1237 ------------ Loss: 7431.44 ------------ Accuracy: 65.3%\n",
            "Step: 1238 ------------ Loss: 7430.83 ------------ Accuracy: 65.3%\n",
            "Step: 1239 ------------ Loss: 7430.23 ------------ Accuracy: 65.3%\n",
            "Step: 1240 ------------ Loss: 7429.62 ------------ Accuracy: 65.3%\n",
            "Step: 1241 ------------ Loss: 7429.02 ------------ Accuracy: 65.3%\n",
            "Step: 1242 ------------ Loss: 7428.41 ------------ Accuracy: 65.3%\n",
            "Step: 1243 ------------ Loss: 7427.81 ------------ Accuracy: 65.3%\n",
            "Step: 1244 ------------ Loss: 7427.21 ------------ Accuracy: 65.3%\n",
            "Step: 1245 ------------ Loss: 7426.61 ------------ Accuracy: 65.3%\n",
            "Step: 1246 ------------ Loss: 7426.0 ------------ Accuracy: 65.3%\n",
            "Step: 1247 ------------ Loss: 7425.4 ------------ Accuracy: 65.3%\n",
            "Step: 1248 ------------ Loss: 7424.8 ------------ Accuracy: 65.3%\n",
            "Step: 1249 ------------ Loss: 7424.2 ------------ Accuracy: 65.3%\n",
            "Step: 1250 ------------ Loss: 7423.6 ------------ Accuracy: 65.3%\n",
            "Step: 1251 ------------ Loss: 7423.0 ------------ Accuracy: 65.3%\n",
            "Step: 1252 ------------ Loss: 7422.4 ------------ Accuracy: 65.3%\n",
            "Step: 1253 ------------ Loss: 7421.8 ------------ Accuracy: 65.3%\n",
            "Step: 1254 ------------ Loss: 7421.2 ------------ Accuracy: 65.3%\n",
            "Step: 1255 ------------ Loss: 7420.6 ------------ Accuracy: 65.3%\n",
            "Step: 1256 ------------ Loss: 7420.0 ------------ Accuracy: 65.5%\n",
            "Step: 1257 ------------ Loss: 7419.41 ------------ Accuracy: 65.5%\n",
            "Step: 1258 ------------ Loss: 7418.81 ------------ Accuracy: 65.5%\n",
            "Step: 1259 ------------ Loss: 7418.21 ------------ Accuracy: 65.5%\n",
            "Step: 1260 ------------ Loss: 7417.62 ------------ Accuracy: 65.5%\n",
            "Step: 1261 ------------ Loss: 7417.02 ------------ Accuracy: 65.5%\n",
            "Step: 1262 ------------ Loss: 7416.42 ------------ Accuracy: 65.5%\n",
            "Step: 1263 ------------ Loss: 7415.83 ------------ Accuracy: 65.5%\n",
            "Step: 1264 ------------ Loss: 7415.23 ------------ Accuracy: 65.5%\n",
            "Step: 1265 ------------ Loss: 7414.64 ------------ Accuracy: 65.5%\n",
            "Step: 1266 ------------ Loss: 7414.05 ------------ Accuracy: 65.5%\n",
            "Step: 1267 ------------ Loss: 7413.45 ------------ Accuracy: 65.5%\n",
            "Step: 1268 ------------ Loss: 7412.86 ------------ Accuracy: 65.5%\n",
            "Step: 1269 ------------ Loss: 7412.27 ------------ Accuracy: 65.5%\n",
            "Step: 1270 ------------ Loss: 7411.67 ------------ Accuracy: 65.5%\n",
            "Step: 1271 ------------ Loss: 7411.08 ------------ Accuracy: 65.5%\n",
            "Step: 1272 ------------ Loss: 7410.49 ------------ Accuracy: 65.5%\n",
            "Step: 1273 ------------ Loss: 7409.9 ------------ Accuracy: 65.5%\n",
            "Step: 1274 ------------ Loss: 7409.31 ------------ Accuracy: 65.5%\n",
            "Step: 1275 ------------ Loss: 7408.72 ------------ Accuracy: 65.6%\n",
            "Step: 1276 ------------ Loss: 7408.13 ------------ Accuracy: 65.6%\n",
            "Step: 1277 ------------ Loss: 7407.54 ------------ Accuracy: 65.6%\n",
            "Step: 1278 ------------ Loss: 7406.95 ------------ Accuracy: 65.6%\n",
            "Step: 1279 ------------ Loss: 7406.36 ------------ Accuracy: 65.6%\n",
            "Step: 1280 ------------ Loss: 7405.77 ------------ Accuracy: 65.6%\n",
            "Step: 1281 ------------ Loss: 7405.18 ------------ Accuracy: 65.5%\n",
            "Step: 1282 ------------ Loss: 7404.6 ------------ Accuracy: 65.5%\n",
            "Step: 1283 ------------ Loss: 7404.01 ------------ Accuracy: 65.5%\n",
            "Step: 1284 ------------ Loss: 7403.42 ------------ Accuracy: 65.5%\n",
            "Step: 1285 ------------ Loss: 7402.84 ------------ Accuracy: 65.5%\n",
            "Step: 1286 ------------ Loss: 7402.25 ------------ Accuracy: 65.5%\n",
            "Step: 1287 ------------ Loss: 7401.67 ------------ Accuracy: 65.5%\n",
            "Step: 1288 ------------ Loss: 7401.08 ------------ Accuracy: 65.5%\n",
            "Step: 1289 ------------ Loss: 7400.5 ------------ Accuracy: 65.5%\n",
            "Step: 1290 ------------ Loss: 7399.91 ------------ Accuracy: 65.5%\n",
            "Step: 1291 ------------ Loss: 7399.33 ------------ Accuracy: 65.5%\n",
            "Step: 1292 ------------ Loss: 7398.74 ------------ Accuracy: 65.5%\n",
            "Step: 1293 ------------ Loss: 7398.16 ------------ Accuracy: 65.5%\n",
            "Step: 1294 ------------ Loss: 7397.58 ------------ Accuracy: 65.5%\n",
            "Step: 1295 ------------ Loss: 7397.0 ------------ Accuracy: 65.5%\n",
            "Step: 1296 ------------ Loss: 7396.41 ------------ Accuracy: 65.5%\n",
            "Step: 1297 ------------ Loss: 7395.83 ------------ Accuracy: 65.5%\n",
            "Step: 1298 ------------ Loss: 7395.25 ------------ Accuracy: 65.5%\n",
            "Step: 1299 ------------ Loss: 7394.67 ------------ Accuracy: 65.5%\n",
            "Step: 1300 ------------ Loss: 7394.09 ------------ Accuracy: 65.5%\n",
            "Step: 1301 ------------ Loss: 7393.51 ------------ Accuracy: 65.5%\n",
            "Step: 1302 ------------ Loss: 7392.93 ------------ Accuracy: 65.5%\n",
            "Step: 1303 ------------ Loss: 7392.35 ------------ Accuracy: 65.5%\n",
            "Step: 1304 ------------ Loss: 7391.77 ------------ Accuracy: 65.6%\n",
            "Step: 1305 ------------ Loss: 7391.2 ------------ Accuracy: 65.6%\n",
            "Step: 1306 ------------ Loss: 7390.62 ------------ Accuracy: 65.6%\n",
            "Step: 1307 ------------ Loss: 7390.04 ------------ Accuracy: 65.6%\n",
            "Step: 1308 ------------ Loss: 7389.46 ------------ Accuracy: 65.6%\n",
            "Step: 1309 ------------ Loss: 7388.89 ------------ Accuracy: 65.6%\n",
            "Step: 1310 ------------ Loss: 7388.31 ------------ Accuracy: 65.6%\n",
            "Step: 1311 ------------ Loss: 7387.73 ------------ Accuracy: 65.6%\n",
            "Step: 1312 ------------ Loss: 7387.16 ------------ Accuracy: 65.6%\n",
            "Step: 1313 ------------ Loss: 7386.58 ------------ Accuracy: 65.6%\n",
            "Step: 1314 ------------ Loss: 7386.01 ------------ Accuracy: 65.6%\n",
            "Step: 1315 ------------ Loss: 7385.43 ------------ Accuracy: 65.6%\n",
            "Step: 1316 ------------ Loss: 7384.86 ------------ Accuracy: 65.6%\n",
            "Step: 1317 ------------ Loss: 7384.29 ------------ Accuracy: 65.6%\n",
            "Step: 1318 ------------ Loss: 7383.71 ------------ Accuracy: 65.6%\n",
            "Step: 1319 ------------ Loss: 7383.14 ------------ Accuracy: 65.6%\n",
            "Step: 1320 ------------ Loss: 7382.57 ------------ Accuracy: 65.6%\n",
            "Step: 1321 ------------ Loss: 7381.99 ------------ Accuracy: 65.6%\n",
            "Step: 1322 ------------ Loss: 7381.42 ------------ Accuracy: 65.6%\n",
            "Step: 1323 ------------ Loss: 7380.85 ------------ Accuracy: 65.7%\n",
            "Step: 1324 ------------ Loss: 7380.28 ------------ Accuracy: 65.7%\n",
            "Step: 1325 ------------ Loss: 7379.71 ------------ Accuracy: 65.7%\n",
            "Step: 1326 ------------ Loss: 7379.14 ------------ Accuracy: 65.7%\n",
            "Step: 1327 ------------ Loss: 7378.57 ------------ Accuracy: 65.7%\n",
            "Step: 1328 ------------ Loss: 7378.0 ------------ Accuracy: 65.7%\n",
            "Step: 1329 ------------ Loss: 7377.43 ------------ Accuracy: 65.7%\n",
            "Step: 1330 ------------ Loss: 7376.86 ------------ Accuracy: 65.8%\n",
            "Step: 1331 ------------ Loss: 7376.29 ------------ Accuracy: 65.8%\n",
            "Step: 1332 ------------ Loss: 7375.73 ------------ Accuracy: 65.8%\n",
            "Step: 1333 ------------ Loss: 7375.16 ------------ Accuracy: 65.8%\n",
            "Step: 1334 ------------ Loss: 7374.59 ------------ Accuracy: 65.8%\n",
            "Step: 1335 ------------ Loss: 7374.02 ------------ Accuracy: 65.8%\n",
            "Step: 1336 ------------ Loss: 7373.46 ------------ Accuracy: 65.8%\n",
            "Step: 1337 ------------ Loss: 7372.89 ------------ Accuracy: 65.8%\n",
            "Step: 1338 ------------ Loss: 7372.33 ------------ Accuracy: 65.8%\n",
            "Step: 1339 ------------ Loss: 7371.76 ------------ Accuracy: 65.8%\n",
            "Step: 1340 ------------ Loss: 7371.2 ------------ Accuracy: 65.8%\n",
            "Step: 1341 ------------ Loss: 7370.63 ------------ Accuracy: 65.8%\n",
            "Step: 1342 ------------ Loss: 7370.07 ------------ Accuracy: 65.8%\n",
            "Step: 1343 ------------ Loss: 7369.5 ------------ Accuracy: 65.8%\n",
            "Step: 1344 ------------ Loss: 7368.94 ------------ Accuracy: 65.8%\n",
            "Step: 1345 ------------ Loss: 7368.38 ------------ Accuracy: 65.8%\n",
            "Step: 1346 ------------ Loss: 7367.81 ------------ Accuracy: 65.8%\n",
            "Step: 1347 ------------ Loss: 7367.25 ------------ Accuracy: 65.9%\n",
            "Step: 1348 ------------ Loss: 7366.69 ------------ Accuracy: 65.9%\n",
            "Step: 1349 ------------ Loss: 7366.13 ------------ Accuracy: 65.9%\n",
            "Step: 1350 ------------ Loss: 7365.57 ------------ Accuracy: 65.9%\n",
            "Step: 1351 ------------ Loss: 7365.01 ------------ Accuracy: 65.9%\n",
            "Step: 1352 ------------ Loss: 7364.45 ------------ Accuracy: 65.9%\n",
            "Step: 1353 ------------ Loss: 7363.89 ------------ Accuracy: 65.9%\n",
            "Step: 1354 ------------ Loss: 7363.33 ------------ Accuracy: 65.9%\n",
            "Step: 1355 ------------ Loss: 7362.77 ------------ Accuracy: 65.9%\n",
            "Step: 1356 ------------ Loss: 7362.21 ------------ Accuracy: 65.9%\n",
            "Step: 1357 ------------ Loss: 7361.65 ------------ Accuracy: 65.9%\n",
            "Step: 1358 ------------ Loss: 7361.09 ------------ Accuracy: 65.9%\n",
            "Step: 1359 ------------ Loss: 7360.53 ------------ Accuracy: 65.9%\n",
            "Step: 1360 ------------ Loss: 7359.98 ------------ Accuracy: 65.9%\n",
            "Step: 1361 ------------ Loss: 7359.42 ------------ Accuracy: 65.9%\n",
            "Step: 1362 ------------ Loss: 7358.86 ------------ Accuracy: 65.9%\n",
            "Step: 1363 ------------ Loss: 7358.3 ------------ Accuracy: 65.9%\n",
            "Step: 1364 ------------ Loss: 7357.75 ------------ Accuracy: 65.9%\n",
            "Step: 1365 ------------ Loss: 7357.19 ------------ Accuracy: 65.9%\n",
            "Step: 1366 ------------ Loss: 7356.64 ------------ Accuracy: 65.9%\n",
            "Step: 1367 ------------ Loss: 7356.08 ------------ Accuracy: 65.9%\n",
            "Step: 1368 ------------ Loss: 7355.53 ------------ Accuracy: 65.9%\n",
            "Step: 1369 ------------ Loss: 7354.97 ------------ Accuracy: 65.9%\n",
            "Step: 1370 ------------ Loss: 7354.42 ------------ Accuracy: 65.9%\n",
            "Step: 1371 ------------ Loss: 7353.87 ------------ Accuracy: 65.9%\n",
            "Step: 1372 ------------ Loss: 7353.31 ------------ Accuracy: 65.9%\n",
            "Step: 1373 ------------ Loss: 7352.76 ------------ Accuracy: 65.9%\n",
            "Step: 1374 ------------ Loss: 7352.21 ------------ Accuracy: 65.9%\n",
            "Step: 1375 ------------ Loss: 7351.66 ------------ Accuracy: 65.9%\n",
            "Step: 1376 ------------ Loss: 7351.1 ------------ Accuracy: 65.9%\n",
            "Step: 1377 ------------ Loss: 7350.55 ------------ Accuracy: 65.9%\n",
            "Step: 1378 ------------ Loss: 7350.0 ------------ Accuracy: 65.9%\n",
            "Step: 1379 ------------ Loss: 7349.45 ------------ Accuracy: 65.9%\n",
            "Step: 1380 ------------ Loss: 7348.9 ------------ Accuracy: 65.9%\n",
            "Step: 1381 ------------ Loss: 7348.35 ------------ Accuracy: 65.9%\n",
            "Step: 1382 ------------ Loss: 7347.8 ------------ Accuracy: 65.9%\n",
            "Step: 1383 ------------ Loss: 7347.25 ------------ Accuracy: 65.9%\n",
            "Step: 1384 ------------ Loss: 7346.7 ------------ Accuracy: 65.9%\n",
            "Step: 1385 ------------ Loss: 7346.15 ------------ Accuracy: 65.9%\n",
            "Step: 1386 ------------ Loss: 7345.61 ------------ Accuracy: 65.9%\n",
            "Step: 1387 ------------ Loss: 7345.06 ------------ Accuracy: 65.8%\n",
            "Step: 1388 ------------ Loss: 7344.51 ------------ Accuracy: 65.8%\n",
            "Step: 1389 ------------ Loss: 7343.96 ------------ Accuracy: 65.8%\n",
            "Step: 1390 ------------ Loss: 7343.42 ------------ Accuracy: 65.8%\n",
            "Step: 1391 ------------ Loss: 7342.87 ------------ Accuracy: 65.8%\n",
            "Step: 1392 ------------ Loss: 7342.32 ------------ Accuracy: 65.8%\n",
            "Step: 1393 ------------ Loss: 7341.78 ------------ Accuracy: 65.8%\n",
            "Step: 1394 ------------ Loss: 7341.23 ------------ Accuracy: 65.8%\n",
            "Step: 1395 ------------ Loss: 7340.69 ------------ Accuracy: 65.8%\n",
            "Step: 1396 ------------ Loss: 7340.14 ------------ Accuracy: 65.8%\n",
            "Step: 1397 ------------ Loss: 7339.6 ------------ Accuracy: 65.8%\n",
            "Step: 1398 ------------ Loss: 7339.06 ------------ Accuracy: 65.8%\n",
            "Step: 1399 ------------ Loss: 7338.51 ------------ Accuracy: 65.8%\n",
            "Step: 1400 ------------ Loss: 7337.97 ------------ Accuracy: 65.8%\n",
            "Step: 1401 ------------ Loss: 7337.43 ------------ Accuracy: 65.8%\n",
            "Step: 1402 ------------ Loss: 7336.88 ------------ Accuracy: 65.8%\n",
            "Step: 1403 ------------ Loss: 7336.34 ------------ Accuracy: 65.8%\n",
            "Step: 1404 ------------ Loss: 7335.8 ------------ Accuracy: 65.8%\n",
            "Step: 1405 ------------ Loss: 7335.26 ------------ Accuracy: 65.8%\n",
            "Step: 1406 ------------ Loss: 7334.72 ------------ Accuracy: 65.8%\n",
            "Step: 1407 ------------ Loss: 7334.18 ------------ Accuracy: 65.8%\n",
            "Step: 1408 ------------ Loss: 7333.64 ------------ Accuracy: 65.8%\n",
            "Step: 1409 ------------ Loss: 7333.1 ------------ Accuracy: 66.0%\n",
            "Step: 1410 ------------ Loss: 7332.56 ------------ Accuracy: 66.0%\n",
            "Step: 1411 ------------ Loss: 7332.02 ------------ Accuracy: 66.0%\n",
            "Step: 1412 ------------ Loss: 7331.48 ------------ Accuracy: 66.0%\n",
            "Step: 1413 ------------ Loss: 7330.94 ------------ Accuracy: 66.0%\n",
            "Step: 1414 ------------ Loss: 7330.4 ------------ Accuracy: 66.0%\n",
            "Step: 1415 ------------ Loss: 7329.86 ------------ Accuracy: 66.0%\n",
            "Step: 1416 ------------ Loss: 7329.33 ------------ Accuracy: 66.0%\n",
            "Step: 1417 ------------ Loss: 7328.79 ------------ Accuracy: 66.0%\n",
            "Step: 1418 ------------ Loss: 7328.25 ------------ Accuracy: 66.0%\n",
            "Step: 1419 ------------ Loss: 7327.72 ------------ Accuracy: 66.0%\n",
            "Step: 1420 ------------ Loss: 7327.18 ------------ Accuracy: 66.0%\n",
            "Step: 1421 ------------ Loss: 7326.64 ------------ Accuracy: 66.0%\n",
            "Step: 1422 ------------ Loss: 7326.11 ------------ Accuracy: 66.0%\n",
            "Step: 1423 ------------ Loss: 7325.57 ------------ Accuracy: 66.0%\n",
            "Step: 1424 ------------ Loss: 7325.04 ------------ Accuracy: 66.0%\n",
            "Step: 1425 ------------ Loss: 7324.5 ------------ Accuracy: 66.0%\n",
            "Step: 1426 ------------ Loss: 7323.97 ------------ Accuracy: 66.0%\n",
            "Step: 1427 ------------ Loss: 7323.43 ------------ Accuracy: 66.0%\n",
            "Step: 1428 ------------ Loss: 7322.9 ------------ Accuracy: 66.0%\n",
            "Step: 1429 ------------ Loss: 7322.37 ------------ Accuracy: 66.0%\n",
            "Step: 1430 ------------ Loss: 7321.84 ------------ Accuracy: 66.0%\n",
            "Step: 1431 ------------ Loss: 7321.3 ------------ Accuracy: 66.0%\n",
            "Step: 1432 ------------ Loss: 7320.77 ------------ Accuracy: 66.0%\n",
            "Step: 1433 ------------ Loss: 7320.24 ------------ Accuracy: 66.0%\n",
            "Step: 1434 ------------ Loss: 7319.71 ------------ Accuracy: 66.0%\n",
            "Step: 1435 ------------ Loss: 7319.18 ------------ Accuracy: 66.0%\n",
            "Step: 1436 ------------ Loss: 7318.65 ------------ Accuracy: 66.0%\n",
            "Step: 1437 ------------ Loss: 7318.12 ------------ Accuracy: 66.0%\n",
            "Step: 1438 ------------ Loss: 7317.58 ------------ Accuracy: 66.1%\n",
            "Step: 1439 ------------ Loss: 7317.06 ------------ Accuracy: 66.1%\n",
            "Step: 1440 ------------ Loss: 7316.53 ------------ Accuracy: 66.1%\n",
            "Step: 1441 ------------ Loss: 7316.0 ------------ Accuracy: 66.1%\n",
            "Step: 1442 ------------ Loss: 7315.47 ------------ Accuracy: 66.1%\n",
            "Step: 1443 ------------ Loss: 7314.94 ------------ Accuracy: 66.1%\n",
            "Step: 1444 ------------ Loss: 7314.41 ------------ Accuracy: 66.1%\n",
            "Step: 1445 ------------ Loss: 7313.88 ------------ Accuracy: 66.1%\n",
            "Step: 1446 ------------ Loss: 7313.36 ------------ Accuracy: 66.1%\n",
            "Step: 1447 ------------ Loss: 7312.83 ------------ Accuracy: 66.1%\n",
            "Step: 1448 ------------ Loss: 7312.3 ------------ Accuracy: 66.1%\n",
            "Step: 1449 ------------ Loss: 7311.78 ------------ Accuracy: 66.1%\n",
            "Step: 1450 ------------ Loss: 7311.25 ------------ Accuracy: 66.1%\n",
            "Step: 1451 ------------ Loss: 7310.72 ------------ Accuracy: 66.1%\n",
            "Step: 1452 ------------ Loss: 7310.2 ------------ Accuracy: 66.1%\n",
            "Step: 1453 ------------ Loss: 7309.67 ------------ Accuracy: 66.1%\n",
            "Step: 1454 ------------ Loss: 7309.15 ------------ Accuracy: 66.1%\n",
            "Step: 1455 ------------ Loss: 7308.62 ------------ Accuracy: 66.1%\n",
            "Step: 1456 ------------ Loss: 7308.1 ------------ Accuracy: 66.1%\n",
            "Step: 1457 ------------ Loss: 7307.58 ------------ Accuracy: 66.1%\n",
            "Step: 1458 ------------ Loss: 7307.05 ------------ Accuracy: 66.1%\n",
            "Step: 1459 ------------ Loss: 7306.53 ------------ Accuracy: 66.1%\n",
            "Step: 1460 ------------ Loss: 7306.01 ------------ Accuracy: 66.1%\n",
            "Step: 1461 ------------ Loss: 7305.49 ------------ Accuracy: 66.1%\n",
            "Step: 1462 ------------ Loss: 7304.96 ------------ Accuracy: 66.1%\n",
            "Step: 1463 ------------ Loss: 7304.44 ------------ Accuracy: 66.1%\n",
            "Step: 1464 ------------ Loss: 7303.92 ------------ Accuracy: 66.1%\n",
            "Step: 1465 ------------ Loss: 7303.4 ------------ Accuracy: 66.0%\n",
            "Step: 1466 ------------ Loss: 7302.88 ------------ Accuracy: 66.0%\n",
            "Step: 1467 ------------ Loss: 7302.36 ------------ Accuracy: 66.0%\n",
            "Step: 1468 ------------ Loss: 7301.84 ------------ Accuracy: 66.0%\n",
            "Step: 1469 ------------ Loss: 7301.32 ------------ Accuracy: 66.0%\n",
            "Step: 1470 ------------ Loss: 7300.8 ------------ Accuracy: 66.0%\n",
            "Step: 1471 ------------ Loss: 7300.28 ------------ Accuracy: 66.0%\n",
            "Step: 1472 ------------ Loss: 7299.76 ------------ Accuracy: 66.0%\n",
            "Step: 1473 ------------ Loss: 7299.24 ------------ Accuracy: 66.0%\n",
            "Step: 1474 ------------ Loss: 7298.72 ------------ Accuracy: 66.1%\n",
            "Step: 1475 ------------ Loss: 7298.21 ------------ Accuracy: 66.1%\n",
            "Step: 1476 ------------ Loss: 7297.69 ------------ Accuracy: 66.1%\n",
            "Step: 1477 ------------ Loss: 7297.17 ------------ Accuracy: 66.1%\n",
            "Step: 1478 ------------ Loss: 7296.66 ------------ Accuracy: 66.1%\n",
            "Step: 1479 ------------ Loss: 7296.14 ------------ Accuracy: 66.1%\n",
            "Step: 1480 ------------ Loss: 7295.62 ------------ Accuracy: 66.1%\n",
            "Step: 1481 ------------ Loss: 7295.11 ------------ Accuracy: 66.1%\n",
            "Step: 1482 ------------ Loss: 7294.59 ------------ Accuracy: 66.1%\n",
            "Step: 1483 ------------ Loss: 7294.08 ------------ Accuracy: 66.1%\n",
            "Step: 1484 ------------ Loss: 7293.56 ------------ Accuracy: 66.1%\n",
            "Step: 1485 ------------ Loss: 7293.05 ------------ Accuracy: 66.1%\n",
            "Step: 1486 ------------ Loss: 7292.53 ------------ Accuracy: 66.1%\n",
            "Step: 1487 ------------ Loss: 7292.02 ------------ Accuracy: 66.1%\n",
            "Step: 1488 ------------ Loss: 7291.51 ------------ Accuracy: 66.1%\n",
            "Step: 1489 ------------ Loss: 7290.99 ------------ Accuracy: 66.1%\n",
            "Step: 1490 ------------ Loss: 7290.48 ------------ Accuracy: 66.1%\n",
            "Step: 1491 ------------ Loss: 7289.97 ------------ Accuracy: 66.1%\n",
            "Step: 1492 ------------ Loss: 7289.45 ------------ Accuracy: 66.1%\n",
            "Step: 1493 ------------ Loss: 7288.94 ------------ Accuracy: 66.1%\n",
            "Step: 1494 ------------ Loss: 7288.43 ------------ Accuracy: 66.1%\n",
            "Step: 1495 ------------ Loss: 7287.92 ------------ Accuracy: 66.1%\n",
            "Step: 1496 ------------ Loss: 7287.41 ------------ Accuracy: 66.1%\n",
            "Step: 1497 ------------ Loss: 7286.9 ------------ Accuracy: 66.1%\n",
            "Step: 1498 ------------ Loss: 7286.39 ------------ Accuracy: 66.1%\n",
            "Step: 1499 ------------ Loss: 7285.88 ------------ Accuracy: 66.1%\n",
            "Step: 1500 ------------ Loss: 7285.37 ------------ Accuracy: 66.1%\n",
            "Step: 1501 ------------ Loss: 7284.86 ------------ Accuracy: 66.1%\n",
            "Step: 1502 ------------ Loss: 7284.35 ------------ Accuracy: 66.1%\n",
            "Step: 1503 ------------ Loss: 7283.84 ------------ Accuracy: 66.1%\n",
            "Step: 1504 ------------ Loss: 7283.33 ------------ Accuracy: 66.1%\n",
            "Step: 1505 ------------ Loss: 7282.82 ------------ Accuracy: 66.1%\n",
            "Step: 1506 ------------ Loss: 7282.32 ------------ Accuracy: 66.1%\n",
            "Step: 1507 ------------ Loss: 7281.81 ------------ Accuracy: 66.1%\n",
            "Step: 1508 ------------ Loss: 7281.3 ------------ Accuracy: 66.1%\n",
            "Step: 1509 ------------ Loss: 7280.79 ------------ Accuracy: 66.1%\n",
            "Step: 1510 ------------ Loss: 7280.29 ------------ Accuracy: 66.1%\n",
            "Step: 1511 ------------ Loss: 7279.78 ------------ Accuracy: 66.1%\n",
            "Step: 1512 ------------ Loss: 7279.28 ------------ Accuracy: 66.1%\n",
            "Step: 1513 ------------ Loss: 7278.77 ------------ Accuracy: 66.1%\n",
            "Step: 1514 ------------ Loss: 7278.27 ------------ Accuracy: 66.1%\n",
            "Step: 1515 ------------ Loss: 7277.76 ------------ Accuracy: 66.1%\n",
            "Step: 1516 ------------ Loss: 7277.26 ------------ Accuracy: 66.1%\n",
            "Step: 1517 ------------ Loss: 7276.75 ------------ Accuracy: 66.1%\n",
            "Step: 1518 ------------ Loss: 7276.25 ------------ Accuracy: 66.1%\n",
            "Step: 1519 ------------ Loss: 7275.74 ------------ Accuracy: 66.1%\n",
            "Step: 1520 ------------ Loss: 7275.24 ------------ Accuracy: 66.1%\n",
            "Step: 1521 ------------ Loss: 7274.74 ------------ Accuracy: 66.1%\n",
            "Step: 1522 ------------ Loss: 7274.23 ------------ Accuracy: 66.1%\n",
            "Step: 1523 ------------ Loss: 7273.73 ------------ Accuracy: 66.1%\n",
            "Step: 1524 ------------ Loss: 7273.23 ------------ Accuracy: 66.1%\n",
            "Step: 1525 ------------ Loss: 7272.73 ------------ Accuracy: 66.1%\n",
            "Step: 1526 ------------ Loss: 7272.23 ------------ Accuracy: 66.1%\n",
            "Step: 1527 ------------ Loss: 7271.73 ------------ Accuracy: 66.2%\n",
            "Step: 1528 ------------ Loss: 7271.22 ------------ Accuracy: 66.2%\n",
            "Step: 1529 ------------ Loss: 7270.72 ------------ Accuracy: 66.2%\n",
            "Step: 1530 ------------ Loss: 7270.22 ------------ Accuracy: 66.2%\n",
            "Step: 1531 ------------ Loss: 7269.72 ------------ Accuracy: 66.2%\n",
            "Step: 1532 ------------ Loss: 7269.22 ------------ Accuracy: 66.2%\n",
            "Step: 1533 ------------ Loss: 7268.72 ------------ Accuracy: 66.2%\n",
            "Step: 1534 ------------ Loss: 7268.23 ------------ Accuracy: 66.2%\n",
            "Step: 1535 ------------ Loss: 7267.73 ------------ Accuracy: 66.2%\n",
            "Step: 1536 ------------ Loss: 7267.23 ------------ Accuracy: 66.2%\n",
            "Step: 1537 ------------ Loss: 7266.73 ------------ Accuracy: 66.2%\n",
            "Step: 1538 ------------ Loss: 7266.23 ------------ Accuracy: 66.2%\n",
            "Step: 1539 ------------ Loss: 7265.74 ------------ Accuracy: 66.2%\n",
            "Step: 1540 ------------ Loss: 7265.24 ------------ Accuracy: 66.2%\n",
            "Step: 1541 ------------ Loss: 7264.74 ------------ Accuracy: 66.2%\n",
            "Step: 1542 ------------ Loss: 7264.25 ------------ Accuracy: 66.2%\n",
            "Step: 1543 ------------ Loss: 7263.75 ------------ Accuracy: 66.2%\n",
            "Step: 1544 ------------ Loss: 7263.25 ------------ Accuracy: 66.2%\n",
            "Step: 1545 ------------ Loss: 7262.76 ------------ Accuracy: 66.2%\n",
            "Step: 1546 ------------ Loss: 7262.26 ------------ Accuracy: 66.2%\n",
            "Step: 1547 ------------ Loss: 7261.77 ------------ Accuracy: 66.2%\n",
            "Step: 1548 ------------ Loss: 7261.27 ------------ Accuracy: 66.2%\n",
            "Step: 1549 ------------ Loss: 7260.78 ------------ Accuracy: 66.2%\n",
            "Step: 1550 ------------ Loss: 7260.28 ------------ Accuracy: 66.2%\n",
            "Step: 1551 ------------ Loss: 7259.79 ------------ Accuracy: 66.2%\n",
            "Step: 1552 ------------ Loss: 7259.3 ------------ Accuracy: 66.2%\n",
            "Step: 1553 ------------ Loss: 7258.8 ------------ Accuracy: 66.2%\n",
            "Step: 1554 ------------ Loss: 7258.31 ------------ Accuracy: 66.2%\n",
            "Step: 1555 ------------ Loss: 7257.82 ------------ Accuracy: 66.2%\n",
            "Step: 1556 ------------ Loss: 7257.33 ------------ Accuracy: 66.2%\n",
            "Step: 1557 ------------ Loss: 7256.83 ------------ Accuracy: 66.2%\n",
            "Step: 1558 ------------ Loss: 7256.34 ------------ Accuracy: 66.2%\n",
            "Step: 1559 ------------ Loss: 7255.85 ------------ Accuracy: 66.2%\n",
            "Step: 1560 ------------ Loss: 7255.36 ------------ Accuracy: 66.2%\n",
            "Step: 1561 ------------ Loss: 7254.87 ------------ Accuracy: 66.2%\n",
            "Step: 1562 ------------ Loss: 7254.38 ------------ Accuracy: 66.2%\n",
            "Step: 1563 ------------ Loss: 7253.89 ------------ Accuracy: 66.2%\n",
            "Step: 1564 ------------ Loss: 7253.4 ------------ Accuracy: 66.2%\n",
            "Step: 1565 ------------ Loss: 7252.91 ------------ Accuracy: 66.2%\n",
            "Step: 1566 ------------ Loss: 7252.42 ------------ Accuracy: 66.2%\n",
            "Step: 1567 ------------ Loss: 7251.93 ------------ Accuracy: 66.2%\n",
            "Step: 1568 ------------ Loss: 7251.44 ------------ Accuracy: 66.2%\n",
            "Step: 1569 ------------ Loss: 7250.96 ------------ Accuracy: 66.2%\n",
            "Step: 1570 ------------ Loss: 7250.47 ------------ Accuracy: 66.2%\n",
            "Step: 1571 ------------ Loss: 7249.98 ------------ Accuracy: 66.2%\n",
            "Step: 1572 ------------ Loss: 7249.49 ------------ Accuracy: 66.2%\n",
            "Step: 1573 ------------ Loss: 7249.01 ------------ Accuracy: 66.2%\n",
            "Step: 1574 ------------ Loss: 7248.52 ------------ Accuracy: 66.2%\n",
            "Step: 1575 ------------ Loss: 7248.03 ------------ Accuracy: 66.2%\n",
            "Step: 1576 ------------ Loss: 7247.55 ------------ Accuracy: 66.2%\n",
            "Step: 1577 ------------ Loss: 7247.06 ------------ Accuracy: 66.2%\n",
            "Step: 1578 ------------ Loss: 7246.57 ------------ Accuracy: 66.2%\n",
            "Step: 1579 ------------ Loss: 7246.09 ------------ Accuracy: 66.2%\n",
            "Step: 1580 ------------ Loss: 7245.6 ------------ Accuracy: 66.2%\n",
            "Step: 1581 ------------ Loss: 7245.12 ------------ Accuracy: 66.1%\n",
            "Step: 1582 ------------ Loss: 7244.63 ------------ Accuracy: 66.1%\n",
            "Step: 1583 ------------ Loss: 7244.15 ------------ Accuracy: 66.1%\n",
            "Step: 1584 ------------ Loss: 7243.67 ------------ Accuracy: 66.1%\n",
            "Step: 1585 ------------ Loss: 7243.18 ------------ Accuracy: 66.1%\n",
            "Step: 1586 ------------ Loss: 7242.7 ------------ Accuracy: 66.1%\n",
            "Step: 1587 ------------ Loss: 7242.22 ------------ Accuracy: 66.1%\n",
            "Step: 1588 ------------ Loss: 7241.73 ------------ Accuracy: 66.1%\n",
            "Step: 1589 ------------ Loss: 7241.25 ------------ Accuracy: 66.1%\n",
            "Step: 1590 ------------ Loss: 7240.77 ------------ Accuracy: 66.1%\n",
            "Step: 1591 ------------ Loss: 7240.29 ------------ Accuracy: 66.1%\n",
            "Step: 1592 ------------ Loss: 7239.81 ------------ Accuracy: 66.1%\n",
            "Step: 1593 ------------ Loss: 7239.33 ------------ Accuracy: 66.1%\n",
            "Step: 1594 ------------ Loss: 7238.85 ------------ Accuracy: 66.0%\n",
            "Step: 1595 ------------ Loss: 7238.37 ------------ Accuracy: 66.0%\n",
            "Step: 1596 ------------ Loss: 7237.88 ------------ Accuracy: 66.0%\n",
            "Step: 1597 ------------ Loss: 7237.4 ------------ Accuracy: 66.1%\n",
            "Step: 1598 ------------ Loss: 7236.93 ------------ Accuracy: 66.1%\n",
            "Step: 1599 ------------ Loss: 7236.45 ------------ Accuracy: 66.1%\n",
            "Step: 1600 ------------ Loss: 7235.97 ------------ Accuracy: 66.1%\n",
            "Step: 1601 ------------ Loss: 7235.49 ------------ Accuracy: 66.1%\n",
            "Step: 1602 ------------ Loss: 7235.01 ------------ Accuracy: 66.1%\n",
            "Step: 1603 ------------ Loss: 7234.53 ------------ Accuracy: 66.1%\n",
            "Step: 1604 ------------ Loss: 7234.05 ------------ Accuracy: 66.1%\n",
            "Step: 1605 ------------ Loss: 7233.58 ------------ Accuracy: 66.1%\n",
            "Step: 1606 ------------ Loss: 7233.1 ------------ Accuracy: 66.1%\n",
            "Step: 1607 ------------ Loss: 7232.62 ------------ Accuracy: 66.1%\n",
            "Step: 1608 ------------ Loss: 7232.15 ------------ Accuracy: 66.1%\n",
            "Step: 1609 ------------ Loss: 7231.67 ------------ Accuracy: 66.1%\n",
            "Step: 1610 ------------ Loss: 7231.19 ------------ Accuracy: 66.1%\n",
            "Step: 1611 ------------ Loss: 7230.72 ------------ Accuracy: 66.1%\n",
            "Step: 1612 ------------ Loss: 7230.24 ------------ Accuracy: 66.1%\n",
            "Step: 1613 ------------ Loss: 7229.77 ------------ Accuracy: 66.1%\n",
            "Step: 1614 ------------ Loss: 7229.29 ------------ Accuracy: 66.1%\n",
            "Step: 1615 ------------ Loss: 7228.82 ------------ Accuracy: 66.1%\n",
            "Step: 1616 ------------ Loss: 7228.34 ------------ Accuracy: 66.1%\n",
            "Step: 1617 ------------ Loss: 7227.87 ------------ Accuracy: 66.1%\n",
            "Step: 1618 ------------ Loss: 7227.39 ------------ Accuracy: 66.1%\n",
            "Step: 1619 ------------ Loss: 7226.92 ------------ Accuracy: 66.1%\n",
            "Step: 1620 ------------ Loss: 7226.45 ------------ Accuracy: 66.1%\n",
            "Step: 1621 ------------ Loss: 7225.97 ------------ Accuracy: 66.0%\n",
            "Step: 1622 ------------ Loss: 7225.5 ------------ Accuracy: 66.0%\n",
            "Step: 1623 ------------ Loss: 7225.03 ------------ Accuracy: 66.0%\n",
            "Step: 1624 ------------ Loss: 7224.56 ------------ Accuracy: 66.0%\n",
            "Step: 1625 ------------ Loss: 7224.09 ------------ Accuracy: 66.0%\n",
            "Step: 1626 ------------ Loss: 7223.61 ------------ Accuracy: 66.0%\n",
            "Step: 1627 ------------ Loss: 7223.14 ------------ Accuracy: 66.0%\n",
            "Step: 1628 ------------ Loss: 7222.67 ------------ Accuracy: 66.0%\n",
            "Step: 1629 ------------ Loss: 7222.2 ------------ Accuracy: 66.0%\n",
            "Step: 1630 ------------ Loss: 7221.73 ------------ Accuracy: 66.0%\n",
            "Step: 1631 ------------ Loss: 7221.26 ------------ Accuracy: 66.0%\n",
            "Step: 1632 ------------ Loss: 7220.79 ------------ Accuracy: 66.0%\n",
            "Step: 1633 ------------ Loss: 7220.32 ------------ Accuracy: 66.0%\n",
            "Step: 1634 ------------ Loss: 7219.85 ------------ Accuracy: 66.0%\n",
            "Step: 1635 ------------ Loss: 7219.38 ------------ Accuracy: 66.0%\n",
            "Step: 1636 ------------ Loss: 7218.92 ------------ Accuracy: 66.1%\n",
            "Step: 1637 ------------ Loss: 7218.45 ------------ Accuracy: 66.1%\n",
            "Step: 1638 ------------ Loss: 7217.98 ------------ Accuracy: 66.1%\n",
            "Step: 1639 ------------ Loss: 7217.51 ------------ Accuracy: 66.1%\n",
            "Step: 1640 ------------ Loss: 7217.04 ------------ Accuracy: 66.1%\n",
            "Step: 1641 ------------ Loss: 7216.58 ------------ Accuracy: 66.1%\n",
            "Step: 1642 ------------ Loss: 7216.11 ------------ Accuracy: 66.1%\n",
            "Step: 1643 ------------ Loss: 7215.64 ------------ Accuracy: 66.1%\n",
            "Step: 1644 ------------ Loss: 7215.18 ------------ Accuracy: 66.1%\n",
            "Step: 1645 ------------ Loss: 7214.71 ------------ Accuracy: 66.1%\n",
            "Step: 1646 ------------ Loss: 7214.24 ------------ Accuracy: 66.1%\n",
            "Step: 1647 ------------ Loss: 7213.78 ------------ Accuracy: 66.1%\n",
            "Step: 1648 ------------ Loss: 7213.31 ------------ Accuracy: 66.1%\n",
            "Step: 1649 ------------ Loss: 7212.85 ------------ Accuracy: 66.0%\n",
            "Step: 1650 ------------ Loss: 7212.38 ------------ Accuracy: 66.0%\n",
            "Step: 1651 ------------ Loss: 7211.92 ------------ Accuracy: 66.0%\n",
            "Step: 1652 ------------ Loss: 7211.46 ------------ Accuracy: 66.0%\n",
            "Step: 1653 ------------ Loss: 7210.99 ------------ Accuracy: 66.0%\n",
            "Step: 1654 ------------ Loss: 7210.53 ------------ Accuracy: 66.0%\n",
            "Step: 1655 ------------ Loss: 7210.07 ------------ Accuracy: 66.0%\n",
            "Step: 1656 ------------ Loss: 7209.6 ------------ Accuracy: 66.0%\n",
            "Step: 1657 ------------ Loss: 7209.14 ------------ Accuracy: 66.0%\n",
            "Step: 1658 ------------ Loss: 7208.68 ------------ Accuracy: 66.0%\n",
            "Step: 1659 ------------ Loss: 7208.22 ------------ Accuracy: 66.0%\n",
            "Step: 1660 ------------ Loss: 7207.75 ------------ Accuracy: 66.0%\n",
            "Step: 1661 ------------ Loss: 7207.29 ------------ Accuracy: 66.0%\n",
            "Step: 1662 ------------ Loss: 7206.83 ------------ Accuracy: 66.0%\n",
            "Step: 1663 ------------ Loss: 7206.37 ------------ Accuracy: 66.0%\n",
            "Step: 1664 ------------ Loss: 7205.91 ------------ Accuracy: 66.0%\n",
            "Step: 1665 ------------ Loss: 7205.45 ------------ Accuracy: 66.0%\n",
            "Step: 1666 ------------ Loss: 7204.99 ------------ Accuracy: 66.0%\n",
            "Step: 1667 ------------ Loss: 7204.53 ------------ Accuracy: 65.9%\n",
            "Step: 1668 ------------ Loss: 7204.07 ------------ Accuracy: 65.9%\n",
            "Step: 1669 ------------ Loss: 7203.61 ------------ Accuracy: 65.9%\n",
            "Step: 1670 ------------ Loss: 7203.15 ------------ Accuracy: 65.9%\n",
            "Step: 1671 ------------ Loss: 7202.69 ------------ Accuracy: 65.9%\n",
            "Step: 1672 ------------ Loss: 7202.23 ------------ Accuracy: 65.9%\n",
            "Step: 1673 ------------ Loss: 7201.77 ------------ Accuracy: 65.9%\n",
            "Step: 1674 ------------ Loss: 7201.32 ------------ Accuracy: 65.9%\n",
            "Step: 1675 ------------ Loss: 7200.86 ------------ Accuracy: 65.9%\n",
            "Step: 1676 ------------ Loss: 7200.4 ------------ Accuracy: 65.9%\n",
            "Step: 1677 ------------ Loss: 7199.94 ------------ Accuracy: 65.9%\n",
            "Step: 1678 ------------ Loss: 7199.49 ------------ Accuracy: 65.9%\n",
            "Step: 1679 ------------ Loss: 7199.03 ------------ Accuracy: 65.9%\n",
            "Step: 1680 ------------ Loss: 7198.57 ------------ Accuracy: 66.0%\n",
            "Step: 1681 ------------ Loss: 7198.12 ------------ Accuracy: 66.0%\n",
            "Step: 1682 ------------ Loss: 7197.66 ------------ Accuracy: 66.0%\n",
            "Step: 1683 ------------ Loss: 7197.21 ------------ Accuracy: 66.0%\n",
            "Step: 1684 ------------ Loss: 7196.75 ------------ Accuracy: 66.0%\n",
            "Step: 1685 ------------ Loss: 7196.3 ------------ Accuracy: 66.0%\n",
            "Step: 1686 ------------ Loss: 7195.84 ------------ Accuracy: 66.0%\n",
            "Step: 1687 ------------ Loss: 7195.39 ------------ Accuracy: 66.0%\n",
            "Step: 1688 ------------ Loss: 7194.93 ------------ Accuracy: 66.0%\n",
            "Step: 1689 ------------ Loss: 7194.48 ------------ Accuracy: 66.0%\n",
            "Step: 1690 ------------ Loss: 7194.03 ------------ Accuracy: 66.0%\n",
            "Step: 1691 ------------ Loss: 7193.57 ------------ Accuracy: 66.0%\n",
            "Step: 1692 ------------ Loss: 7193.12 ------------ Accuracy: 66.0%\n",
            "Step: 1693 ------------ Loss: 7192.67 ------------ Accuracy: 66.0%\n",
            "Step: 1694 ------------ Loss: 7192.22 ------------ Accuracy: 66.0%\n",
            "Step: 1695 ------------ Loss: 7191.76 ------------ Accuracy: 66.0%\n",
            "Step: 1696 ------------ Loss: 7191.31 ------------ Accuracy: 66.0%\n",
            "Step: 1697 ------------ Loss: 7190.86 ------------ Accuracy: 66.0%\n",
            "Step: 1698 ------------ Loss: 7190.41 ------------ Accuracy: 66.0%\n",
            "Step: 1699 ------------ Loss: 7189.96 ------------ Accuracy: 66.0%\n",
            "Step: 1700 ------------ Loss: 7189.51 ------------ Accuracy: 66.1%\n",
            "Step: 1701 ------------ Loss: 7189.06 ------------ Accuracy: 66.1%\n",
            "Step: 1702 ------------ Loss: 7188.61 ------------ Accuracy: 66.1%\n",
            "Step: 1703 ------------ Loss: 7188.16 ------------ Accuracy: 66.1%\n",
            "Step: 1704 ------------ Loss: 7187.71 ------------ Accuracy: 66.1%\n",
            "Step: 1705 ------------ Loss: 7187.26 ------------ Accuracy: 66.1%\n",
            "Step: 1706 ------------ Loss: 7186.81 ------------ Accuracy: 66.1%\n",
            "Step: 1707 ------------ Loss: 7186.36 ------------ Accuracy: 66.1%\n",
            "Step: 1708 ------------ Loss: 7185.91 ------------ Accuracy: 66.1%\n",
            "Step: 1709 ------------ Loss: 7185.46 ------------ Accuracy: 66.1%\n",
            "Step: 1710 ------------ Loss: 7185.01 ------------ Accuracy: 66.1%\n",
            "Step: 1711 ------------ Loss: 7184.57 ------------ Accuracy: 66.1%\n",
            "Step: 1712 ------------ Loss: 7184.12 ------------ Accuracy: 66.1%\n",
            "Step: 1713 ------------ Loss: 7183.67 ------------ Accuracy: 66.1%\n",
            "Step: 1714 ------------ Loss: 7183.22 ------------ Accuracy: 66.1%\n",
            "Step: 1715 ------------ Loss: 7182.78 ------------ Accuracy: 66.1%\n",
            "Step: 1716 ------------ Loss: 7182.33 ------------ Accuracy: 66.1%\n",
            "Step: 1717 ------------ Loss: 7181.88 ------------ Accuracy: 66.1%\n",
            "Step: 1718 ------------ Loss: 7181.44 ------------ Accuracy: 66.1%\n",
            "Step: 1719 ------------ Loss: 7180.99 ------------ Accuracy: 66.1%\n",
            "Step: 1720 ------------ Loss: 7180.55 ------------ Accuracy: 66.1%\n",
            "Step: 1721 ------------ Loss: 7180.1 ------------ Accuracy: 66.1%\n",
            "Step: 1722 ------------ Loss: 7179.66 ------------ Accuracy: 66.1%\n",
            "Step: 1723 ------------ Loss: 7179.21 ------------ Accuracy: 66.1%\n",
            "Step: 1724 ------------ Loss: 7178.77 ------------ Accuracy: 66.1%\n",
            "Step: 1725 ------------ Loss: 7178.32 ------------ Accuracy: 66.1%\n",
            "Step: 1726 ------------ Loss: 7177.88 ------------ Accuracy: 66.1%\n",
            "Step: 1727 ------------ Loss: 7177.44 ------------ Accuracy: 66.1%\n",
            "Step: 1728 ------------ Loss: 7176.99 ------------ Accuracy: 66.1%\n",
            "Step: 1729 ------------ Loss: 7176.55 ------------ Accuracy: 66.1%\n",
            "Step: 1730 ------------ Loss: 7176.11 ------------ Accuracy: 66.1%\n",
            "Step: 1731 ------------ Loss: 7175.66 ------------ Accuracy: 66.1%\n",
            "Step: 1732 ------------ Loss: 7175.22 ------------ Accuracy: 66.1%\n",
            "Step: 1733 ------------ Loss: 7174.78 ------------ Accuracy: 66.1%\n",
            "Step: 1734 ------------ Loss: 7174.34 ------------ Accuracy: 66.1%\n",
            "Step: 1735 ------------ Loss: 7173.9 ------------ Accuracy: 66.1%\n",
            "Step: 1736 ------------ Loss: 7173.46 ------------ Accuracy: 66.1%\n",
            "Step: 1737 ------------ Loss: 7173.01 ------------ Accuracy: 66.1%\n",
            "Step: 1738 ------------ Loss: 7172.57 ------------ Accuracy: 66.1%\n",
            "Step: 1739 ------------ Loss: 7172.13 ------------ Accuracy: 66.1%\n",
            "Step: 1740 ------------ Loss: 7171.69 ------------ Accuracy: 66.1%\n",
            "Step: 1741 ------------ Loss: 7171.25 ------------ Accuracy: 66.1%\n",
            "Step: 1742 ------------ Loss: 7170.81 ------------ Accuracy: 66.1%\n",
            "Step: 1743 ------------ Loss: 7170.37 ------------ Accuracy: 66.1%\n",
            "Step: 1744 ------------ Loss: 7169.93 ------------ Accuracy: 66.1%\n",
            "Step: 1745 ------------ Loss: 7169.5 ------------ Accuracy: 66.1%\n",
            "Step: 1746 ------------ Loss: 7169.06 ------------ Accuracy: 66.1%\n",
            "Step: 1747 ------------ Loss: 7168.62 ------------ Accuracy: 66.0%\n",
            "Step: 1748 ------------ Loss: 7168.18 ------------ Accuracy: 66.0%\n",
            "Step: 1749 ------------ Loss: 7167.74 ------------ Accuracy: 66.0%\n",
            "Step: 1750 ------------ Loss: 7167.31 ------------ Accuracy: 66.0%\n",
            "Step: 1751 ------------ Loss: 7166.87 ------------ Accuracy: 66.0%\n",
            "Step: 1752 ------------ Loss: 7166.43 ------------ Accuracy: 66.0%\n",
            "Step: 1753 ------------ Loss: 7165.99 ------------ Accuracy: 66.0%\n",
            "Step: 1754 ------------ Loss: 7165.56 ------------ Accuracy: 66.0%\n",
            "Step: 1755 ------------ Loss: 7165.12 ------------ Accuracy: 66.0%\n",
            "Step: 1756 ------------ Loss: 7164.69 ------------ Accuracy: 66.0%\n",
            "Step: 1757 ------------ Loss: 7164.25 ------------ Accuracy: 66.0%\n",
            "Step: 1758 ------------ Loss: 7163.81 ------------ Accuracy: 66.0%\n",
            "Step: 1759 ------------ Loss: 7163.38 ------------ Accuracy: 66.0%\n",
            "Step: 1760 ------------ Loss: 7162.94 ------------ Accuracy: 66.0%\n",
            "Step: 1761 ------------ Loss: 7162.51 ------------ Accuracy: 66.0%\n",
            "Step: 1762 ------------ Loss: 7162.07 ------------ Accuracy: 66.0%\n",
            "Step: 1763 ------------ Loss: 7161.64 ------------ Accuracy: 66.0%\n",
            "Step: 1764 ------------ Loss: 7161.21 ------------ Accuracy: 66.0%\n",
            "Step: 1765 ------------ Loss: 7160.77 ------------ Accuracy: 66.0%\n",
            "Step: 1766 ------------ Loss: 7160.34 ------------ Accuracy: 66.0%\n",
            "Step: 1767 ------------ Loss: 7159.91 ------------ Accuracy: 66.0%\n",
            "Step: 1768 ------------ Loss: 7159.47 ------------ Accuracy: 66.0%\n",
            "Step: 1769 ------------ Loss: 7159.04 ------------ Accuracy: 66.0%\n",
            "Step: 1770 ------------ Loss: 7158.61 ------------ Accuracy: 66.0%\n",
            "Step: 1771 ------------ Loss: 7158.18 ------------ Accuracy: 66.0%\n",
            "Step: 1772 ------------ Loss: 7157.74 ------------ Accuracy: 66.0%\n",
            "Step: 1773 ------------ Loss: 7157.31 ------------ Accuracy: 66.0%\n",
            "Step: 1774 ------------ Loss: 7156.88 ------------ Accuracy: 66.0%\n",
            "Step: 1775 ------------ Loss: 7156.45 ------------ Accuracy: 66.0%\n",
            "Step: 1776 ------------ Loss: 7156.02 ------------ Accuracy: 66.0%\n",
            "Step: 1777 ------------ Loss: 7155.59 ------------ Accuracy: 66.0%\n",
            "Step: 1778 ------------ Loss: 7155.16 ------------ Accuracy: 66.0%\n",
            "Step: 1779 ------------ Loss: 7154.73 ------------ Accuracy: 66.0%\n",
            "Step: 1780 ------------ Loss: 7154.3 ------------ Accuracy: 66.1%\n",
            "Step: 1781 ------------ Loss: 7153.87 ------------ Accuracy: 66.1%\n",
            "Step: 1782 ------------ Loss: 7153.44 ------------ Accuracy: 66.1%\n",
            "Step: 1783 ------------ Loss: 7153.01 ------------ Accuracy: 66.1%\n",
            "Step: 1784 ------------ Loss: 7152.58 ------------ Accuracy: 66.1%\n",
            "Step: 1785 ------------ Loss: 7152.15 ------------ Accuracy: 66.1%\n",
            "Step: 1786 ------------ Loss: 7151.72 ------------ Accuracy: 66.1%\n",
            "Step: 1787 ------------ Loss: 7151.3 ------------ Accuracy: 66.1%\n",
            "Step: 1788 ------------ Loss: 7150.87 ------------ Accuracy: 66.1%\n",
            "Step: 1789 ------------ Loss: 7150.44 ------------ Accuracy: 66.1%\n",
            "Step: 1790 ------------ Loss: 7150.01 ------------ Accuracy: 66.1%\n",
            "Step: 1791 ------------ Loss: 7149.59 ------------ Accuracy: 66.1%\n",
            "Step: 1792 ------------ Loss: 7149.16 ------------ Accuracy: 66.1%\n",
            "Step: 1793 ------------ Loss: 7148.73 ------------ Accuracy: 66.1%\n",
            "Step: 1794 ------------ Loss: 7148.31 ------------ Accuracy: 66.1%\n",
            "Step: 1795 ------------ Loss: 7147.88 ------------ Accuracy: 66.1%\n",
            "Step: 1796 ------------ Loss: 7147.45 ------------ Accuracy: 66.1%\n",
            "Step: 1797 ------------ Loss: 7147.03 ------------ Accuracy: 66.1%\n",
            "Step: 1798 ------------ Loss: 7146.6 ------------ Accuracy: 66.1%\n",
            "Step: 1799 ------------ Loss: 7146.18 ------------ Accuracy: 66.1%\n",
            "Step: 1800 ------------ Loss: 7145.75 ------------ Accuracy: 66.1%\n",
            "Step: 1801 ------------ Loss: 7145.33 ------------ Accuracy: 66.1%\n",
            "Step: 1802 ------------ Loss: 7144.9 ------------ Accuracy: 66.1%\n",
            "Step: 1803 ------------ Loss: 7144.48 ------------ Accuracy: 66.1%\n",
            "Step: 1804 ------------ Loss: 7144.06 ------------ Accuracy: 66.1%\n",
            "Step: 1805 ------------ Loss: 7143.63 ------------ Accuracy: 66.1%\n",
            "Step: 1806 ------------ Loss: 7143.21 ------------ Accuracy: 66.1%\n",
            "Step: 1807 ------------ Loss: 7142.79 ------------ Accuracy: 66.1%\n",
            "Step: 1808 ------------ Loss: 7142.36 ------------ Accuracy: 66.1%\n",
            "Step: 1809 ------------ Loss: 7141.94 ------------ Accuracy: 66.1%\n",
            "Step: 1810 ------------ Loss: 7141.52 ------------ Accuracy: 66.1%\n",
            "Step: 1811 ------------ Loss: 7141.1 ------------ Accuracy: 66.1%\n",
            "Step: 1812 ------------ Loss: 7140.67 ------------ Accuracy: 66.1%\n",
            "Step: 1813 ------------ Loss: 7140.25 ------------ Accuracy: 66.1%\n",
            "Step: 1814 ------------ Loss: 7139.83 ------------ Accuracy: 66.1%\n",
            "Step: 1815 ------------ Loss: 7139.41 ------------ Accuracy: 66.1%\n",
            "Step: 1816 ------------ Loss: 7138.99 ------------ Accuracy: 66.1%\n",
            "Step: 1817 ------------ Loss: 7138.57 ------------ Accuracy: 66.1%\n",
            "Step: 1818 ------------ Loss: 7138.15 ------------ Accuracy: 66.1%\n",
            "Step: 1819 ------------ Loss: 7137.73 ------------ Accuracy: 66.1%\n",
            "Step: 1820 ------------ Loss: 7137.31 ------------ Accuracy: 66.1%\n",
            "Step: 1821 ------------ Loss: 7136.89 ------------ Accuracy: 66.1%\n",
            "Step: 1822 ------------ Loss: 7136.47 ------------ Accuracy: 66.1%\n",
            "Step: 1823 ------------ Loss: 7136.05 ------------ Accuracy: 66.1%\n",
            "Step: 1824 ------------ Loss: 7135.63 ------------ Accuracy: 66.1%\n",
            "Step: 1825 ------------ Loss: 7135.21 ------------ Accuracy: 66.1%\n",
            "Step: 1826 ------------ Loss: 7134.79 ------------ Accuracy: 66.1%\n",
            "Step: 1827 ------------ Loss: 7134.37 ------------ Accuracy: 66.1%\n",
            "Step: 1828 ------------ Loss: 7133.96 ------------ Accuracy: 66.1%\n",
            "Step: 1829 ------------ Loss: 7133.54 ------------ Accuracy: 66.1%\n",
            "Step: 1830 ------------ Loss: 7133.12 ------------ Accuracy: 66.1%\n",
            "Step: 1831 ------------ Loss: 7132.7 ------------ Accuracy: 66.1%\n",
            "Step: 1832 ------------ Loss: 7132.29 ------------ Accuracy: 66.1%\n",
            "Step: 1833 ------------ Loss: 7131.87 ------------ Accuracy: 66.1%\n",
            "Step: 1834 ------------ Loss: 7131.45 ------------ Accuracy: 66.1%\n",
            "Step: 1835 ------------ Loss: 7131.04 ------------ Accuracy: 66.1%\n",
            "Step: 1836 ------------ Loss: 7130.62 ------------ Accuracy: 66.1%\n",
            "Step: 1837 ------------ Loss: 7130.21 ------------ Accuracy: 66.1%\n",
            "Step: 1838 ------------ Loss: 7129.79 ------------ Accuracy: 66.1%\n",
            "Step: 1839 ------------ Loss: 7129.38 ------------ Accuracy: 66.1%\n",
            "Step: 1840 ------------ Loss: 7128.96 ------------ Accuracy: 66.1%\n",
            "Step: 1841 ------------ Loss: 7128.55 ------------ Accuracy: 66.1%\n",
            "Step: 1842 ------------ Loss: 7128.13 ------------ Accuracy: 66.1%\n",
            "Step: 1843 ------------ Loss: 7127.72 ------------ Accuracy: 66.1%\n",
            "Step: 1844 ------------ Loss: 7127.3 ------------ Accuracy: 66.1%\n",
            "Step: 1845 ------------ Loss: 7126.89 ------------ Accuracy: 66.1%\n",
            "Step: 1846 ------------ Loss: 7126.47 ------------ Accuracy: 66.1%\n",
            "Step: 1847 ------------ Loss: 7126.06 ------------ Accuracy: 66.1%\n",
            "Step: 1848 ------------ Loss: 7125.65 ------------ Accuracy: 66.1%\n",
            "Step: 1849 ------------ Loss: 7125.24 ------------ Accuracy: 66.1%\n",
            "Step: 1850 ------------ Loss: 7124.82 ------------ Accuracy: 66.1%\n",
            "Step: 1851 ------------ Loss: 7124.41 ------------ Accuracy: 66.1%\n",
            "Step: 1852 ------------ Loss: 7124.0 ------------ Accuracy: 66.1%\n",
            "Step: 1853 ------------ Loss: 7123.59 ------------ Accuracy: 66.3%\n",
            "Step: 1854 ------------ Loss: 7123.17 ------------ Accuracy: 66.3%\n",
            "Step: 1855 ------------ Loss: 7122.76 ------------ Accuracy: 66.3%\n",
            "Step: 1856 ------------ Loss: 7122.35 ------------ Accuracy: 66.3%\n",
            "Step: 1857 ------------ Loss: 7121.94 ------------ Accuracy: 66.3%\n",
            "Step: 1858 ------------ Loss: 7121.53 ------------ Accuracy: 66.3%\n",
            "Step: 1859 ------------ Loss: 7121.12 ------------ Accuracy: 66.3%\n",
            "Step: 1860 ------------ Loss: 7120.71 ------------ Accuracy: 66.3%\n",
            "Step: 1861 ------------ Loss: 7120.3 ------------ Accuracy: 66.3%\n",
            "Step: 1862 ------------ Loss: 7119.89 ------------ Accuracy: 66.3%\n",
            "Step: 1863 ------------ Loss: 7119.48 ------------ Accuracy: 66.3%\n",
            "Step: 1864 ------------ Loss: 7119.07 ------------ Accuracy: 66.3%\n",
            "Step: 1865 ------------ Loss: 7118.66 ------------ Accuracy: 66.3%\n",
            "Step: 1866 ------------ Loss: 7118.25 ------------ Accuracy: 66.3%\n",
            "Step: 1867 ------------ Loss: 7117.84 ------------ Accuracy: 66.3%\n",
            "Step: 1868 ------------ Loss: 7117.43 ------------ Accuracy: 66.3%\n",
            "Step: 1869 ------------ Loss: 7117.03 ------------ Accuracy: 66.3%\n",
            "Step: 1870 ------------ Loss: 7116.62 ------------ Accuracy: 66.3%\n",
            "Step: 1871 ------------ Loss: 7116.21 ------------ Accuracy: 66.3%\n",
            "Step: 1872 ------------ Loss: 7115.8 ------------ Accuracy: 66.3%\n",
            "Step: 1873 ------------ Loss: 7115.4 ------------ Accuracy: 66.3%\n",
            "Step: 1874 ------------ Loss: 7114.99 ------------ Accuracy: 66.3%\n",
            "Step: 1875 ------------ Loss: 7114.58 ------------ Accuracy: 66.3%\n",
            "Step: 1876 ------------ Loss: 7114.18 ------------ Accuracy: 66.3%\n",
            "Step: 1877 ------------ Loss: 7113.77 ------------ Accuracy: 66.3%\n",
            "Step: 1878 ------------ Loss: 7113.36 ------------ Accuracy: 66.3%\n",
            "Step: 1879 ------------ Loss: 7112.96 ------------ Accuracy: 66.3%\n",
            "Step: 1880 ------------ Loss: 7112.55 ------------ Accuracy: 66.3%\n",
            "Step: 1881 ------------ Loss: 7112.15 ------------ Accuracy: 66.3%\n",
            "Step: 1882 ------------ Loss: 7111.74 ------------ Accuracy: 66.3%\n",
            "Step: 1883 ------------ Loss: 7111.34 ------------ Accuracy: 66.3%\n",
            "Step: 1884 ------------ Loss: 7110.93 ------------ Accuracy: 66.3%\n",
            "Step: 1885 ------------ Loss: 7110.53 ------------ Accuracy: 66.3%\n",
            "Step: 1886 ------------ Loss: 7110.12 ------------ Accuracy: 66.3%\n",
            "Step: 1887 ------------ Loss: 7109.72 ------------ Accuracy: 66.3%\n",
            "Step: 1888 ------------ Loss: 7109.32 ------------ Accuracy: 66.3%\n",
            "Step: 1889 ------------ Loss: 7108.91 ------------ Accuracy: 66.3%\n",
            "Step: 1890 ------------ Loss: 7108.51 ------------ Accuracy: 66.3%\n",
            "Step: 1891 ------------ Loss: 7108.11 ------------ Accuracy: 66.3%\n",
            "Step: 1892 ------------ Loss: 7107.7 ------------ Accuracy: 66.3%\n",
            "Step: 1893 ------------ Loss: 7107.3 ------------ Accuracy: 66.3%\n",
            "Step: 1894 ------------ Loss: 7106.9 ------------ Accuracy: 66.3%\n",
            "Step: 1895 ------------ Loss: 7106.5 ------------ Accuracy: 66.3%\n",
            "Step: 1896 ------------ Loss: 7106.09 ------------ Accuracy: 66.3%\n",
            "Step: 1897 ------------ Loss: 7105.69 ------------ Accuracy: 66.3%\n",
            "Step: 1898 ------------ Loss: 7105.29 ------------ Accuracy: 66.4%\n",
            "Step: 1899 ------------ Loss: 7104.89 ------------ Accuracy: 66.4%\n",
            "Step: 1900 ------------ Loss: 7104.49 ------------ Accuracy: 66.4%\n",
            "Step: 1901 ------------ Loss: 7104.09 ------------ Accuracy: 66.4%\n",
            "Step: 1902 ------------ Loss: 7103.69 ------------ Accuracy: 66.4%\n",
            "Step: 1903 ------------ Loss: 7103.29 ------------ Accuracy: 66.4%\n",
            "Step: 1904 ------------ Loss: 7102.89 ------------ Accuracy: 66.4%\n",
            "Step: 1905 ------------ Loss: 7102.49 ------------ Accuracy: 66.4%\n",
            "Step: 1906 ------------ Loss: 7102.09 ------------ Accuracy: 66.4%\n",
            "Step: 1907 ------------ Loss: 7101.69 ------------ Accuracy: 66.4%\n",
            "Step: 1908 ------------ Loss: 7101.29 ------------ Accuracy: 66.4%\n",
            "Step: 1909 ------------ Loss: 7100.89 ------------ Accuracy: 66.4%\n",
            "Step: 1910 ------------ Loss: 7100.49 ------------ Accuracy: 66.4%\n",
            "Step: 1911 ------------ Loss: 7100.09 ------------ Accuracy: 66.4%\n",
            "Step: 1912 ------------ Loss: 7099.69 ------------ Accuracy: 66.4%\n",
            "Step: 1913 ------------ Loss: 7099.3 ------------ Accuracy: 66.4%\n",
            "Step: 1914 ------------ Loss: 7098.9 ------------ Accuracy: 66.4%\n",
            "Step: 1915 ------------ Loss: 7098.5 ------------ Accuracy: 66.4%\n",
            "Step: 1916 ------------ Loss: 7098.1 ------------ Accuracy: 66.4%\n",
            "Step: 1917 ------------ Loss: 7097.71 ------------ Accuracy: 66.4%\n",
            "Step: 1918 ------------ Loss: 7097.31 ------------ Accuracy: 66.4%\n",
            "Step: 1919 ------------ Loss: 7096.91 ------------ Accuracy: 66.4%\n",
            "Step: 1920 ------------ Loss: 7096.51 ------------ Accuracy: 66.4%\n",
            "Step: 1921 ------------ Loss: 7096.12 ------------ Accuracy: 66.4%\n",
            "Step: 1922 ------------ Loss: 7095.72 ------------ Accuracy: 66.4%\n",
            "Step: 1923 ------------ Loss: 7095.33 ------------ Accuracy: 66.4%\n",
            "Step: 1924 ------------ Loss: 7094.93 ------------ Accuracy: 66.4%\n",
            "Step: 1925 ------------ Loss: 7094.54 ------------ Accuracy: 66.4%\n",
            "Step: 1926 ------------ Loss: 7094.14 ------------ Accuracy: 66.4%\n",
            "Step: 1927 ------------ Loss: 7093.75 ------------ Accuracy: 66.4%\n",
            "Step: 1928 ------------ Loss: 7093.35 ------------ Accuracy: 66.4%\n",
            "Step: 1929 ------------ Loss: 7092.96 ------------ Accuracy: 66.4%\n",
            "Step: 1930 ------------ Loss: 7092.56 ------------ Accuracy: 66.4%\n",
            "Step: 1931 ------------ Loss: 7092.17 ------------ Accuracy: 66.4%\n",
            "Step: 1932 ------------ Loss: 7091.77 ------------ Accuracy: 66.4%\n",
            "Step: 1933 ------------ Loss: 7091.38 ------------ Accuracy: 66.4%\n",
            "Step: 1934 ------------ Loss: 7090.99 ------------ Accuracy: 66.4%\n",
            "Step: 1935 ------------ Loss: 7090.59 ------------ Accuracy: 66.4%\n",
            "Step: 1936 ------------ Loss: 7090.2 ------------ Accuracy: 66.4%\n",
            "Step: 1937 ------------ Loss: 7089.81 ------------ Accuracy: 66.4%\n",
            "Step: 1938 ------------ Loss: 7089.42 ------------ Accuracy: 66.4%\n",
            "Step: 1939 ------------ Loss: 7089.02 ------------ Accuracy: 66.4%\n",
            "Step: 1940 ------------ Loss: 7088.63 ------------ Accuracy: 66.4%\n",
            "Step: 1941 ------------ Loss: 7088.24 ------------ Accuracy: 66.4%\n",
            "Step: 1942 ------------ Loss: 7087.85 ------------ Accuracy: 66.4%\n",
            "Step: 1943 ------------ Loss: 7087.46 ------------ Accuracy: 66.4%\n",
            "Step: 1944 ------------ Loss: 7087.07 ------------ Accuracy: 66.4%\n",
            "Step: 1945 ------------ Loss: 7086.67 ------------ Accuracy: 66.4%\n",
            "Step: 1946 ------------ Loss: 7086.28 ------------ Accuracy: 66.4%\n",
            "Step: 1947 ------------ Loss: 7085.89 ------------ Accuracy: 66.4%\n",
            "Step: 1948 ------------ Loss: 7085.5 ------------ Accuracy: 66.4%\n",
            "Step: 1949 ------------ Loss: 7085.11 ------------ Accuracy: 66.4%\n",
            "Step: 1950 ------------ Loss: 7084.72 ------------ Accuracy: 66.4%\n",
            "Step: 1951 ------------ Loss: 7084.33 ------------ Accuracy: 66.4%\n",
            "Step: 1952 ------------ Loss: 7083.94 ------------ Accuracy: 66.4%\n",
            "Step: 1953 ------------ Loss: 7083.56 ------------ Accuracy: 66.4%\n",
            "Step: 1954 ------------ Loss: 7083.17 ------------ Accuracy: 66.4%\n",
            "Step: 1955 ------------ Loss: 7082.78 ------------ Accuracy: 66.3%\n",
            "Step: 1956 ------------ Loss: 7082.39 ------------ Accuracy: 66.3%\n",
            "Step: 1957 ------------ Loss: 7082.0 ------------ Accuracy: 66.3%\n",
            "Step: 1958 ------------ Loss: 7081.61 ------------ Accuracy: 66.3%\n",
            "Step: 1959 ------------ Loss: 7081.22 ------------ Accuracy: 66.3%\n",
            "Step: 1960 ------------ Loss: 7080.84 ------------ Accuracy: 66.3%\n",
            "Step: 1961 ------------ Loss: 7080.45 ------------ Accuracy: 66.3%\n",
            "Step: 1962 ------------ Loss: 7080.06 ------------ Accuracy: 66.3%\n",
            "Step: 1963 ------------ Loss: 7079.68 ------------ Accuracy: 66.3%\n",
            "Step: 1964 ------------ Loss: 7079.29 ------------ Accuracy: 66.3%\n",
            "Step: 1965 ------------ Loss: 7078.9 ------------ Accuracy: 66.3%\n",
            "Step: 1966 ------------ Loss: 7078.52 ------------ Accuracy: 66.3%\n",
            "Step: 1967 ------------ Loss: 7078.13 ------------ Accuracy: 66.3%\n",
            "Step: 1968 ------------ Loss: 7077.74 ------------ Accuracy: 66.3%\n",
            "Step: 1969 ------------ Loss: 7077.36 ------------ Accuracy: 66.3%\n",
            "Step: 1970 ------------ Loss: 7076.97 ------------ Accuracy: 66.3%\n",
            "Step: 1971 ------------ Loss: 7076.59 ------------ Accuracy: 66.3%\n",
            "Step: 1972 ------------ Loss: 7076.2 ------------ Accuracy: 66.3%\n",
            "Step: 1973 ------------ Loss: 7075.82 ------------ Accuracy: 66.3%\n",
            "Step: 1974 ------------ Loss: 7075.43 ------------ Accuracy: 66.3%\n",
            "Step: 1975 ------------ Loss: 7075.05 ------------ Accuracy: 66.3%\n",
            "Step: 1976 ------------ Loss: 7074.66 ------------ Accuracy: 66.3%\n",
            "Step: 1977 ------------ Loss: 7074.28 ------------ Accuracy: 66.3%\n",
            "Step: 1978 ------------ Loss: 7073.9 ------------ Accuracy: 66.3%\n",
            "Step: 1979 ------------ Loss: 7073.51 ------------ Accuracy: 66.3%\n",
            "Step: 1980 ------------ Loss: 7073.13 ------------ Accuracy: 66.3%\n",
            "Step: 1981 ------------ Loss: 7072.75 ------------ Accuracy: 66.3%\n",
            "Step: 1982 ------------ Loss: 7072.36 ------------ Accuracy: 66.4%\n",
            "Step: 1983 ------------ Loss: 7071.98 ------------ Accuracy: 66.4%\n",
            "Step: 1984 ------------ Loss: 7071.6 ------------ Accuracy: 66.4%\n",
            "Step: 1985 ------------ Loss: 7071.21 ------------ Accuracy: 66.4%\n",
            "Step: 1986 ------------ Loss: 7070.83 ------------ Accuracy: 66.4%\n",
            "Step: 1987 ------------ Loss: 7070.45 ------------ Accuracy: 66.4%\n",
            "Step: 1988 ------------ Loss: 7070.07 ------------ Accuracy: 66.5%\n",
            "Step: 1989 ------------ Loss: 7069.69 ------------ Accuracy: 66.5%\n",
            "Step: 1990 ------------ Loss: 7069.31 ------------ Accuracy: 66.5%\n",
            "Step: 1991 ------------ Loss: 7068.93 ------------ Accuracy: 66.5%\n",
            "Step: 1992 ------------ Loss: 7068.54 ------------ Accuracy: 66.5%\n",
            "Step: 1993 ------------ Loss: 7068.16 ------------ Accuracy: 66.5%\n",
            "Step: 1994 ------------ Loss: 7067.78 ------------ Accuracy: 66.5%\n",
            "Step: 1995 ------------ Loss: 7067.4 ------------ Accuracy: 66.5%\n",
            "Step: 1996 ------------ Loss: 7067.02 ------------ Accuracy: 66.5%\n",
            "Step: 1997 ------------ Loss: 7066.64 ------------ Accuracy: 66.5%\n",
            "Step: 1998 ------------ Loss: 7066.26 ------------ Accuracy: 66.5%\n",
            "Step: 1999 ------------ Loss: 7065.88 ------------ Accuracy: 66.5%\n",
            "Step: 2000 ------------ Loss: 7065.51 ------------ Accuracy: 66.5%\n",
            "Step: 2001 ------------ Loss: 7065.13 ------------ Accuracy: 66.5%\n",
            "Step: 2002 ------------ Loss: 7064.75 ------------ Accuracy: 66.5%\n",
            "Step: 2003 ------------ Loss: 7064.37 ------------ Accuracy: 66.5%\n",
            "Step: 2004 ------------ Loss: 7063.99 ------------ Accuracy: 66.5%\n",
            "Step: 2005 ------------ Loss: 7063.61 ------------ Accuracy: 66.6%\n",
            "Step: 2006 ------------ Loss: 7063.23 ------------ Accuracy: 66.6%\n",
            "Step: 2007 ------------ Loss: 7062.86 ------------ Accuracy: 66.6%\n",
            "Step: 2008 ------------ Loss: 7062.48 ------------ Accuracy: 66.6%\n",
            "Step: 2009 ------------ Loss: 7062.1 ------------ Accuracy: 66.6%\n",
            "Step: 2010 ------------ Loss: 7061.73 ------------ Accuracy: 66.6%\n",
            "Step: 2011 ------------ Loss: 7061.35 ------------ Accuracy: 66.6%\n",
            "Step: 2012 ------------ Loss: 7060.97 ------------ Accuracy: 66.6%\n",
            "Step: 2013 ------------ Loss: 7060.6 ------------ Accuracy: 66.6%\n",
            "Step: 2014 ------------ Loss: 7060.22 ------------ Accuracy: 66.6%\n",
            "Step: 2015 ------------ Loss: 7059.84 ------------ Accuracy: 66.6%\n",
            "Step: 2016 ------------ Loss: 7059.47 ------------ Accuracy: 66.6%\n",
            "Step: 2017 ------------ Loss: 7059.09 ------------ Accuracy: 66.6%\n",
            "Step: 2018 ------------ Loss: 7058.72 ------------ Accuracy: 66.6%\n",
            "Step: 2019 ------------ Loss: 7058.34 ------------ Accuracy: 66.6%\n",
            "Step: 2020 ------------ Loss: 7057.97 ------------ Accuracy: 66.6%\n",
            "Step: 2021 ------------ Loss: 7057.59 ------------ Accuracy: 66.6%\n",
            "Step: 2022 ------------ Loss: 7057.22 ------------ Accuracy: 66.6%\n",
            "Step: 2023 ------------ Loss: 7056.84 ------------ Accuracy: 66.6%\n",
            "Step: 2024 ------------ Loss: 7056.47 ------------ Accuracy: 66.6%\n",
            "Step: 2025 ------------ Loss: 7056.09 ------------ Accuracy: 66.6%\n",
            "Step: 2026 ------------ Loss: 7055.72 ------------ Accuracy: 66.6%\n",
            "Step: 2027 ------------ Loss: 7055.35 ------------ Accuracy: 66.6%\n",
            "Step: 2028 ------------ Loss: 7054.97 ------------ Accuracy: 66.6%\n",
            "Step: 2029 ------------ Loss: 7054.6 ------------ Accuracy: 66.6%\n",
            "Step: 2030 ------------ Loss: 7054.23 ------------ Accuracy: 66.6%\n",
            "Step: 2031 ------------ Loss: 7053.85 ------------ Accuracy: 66.6%\n",
            "Step: 2032 ------------ Loss: 7053.48 ------------ Accuracy: 66.6%\n",
            "Step: 2033 ------------ Loss: 7053.11 ------------ Accuracy: 66.6%\n",
            "Step: 2034 ------------ Loss: 7052.74 ------------ Accuracy: 66.6%\n",
            "Step: 2035 ------------ Loss: 7052.37 ------------ Accuracy: 66.6%\n",
            "Step: 2036 ------------ Loss: 7051.99 ------------ Accuracy: 66.6%\n",
            "Step: 2037 ------------ Loss: 7051.62 ------------ Accuracy: 66.6%\n",
            "Step: 2038 ------------ Loss: 7051.25 ------------ Accuracy: 66.6%\n",
            "Step: 2039 ------------ Loss: 7050.88 ------------ Accuracy: 66.6%\n",
            "Step: 2040 ------------ Loss: 7050.51 ------------ Accuracy: 66.6%\n",
            "Step: 2041 ------------ Loss: 7050.14 ------------ Accuracy: 66.6%\n",
            "Step: 2042 ------------ Loss: 7049.77 ------------ Accuracy: 66.6%\n",
            "Step: 2043 ------------ Loss: 7049.4 ------------ Accuracy: 66.6%\n",
            "Step: 2044 ------------ Loss: 7049.03 ------------ Accuracy: 66.6%\n",
            "Step: 2045 ------------ Loss: 7048.66 ------------ Accuracy: 66.6%\n",
            "Step: 2046 ------------ Loss: 7048.29 ------------ Accuracy: 66.6%\n",
            "Step: 2047 ------------ Loss: 7047.92 ------------ Accuracy: 66.6%\n",
            "Step: 2048 ------------ Loss: 7047.55 ------------ Accuracy: 66.6%\n",
            "Step: 2049 ------------ Loss: 7047.18 ------------ Accuracy: 66.6%\n",
            "Step: 2050 ------------ Loss: 7046.81 ------------ Accuracy: 66.6%\n",
            "Step: 2051 ------------ Loss: 7046.44 ------------ Accuracy: 66.6%\n",
            "Step: 2052 ------------ Loss: 7046.07 ------------ Accuracy: 66.6%\n",
            "Step: 2053 ------------ Loss: 7045.7 ------------ Accuracy: 66.6%\n",
            "Step: 2054 ------------ Loss: 7045.34 ------------ Accuracy: 66.6%\n",
            "Step: 2055 ------------ Loss: 7044.97 ------------ Accuracy: 66.6%\n",
            "Step: 2056 ------------ Loss: 7044.6 ------------ Accuracy: 66.6%\n",
            "Step: 2057 ------------ Loss: 7044.23 ------------ Accuracy: 66.6%\n",
            "Step: 2058 ------------ Loss: 7043.87 ------------ Accuracy: 66.6%\n",
            "Step: 2059 ------------ Loss: 7043.5 ------------ Accuracy: 66.6%\n",
            "Step: 2060 ------------ Loss: 7043.13 ------------ Accuracy: 66.6%\n",
            "Step: 2061 ------------ Loss: 7042.77 ------------ Accuracy: 66.6%\n",
            "Step: 2062 ------------ Loss: 7042.4 ------------ Accuracy: 66.6%\n",
            "Step: 2063 ------------ Loss: 7042.03 ------------ Accuracy: 66.6%\n",
            "Step: 2064 ------------ Loss: 7041.67 ------------ Accuracy: 66.6%\n",
            "Step: 2065 ------------ Loss: 7041.3 ------------ Accuracy: 66.6%\n",
            "Step: 2066 ------------ Loss: 7040.93 ------------ Accuracy: 66.6%\n",
            "Step: 2067 ------------ Loss: 7040.57 ------------ Accuracy: 66.6%\n",
            "Step: 2068 ------------ Loss: 7040.2 ------------ Accuracy: 66.6%\n",
            "Step: 2069 ------------ Loss: 7039.84 ------------ Accuracy: 66.6%\n",
            "Step: 2070 ------------ Loss: 7039.47 ------------ Accuracy: 66.6%\n",
            "Step: 2071 ------------ Loss: 7039.11 ------------ Accuracy: 66.6%\n",
            "Step: 2072 ------------ Loss: 7038.74 ------------ Accuracy: 66.6%\n",
            "Step: 2073 ------------ Loss: 7038.38 ------------ Accuracy: 66.6%\n",
            "Step: 2074 ------------ Loss: 7038.02 ------------ Accuracy: 66.6%\n",
            "Step: 2075 ------------ Loss: 7037.65 ------------ Accuracy: 66.6%\n",
            "Step: 2076 ------------ Loss: 7037.29 ------------ Accuracy: 66.6%\n",
            "Step: 2077 ------------ Loss: 7036.92 ------------ Accuracy: 66.6%\n",
            "Step: 2078 ------------ Loss: 7036.56 ------------ Accuracy: 66.6%\n",
            "Step: 2079 ------------ Loss: 7036.2 ------------ Accuracy: 66.6%\n",
            "Step: 2080 ------------ Loss: 7035.84 ------------ Accuracy: 66.6%\n",
            "Step: 2081 ------------ Loss: 7035.47 ------------ Accuracy: 66.6%\n",
            "Step: 2082 ------------ Loss: 7035.11 ------------ Accuracy: 66.6%\n",
            "Step: 2083 ------------ Loss: 7034.75 ------------ Accuracy: 66.6%\n",
            "Step: 2084 ------------ Loss: 7034.39 ------------ Accuracy: 66.6%\n",
            "Step: 2085 ------------ Loss: 7034.02 ------------ Accuracy: 66.6%\n",
            "Step: 2086 ------------ Loss: 7033.66 ------------ Accuracy: 66.6%\n",
            "Step: 2087 ------------ Loss: 7033.3 ------------ Accuracy: 66.6%\n",
            "Step: 2088 ------------ Loss: 7032.94 ------------ Accuracy: 66.6%\n",
            "Step: 2089 ------------ Loss: 7032.58 ------------ Accuracy: 66.6%\n",
            "Step: 2090 ------------ Loss: 7032.22 ------------ Accuracy: 66.6%\n",
            "Step: 2091 ------------ Loss: 7031.85 ------------ Accuracy: 66.6%\n",
            "Step: 2092 ------------ Loss: 7031.49 ------------ Accuracy: 66.6%\n",
            "Step: 2093 ------------ Loss: 7031.13 ------------ Accuracy: 66.6%\n",
            "Step: 2094 ------------ Loss: 7030.77 ------------ Accuracy: 66.6%\n",
            "Step: 2095 ------------ Loss: 7030.41 ------------ Accuracy: 66.6%\n",
            "Step: 2096 ------------ Loss: 7030.05 ------------ Accuracy: 66.6%\n",
            "Step: 2097 ------------ Loss: 7029.69 ------------ Accuracy: 66.6%\n",
            "Step: 2098 ------------ Loss: 7029.33 ------------ Accuracy: 66.6%\n",
            "Step: 2099 ------------ Loss: 7028.98 ------------ Accuracy: 66.6%\n",
            "Step: 2100 ------------ Loss: 7028.62 ------------ Accuracy: 66.6%\n",
            "Step: 2101 ------------ Loss: 7028.26 ------------ Accuracy: 66.8%\n",
            "Step: 2102 ------------ Loss: 7027.9 ------------ Accuracy: 66.8%\n",
            "Step: 2103 ------------ Loss: 7027.54 ------------ Accuracy: 66.8%\n",
            "Step: 2104 ------------ Loss: 7027.18 ------------ Accuracy: 66.8%\n",
            "Step: 2105 ------------ Loss: 7026.82 ------------ Accuracy: 66.8%\n",
            "Step: 2106 ------------ Loss: 7026.47 ------------ Accuracy: 66.8%\n",
            "Step: 2107 ------------ Loss: 7026.11 ------------ Accuracy: 66.8%\n",
            "Step: 2108 ------------ Loss: 7025.75 ------------ Accuracy: 66.8%\n",
            "Step: 2109 ------------ Loss: 7025.39 ------------ Accuracy: 66.8%\n",
            "Step: 2110 ------------ Loss: 7025.04 ------------ Accuracy: 66.8%\n",
            "Step: 2111 ------------ Loss: 7024.68 ------------ Accuracy: 66.8%\n",
            "Step: 2112 ------------ Loss: 7024.32 ------------ Accuracy: 66.8%\n",
            "Step: 2113 ------------ Loss: 7023.96 ------------ Accuracy: 66.8%\n",
            "Step: 2114 ------------ Loss: 7023.61 ------------ Accuracy: 66.8%\n",
            "Step: 2115 ------------ Loss: 7023.25 ------------ Accuracy: 66.8%\n",
            "Step: 2116 ------------ Loss: 7022.9 ------------ Accuracy: 66.8%\n",
            "Step: 2117 ------------ Loss: 7022.54 ------------ Accuracy: 66.8%\n",
            "Step: 2118 ------------ Loss: 7022.18 ------------ Accuracy: 66.8%\n",
            "Step: 2119 ------------ Loss: 7021.83 ------------ Accuracy: 66.8%\n",
            "Step: 2120 ------------ Loss: 7021.47 ------------ Accuracy: 66.8%\n",
            "Step: 2121 ------------ Loss: 7021.12 ------------ Accuracy: 66.8%\n",
            "Step: 2122 ------------ Loss: 7020.76 ------------ Accuracy: 66.8%\n",
            "Step: 2123 ------------ Loss: 7020.41 ------------ Accuracy: 66.8%\n",
            "Step: 2124 ------------ Loss: 7020.05 ------------ Accuracy: 66.8%\n",
            "Step: 2125 ------------ Loss: 7019.7 ------------ Accuracy: 66.8%\n",
            "Step: 2126 ------------ Loss: 7019.35 ------------ Accuracy: 66.8%\n",
            "Step: 2127 ------------ Loss: 7018.99 ------------ Accuracy: 66.8%\n",
            "Step: 2128 ------------ Loss: 7018.64 ------------ Accuracy: 66.8%\n",
            "Step: 2129 ------------ Loss: 7018.28 ------------ Accuracy: 66.9%\n",
            "Step: 2130 ------------ Loss: 7017.93 ------------ Accuracy: 66.9%\n",
            "Step: 2131 ------------ Loss: 7017.58 ------------ Accuracy: 66.9%\n",
            "Step: 2132 ------------ Loss: 7017.22 ------------ Accuracy: 66.9%\n",
            "Step: 2133 ------------ Loss: 7016.87 ------------ Accuracy: 66.9%\n",
            "Step: 2134 ------------ Loss: 7016.52 ------------ Accuracy: 66.9%\n",
            "Step: 2135 ------------ Loss: 7016.17 ------------ Accuracy: 66.9%\n",
            "Step: 2136 ------------ Loss: 7015.81 ------------ Accuracy: 66.9%\n",
            "Step: 2137 ------------ Loss: 7015.46 ------------ Accuracy: 66.9%\n",
            "Step: 2138 ------------ Loss: 7015.11 ------------ Accuracy: 66.9%\n",
            "Step: 2139 ------------ Loss: 7014.76 ------------ Accuracy: 66.9%\n",
            "Step: 2140 ------------ Loss: 7014.41 ------------ Accuracy: 66.9%\n",
            "Step: 2141 ------------ Loss: 7014.06 ------------ Accuracy: 66.9%\n",
            "Step: 2142 ------------ Loss: 7013.7 ------------ Accuracy: 66.9%\n",
            "Step: 2143 ------------ Loss: 7013.35 ------------ Accuracy: 66.9%\n",
            "Step: 2144 ------------ Loss: 7013.0 ------------ Accuracy: 66.9%\n",
            "Step: 2145 ------------ Loss: 7012.65 ------------ Accuracy: 66.9%\n",
            "Step: 2146 ------------ Loss: 7012.3 ------------ Accuracy: 66.9%\n",
            "Step: 2147 ------------ Loss: 7011.95 ------------ Accuracy: 66.9%\n",
            "Step: 2148 ------------ Loss: 7011.6 ------------ Accuracy: 66.9%\n",
            "Step: 2149 ------------ Loss: 7011.25 ------------ Accuracy: 67.0%\n",
            "Step: 2150 ------------ Loss: 7010.9 ------------ Accuracy: 67.0%\n",
            "Step: 2151 ------------ Loss: 7010.55 ------------ Accuracy: 67.0%\n",
            "Step: 2152 ------------ Loss: 7010.2 ------------ Accuracy: 67.0%\n",
            "Step: 2153 ------------ Loss: 7009.85 ------------ Accuracy: 67.0%\n",
            "Step: 2154 ------------ Loss: 7009.5 ------------ Accuracy: 67.0%\n",
            "Step: 2155 ------------ Loss: 7009.16 ------------ Accuracy: 67.0%\n",
            "Step: 2156 ------------ Loss: 7008.81 ------------ Accuracy: 67.0%\n",
            "Step: 2157 ------------ Loss: 7008.46 ------------ Accuracy: 67.0%\n",
            "Step: 2158 ------------ Loss: 7008.11 ------------ Accuracy: 67.0%\n",
            "Step: 2159 ------------ Loss: 7007.76 ------------ Accuracy: 67.0%\n",
            "Step: 2160 ------------ Loss: 7007.41 ------------ Accuracy: 67.0%\n",
            "Step: 2161 ------------ Loss: 7007.07 ------------ Accuracy: 67.0%\n",
            "Step: 2162 ------------ Loss: 7006.72 ------------ Accuracy: 67.0%\n",
            "Step: 2163 ------------ Loss: 7006.37 ------------ Accuracy: 67.0%\n",
            "Step: 2164 ------------ Loss: 7006.02 ------------ Accuracy: 67.0%\n",
            "Step: 2165 ------------ Loss: 7005.68 ------------ Accuracy: 67.0%\n",
            "Step: 2166 ------------ Loss: 7005.33 ------------ Accuracy: 67.0%\n",
            "Step: 2167 ------------ Loss: 7004.98 ------------ Accuracy: 67.0%\n",
            "Step: 2168 ------------ Loss: 7004.64 ------------ Accuracy: 67.0%\n",
            "Step: 2169 ------------ Loss: 7004.29 ------------ Accuracy: 67.0%\n",
            "Step: 2170 ------------ Loss: 7003.94 ------------ Accuracy: 67.0%\n",
            "Step: 2171 ------------ Loss: 7003.6 ------------ Accuracy: 67.0%\n",
            "Step: 2172 ------------ Loss: 7003.25 ------------ Accuracy: 67.0%\n",
            "Step: 2173 ------------ Loss: 7002.91 ------------ Accuracy: 67.0%\n",
            "Step: 2174 ------------ Loss: 7002.56 ------------ Accuracy: 67.0%\n",
            "Step: 2175 ------------ Loss: 7002.22 ------------ Accuracy: 67.0%\n",
            "Step: 2176 ------------ Loss: 7001.87 ------------ Accuracy: 67.0%\n",
            "Step: 2177 ------------ Loss: 7001.53 ------------ Accuracy: 67.0%\n",
            "Step: 2178 ------------ Loss: 7001.18 ------------ Accuracy: 67.0%\n",
            "Step: 2179 ------------ Loss: 7000.84 ------------ Accuracy: 67.0%\n",
            "Step: 2180 ------------ Loss: 7000.49 ------------ Accuracy: 67.0%\n",
            "Step: 2181 ------------ Loss: 7000.15 ------------ Accuracy: 67.0%\n",
            "Step: 2182 ------------ Loss: 6999.81 ------------ Accuracy: 67.0%\n",
            "Step: 2183 ------------ Loss: 6999.46 ------------ Accuracy: 67.0%\n",
            "Step: 2184 ------------ Loss: 6999.12 ------------ Accuracy: 67.0%\n",
            "Step: 2185 ------------ Loss: 6998.78 ------------ Accuracy: 67.0%\n",
            "Step: 2186 ------------ Loss: 6998.43 ------------ Accuracy: 67.0%\n",
            "Step: 2187 ------------ Loss: 6998.09 ------------ Accuracy: 67.0%\n",
            "Step: 2188 ------------ Loss: 6997.75 ------------ Accuracy: 67.0%\n",
            "Step: 2189 ------------ Loss: 6997.4 ------------ Accuracy: 67.0%\n",
            "Step: 2190 ------------ Loss: 6997.06 ------------ Accuracy: 67.0%\n",
            "Step: 2191 ------------ Loss: 6996.72 ------------ Accuracy: 67.0%\n",
            "Step: 2192 ------------ Loss: 6996.38 ------------ Accuracy: 67.0%\n",
            "Step: 2193 ------------ Loss: 6996.03 ------------ Accuracy: 67.0%\n",
            "Step: 2194 ------------ Loss: 6995.69 ------------ Accuracy: 67.0%\n",
            "Step: 2195 ------------ Loss: 6995.35 ------------ Accuracy: 67.0%\n",
            "Step: 2196 ------------ Loss: 6995.01 ------------ Accuracy: 67.0%\n",
            "Step: 2197 ------------ Loss: 6994.67 ------------ Accuracy: 67.0%\n",
            "Step: 2198 ------------ Loss: 6994.33 ------------ Accuracy: 67.0%\n",
            "Step: 2199 ------------ Loss: 6993.99 ------------ Accuracy: 67.0%\n",
            "Step: 2200 ------------ Loss: 6993.65 ------------ Accuracy: 67.0%\n",
            "Step: 2201 ------------ Loss: 6993.31 ------------ Accuracy: 67.0%\n",
            "Step: 2202 ------------ Loss: 6992.96 ------------ Accuracy: 67.0%\n",
            "Step: 2203 ------------ Loss: 6992.62 ------------ Accuracy: 67.0%\n",
            "Step: 2204 ------------ Loss: 6992.28 ------------ Accuracy: 67.0%\n",
            "Step: 2205 ------------ Loss: 6991.94 ------------ Accuracy: 67.0%\n",
            "Step: 2206 ------------ Loss: 6991.61 ------------ Accuracy: 67.1%\n",
            "Step: 2207 ------------ Loss: 6991.27 ------------ Accuracy: 67.1%\n",
            "Step: 2208 ------------ Loss: 6990.93 ------------ Accuracy: 67.1%\n",
            "Step: 2209 ------------ Loss: 6990.59 ------------ Accuracy: 67.1%\n",
            "Step: 2210 ------------ Loss: 6990.25 ------------ Accuracy: 67.1%\n",
            "Step: 2211 ------------ Loss: 6989.91 ------------ Accuracy: 67.1%\n",
            "Step: 2212 ------------ Loss: 6989.57 ------------ Accuracy: 67.1%\n",
            "Step: 2213 ------------ Loss: 6989.23 ------------ Accuracy: 67.1%\n",
            "Step: 2214 ------------ Loss: 6988.89 ------------ Accuracy: 67.1%\n",
            "Step: 2215 ------------ Loss: 6988.56 ------------ Accuracy: 67.1%\n",
            "Step: 2216 ------------ Loss: 6988.22 ------------ Accuracy: 67.1%\n",
            "Step: 2217 ------------ Loss: 6987.88 ------------ Accuracy: 67.1%\n",
            "Step: 2218 ------------ Loss: 6987.54 ------------ Accuracy: 67.1%\n",
            "Step: 2219 ------------ Loss: 6987.21 ------------ Accuracy: 67.1%\n",
            "Step: 2220 ------------ Loss: 6986.87 ------------ Accuracy: 67.1%\n",
            "Step: 2221 ------------ Loss: 6986.53 ------------ Accuracy: 67.1%\n",
            "Step: 2222 ------------ Loss: 6986.19 ------------ Accuracy: 67.1%\n",
            "Step: 2223 ------------ Loss: 6985.86 ------------ Accuracy: 67.1%\n",
            "Step: 2224 ------------ Loss: 6985.52 ------------ Accuracy: 67.1%\n",
            "Step: 2225 ------------ Loss: 6985.18 ------------ Accuracy: 67.1%\n",
            "Step: 2226 ------------ Loss: 6984.85 ------------ Accuracy: 67.1%\n",
            "Step: 2227 ------------ Loss: 6984.51 ------------ Accuracy: 67.1%\n",
            "Step: 2228 ------------ Loss: 6984.18 ------------ Accuracy: 67.1%\n",
            "Step: 2229 ------------ Loss: 6983.84 ------------ Accuracy: 67.1%\n",
            "Step: 2230 ------------ Loss: 6983.51 ------------ Accuracy: 67.1%\n",
            "Step: 2231 ------------ Loss: 6983.17 ------------ Accuracy: 67.1%\n",
            "Step: 2232 ------------ Loss: 6982.84 ------------ Accuracy: 67.1%\n",
            "Step: 2233 ------------ Loss: 6982.5 ------------ Accuracy: 67.1%\n",
            "Step: 2234 ------------ Loss: 6982.17 ------------ Accuracy: 67.1%\n",
            "Step: 2235 ------------ Loss: 6981.83 ------------ Accuracy: 67.1%\n",
            "Step: 2236 ------------ Loss: 6981.5 ------------ Accuracy: 67.1%\n",
            "Step: 2237 ------------ Loss: 6981.16 ------------ Accuracy: 67.1%\n",
            "Step: 2238 ------------ Loss: 6980.83 ------------ Accuracy: 67.1%\n",
            "Step: 2239 ------------ Loss: 6980.49 ------------ Accuracy: 67.1%\n",
            "Step: 2240 ------------ Loss: 6980.16 ------------ Accuracy: 67.1%\n",
            "Step: 2241 ------------ Loss: 6979.83 ------------ Accuracy: 67.1%\n",
            "Step: 2242 ------------ Loss: 6979.49 ------------ Accuracy: 67.3%\n",
            "Step: 2243 ------------ Loss: 6979.16 ------------ Accuracy: 67.3%\n",
            "Step: 2244 ------------ Loss: 6978.83 ------------ Accuracy: 67.3%\n",
            "Step: 2245 ------------ Loss: 6978.49 ------------ Accuracy: 67.3%\n",
            "Step: 2246 ------------ Loss: 6978.16 ------------ Accuracy: 67.3%\n",
            "Step: 2247 ------------ Loss: 6977.83 ------------ Accuracy: 67.3%\n",
            "Step: 2248 ------------ Loss: 6977.5 ------------ Accuracy: 67.3%\n",
            "Step: 2249 ------------ Loss: 6977.16 ------------ Accuracy: 67.3%\n",
            "Step: 2250 ------------ Loss: 6976.83 ------------ Accuracy: 67.3%\n",
            "Step: 2251 ------------ Loss: 6976.5 ------------ Accuracy: 67.3%\n",
            "Step: 2252 ------------ Loss: 6976.17 ------------ Accuracy: 67.3%\n",
            "Step: 2253 ------------ Loss: 6975.84 ------------ Accuracy: 67.3%\n",
            "Step: 2254 ------------ Loss: 6975.5 ------------ Accuracy: 67.3%\n",
            "Step: 2255 ------------ Loss: 6975.17 ------------ Accuracy: 67.3%\n",
            "Step: 2256 ------------ Loss: 6974.84 ------------ Accuracy: 67.3%\n",
            "Step: 2257 ------------ Loss: 6974.51 ------------ Accuracy: 67.3%\n",
            "Step: 2258 ------------ Loss: 6974.18 ------------ Accuracy: 67.3%\n",
            "Step: 2259 ------------ Loss: 6973.85 ------------ Accuracy: 67.3%\n",
            "Step: 2260 ------------ Loss: 6973.52 ------------ Accuracy: 67.3%\n",
            "Step: 2261 ------------ Loss: 6973.19 ------------ Accuracy: 67.3%\n",
            "Step: 2262 ------------ Loss: 6972.86 ------------ Accuracy: 67.3%\n",
            "Step: 2263 ------------ Loss: 6972.53 ------------ Accuracy: 67.3%\n",
            "Step: 2264 ------------ Loss: 6972.2 ------------ Accuracy: 67.3%\n",
            "Step: 2265 ------------ Loss: 6971.87 ------------ Accuracy: 67.3%\n",
            "Step: 2266 ------------ Loss: 6971.54 ------------ Accuracy: 67.3%\n",
            "Step: 2267 ------------ Loss: 6971.21 ------------ Accuracy: 67.3%\n",
            "Step: 2268 ------------ Loss: 6970.88 ------------ Accuracy: 67.3%\n",
            "Step: 2269 ------------ Loss: 6970.55 ------------ Accuracy: 67.3%\n",
            "Step: 2270 ------------ Loss: 6970.23 ------------ Accuracy: 67.3%\n",
            "Step: 2271 ------------ Loss: 6969.9 ------------ Accuracy: 67.3%\n",
            "Step: 2272 ------------ Loss: 6969.57 ------------ Accuracy: 67.3%\n",
            "Step: 2273 ------------ Loss: 6969.24 ------------ Accuracy: 67.3%\n",
            "Step: 2274 ------------ Loss: 6968.91 ------------ Accuracy: 67.3%\n",
            "Step: 2275 ------------ Loss: 6968.58 ------------ Accuracy: 67.3%\n",
            "Step: 2276 ------------ Loss: 6968.26 ------------ Accuracy: 67.3%\n",
            "Step: 2277 ------------ Loss: 6967.93 ------------ Accuracy: 67.3%\n",
            "Step: 2278 ------------ Loss: 6967.6 ------------ Accuracy: 67.3%\n",
            "Step: 2279 ------------ Loss: 6967.27 ------------ Accuracy: 67.3%\n",
            "Step: 2280 ------------ Loss: 6966.95 ------------ Accuracy: 67.3%\n",
            "Step: 2281 ------------ Loss: 6966.62 ------------ Accuracy: 67.3%\n",
            "Step: 2282 ------------ Loss: 6966.29 ------------ Accuracy: 67.3%\n",
            "Step: 2283 ------------ Loss: 6965.97 ------------ Accuracy: 67.3%\n",
            "Step: 2284 ------------ Loss: 6965.64 ------------ Accuracy: 67.3%\n",
            "Step: 2285 ------------ Loss: 6965.31 ------------ Accuracy: 67.3%\n",
            "Step: 2286 ------------ Loss: 6964.99 ------------ Accuracy: 67.3%\n",
            "Step: 2287 ------------ Loss: 6964.66 ------------ Accuracy: 67.3%\n",
            "Step: 2288 ------------ Loss: 6964.34 ------------ Accuracy: 67.3%\n",
            "Step: 2289 ------------ Loss: 6964.01 ------------ Accuracy: 67.3%\n",
            "Step: 2290 ------------ Loss: 6963.69 ------------ Accuracy: 67.3%\n",
            "Step: 2291 ------------ Loss: 6963.36 ------------ Accuracy: 67.3%\n",
            "Step: 2292 ------------ Loss: 6963.03 ------------ Accuracy: 67.3%\n",
            "Step: 2293 ------------ Loss: 6962.71 ------------ Accuracy: 67.3%\n",
            "Step: 2294 ------------ Loss: 6962.39 ------------ Accuracy: 67.3%\n",
            "Step: 2295 ------------ Loss: 6962.06 ------------ Accuracy: 67.3%\n",
            "Step: 2296 ------------ Loss: 6961.74 ------------ Accuracy: 67.3%\n",
            "Step: 2297 ------------ Loss: 6961.41 ------------ Accuracy: 67.3%\n",
            "Step: 2298 ------------ Loss: 6961.09 ------------ Accuracy: 67.3%\n",
            "Step: 2299 ------------ Loss: 6960.76 ------------ Accuracy: 67.3%\n",
            "Step: 2300 ------------ Loss: 6960.44 ------------ Accuracy: 67.3%\n",
            "Step: 2301 ------------ Loss: 6960.12 ------------ Accuracy: 67.3%\n",
            "Step: 2302 ------------ Loss: 6959.79 ------------ Accuracy: 67.3%\n",
            "Step: 2303 ------------ Loss: 6959.47 ------------ Accuracy: 67.3%\n",
            "Step: 2304 ------------ Loss: 6959.15 ------------ Accuracy: 67.4%\n",
            "Step: 2305 ------------ Loss: 6958.82 ------------ Accuracy: 67.4%\n",
            "Step: 2306 ------------ Loss: 6958.5 ------------ Accuracy: 67.4%\n",
            "Step: 2307 ------------ Loss: 6958.18 ------------ Accuracy: 67.4%\n",
            "Step: 2308 ------------ Loss: 6957.86 ------------ Accuracy: 67.4%\n",
            "Step: 2309 ------------ Loss: 6957.53 ------------ Accuracy: 67.4%\n",
            "Step: 2310 ------------ Loss: 6957.21 ------------ Accuracy: 67.4%\n",
            "Step: 2311 ------------ Loss: 6956.89 ------------ Accuracy: 67.4%\n",
            "Step: 2312 ------------ Loss: 6956.57 ------------ Accuracy: 67.4%\n",
            "Step: 2313 ------------ Loss: 6956.25 ------------ Accuracy: 67.4%\n",
            "Step: 2314 ------------ Loss: 6955.92 ------------ Accuracy: 67.4%\n",
            "Step: 2315 ------------ Loss: 6955.6 ------------ Accuracy: 67.4%\n",
            "Step: 2316 ------------ Loss: 6955.28 ------------ Accuracy: 67.4%\n",
            "Step: 2317 ------------ Loss: 6954.96 ------------ Accuracy: 67.4%\n",
            "Step: 2318 ------------ Loss: 6954.64 ------------ Accuracy: 67.4%\n",
            "Step: 2319 ------------ Loss: 6954.32 ------------ Accuracy: 67.4%\n",
            "Step: 2320 ------------ Loss: 6954.0 ------------ Accuracy: 67.4%\n",
            "Step: 2321 ------------ Loss: 6953.68 ------------ Accuracy: 67.4%\n",
            "Step: 2322 ------------ Loss: 6953.36 ------------ Accuracy: 67.4%\n",
            "Step: 2323 ------------ Loss: 6953.04 ------------ Accuracy: 67.4%\n",
            "Step: 2324 ------------ Loss: 6952.72 ------------ Accuracy: 67.4%\n",
            "Step: 2325 ------------ Loss: 6952.4 ------------ Accuracy: 67.4%\n",
            "Step: 2326 ------------ Loss: 6952.08 ------------ Accuracy: 67.4%\n",
            "Step: 2327 ------------ Loss: 6951.76 ------------ Accuracy: 67.4%\n",
            "Step: 2328 ------------ Loss: 6951.44 ------------ Accuracy: 67.4%\n",
            "Step: 2329 ------------ Loss: 6951.12 ------------ Accuracy: 67.4%\n",
            "Step: 2330 ------------ Loss: 6950.8 ------------ Accuracy: 67.4%\n",
            "Step: 2331 ------------ Loss: 6950.48 ------------ Accuracy: 67.4%\n",
            "Step: 2332 ------------ Loss: 6950.16 ------------ Accuracy: 67.4%\n",
            "Step: 2333 ------------ Loss: 6949.85 ------------ Accuracy: 67.4%\n",
            "Step: 2334 ------------ Loss: 6949.53 ------------ Accuracy: 67.4%\n",
            "Step: 2335 ------------ Loss: 6949.21 ------------ Accuracy: 67.4%\n",
            "Step: 2336 ------------ Loss: 6948.89 ------------ Accuracy: 67.4%\n",
            "Step: 2337 ------------ Loss: 6948.57 ------------ Accuracy: 67.4%\n",
            "Step: 2338 ------------ Loss: 6948.25 ------------ Accuracy: 67.4%\n",
            "Step: 2339 ------------ Loss: 6947.94 ------------ Accuracy: 67.4%\n",
            "Step: 2340 ------------ Loss: 6947.62 ------------ Accuracy: 67.4%\n",
            "Step: 2341 ------------ Loss: 6947.3 ------------ Accuracy: 67.4%\n",
            "Step: 2342 ------------ Loss: 6946.99 ------------ Accuracy: 67.4%\n",
            "Step: 2343 ------------ Loss: 6946.67 ------------ Accuracy: 67.4%\n",
            "Step: 2344 ------------ Loss: 6946.35 ------------ Accuracy: 67.4%\n",
            "Step: 2345 ------------ Loss: 6946.04 ------------ Accuracy: 67.4%\n",
            "Step: 2346 ------------ Loss: 6945.72 ------------ Accuracy: 67.4%\n",
            "Step: 2347 ------------ Loss: 6945.4 ------------ Accuracy: 67.4%\n",
            "Step: 2348 ------------ Loss: 6945.09 ------------ Accuracy: 67.4%\n",
            "Step: 2349 ------------ Loss: 6944.77 ------------ Accuracy: 67.4%\n",
            "Step: 2350 ------------ Loss: 6944.45 ------------ Accuracy: 67.4%\n",
            "Step: 2351 ------------ Loss: 6944.14 ------------ Accuracy: 67.4%\n",
            "Step: 2352 ------------ Loss: 6943.82 ------------ Accuracy: 67.4%\n",
            "Step: 2353 ------------ Loss: 6943.51 ------------ Accuracy: 67.4%\n",
            "Step: 2354 ------------ Loss: 6943.19 ------------ Accuracy: 67.4%\n",
            "Step: 2355 ------------ Loss: 6942.88 ------------ Accuracy: 67.4%\n",
            "Step: 2356 ------------ Loss: 6942.56 ------------ Accuracy: 67.4%\n",
            "Step: 2357 ------------ Loss: 6942.25 ------------ Accuracy: 67.4%\n",
            "Step: 2358 ------------ Loss: 6941.93 ------------ Accuracy: 67.4%\n",
            "Step: 2359 ------------ Loss: 6941.62 ------------ Accuracy: 67.4%\n",
            "Step: 2360 ------------ Loss: 6941.3 ------------ Accuracy: 67.4%\n",
            "Step: 2361 ------------ Loss: 6940.99 ------------ Accuracy: 67.4%\n",
            "Step: 2362 ------------ Loss: 6940.68 ------------ Accuracy: 67.4%\n",
            "Step: 2363 ------------ Loss: 6940.36 ------------ Accuracy: 67.4%\n",
            "Step: 2364 ------------ Loss: 6940.05 ------------ Accuracy: 67.4%\n",
            "Step: 2365 ------------ Loss: 6939.74 ------------ Accuracy: 67.4%\n",
            "Step: 2366 ------------ Loss: 6939.42 ------------ Accuracy: 67.4%\n",
            "Step: 2367 ------------ Loss: 6939.11 ------------ Accuracy: 67.4%\n",
            "Step: 2368 ------------ Loss: 6938.8 ------------ Accuracy: 67.4%\n",
            "Step: 2369 ------------ Loss: 6938.48 ------------ Accuracy: 67.4%\n",
            "Step: 2370 ------------ Loss: 6938.17 ------------ Accuracy: 67.4%\n",
            "Step: 2371 ------------ Loss: 6937.86 ------------ Accuracy: 67.4%\n",
            "Step: 2372 ------------ Loss: 6937.55 ------------ Accuracy: 67.4%\n",
            "Step: 2373 ------------ Loss: 6937.23 ------------ Accuracy: 67.4%\n",
            "Step: 2374 ------------ Loss: 6936.92 ------------ Accuracy: 67.4%\n",
            "Step: 2375 ------------ Loss: 6936.61 ------------ Accuracy: 67.4%\n",
            "Step: 2376 ------------ Loss: 6936.3 ------------ Accuracy: 67.4%\n",
            "Step: 2377 ------------ Loss: 6935.99 ------------ Accuracy: 67.4%\n",
            "Step: 2378 ------------ Loss: 6935.67 ------------ Accuracy: 67.4%\n",
            "Step: 2379 ------------ Loss: 6935.36 ------------ Accuracy: 67.4%\n",
            "Step: 2380 ------------ Loss: 6935.05 ------------ Accuracy: 67.4%\n",
            "Step: 2381 ------------ Loss: 6934.74 ------------ Accuracy: 68.0%\n",
            "Step: 2382 ------------ Loss: 6934.43 ------------ Accuracy: 68.0%\n",
            "Step: 2383 ------------ Loss: 6934.12 ------------ Accuracy: 68.0%\n",
            "Step: 2384 ------------ Loss: 6933.81 ------------ Accuracy: 68.0%\n",
            "Step: 2385 ------------ Loss: 6933.5 ------------ Accuracy: 68.0%\n",
            "Step: 2386 ------------ Loss: 6933.19 ------------ Accuracy: 68.0%\n",
            "Step: 2387 ------------ Loss: 6932.88 ------------ Accuracy: 68.0%\n",
            "Step: 2388 ------------ Loss: 6932.57 ------------ Accuracy: 68.0%\n",
            "Step: 2389 ------------ Loss: 6932.26 ------------ Accuracy: 68.0%\n",
            "Step: 2390 ------------ Loss: 6931.95 ------------ Accuracy: 68.0%\n",
            "Step: 2391 ------------ Loss: 6931.64 ------------ Accuracy: 68.0%\n",
            "Step: 2392 ------------ Loss: 6931.33 ------------ Accuracy: 68.0%\n",
            "Step: 2393 ------------ Loss: 6931.02 ------------ Accuracy: 68.0%\n",
            "Step: 2394 ------------ Loss: 6930.71 ------------ Accuracy: 68.0%\n",
            "Step: 2395 ------------ Loss: 6930.4 ------------ Accuracy: 68.0%\n",
            "Step: 2396 ------------ Loss: 6930.09 ------------ Accuracy: 68.0%\n",
            "Step: 2397 ------------ Loss: 6929.78 ------------ Accuracy: 68.0%\n",
            "Step: 2398 ------------ Loss: 6929.48 ------------ Accuracy: 68.0%\n",
            "Step: 2399 ------------ Loss: 6929.17 ------------ Accuracy: 68.0%\n",
            "Step: 2400 ------------ Loss: 6928.86 ------------ Accuracy: 68.0%\n",
            "Step: 2401 ------------ Loss: 6928.55 ------------ Accuracy: 68.0%\n",
            "Step: 2402 ------------ Loss: 6928.24 ------------ Accuracy: 68.0%\n",
            "Step: 2403 ------------ Loss: 6927.94 ------------ Accuracy: 68.0%\n",
            "Step: 2404 ------------ Loss: 6927.63 ------------ Accuracy: 68.0%\n",
            "Step: 2405 ------------ Loss: 6927.32 ------------ Accuracy: 68.0%\n",
            "Step: 2406 ------------ Loss: 6927.01 ------------ Accuracy: 68.0%\n",
            "Step: 2407 ------------ Loss: 6926.71 ------------ Accuracy: 68.0%\n",
            "Step: 2408 ------------ Loss: 6926.4 ------------ Accuracy: 68.0%\n",
            "Step: 2409 ------------ Loss: 6926.09 ------------ Accuracy: 68.0%\n",
            "Step: 2410 ------------ Loss: 6925.79 ------------ Accuracy: 68.0%\n",
            "Step: 2411 ------------ Loss: 6925.48 ------------ Accuracy: 68.0%\n",
            "Step: 2412 ------------ Loss: 6925.17 ------------ Accuracy: 68.0%\n",
            "Step: 2413 ------------ Loss: 6924.87 ------------ Accuracy: 68.1%\n",
            "Step: 2414 ------------ Loss: 6924.56 ------------ Accuracy: 68.1%\n",
            "Step: 2415 ------------ Loss: 6924.25 ------------ Accuracy: 68.1%\n",
            "Step: 2416 ------------ Loss: 6923.95 ------------ Accuracy: 68.1%\n",
            "Step: 2417 ------------ Loss: 6923.64 ------------ Accuracy: 68.1%\n",
            "Step: 2418 ------------ Loss: 6923.34 ------------ Accuracy: 68.1%\n",
            "Step: 2419 ------------ Loss: 6923.03 ------------ Accuracy: 68.1%\n",
            "Step: 2420 ------------ Loss: 6922.73 ------------ Accuracy: 68.1%\n",
            "Step: 2421 ------------ Loss: 6922.42 ------------ Accuracy: 68.1%\n",
            "Step: 2422 ------------ Loss: 6922.12 ------------ Accuracy: 68.1%\n",
            "Step: 2423 ------------ Loss: 6921.81 ------------ Accuracy: 68.1%\n",
            "Step: 2424 ------------ Loss: 6921.51 ------------ Accuracy: 68.1%\n",
            "Step: 2425 ------------ Loss: 6921.2 ------------ Accuracy: 68.1%\n",
            "Step: 2426 ------------ Loss: 6920.9 ------------ Accuracy: 68.1%\n",
            "Step: 2427 ------------ Loss: 6920.59 ------------ Accuracy: 68.1%\n",
            "Step: 2428 ------------ Loss: 6920.29 ------------ Accuracy: 68.1%\n",
            "Step: 2429 ------------ Loss: 6919.99 ------------ Accuracy: 68.1%\n",
            "Step: 2430 ------------ Loss: 6919.68 ------------ Accuracy: 68.1%\n",
            "Step: 2431 ------------ Loss: 6919.38 ------------ Accuracy: 68.1%\n",
            "Step: 2432 ------------ Loss: 6919.08 ------------ Accuracy: 68.1%\n",
            "Step: 2433 ------------ Loss: 6918.77 ------------ Accuracy: 68.1%\n",
            "Step: 2434 ------------ Loss: 6918.47 ------------ Accuracy: 68.1%\n",
            "Step: 2435 ------------ Loss: 6918.17 ------------ Accuracy: 68.1%\n",
            "Step: 2436 ------------ Loss: 6917.86 ------------ Accuracy: 68.1%\n",
            "Step: 2437 ------------ Loss: 6917.56 ------------ Accuracy: 68.1%\n",
            "Step: 2438 ------------ Loss: 6917.26 ------------ Accuracy: 68.1%\n",
            "Step: 2439 ------------ Loss: 6916.96 ------------ Accuracy: 68.1%\n",
            "Step: 2440 ------------ Loss: 6916.65 ------------ Accuracy: 68.1%\n",
            "Step: 2441 ------------ Loss: 6916.35 ------------ Accuracy: 68.1%\n",
            "Step: 2442 ------------ Loss: 6916.05 ------------ Accuracy: 68.1%\n",
            "Step: 2443 ------------ Loss: 6915.75 ------------ Accuracy: 68.1%\n",
            "Step: 2444 ------------ Loss: 6915.45 ------------ Accuracy: 68.1%\n",
            "Step: 2445 ------------ Loss: 6915.14 ------------ Accuracy: 68.1%\n",
            "Step: 2446 ------------ Loss: 6914.84 ------------ Accuracy: 68.1%\n",
            "Step: 2447 ------------ Loss: 6914.54 ------------ Accuracy: 68.1%\n",
            "Step: 2448 ------------ Loss: 6914.24 ------------ Accuracy: 68.1%\n",
            "Step: 2449 ------------ Loss: 6913.94 ------------ Accuracy: 68.1%\n",
            "Step: 2450 ------------ Loss: 6913.64 ------------ Accuracy: 68.1%\n",
            "Step: 2451 ------------ Loss: 6913.34 ------------ Accuracy: 68.1%\n",
            "Step: 2452 ------------ Loss: 6913.04 ------------ Accuracy: 68.1%\n",
            "Step: 2453 ------------ Loss: 6912.74 ------------ Accuracy: 68.1%\n",
            "Step: 2454 ------------ Loss: 6912.44 ------------ Accuracy: 68.1%\n",
            "Step: 2455 ------------ Loss: 6912.14 ------------ Accuracy: 68.1%\n",
            "Step: 2456 ------------ Loss: 6911.84 ------------ Accuracy: 68.1%\n",
            "Step: 2457 ------------ Loss: 6911.54 ------------ Accuracy: 68.1%\n",
            "Step: 2458 ------------ Loss: 6911.24 ------------ Accuracy: 68.1%\n",
            "Step: 2459 ------------ Loss: 6910.94 ------------ Accuracy: 68.1%\n",
            "Step: 2460 ------------ Loss: 6910.64 ------------ Accuracy: 68.1%\n",
            "Step: 2461 ------------ Loss: 6910.34 ------------ Accuracy: 68.1%\n",
            "Step: 2462 ------------ Loss: 6910.04 ------------ Accuracy: 68.1%\n",
            "Step: 2463 ------------ Loss: 6909.74 ------------ Accuracy: 68.1%\n",
            "Step: 2464 ------------ Loss: 6909.44 ------------ Accuracy: 68.1%\n",
            "Step: 2465 ------------ Loss: 6909.14 ------------ Accuracy: 68.1%\n",
            "Step: 2466 ------------ Loss: 6908.85 ------------ Accuracy: 68.1%\n",
            "Step: 2467 ------------ Loss: 6908.55 ------------ Accuracy: 68.1%\n",
            "Step: 2468 ------------ Loss: 6908.25 ------------ Accuracy: 68.1%\n",
            "Step: 2469 ------------ Loss: 6907.95 ------------ Accuracy: 68.1%\n",
            "Step: 2470 ------------ Loss: 6907.65 ------------ Accuracy: 68.1%\n",
            "Step: 2471 ------------ Loss: 6907.36 ------------ Accuracy: 68.1%\n",
            "Step: 2472 ------------ Loss: 6907.06 ------------ Accuracy: 68.1%\n",
            "Step: 2473 ------------ Loss: 6906.76 ------------ Accuracy: 68.1%\n",
            "Step: 2474 ------------ Loss: 6906.46 ------------ Accuracy: 68.1%\n",
            "Step: 2475 ------------ Loss: 6906.17 ------------ Accuracy: 68.1%\n",
            "Step: 2476 ------------ Loss: 6905.87 ------------ Accuracy: 68.1%\n",
            "Step: 2477 ------------ Loss: 6905.57 ------------ Accuracy: 68.1%\n",
            "Step: 2478 ------------ Loss: 6905.27 ------------ Accuracy: 68.1%\n",
            "Step: 2479 ------------ Loss: 6904.98 ------------ Accuracy: 68.1%\n",
            "Step: 2480 ------------ Loss: 6904.68 ------------ Accuracy: 68.1%\n",
            "Step: 2481 ------------ Loss: 6904.38 ------------ Accuracy: 68.1%\n",
            "Step: 2482 ------------ Loss: 6904.09 ------------ Accuracy: 68.1%\n",
            "Step: 2483 ------------ Loss: 6903.79 ------------ Accuracy: 68.1%\n",
            "Step: 2484 ------------ Loss: 6903.5 ------------ Accuracy: 68.1%\n",
            "Step: 2485 ------------ Loss: 6903.2 ------------ Accuracy: 68.1%\n",
            "Step: 2486 ------------ Loss: 6902.9 ------------ Accuracy: 68.1%\n",
            "Step: 2487 ------------ Loss: 6902.61 ------------ Accuracy: 68.1%\n",
            "Step: 2488 ------------ Loss: 6902.31 ------------ Accuracy: 68.1%\n",
            "Step: 2489 ------------ Loss: 6902.02 ------------ Accuracy: 68.1%\n",
            "Step: 2490 ------------ Loss: 6901.72 ------------ Accuracy: 68.1%\n",
            "Step: 2491 ------------ Loss: 6901.43 ------------ Accuracy: 68.1%\n",
            "Step: 2492 ------------ Loss: 6901.13 ------------ Accuracy: 68.1%\n",
            "Step: 2493 ------------ Loss: 6900.84 ------------ Accuracy: 68.1%\n",
            "Step: 2494 ------------ Loss: 6900.54 ------------ Accuracy: 68.1%\n",
            "Step: 2495 ------------ Loss: 6900.25 ------------ Accuracy: 68.1%\n",
            "Step: 2496 ------------ Loss: 6899.96 ------------ Accuracy: 68.3%\n",
            "Step: 2497 ------------ Loss: 6899.66 ------------ Accuracy: 68.3%\n",
            "Step: 2498 ------------ Loss: 6899.37 ------------ Accuracy: 68.3%\n",
            "Step: 2499 ------------ Loss: 6899.07 ------------ Accuracy: 68.3%\n",
            "Step: 2500 ------------ Loss: 6898.78 ------------ Accuracy: 68.3%\n",
            "Step: 2501 ------------ Loss: 6898.49 ------------ Accuracy: 68.3%\n",
            "Step: 2502 ------------ Loss: 6898.19 ------------ Accuracy: 68.3%\n",
            "Step: 2503 ------------ Loss: 6897.9 ------------ Accuracy: 68.3%\n",
            "Step: 2504 ------------ Loss: 6897.61 ------------ Accuracy: 68.3%\n",
            "Step: 2505 ------------ Loss: 6897.31 ------------ Accuracy: 68.3%\n",
            "Step: 2506 ------------ Loss: 6897.02 ------------ Accuracy: 68.3%\n",
            "Step: 2507 ------------ Loss: 6896.73 ------------ Accuracy: 68.4%\n",
            "Step: 2508 ------------ Loss: 6896.43 ------------ Accuracy: 68.4%\n",
            "Step: 2509 ------------ Loss: 6896.14 ------------ Accuracy: 68.4%\n",
            "Step: 2510 ------------ Loss: 6895.85 ------------ Accuracy: 68.4%\n",
            "Step: 2511 ------------ Loss: 6895.56 ------------ Accuracy: 68.4%\n",
            "Step: 2512 ------------ Loss: 6895.27 ------------ Accuracy: 68.4%\n",
            "Step: 2513 ------------ Loss: 6894.97 ------------ Accuracy: 68.4%\n",
            "Step: 2514 ------------ Loss: 6894.68 ------------ Accuracy: 68.4%\n",
            "Step: 2515 ------------ Loss: 6894.39 ------------ Accuracy: 68.4%\n",
            "Step: 2516 ------------ Loss: 6894.1 ------------ Accuracy: 68.4%\n",
            "Step: 2517 ------------ Loss: 6893.81 ------------ Accuracy: 68.4%\n",
            "Step: 2518 ------------ Loss: 6893.52 ------------ Accuracy: 68.4%\n",
            "Step: 2519 ------------ Loss: 6893.23 ------------ Accuracy: 68.4%\n",
            "Step: 2520 ------------ Loss: 6892.93 ------------ Accuracy: 68.4%\n",
            "Step: 2521 ------------ Loss: 6892.64 ------------ Accuracy: 68.4%\n",
            "Step: 2522 ------------ Loss: 6892.35 ------------ Accuracy: 68.4%\n",
            "Step: 2523 ------------ Loss: 6892.06 ------------ Accuracy: 68.4%\n",
            "Step: 2524 ------------ Loss: 6891.77 ------------ Accuracy: 68.4%\n",
            "Step: 2525 ------------ Loss: 6891.48 ------------ Accuracy: 68.4%\n",
            "Step: 2526 ------------ Loss: 6891.19 ------------ Accuracy: 68.4%\n",
            "Step: 2527 ------------ Loss: 6890.9 ------------ Accuracy: 68.4%\n",
            "Step: 2528 ------------ Loss: 6890.61 ------------ Accuracy: 68.4%\n",
            "Step: 2529 ------------ Loss: 6890.32 ------------ Accuracy: 68.4%\n",
            "Step: 2530 ------------ Loss: 6890.03 ------------ Accuracy: 68.4%\n",
            "Step: 2531 ------------ Loss: 6889.74 ------------ Accuracy: 68.4%\n",
            "Step: 2532 ------------ Loss: 6889.45 ------------ Accuracy: 68.4%\n",
            "Step: 2533 ------------ Loss: 6889.16 ------------ Accuracy: 68.4%\n",
            "Step: 2534 ------------ Loss: 6888.87 ------------ Accuracy: 68.4%\n",
            "Step: 2535 ------------ Loss: 6888.59 ------------ Accuracy: 68.4%\n",
            "Step: 2536 ------------ Loss: 6888.3 ------------ Accuracy: 68.4%\n",
            "Step: 2537 ------------ Loss: 6888.01 ------------ Accuracy: 68.4%\n",
            "Step: 2538 ------------ Loss: 6887.72 ------------ Accuracy: 68.4%\n",
            "Step: 2539 ------------ Loss: 6887.43 ------------ Accuracy: 68.4%\n",
            "Step: 2540 ------------ Loss: 6887.14 ------------ Accuracy: 68.4%\n",
            "Step: 2541 ------------ Loss: 6886.85 ------------ Accuracy: 68.4%\n",
            "Step: 2542 ------------ Loss: 6886.57 ------------ Accuracy: 68.4%\n",
            "Step: 2543 ------------ Loss: 6886.28 ------------ Accuracy: 68.4%\n",
            "Step: 2544 ------------ Loss: 6885.99 ------------ Accuracy: 68.4%\n",
            "Step: 2545 ------------ Loss: 6885.7 ------------ Accuracy: 68.4%\n",
            "Step: 2546 ------------ Loss: 6885.42 ------------ Accuracy: 68.4%\n",
            "Step: 2547 ------------ Loss: 6885.13 ------------ Accuracy: 68.4%\n",
            "Step: 2548 ------------ Loss: 6884.84 ------------ Accuracy: 68.4%\n",
            "Step: 2549 ------------ Loss: 6884.55 ------------ Accuracy: 68.4%\n",
            "Step: 2550 ------------ Loss: 6884.27 ------------ Accuracy: 68.4%\n",
            "Step: 2551 ------------ Loss: 6883.98 ------------ Accuracy: 68.4%\n",
            "Step: 2552 ------------ Loss: 6883.69 ------------ Accuracy: 68.4%\n",
            "Step: 2553 ------------ Loss: 6883.41 ------------ Accuracy: 68.4%\n",
            "Step: 2554 ------------ Loss: 6883.12 ------------ Accuracy: 68.4%\n",
            "Step: 2555 ------------ Loss: 6882.84 ------------ Accuracy: 68.4%\n",
            "Step: 2556 ------------ Loss: 6882.55 ------------ Accuracy: 68.4%\n",
            "Step: 2557 ------------ Loss: 6882.26 ------------ Accuracy: 68.4%\n",
            "Step: 2558 ------------ Loss: 6881.98 ------------ Accuracy: 68.4%\n",
            "Step: 2559 ------------ Loss: 6881.69 ------------ Accuracy: 68.4%\n",
            "Step: 2560 ------------ Loss: 6881.41 ------------ Accuracy: 68.4%\n",
            "Step: 2561 ------------ Loss: 6881.12 ------------ Accuracy: 68.4%\n",
            "Step: 2562 ------------ Loss: 6880.84 ------------ Accuracy: 68.4%\n",
            "Step: 2563 ------------ Loss: 6880.55 ------------ Accuracy: 68.4%\n",
            "Step: 2564 ------------ Loss: 6880.27 ------------ Accuracy: 68.4%\n",
            "Step: 2565 ------------ Loss: 6879.98 ------------ Accuracy: 68.4%\n",
            "Step: 2566 ------------ Loss: 6879.7 ------------ Accuracy: 68.4%\n",
            "Step: 2567 ------------ Loss: 6879.41 ------------ Accuracy: 68.4%\n",
            "Step: 2568 ------------ Loss: 6879.13 ------------ Accuracy: 68.4%\n",
            "Step: 2569 ------------ Loss: 6878.84 ------------ Accuracy: 68.4%\n",
            "Step: 2570 ------------ Loss: 6878.56 ------------ Accuracy: 68.4%\n",
            "Step: 2571 ------------ Loss: 6878.27 ------------ Accuracy: 68.4%\n",
            "Step: 2572 ------------ Loss: 6877.99 ------------ Accuracy: 68.4%\n",
            "Step: 2573 ------------ Loss: 6877.71 ------------ Accuracy: 68.4%\n",
            "Step: 2574 ------------ Loss: 6877.42 ------------ Accuracy: 68.3%\n",
            "Step: 2575 ------------ Loss: 6877.14 ------------ Accuracy: 68.3%\n",
            "Step: 2576 ------------ Loss: 6876.85 ------------ Accuracy: 68.3%\n",
            "Step: 2577 ------------ Loss: 6876.57 ------------ Accuracy: 68.3%\n",
            "Step: 2578 ------------ Loss: 6876.29 ------------ Accuracy: 68.3%\n",
            "Step: 2579 ------------ Loss: 6876.01 ------------ Accuracy: 68.5%\n",
            "Step: 2580 ------------ Loss: 6875.72 ------------ Accuracy: 68.5%\n",
            "Step: 2581 ------------ Loss: 6875.44 ------------ Accuracy: 68.5%\n",
            "Step: 2582 ------------ Loss: 6875.16 ------------ Accuracy: 68.5%\n",
            "Step: 2583 ------------ Loss: 6874.87 ------------ Accuracy: 68.5%\n",
            "Step: 2584 ------------ Loss: 6874.59 ------------ Accuracy: 68.5%\n",
            "Step: 2585 ------------ Loss: 6874.31 ------------ Accuracy: 68.5%\n",
            "Step: 2586 ------------ Loss: 6874.03 ------------ Accuracy: 68.5%\n",
            "Step: 2587 ------------ Loss: 6873.75 ------------ Accuracy: 68.5%\n",
            "Step: 2588 ------------ Loss: 6873.46 ------------ Accuracy: 68.5%\n",
            "Step: 2589 ------------ Loss: 6873.18 ------------ Accuracy: 68.5%\n",
            "Step: 2590 ------------ Loss: 6872.9 ------------ Accuracy: 68.5%\n",
            "Step: 2591 ------------ Loss: 6872.62 ------------ Accuracy: 68.5%\n",
            "Step: 2592 ------------ Loss: 6872.34 ------------ Accuracy: 68.5%\n",
            "Step: 2593 ------------ Loss: 6872.06 ------------ Accuracy: 68.5%\n",
            "Step: 2594 ------------ Loss: 6871.77 ------------ Accuracy: 68.5%\n",
            "Step: 2595 ------------ Loss: 6871.49 ------------ Accuracy: 68.5%\n",
            "Step: 2596 ------------ Loss: 6871.21 ------------ Accuracy: 68.5%\n",
            "Step: 2597 ------------ Loss: 6870.93 ------------ Accuracy: 68.5%\n",
            "Step: 2598 ------------ Loss: 6870.65 ------------ Accuracy: 68.5%\n",
            "Step: 2599 ------------ Loss: 6870.37 ------------ Accuracy: 68.5%\n",
            "Step: 2600 ------------ Loss: 6870.09 ------------ Accuracy: 68.5%\n",
            "Step: 2601 ------------ Loss: 6869.81 ------------ Accuracy: 68.5%\n",
            "Step: 2602 ------------ Loss: 6869.53 ------------ Accuracy: 68.5%\n",
            "Step: 2603 ------------ Loss: 6869.25 ------------ Accuracy: 68.5%\n",
            "Step: 2604 ------------ Loss: 6868.97 ------------ Accuracy: 68.5%\n",
            "Step: 2605 ------------ Loss: 6868.69 ------------ Accuracy: 68.5%\n",
            "Step: 2606 ------------ Loss: 6868.41 ------------ Accuracy: 68.5%\n",
            "Step: 2607 ------------ Loss: 6868.13 ------------ Accuracy: 68.5%\n",
            "Step: 2608 ------------ Loss: 6867.85 ------------ Accuracy: 68.5%\n",
            "Step: 2609 ------------ Loss: 6867.57 ------------ Accuracy: 68.5%\n",
            "Step: 2610 ------------ Loss: 6867.29 ------------ Accuracy: 68.5%\n",
            "Step: 2611 ------------ Loss: 6867.02 ------------ Accuracy: 68.5%\n",
            "Step: 2612 ------------ Loss: 6866.74 ------------ Accuracy: 68.5%\n",
            "Step: 2613 ------------ Loss: 6866.46 ------------ Accuracy: 68.5%\n",
            "Step: 2614 ------------ Loss: 6866.18 ------------ Accuracy: 68.5%\n",
            "Step: 2615 ------------ Loss: 6865.9 ------------ Accuracy: 68.5%\n",
            "Step: 2616 ------------ Loss: 6865.62 ------------ Accuracy: 68.5%\n",
            "Step: 2617 ------------ Loss: 6865.34 ------------ Accuracy: 68.5%\n",
            "Step: 2618 ------------ Loss: 6865.07 ------------ Accuracy: 68.5%\n",
            "Step: 2619 ------------ Loss: 6864.79 ------------ Accuracy: 68.5%\n",
            "Step: 2620 ------------ Loss: 6864.51 ------------ Accuracy: 68.5%\n",
            "Step: 2621 ------------ Loss: 6864.23 ------------ Accuracy: 68.5%\n",
            "Step: 2622 ------------ Loss: 6863.96 ------------ Accuracy: 68.5%\n",
            "Step: 2623 ------------ Loss: 6863.68 ------------ Accuracy: 68.5%\n",
            "Step: 2624 ------------ Loss: 6863.4 ------------ Accuracy: 68.5%\n",
            "Step: 2625 ------------ Loss: 6863.12 ------------ Accuracy: 68.5%\n",
            "Step: 2626 ------------ Loss: 6862.85 ------------ Accuracy: 68.5%\n",
            "Step: 2627 ------------ Loss: 6862.57 ------------ Accuracy: 68.5%\n",
            "Step: 2628 ------------ Loss: 6862.29 ------------ Accuracy: 68.5%\n",
            "Step: 2629 ------------ Loss: 6862.02 ------------ Accuracy: 68.5%\n",
            "Step: 2630 ------------ Loss: 6861.74 ------------ Accuracy: 68.5%\n",
            "Step: 2631 ------------ Loss: 6861.46 ------------ Accuracy: 68.5%\n",
            "Step: 2632 ------------ Loss: 6861.19 ------------ Accuracy: 68.5%\n",
            "Step: 2633 ------------ Loss: 6860.91 ------------ Accuracy: 68.5%\n",
            "Step: 2634 ------------ Loss: 6860.63 ------------ Accuracy: 68.5%\n",
            "Step: 2635 ------------ Loss: 6860.36 ------------ Accuracy: 68.5%\n",
            "Step: 2636 ------------ Loss: 6860.08 ------------ Accuracy: 68.5%\n",
            "Step: 2637 ------------ Loss: 6859.81 ------------ Accuracy: 68.5%\n",
            "Step: 2638 ------------ Loss: 6859.53 ------------ Accuracy: 68.5%\n",
            "Step: 2639 ------------ Loss: 6859.26 ------------ Accuracy: 68.5%\n",
            "Step: 2640 ------------ Loss: 6858.98 ------------ Accuracy: 68.5%\n",
            "Step: 2641 ------------ Loss: 6858.71 ------------ Accuracy: 68.5%\n",
            "Step: 2642 ------------ Loss: 6858.43 ------------ Accuracy: 68.5%\n",
            "Step: 2643 ------------ Loss: 6858.16 ------------ Accuracy: 68.5%\n",
            "Step: 2644 ------------ Loss: 6857.88 ------------ Accuracy: 68.5%\n",
            "Step: 2645 ------------ Loss: 6857.61 ------------ Accuracy: 68.5%\n",
            "Step: 2646 ------------ Loss: 6857.33 ------------ Accuracy: 68.5%\n",
            "Step: 2647 ------------ Loss: 6857.06 ------------ Accuracy: 68.5%\n",
            "Step: 2648 ------------ Loss: 6856.78 ------------ Accuracy: 68.5%\n",
            "Step: 2649 ------------ Loss: 6856.51 ------------ Accuracy: 68.5%\n",
            "Step: 2650 ------------ Loss: 6856.24 ------------ Accuracy: 68.5%\n",
            "Step: 2651 ------------ Loss: 6855.96 ------------ Accuracy: 68.5%\n",
            "Step: 2652 ------------ Loss: 6855.69 ------------ Accuracy: 68.5%\n",
            "Step: 2653 ------------ Loss: 6855.41 ------------ Accuracy: 68.5%\n",
            "Step: 2654 ------------ Loss: 6855.14 ------------ Accuracy: 68.5%\n",
            "Step: 2655 ------------ Loss: 6854.87 ------------ Accuracy: 68.5%\n",
            "Step: 2656 ------------ Loss: 6854.59 ------------ Accuracy: 68.5%\n",
            "Step: 2657 ------------ Loss: 6854.32 ------------ Accuracy: 68.5%\n",
            "Step: 2658 ------------ Loss: 6854.05 ------------ Accuracy: 68.5%\n",
            "Step: 2659 ------------ Loss: 6853.78 ------------ Accuracy: 68.5%\n",
            "Step: 2660 ------------ Loss: 6853.5 ------------ Accuracy: 68.5%\n",
            "Step: 2661 ------------ Loss: 6853.23 ------------ Accuracy: 68.5%\n",
            "Step: 2662 ------------ Loss: 6852.96 ------------ Accuracy: 68.5%\n",
            "Step: 2663 ------------ Loss: 6852.68 ------------ Accuracy: 68.5%\n",
            "Step: 2664 ------------ Loss: 6852.41 ------------ Accuracy: 68.5%\n",
            "Step: 2665 ------------ Loss: 6852.14 ------------ Accuracy: 68.5%\n",
            "Step: 2666 ------------ Loss: 6851.87 ------------ Accuracy: 68.5%\n",
            "Step: 2667 ------------ Loss: 6851.6 ------------ Accuracy: 68.5%\n",
            "Step: 2668 ------------ Loss: 6851.32 ------------ Accuracy: 68.5%\n",
            "Step: 2669 ------------ Loss: 6851.05 ------------ Accuracy: 68.5%\n",
            "Step: 2670 ------------ Loss: 6850.78 ------------ Accuracy: 68.5%\n",
            "Step: 2671 ------------ Loss: 6850.51 ------------ Accuracy: 68.5%\n",
            "Step: 2672 ------------ Loss: 6850.24 ------------ Accuracy: 68.5%\n",
            "Step: 2673 ------------ Loss: 6849.97 ------------ Accuracy: 68.6%\n",
            "Step: 2674 ------------ Loss: 6849.7 ------------ Accuracy: 68.6%\n",
            "Step: 2675 ------------ Loss: 6849.43 ------------ Accuracy: 68.6%\n",
            "Step: 2676 ------------ Loss: 6849.15 ------------ Accuracy: 68.6%\n",
            "Step: 2677 ------------ Loss: 6848.88 ------------ Accuracy: 68.6%\n",
            "Step: 2678 ------------ Loss: 6848.61 ------------ Accuracy: 68.6%\n",
            "Step: 2679 ------------ Loss: 6848.34 ------------ Accuracy: 68.6%\n",
            "Step: 2680 ------------ Loss: 6848.07 ------------ Accuracy: 68.6%\n",
            "Step: 2681 ------------ Loss: 6847.8 ------------ Accuracy: 68.6%\n",
            "Step: 2682 ------------ Loss: 6847.53 ------------ Accuracy: 68.6%\n",
            "Step: 2683 ------------ Loss: 6847.26 ------------ Accuracy: 68.6%\n",
            "Step: 2684 ------------ Loss: 6846.99 ------------ Accuracy: 68.6%\n",
            "Step: 2685 ------------ Loss: 6846.72 ------------ Accuracy: 68.6%\n",
            "Step: 2686 ------------ Loss: 6846.45 ------------ Accuracy: 68.6%\n",
            "Step: 2687 ------------ Loss: 6846.18 ------------ Accuracy: 68.6%\n",
            "Step: 2688 ------------ Loss: 6845.91 ------------ Accuracy: 68.6%\n",
            "Step: 2689 ------------ Loss: 6845.65 ------------ Accuracy: 68.6%\n",
            "Step: 2690 ------------ Loss: 6845.38 ------------ Accuracy: 68.6%\n",
            "Step: 2691 ------------ Loss: 6845.11 ------------ Accuracy: 68.6%\n",
            "Step: 2692 ------------ Loss: 6844.84 ------------ Accuracy: 68.6%\n",
            "Step: 2693 ------------ Loss: 6844.57 ------------ Accuracy: 68.6%\n",
            "Step: 2694 ------------ Loss: 6844.3 ------------ Accuracy: 68.6%\n",
            "Step: 2695 ------------ Loss: 6844.03 ------------ Accuracy: 68.6%\n",
            "Step: 2696 ------------ Loss: 6843.76 ------------ Accuracy: 68.6%\n",
            "Step: 2697 ------------ Loss: 6843.5 ------------ Accuracy: 68.6%\n",
            "Step: 2698 ------------ Loss: 6843.23 ------------ Accuracy: 68.6%\n",
            "Step: 2699 ------------ Loss: 6842.96 ------------ Accuracy: 68.6%\n",
            "Step: 2700 ------------ Loss: 6842.69 ------------ Accuracy: 68.6%\n",
            "Step: 2701 ------------ Loss: 6842.42 ------------ Accuracy: 68.6%\n",
            "Step: 2702 ------------ Loss: 6842.16 ------------ Accuracy: 68.5%\n",
            "Step: 2703 ------------ Loss: 6841.89 ------------ Accuracy: 68.5%\n",
            "Step: 2704 ------------ Loss: 6841.62 ------------ Accuracy: 68.5%\n",
            "Step: 2705 ------------ Loss: 6841.35 ------------ Accuracy: 68.5%\n",
            "Step: 2706 ------------ Loss: 6841.09 ------------ Accuracy: 68.5%\n",
            "Step: 2707 ------------ Loss: 6840.82 ------------ Accuracy: 68.5%\n",
            "Step: 2708 ------------ Loss: 6840.55 ------------ Accuracy: 68.6%\n",
            "Step: 2709 ------------ Loss: 6840.29 ------------ Accuracy: 68.6%\n",
            "Step: 2710 ------------ Loss: 6840.02 ------------ Accuracy: 68.6%\n",
            "Step: 2711 ------------ Loss: 6839.75 ------------ Accuracy: 68.6%\n",
            "Step: 2712 ------------ Loss: 6839.49 ------------ Accuracy: 68.6%\n",
            "Step: 2713 ------------ Loss: 6839.22 ------------ Accuracy: 68.6%\n",
            "Step: 2714 ------------ Loss: 6838.95 ------------ Accuracy: 68.6%\n",
            "Step: 2715 ------------ Loss: 6838.69 ------------ Accuracy: 68.6%\n",
            "Step: 2716 ------------ Loss: 6838.42 ------------ Accuracy: 68.7%\n",
            "Step: 2717 ------------ Loss: 6838.16 ------------ Accuracy: 68.7%\n",
            "Step: 2718 ------------ Loss: 6837.89 ------------ Accuracy: 68.7%\n",
            "Step: 2719 ------------ Loss: 6837.62 ------------ Accuracy: 68.7%\n",
            "Step: 2720 ------------ Loss: 6837.36 ------------ Accuracy: 68.7%\n",
            "Step: 2721 ------------ Loss: 6837.09 ------------ Accuracy: 68.7%\n",
            "Step: 2722 ------------ Loss: 6836.83 ------------ Accuracy: 68.7%\n",
            "Step: 2723 ------------ Loss: 6836.56 ------------ Accuracy: 68.7%\n",
            "Step: 2724 ------------ Loss: 6836.3 ------------ Accuracy: 68.7%\n",
            "Step: 2725 ------------ Loss: 6836.03 ------------ Accuracy: 68.7%\n",
            "Step: 2726 ------------ Loss: 6835.77 ------------ Accuracy: 68.7%\n",
            "Step: 2727 ------------ Loss: 6835.5 ------------ Accuracy: 68.7%\n",
            "Step: 2728 ------------ Loss: 6835.24 ------------ Accuracy: 68.7%\n",
            "Step: 2729 ------------ Loss: 6834.97 ------------ Accuracy: 68.7%\n",
            "Step: 2730 ------------ Loss: 6834.71 ------------ Accuracy: 68.7%\n",
            "Step: 2731 ------------ Loss: 6834.45 ------------ Accuracy: 68.7%\n",
            "Step: 2732 ------------ Loss: 6834.18 ------------ Accuracy: 68.7%\n",
            "Step: 2733 ------------ Loss: 6833.92 ------------ Accuracy: 68.7%\n",
            "Step: 2734 ------------ Loss: 6833.65 ------------ Accuracy: 68.7%\n",
            "Step: 2735 ------------ Loss: 6833.39 ------------ Accuracy: 68.7%\n",
            "Step: 2736 ------------ Loss: 6833.13 ------------ Accuracy: 68.7%\n",
            "Step: 2737 ------------ Loss: 6832.86 ------------ Accuracy: 68.7%\n",
            "Step: 2738 ------------ Loss: 6832.6 ------------ Accuracy: 68.7%\n",
            "Step: 2739 ------------ Loss: 6832.34 ------------ Accuracy: 68.7%\n",
            "Step: 2740 ------------ Loss: 6832.07 ------------ Accuracy: 68.7%\n",
            "Step: 2741 ------------ Loss: 6831.81 ------------ Accuracy: 68.7%\n",
            "Step: 2742 ------------ Loss: 6831.55 ------------ Accuracy: 68.7%\n",
            "Step: 2743 ------------ Loss: 6831.28 ------------ Accuracy: 68.7%\n",
            "Step: 2744 ------------ Loss: 6831.02 ------------ Accuracy: 68.7%\n",
            "Step: 2745 ------------ Loss: 6830.76 ------------ Accuracy: 68.7%\n",
            "Step: 2746 ------------ Loss: 6830.5 ------------ Accuracy: 68.8%\n",
            "Step: 2747 ------------ Loss: 6830.23 ------------ Accuracy: 68.8%\n",
            "Step: 2748 ------------ Loss: 6829.97 ------------ Accuracy: 68.8%\n",
            "Step: 2749 ------------ Loss: 6829.71 ------------ Accuracy: 68.8%\n",
            "Step: 2750 ------------ Loss: 6829.45 ------------ Accuracy: 68.8%\n",
            "Step: 2751 ------------ Loss: 6829.19 ------------ Accuracy: 68.8%\n",
            "Step: 2752 ------------ Loss: 6828.92 ------------ Accuracy: 68.8%\n",
            "Step: 2753 ------------ Loss: 6828.66 ------------ Accuracy: 68.8%\n",
            "Step: 2754 ------------ Loss: 6828.4 ------------ Accuracy: 68.8%\n",
            "Step: 2755 ------------ Loss: 6828.14 ------------ Accuracy: 68.8%\n",
            "Step: 2756 ------------ Loss: 6827.88 ------------ Accuracy: 68.8%\n",
            "Step: 2757 ------------ Loss: 6827.62 ------------ Accuracy: 68.8%\n",
            "Step: 2758 ------------ Loss: 6827.36 ------------ Accuracy: 68.8%\n",
            "Step: 2759 ------------ Loss: 6827.1 ------------ Accuracy: 68.8%\n",
            "Step: 2760 ------------ Loss: 6826.83 ------------ Accuracy: 68.8%\n",
            "Step: 2761 ------------ Loss: 6826.57 ------------ Accuracy: 68.8%\n",
            "Step: 2762 ------------ Loss: 6826.31 ------------ Accuracy: 68.8%\n",
            "Step: 2763 ------------ Loss: 6826.05 ------------ Accuracy: 68.8%\n",
            "Step: 2764 ------------ Loss: 6825.79 ------------ Accuracy: 68.9%\n",
            "Step: 2765 ------------ Loss: 6825.53 ------------ Accuracy: 68.9%\n",
            "Step: 2766 ------------ Loss: 6825.27 ------------ Accuracy: 68.9%\n",
            "Step: 2767 ------------ Loss: 6825.01 ------------ Accuracy: 68.9%\n",
            "Step: 2768 ------------ Loss: 6824.75 ------------ Accuracy: 68.9%\n",
            "Step: 2769 ------------ Loss: 6824.49 ------------ Accuracy: 68.9%\n",
            "Step: 2770 ------------ Loss: 6824.23 ------------ Accuracy: 68.9%\n",
            "Step: 2771 ------------ Loss: 6823.97 ------------ Accuracy: 68.9%\n",
            "Step: 2772 ------------ Loss: 6823.71 ------------ Accuracy: 68.9%\n",
            "Step: 2773 ------------ Loss: 6823.45 ------------ Accuracy: 68.9%\n",
            "Step: 2774 ------------ Loss: 6823.19 ------------ Accuracy: 68.9%\n",
            "Step: 2775 ------------ Loss: 6822.94 ------------ Accuracy: 68.9%\n",
            "Step: 2776 ------------ Loss: 6822.68 ------------ Accuracy: 68.9%\n",
            "Step: 2777 ------------ Loss: 6822.42 ------------ Accuracy: 68.9%\n",
            "Step: 2778 ------------ Loss: 6822.16 ------------ Accuracy: 68.9%\n",
            "Step: 2779 ------------ Loss: 6821.9 ------------ Accuracy: 68.9%\n",
            "Step: 2780 ------------ Loss: 6821.64 ------------ Accuracy: 68.9%\n",
            "Step: 2781 ------------ Loss: 6821.38 ------------ Accuracy: 68.9%\n",
            "Step: 2782 ------------ Loss: 6821.12 ------------ Accuracy: 68.9%\n",
            "Step: 2783 ------------ Loss: 6820.87 ------------ Accuracy: 68.9%\n",
            "Step: 2784 ------------ Loss: 6820.61 ------------ Accuracy: 68.9%\n",
            "Step: 2785 ------------ Loss: 6820.35 ------------ Accuracy: 68.9%\n",
            "Step: 2786 ------------ Loss: 6820.09 ------------ Accuracy: 68.9%\n",
            "Step: 2787 ------------ Loss: 6819.83 ------------ Accuracy: 68.9%\n",
            "Step: 2788 ------------ Loss: 6819.58 ------------ Accuracy: 68.9%\n",
            "Step: 2789 ------------ Loss: 6819.32 ------------ Accuracy: 68.9%\n",
            "Step: 2790 ------------ Loss: 6819.06 ------------ Accuracy: 68.9%\n",
            "Step: 2791 ------------ Loss: 6818.8 ------------ Accuracy: 68.9%\n",
            "Step: 2792 ------------ Loss: 6818.55 ------------ Accuracy: 68.9%\n",
            "Step: 2793 ------------ Loss: 6818.29 ------------ Accuracy: 68.9%\n",
            "Step: 2794 ------------ Loss: 6818.03 ------------ Accuracy: 68.9%\n",
            "Step: 2795 ------------ Loss: 6817.78 ------------ Accuracy: 68.9%\n",
            "Step: 2796 ------------ Loss: 6817.52 ------------ Accuracy: 68.9%\n",
            "Step: 2797 ------------ Loss: 6817.26 ------------ Accuracy: 68.9%\n",
            "Step: 2798 ------------ Loss: 6817.01 ------------ Accuracy: 68.9%\n",
            "Step: 2799 ------------ Loss: 6816.75 ------------ Accuracy: 68.9%\n",
            "Step: 2800 ------------ Loss: 6816.49 ------------ Accuracy: 68.9%\n",
            "Step: 2801 ------------ Loss: 6816.24 ------------ Accuracy: 68.9%\n",
            "Step: 2802 ------------ Loss: 6815.98 ------------ Accuracy: 68.9%\n",
            "Step: 2803 ------------ Loss: 6815.73 ------------ Accuracy: 68.9%\n",
            "Step: 2804 ------------ Loss: 6815.47 ------------ Accuracy: 68.9%\n",
            "Step: 2805 ------------ Loss: 6815.21 ------------ Accuracy: 68.9%\n",
            "Step: 2806 ------------ Loss: 6814.96 ------------ Accuracy: 68.9%\n",
            "Step: 2807 ------------ Loss: 6814.7 ------------ Accuracy: 68.9%\n",
            "Step: 2808 ------------ Loss: 6814.45 ------------ Accuracy: 68.9%\n",
            "Step: 2809 ------------ Loss: 6814.19 ------------ Accuracy: 68.9%\n",
            "Step: 2810 ------------ Loss: 6813.94 ------------ Accuracy: 68.9%\n",
            "Step: 2811 ------------ Loss: 6813.68 ------------ Accuracy: 68.9%\n",
            "Step: 2812 ------------ Loss: 6813.43 ------------ Accuracy: 68.9%\n",
            "Step: 2813 ------------ Loss: 6813.17 ------------ Accuracy: 68.9%\n",
            "Step: 2814 ------------ Loss: 6812.92 ------------ Accuracy: 68.9%\n",
            "Step: 2815 ------------ Loss: 6812.66 ------------ Accuracy: 68.9%\n",
            "Step: 2816 ------------ Loss: 6812.41 ------------ Accuracy: 68.9%\n",
            "Step: 2817 ------------ Loss: 6812.15 ------------ Accuracy: 68.9%\n",
            "Step: 2818 ------------ Loss: 6811.9 ------------ Accuracy: 68.9%\n",
            "Step: 2819 ------------ Loss: 6811.65 ------------ Accuracy: 68.9%\n",
            "Step: 2820 ------------ Loss: 6811.39 ------------ Accuracy: 68.9%\n",
            "Step: 2821 ------------ Loss: 6811.14 ------------ Accuracy: 68.9%\n",
            "Step: 2822 ------------ Loss: 6810.88 ------------ Accuracy: 68.9%\n",
            "Step: 2823 ------------ Loss: 6810.63 ------------ Accuracy: 68.9%\n",
            "Step: 2824 ------------ Loss: 6810.38 ------------ Accuracy: 68.9%\n",
            "Step: 2825 ------------ Loss: 6810.12 ------------ Accuracy: 68.9%\n",
            "Step: 2826 ------------ Loss: 6809.87 ------------ Accuracy: 68.9%\n",
            "Step: 2827 ------------ Loss: 6809.62 ------------ Accuracy: 68.9%\n",
            "Step: 2828 ------------ Loss: 6809.36 ------------ Accuracy: 68.9%\n",
            "Step: 2829 ------------ Loss: 6809.11 ------------ Accuracy: 68.9%\n",
            "Step: 2830 ------------ Loss: 6808.86 ------------ Accuracy: 68.9%\n",
            "Step: 2831 ------------ Loss: 6808.6 ------------ Accuracy: 68.9%\n",
            "Step: 2832 ------------ Loss: 6808.35 ------------ Accuracy: 68.9%\n",
            "Step: 2833 ------------ Loss: 6808.1 ------------ Accuracy: 68.9%\n",
            "Step: 2834 ------------ Loss: 6807.85 ------------ Accuracy: 68.9%\n",
            "Step: 2835 ------------ Loss: 6807.59 ------------ Accuracy: 68.9%\n",
            "Step: 2836 ------------ Loss: 6807.34 ------------ Accuracy: 68.9%\n",
            "Step: 2837 ------------ Loss: 6807.09 ------------ Accuracy: 68.9%\n",
            "Step: 2838 ------------ Loss: 6806.84 ------------ Accuracy: 68.9%\n",
            "Step: 2839 ------------ Loss: 6806.58 ------------ Accuracy: 68.9%\n",
            "Step: 2840 ------------ Loss: 6806.33 ------------ Accuracy: 68.9%\n",
            "Step: 2841 ------------ Loss: 6806.08 ------------ Accuracy: 68.9%\n",
            "Step: 2842 ------------ Loss: 6805.83 ------------ Accuracy: 68.9%\n",
            "Step: 2843 ------------ Loss: 6805.58 ------------ Accuracy: 68.9%\n",
            "Step: 2844 ------------ Loss: 6805.33 ------------ Accuracy: 68.9%\n",
            "Step: 2845 ------------ Loss: 6805.07 ------------ Accuracy: 68.9%\n",
            "Step: 2846 ------------ Loss: 6804.82 ------------ Accuracy: 68.9%\n",
            "Step: 2847 ------------ Loss: 6804.57 ------------ Accuracy: 68.9%\n",
            "Step: 2848 ------------ Loss: 6804.32 ------------ Accuracy: 68.9%\n",
            "Step: 2849 ------------ Loss: 6804.07 ------------ Accuracy: 68.9%\n",
            "Step: 2850 ------------ Loss: 6803.82 ------------ Accuracy: 68.9%\n",
            "Step: 2851 ------------ Loss: 6803.57 ------------ Accuracy: 68.9%\n",
            "Step: 2852 ------------ Loss: 6803.32 ------------ Accuracy: 68.9%\n",
            "Step: 2853 ------------ Loss: 6803.07 ------------ Accuracy: 68.9%\n",
            "Step: 2854 ------------ Loss: 6802.82 ------------ Accuracy: 68.9%\n",
            "Step: 2855 ------------ Loss: 6802.57 ------------ Accuracy: 68.9%\n",
            "Step: 2856 ------------ Loss: 6802.32 ------------ Accuracy: 68.9%\n",
            "Step: 2857 ------------ Loss: 6802.07 ------------ Accuracy: 68.9%\n",
            "Step: 2858 ------------ Loss: 6801.82 ------------ Accuracy: 68.9%\n",
            "Step: 2859 ------------ Loss: 6801.57 ------------ Accuracy: 68.9%\n",
            "Step: 2860 ------------ Loss: 6801.32 ------------ Accuracy: 68.9%\n",
            "Step: 2861 ------------ Loss: 6801.07 ------------ Accuracy: 68.9%\n",
            "Step: 2862 ------------ Loss: 6800.82 ------------ Accuracy: 68.9%\n",
            "Step: 2863 ------------ Loss: 6800.57 ------------ Accuracy: 68.9%\n",
            "Step: 2864 ------------ Loss: 6800.32 ------------ Accuracy: 68.9%\n",
            "Step: 2865 ------------ Loss: 6800.07 ------------ Accuracy: 68.9%\n",
            "Step: 2866 ------------ Loss: 6799.82 ------------ Accuracy: 68.9%\n",
            "Step: 2867 ------------ Loss: 6799.57 ------------ Accuracy: 68.9%\n",
            "Step: 2868 ------------ Loss: 6799.32 ------------ Accuracy: 68.9%\n",
            "Step: 2869 ------------ Loss: 6799.07 ------------ Accuracy: 68.9%\n",
            "Step: 2870 ------------ Loss: 6798.83 ------------ Accuracy: 68.9%\n",
            "Step: 2871 ------------ Loss: 6798.58 ------------ Accuracy: 68.9%\n",
            "Step: 2872 ------------ Loss: 6798.33 ------------ Accuracy: 68.9%\n",
            "Step: 2873 ------------ Loss: 6798.08 ------------ Accuracy: 68.9%\n",
            "Step: 2874 ------------ Loss: 6797.83 ------------ Accuracy: 68.9%\n",
            "Step: 2875 ------------ Loss: 6797.58 ------------ Accuracy: 68.9%\n",
            "Step: 2876 ------------ Loss: 6797.34 ------------ Accuracy: 68.9%\n",
            "Step: 2877 ------------ Loss: 6797.09 ------------ Accuracy: 68.9%\n",
            "Step: 2878 ------------ Loss: 6796.84 ------------ Accuracy: 68.9%\n",
            "Step: 2879 ------------ Loss: 6796.59 ------------ Accuracy: 68.9%\n",
            "Step: 2880 ------------ Loss: 6796.35 ------------ Accuracy: 68.9%\n",
            "Step: 2881 ------------ Loss: 6796.1 ------------ Accuracy: 68.9%\n",
            "Step: 2882 ------------ Loss: 6795.85 ------------ Accuracy: 68.9%\n",
            "Step: 2883 ------------ Loss: 6795.6 ------------ Accuracy: 68.9%\n",
            "Step: 2884 ------------ Loss: 6795.36 ------------ Accuracy: 68.9%\n",
            "Step: 2885 ------------ Loss: 6795.11 ------------ Accuracy: 68.9%\n",
            "Step: 2886 ------------ Loss: 6794.86 ------------ Accuracy: 68.9%\n",
            "Step: 2887 ------------ Loss: 6794.62 ------------ Accuracy: 68.9%\n",
            "Step: 2888 ------------ Loss: 6794.37 ------------ Accuracy: 68.9%\n",
            "Step: 2889 ------------ Loss: 6794.12 ------------ Accuracy: 68.9%\n",
            "Step: 2890 ------------ Loss: 6793.88 ------------ Accuracy: 68.9%\n",
            "Step: 2891 ------------ Loss: 6793.63 ------------ Accuracy: 68.9%\n",
            "Step: 2892 ------------ Loss: 6793.38 ------------ Accuracy: 68.9%\n",
            "Step: 2893 ------------ Loss: 6793.14 ------------ Accuracy: 68.9%\n",
            "Step: 2894 ------------ Loss: 6792.89 ------------ Accuracy: 68.9%\n",
            "Step: 2895 ------------ Loss: 6792.64 ------------ Accuracy: 68.9%\n",
            "Step: 2896 ------------ Loss: 6792.4 ------------ Accuracy: 68.9%\n",
            "Step: 2897 ------------ Loss: 6792.15 ------------ Accuracy: 68.9%\n",
            "Step: 2898 ------------ Loss: 6791.91 ------------ Accuracy: 68.9%\n",
            "Step: 2899 ------------ Loss: 6791.66 ------------ Accuracy: 68.9%\n",
            "Step: 2900 ------------ Loss: 6791.42 ------------ Accuracy: 68.9%\n",
            "Step: 2901 ------------ Loss: 6791.17 ------------ Accuracy: 68.9%\n",
            "Step: 2902 ------------ Loss: 6790.92 ------------ Accuracy: 68.9%\n",
            "Step: 2903 ------------ Loss: 6790.68 ------------ Accuracy: 68.9%\n",
            "Step: 2904 ------------ Loss: 6790.43 ------------ Accuracy: 68.9%\n",
            "Step: 2905 ------------ Loss: 6790.19 ------------ Accuracy: 68.9%\n",
            "Step: 2906 ------------ Loss: 6789.94 ------------ Accuracy: 68.9%\n",
            "Step: 2907 ------------ Loss: 6789.7 ------------ Accuracy: 68.9%\n",
            "Step: 2908 ------------ Loss: 6789.46 ------------ Accuracy: 68.9%\n",
            "Step: 2909 ------------ Loss: 6789.21 ------------ Accuracy: 68.9%\n",
            "Step: 2910 ------------ Loss: 6788.97 ------------ Accuracy: 68.9%\n",
            "Step: 2911 ------------ Loss: 6788.72 ------------ Accuracy: 68.9%\n",
            "Step: 2912 ------------ Loss: 6788.48 ------------ Accuracy: 68.9%\n",
            "Step: 2913 ------------ Loss: 6788.23 ------------ Accuracy: 68.9%\n",
            "Step: 2914 ------------ Loss: 6787.99 ------------ Accuracy: 68.9%\n",
            "Step: 2915 ------------ Loss: 6787.75 ------------ Accuracy: 68.9%\n",
            "Step: 2916 ------------ Loss: 6787.5 ------------ Accuracy: 68.9%\n",
            "Step: 2917 ------------ Loss: 6787.26 ------------ Accuracy: 68.9%\n",
            "Step: 2918 ------------ Loss: 6787.01 ------------ Accuracy: 68.9%\n",
            "Step: 2919 ------------ Loss: 6786.77 ------------ Accuracy: 68.9%\n",
            "Step: 2920 ------------ Loss: 6786.53 ------------ Accuracy: 68.9%\n",
            "Step: 2921 ------------ Loss: 6786.28 ------------ Accuracy: 68.9%\n",
            "Step: 2922 ------------ Loss: 6786.04 ------------ Accuracy: 68.9%\n",
            "Step: 2923 ------------ Loss: 6785.8 ------------ Accuracy: 68.9%\n",
            "Step: 2924 ------------ Loss: 6785.55 ------------ Accuracy: 68.9%\n",
            "Step: 2925 ------------ Loss: 6785.31 ------------ Accuracy: 68.9%\n",
            "Step: 2926 ------------ Loss: 6785.07 ------------ Accuracy: 68.9%\n",
            "Step: 2927 ------------ Loss: 6784.83 ------------ Accuracy: 68.9%\n",
            "Step: 2928 ------------ Loss: 6784.58 ------------ Accuracy: 68.9%\n",
            "Step: 2929 ------------ Loss: 6784.34 ------------ Accuracy: 68.9%\n",
            "Step: 2930 ------------ Loss: 6784.1 ------------ Accuracy: 68.9%\n",
            "Step: 2931 ------------ Loss: 6783.86 ------------ Accuracy: 68.9%\n",
            "Step: 2932 ------------ Loss: 6783.61 ------------ Accuracy: 68.9%\n",
            "Step: 2933 ------------ Loss: 6783.37 ------------ Accuracy: 68.9%\n",
            "Step: 2934 ------------ Loss: 6783.13 ------------ Accuracy: 68.9%\n",
            "Step: 2935 ------------ Loss: 6782.89 ------------ Accuracy: 68.9%\n",
            "Step: 2936 ------------ Loss: 6782.65 ------------ Accuracy: 68.9%\n",
            "Step: 2937 ------------ Loss: 6782.41 ------------ Accuracy: 68.9%\n",
            "Step: 2938 ------------ Loss: 6782.16 ------------ Accuracy: 68.9%\n",
            "Step: 2939 ------------ Loss: 6781.92 ------------ Accuracy: 68.9%\n",
            "Step: 2940 ------------ Loss: 6781.68 ------------ Accuracy: 68.9%\n",
            "Step: 2941 ------------ Loss: 6781.44 ------------ Accuracy: 68.9%\n",
            "Step: 2942 ------------ Loss: 6781.2 ------------ Accuracy: 68.9%\n",
            "Step: 2943 ------------ Loss: 6780.96 ------------ Accuracy: 68.9%\n",
            "Step: 2944 ------------ Loss: 6780.72 ------------ Accuracy: 68.9%\n",
            "Step: 2945 ------------ Loss: 6780.48 ------------ Accuracy: 68.9%\n",
            "Step: 2946 ------------ Loss: 6780.23 ------------ Accuracy: 68.9%\n",
            "Step: 2947 ------------ Loss: 6779.99 ------------ Accuracy: 68.9%\n",
            "Step: 2948 ------------ Loss: 6779.75 ------------ Accuracy: 68.9%\n",
            "Step: 2949 ------------ Loss: 6779.51 ------------ Accuracy: 68.9%\n",
            "Step: 2950 ------------ Loss: 6779.27 ------------ Accuracy: 68.9%\n",
            "Step: 2951 ------------ Loss: 6779.03 ------------ Accuracy: 68.9%\n",
            "Step: 2952 ------------ Loss: 6778.79 ------------ Accuracy: 68.9%\n",
            "Step: 2953 ------------ Loss: 6778.55 ------------ Accuracy: 68.9%\n",
            "Step: 2954 ------------ Loss: 6778.31 ------------ Accuracy: 68.9%\n",
            "Step: 2955 ------------ Loss: 6778.07 ------------ Accuracy: 68.9%\n",
            "Step: 2956 ------------ Loss: 6777.83 ------------ Accuracy: 68.9%\n",
            "Step: 2957 ------------ Loss: 6777.59 ------------ Accuracy: 68.9%\n",
            "Step: 2958 ------------ Loss: 6777.35 ------------ Accuracy: 68.9%\n",
            "Step: 2959 ------------ Loss: 6777.11 ------------ Accuracy: 68.9%\n",
            "Step: 2960 ------------ Loss: 6776.87 ------------ Accuracy: 68.9%\n",
            "Step: 2961 ------------ Loss: 6776.64 ------------ Accuracy: 68.9%\n",
            "Step: 2962 ------------ Loss: 6776.4 ------------ Accuracy: 68.9%\n",
            "Step: 2963 ------------ Loss: 6776.16 ------------ Accuracy: 68.9%\n",
            "Step: 2964 ------------ Loss: 6775.92 ------------ Accuracy: 68.9%\n",
            "Step: 2965 ------------ Loss: 6775.68 ------------ Accuracy: 68.9%\n",
            "Step: 2966 ------------ Loss: 6775.44 ------------ Accuracy: 68.9%\n",
            "Step: 2967 ------------ Loss: 6775.2 ------------ Accuracy: 68.9%\n",
            "Step: 2968 ------------ Loss: 6774.96 ------------ Accuracy: 68.9%\n",
            "Step: 2969 ------------ Loss: 6774.73 ------------ Accuracy: 68.9%\n",
            "Step: 2970 ------------ Loss: 6774.49 ------------ Accuracy: 68.9%\n",
            "Step: 2971 ------------ Loss: 6774.25 ------------ Accuracy: 68.9%\n",
            "Step: 2972 ------------ Loss: 6774.01 ------------ Accuracy: 68.9%\n",
            "Step: 2973 ------------ Loss: 6773.77 ------------ Accuracy: 68.9%\n",
            "Step: 2974 ------------ Loss: 6773.53 ------------ Accuracy: 68.9%\n",
            "Step: 2975 ------------ Loss: 6773.3 ------------ Accuracy: 68.9%\n",
            "Step: 2976 ------------ Loss: 6773.06 ------------ Accuracy: 68.9%\n",
            "Step: 2977 ------------ Loss: 6772.82 ------------ Accuracy: 68.9%\n",
            "Step: 2978 ------------ Loss: 6772.58 ------------ Accuracy: 68.9%\n",
            "Step: 2979 ------------ Loss: 6772.35 ------------ Accuracy: 68.9%\n",
            "Step: 2980 ------------ Loss: 6772.11 ------------ Accuracy: 68.9%\n",
            "Step: 2981 ------------ Loss: 6771.87 ------------ Accuracy: 68.9%\n",
            "Step: 2982 ------------ Loss: 6771.63 ------------ Accuracy: 68.9%\n",
            "Step: 2983 ------------ Loss: 6771.4 ------------ Accuracy: 68.9%\n",
            "Step: 2984 ------------ Loss: 6771.16 ------------ Accuracy: 68.9%\n",
            "Step: 2985 ------------ Loss: 6770.92 ------------ Accuracy: 68.9%\n",
            "Step: 2986 ------------ Loss: 6770.69 ------------ Accuracy: 68.9%\n",
            "Step: 2987 ------------ Loss: 6770.45 ------------ Accuracy: 68.9%\n",
            "Step: 2988 ------------ Loss: 6770.21 ------------ Accuracy: 68.9%\n",
            "Step: 2989 ------------ Loss: 6769.98 ------------ Accuracy: 68.9%\n",
            "Step: 2990 ------------ Loss: 6769.74 ------------ Accuracy: 68.8%\n",
            "Step: 2991 ------------ Loss: 6769.5 ------------ Accuracy: 68.8%\n",
            "Step: 2992 ------------ Loss: 6769.27 ------------ Accuracy: 68.8%\n",
            "Step: 2993 ------------ Loss: 6769.03 ------------ Accuracy: 68.8%\n",
            "Step: 2994 ------------ Loss: 6768.8 ------------ Accuracy: 68.8%\n",
            "Step: 2995 ------------ Loss: 6768.56 ------------ Accuracy: 68.8%\n",
            "Step: 2996 ------------ Loss: 6768.32 ------------ Accuracy: 68.8%\n",
            "Step: 2997 ------------ Loss: 6768.09 ------------ Accuracy: 68.8%\n",
            "Step: 2998 ------------ Loss: 6767.85 ------------ Accuracy: 68.8%\n",
            "Step: 2999 ------------ Loss: 6767.62 ------------ Accuracy: 68.8%\n",
            "Step: 3000 ------------ Loss: 6767.38 ------------ Accuracy: 68.8%\n",
            "Step: 3001 ------------ Loss: 6767.15 ------------ Accuracy: 68.8%\n",
            "Step: 3002 ------------ Loss: 6766.91 ------------ Accuracy: 68.8%\n",
            "Step: 3003 ------------ Loss: 6766.68 ------------ Accuracy: 68.8%\n",
            "Step: 3004 ------------ Loss: 6766.44 ------------ Accuracy: 68.8%\n",
            "Step: 3005 ------------ Loss: 6766.21 ------------ Accuracy: 68.8%\n",
            "Step: 3006 ------------ Loss: 6765.97 ------------ Accuracy: 68.9%\n",
            "Step: 3007 ------------ Loss: 6765.74 ------------ Accuracy: 68.9%\n",
            "Step: 3008 ------------ Loss: 6765.5 ------------ Accuracy: 68.9%\n",
            "Step: 3009 ------------ Loss: 6765.27 ------------ Accuracy: 68.9%\n",
            "Step: 3010 ------------ Loss: 6765.03 ------------ Accuracy: 68.9%\n",
            "Step: 3011 ------------ Loss: 6764.8 ------------ Accuracy: 68.9%\n",
            "Step: 3012 ------------ Loss: 6764.57 ------------ Accuracy: 68.9%\n",
            "Step: 3013 ------------ Loss: 6764.33 ------------ Accuracy: 68.9%\n",
            "Step: 3014 ------------ Loss: 6764.1 ------------ Accuracy: 68.9%\n",
            "Step: 3015 ------------ Loss: 6763.86 ------------ Accuracy: 68.9%\n",
            "Step: 3016 ------------ Loss: 6763.63 ------------ Accuracy: 68.9%\n",
            "Step: 3017 ------------ Loss: 6763.4 ------------ Accuracy: 68.9%\n",
            "Step: 3018 ------------ Loss: 6763.16 ------------ Accuracy: 68.9%\n",
            "Step: 3019 ------------ Loss: 6762.93 ------------ Accuracy: 68.9%\n",
            "Step: 3020 ------------ Loss: 6762.7 ------------ Accuracy: 68.9%\n",
            "Step: 3021 ------------ Loss: 6762.46 ------------ Accuracy: 68.9%\n",
            "Step: 3022 ------------ Loss: 6762.23 ------------ Accuracy: 68.9%\n",
            "Step: 3023 ------------ Loss: 6762.0 ------------ Accuracy: 68.9%\n",
            "Step: 3024 ------------ Loss: 6761.76 ------------ Accuracy: 68.9%\n",
            "Step: 3025 ------------ Loss: 6761.53 ------------ Accuracy: 68.9%\n",
            "Step: 3026 ------------ Loss: 6761.3 ------------ Accuracy: 68.9%\n",
            "Step: 3027 ------------ Loss: 6761.06 ------------ Accuracy: 68.9%\n",
            "Step: 3028 ------------ Loss: 6760.83 ------------ Accuracy: 68.9%\n",
            "Step: 3029 ------------ Loss: 6760.6 ------------ Accuracy: 68.9%\n",
            "Step: 3030 ------------ Loss: 6760.37 ------------ Accuracy: 68.9%\n",
            "Step: 3031 ------------ Loss: 6760.13 ------------ Accuracy: 68.9%\n",
            "Step: 3032 ------------ Loss: 6759.9 ------------ Accuracy: 68.9%\n",
            "Step: 3033 ------------ Loss: 6759.67 ------------ Accuracy: 68.9%\n",
            "Step: 3034 ------------ Loss: 6759.44 ------------ Accuracy: 68.9%\n",
            "Step: 3035 ------------ Loss: 6759.21 ------------ Accuracy: 68.9%\n",
            "Step: 3036 ------------ Loss: 6758.97 ------------ Accuracy: 68.9%\n",
            "Step: 3037 ------------ Loss: 6758.74 ------------ Accuracy: 68.9%\n",
            "Step: 3038 ------------ Loss: 6758.51 ------------ Accuracy: 68.9%\n",
            "Step: 3039 ------------ Loss: 6758.28 ------------ Accuracy: 68.9%\n",
            "Step: 3040 ------------ Loss: 6758.05 ------------ Accuracy: 69.0%\n",
            "Step: 3041 ------------ Loss: 6757.82 ------------ Accuracy: 69.0%\n",
            "Step: 3042 ------------ Loss: 6757.58 ------------ Accuracy: 69.0%\n",
            "Step: 3043 ------------ Loss: 6757.35 ------------ Accuracy: 69.0%\n",
            "Step: 3044 ------------ Loss: 6757.12 ------------ Accuracy: 69.0%\n",
            "Step: 3045 ------------ Loss: 6756.89 ------------ Accuracy: 69.0%\n",
            "Step: 3046 ------------ Loss: 6756.66 ------------ Accuracy: 69.0%\n",
            "Step: 3047 ------------ Loss: 6756.43 ------------ Accuracy: 69.0%\n",
            "Step: 3048 ------------ Loss: 6756.2 ------------ Accuracy: 69.0%\n",
            "Step: 3049 ------------ Loss: 6755.97 ------------ Accuracy: 69.0%\n",
            "Step: 3050 ------------ Loss: 6755.74 ------------ Accuracy: 69.0%\n",
            "Step: 3051 ------------ Loss: 6755.51 ------------ Accuracy: 69.0%\n",
            "Step: 3052 ------------ Loss: 6755.28 ------------ Accuracy: 69.0%\n",
            "Step: 3053 ------------ Loss: 6755.05 ------------ Accuracy: 69.0%\n",
            "Step: 3054 ------------ Loss: 6754.82 ------------ Accuracy: 69.0%\n",
            "Step: 3055 ------------ Loss: 6754.59 ------------ Accuracy: 69.0%\n",
            "Step: 3056 ------------ Loss: 6754.36 ------------ Accuracy: 69.0%\n",
            "Step: 3057 ------------ Loss: 6754.13 ------------ Accuracy: 69.0%\n",
            "Step: 3058 ------------ Loss: 6753.9 ------------ Accuracy: 69.0%\n",
            "Step: 3059 ------------ Loss: 6753.67 ------------ Accuracy: 69.0%\n",
            "Step: 3060 ------------ Loss: 6753.44 ------------ Accuracy: 69.0%\n",
            "Step: 3061 ------------ Loss: 6753.21 ------------ Accuracy: 69.0%\n",
            "Step: 3062 ------------ Loss: 6752.98 ------------ Accuracy: 69.0%\n",
            "Step: 3063 ------------ Loss: 6752.75 ------------ Accuracy: 69.0%\n",
            "Step: 3064 ------------ Loss: 6752.52 ------------ Accuracy: 69.0%\n",
            "Step: 3065 ------------ Loss: 6752.29 ------------ Accuracy: 69.0%\n",
            "Step: 3066 ------------ Loss: 6752.06 ------------ Accuracy: 69.0%\n",
            "Step: 3067 ------------ Loss: 6751.83 ------------ Accuracy: 69.0%\n",
            "Step: 3068 ------------ Loss: 6751.6 ------------ Accuracy: 69.0%\n",
            "Step: 3069 ------------ Loss: 6751.37 ------------ Accuracy: 69.0%\n",
            "Step: 3070 ------------ Loss: 6751.15 ------------ Accuracy: 69.0%\n",
            "Step: 3071 ------------ Loss: 6750.92 ------------ Accuracy: 69.0%\n",
            "Step: 3072 ------------ Loss: 6750.69 ------------ Accuracy: 69.0%\n",
            "Step: 3073 ------------ Loss: 6750.46 ------------ Accuracy: 69.0%\n",
            "Step: 3074 ------------ Loss: 6750.23 ------------ Accuracy: 69.0%\n",
            "Step: 3075 ------------ Loss: 6750.0 ------------ Accuracy: 69.0%\n",
            "Step: 3076 ------------ Loss: 6749.77 ------------ Accuracy: 69.0%\n",
            "Step: 3077 ------------ Loss: 6749.55 ------------ Accuracy: 69.0%\n",
            "Step: 3078 ------------ Loss: 6749.32 ------------ Accuracy: 69.0%\n",
            "Step: 3079 ------------ Loss: 6749.09 ------------ Accuracy: 69.0%\n",
            "Step: 3080 ------------ Loss: 6748.86 ------------ Accuracy: 69.0%\n",
            "Step: 3081 ------------ Loss: 6748.64 ------------ Accuracy: 69.0%\n",
            "Step: 3082 ------------ Loss: 6748.41 ------------ Accuracy: 69.0%\n",
            "Step: 3083 ------------ Loss: 6748.18 ------------ Accuracy: 69.0%\n",
            "Step: 3084 ------------ Loss: 6747.95 ------------ Accuracy: 69.0%\n",
            "Step: 3085 ------------ Loss: 6747.73 ------------ Accuracy: 69.0%\n",
            "Step: 3086 ------------ Loss: 6747.5 ------------ Accuracy: 69.0%\n",
            "Step: 3087 ------------ Loss: 6747.27 ------------ Accuracy: 69.0%\n",
            "Step: 3088 ------------ Loss: 6747.04 ------------ Accuracy: 69.0%\n",
            "Step: 3089 ------------ Loss: 6746.82 ------------ Accuracy: 69.0%\n",
            "Step: 3090 ------------ Loss: 6746.59 ------------ Accuracy: 69.0%\n",
            "Step: 3091 ------------ Loss: 6746.36 ------------ Accuracy: 69.0%\n",
            "Step: 3092 ------------ Loss: 6746.14 ------------ Accuracy: 69.0%\n",
            "Step: 3093 ------------ Loss: 6745.91 ------------ Accuracy: 69.0%\n",
            "Step: 3094 ------------ Loss: 6745.68 ------------ Accuracy: 69.0%\n",
            "Step: 3095 ------------ Loss: 6745.46 ------------ Accuracy: 69.0%\n",
            "Step: 3096 ------------ Loss: 6745.23 ------------ Accuracy: 69.0%\n",
            "Step: 3097 ------------ Loss: 6745.01 ------------ Accuracy: 69.0%\n",
            "Step: 3098 ------------ Loss: 6744.78 ------------ Accuracy: 69.0%\n",
            "Step: 3099 ------------ Loss: 6744.55 ------------ Accuracy: 69.0%\n",
            "Step: 3100 ------------ Loss: 6744.33 ------------ Accuracy: 69.0%\n",
            "Step: 3101 ------------ Loss: 6744.1 ------------ Accuracy: 69.0%\n",
            "Step: 3102 ------------ Loss: 6743.88 ------------ Accuracy: 69.0%\n",
            "Step: 3103 ------------ Loss: 6743.65 ------------ Accuracy: 69.0%\n",
            "Step: 3104 ------------ Loss: 6743.42 ------------ Accuracy: 69.0%\n",
            "Step: 3105 ------------ Loss: 6743.2 ------------ Accuracy: 69.0%\n",
            "Step: 3106 ------------ Loss: 6742.97 ------------ Accuracy: 69.0%\n",
            "Step: 3107 ------------ Loss: 6742.75 ------------ Accuracy: 69.0%\n",
            "Step: 3108 ------------ Loss: 6742.52 ------------ Accuracy: 69.0%\n",
            "Step: 3109 ------------ Loss: 6742.3 ------------ Accuracy: 69.0%\n",
            "Step: 3110 ------------ Loss: 6742.07 ------------ Accuracy: 69.0%\n",
            "Step: 3111 ------------ Loss: 6741.85 ------------ Accuracy: 69.0%\n",
            "Step: 3112 ------------ Loss: 6741.62 ------------ Accuracy: 69.0%\n",
            "Step: 3113 ------------ Loss: 6741.4 ------------ Accuracy: 69.0%\n",
            "Step: 3114 ------------ Loss: 6741.17 ------------ Accuracy: 69.0%\n",
            "Step: 3115 ------------ Loss: 6740.95 ------------ Accuracy: 69.0%\n",
            "Step: 3116 ------------ Loss: 6740.73 ------------ Accuracy: 69.0%\n",
            "Step: 3117 ------------ Loss: 6740.5 ------------ Accuracy: 69.0%\n",
            "Step: 3118 ------------ Loss: 6740.28 ------------ Accuracy: 69.0%\n",
            "Step: 3119 ------------ Loss: 6740.05 ------------ Accuracy: 69.0%\n",
            "Step: 3120 ------------ Loss: 6739.83 ------------ Accuracy: 69.0%\n",
            "Step: 3121 ------------ Loss: 6739.6 ------------ Accuracy: 69.0%\n",
            "Step: 3122 ------------ Loss: 6739.38 ------------ Accuracy: 69.0%\n",
            "Step: 3123 ------------ Loss: 6739.16 ------------ Accuracy: 69.0%\n",
            "Step: 3124 ------------ Loss: 6738.93 ------------ Accuracy: 69.0%\n",
            "Step: 3125 ------------ Loss: 6738.71 ------------ Accuracy: 69.0%\n",
            "Step: 3126 ------------ Loss: 6738.49 ------------ Accuracy: 69.0%\n",
            "Step: 3127 ------------ Loss: 6738.26 ------------ Accuracy: 69.0%\n",
            "Step: 3128 ------------ Loss: 6738.04 ------------ Accuracy: 69.0%\n",
            "Step: 3129 ------------ Loss: 6737.82 ------------ Accuracy: 69.0%\n",
            "Step: 3130 ------------ Loss: 6737.59 ------------ Accuracy: 69.0%\n",
            "Step: 3131 ------------ Loss: 6737.37 ------------ Accuracy: 69.0%\n",
            "Step: 3132 ------------ Loss: 6737.15 ------------ Accuracy: 69.0%\n",
            "Step: 3133 ------------ Loss: 6736.92 ------------ Accuracy: 69.0%\n",
            "Step: 3134 ------------ Loss: 6736.7 ------------ Accuracy: 69.0%\n",
            "Step: 3135 ------------ Loss: 6736.48 ------------ Accuracy: 69.0%\n",
            "Step: 3136 ------------ Loss: 6736.26 ------------ Accuracy: 69.0%\n",
            "Step: 3137 ------------ Loss: 6736.03 ------------ Accuracy: 69.0%\n",
            "Step: 3138 ------------ Loss: 6735.81 ------------ Accuracy: 69.0%\n",
            "Step: 3139 ------------ Loss: 6735.59 ------------ Accuracy: 69.0%\n",
            "Step: 3140 ------------ Loss: 6735.37 ------------ Accuracy: 69.0%\n",
            "Step: 3141 ------------ Loss: 6735.14 ------------ Accuracy: 69.0%\n",
            "Step: 3142 ------------ Loss: 6734.92 ------------ Accuracy: 69.0%\n",
            "Step: 3143 ------------ Loss: 6734.7 ------------ Accuracy: 69.0%\n",
            "Step: 3144 ------------ Loss: 6734.48 ------------ Accuracy: 69.0%\n",
            "Step: 3145 ------------ Loss: 6734.26 ------------ Accuracy: 69.0%\n",
            "Step: 3146 ------------ Loss: 6734.03 ------------ Accuracy: 69.0%\n",
            "Step: 3147 ------------ Loss: 6733.81 ------------ Accuracy: 69.0%\n",
            "Step: 3148 ------------ Loss: 6733.59 ------------ Accuracy: 69.0%\n",
            "Step: 3149 ------------ Loss: 6733.37 ------------ Accuracy: 69.0%\n",
            "Step: 3150 ------------ Loss: 6733.15 ------------ Accuracy: 69.0%\n",
            "Step: 3151 ------------ Loss: 6732.93 ------------ Accuracy: 69.0%\n",
            "Step: 3152 ------------ Loss: 6732.71 ------------ Accuracy: 69.0%\n",
            "Step: 3153 ------------ Loss: 6732.48 ------------ Accuracy: 69.0%\n",
            "Step: 3154 ------------ Loss: 6732.26 ------------ Accuracy: 69.1%\n",
            "Step: 3155 ------------ Loss: 6732.04 ------------ Accuracy: 69.1%\n",
            "Step: 3156 ------------ Loss: 6731.82 ------------ Accuracy: 69.1%\n",
            "Step: 3157 ------------ Loss: 6731.6 ------------ Accuracy: 69.1%\n",
            "Step: 3158 ------------ Loss: 6731.38 ------------ Accuracy: 69.1%\n",
            "Step: 3159 ------------ Loss: 6731.16 ------------ Accuracy: 69.1%\n",
            "Step: 3160 ------------ Loss: 6730.94 ------------ Accuracy: 69.1%\n",
            "Step: 3161 ------------ Loss: 6730.72 ------------ Accuracy: 69.1%\n",
            "Step: 3162 ------------ Loss: 6730.5 ------------ Accuracy: 69.1%\n",
            "Step: 3163 ------------ Loss: 6730.28 ------------ Accuracy: 69.1%\n",
            "Step: 3164 ------------ Loss: 6730.06 ------------ Accuracy: 69.1%\n",
            "Step: 3165 ------------ Loss: 6729.84 ------------ Accuracy: 69.2%\n",
            "Step: 3166 ------------ Loss: 6729.62 ------------ Accuracy: 69.2%\n",
            "Step: 3167 ------------ Loss: 6729.4 ------------ Accuracy: 69.2%\n",
            "Step: 3168 ------------ Loss: 6729.18 ------------ Accuracy: 69.2%\n",
            "Step: 3169 ------------ Loss: 6728.96 ------------ Accuracy: 69.2%\n",
            "Step: 3170 ------------ Loss: 6728.74 ------------ Accuracy: 69.2%\n",
            "Step: 3171 ------------ Loss: 6728.52 ------------ Accuracy: 69.2%\n",
            "Step: 3172 ------------ Loss: 6728.3 ------------ Accuracy: 69.2%\n",
            "Step: 3173 ------------ Loss: 6728.08 ------------ Accuracy: 69.2%\n",
            "Step: 3174 ------------ Loss: 6727.86 ------------ Accuracy: 69.2%\n",
            "Step: 3175 ------------ Loss: 6727.64 ------------ Accuracy: 69.2%\n",
            "Step: 3176 ------------ Loss: 6727.42 ------------ Accuracy: 69.2%\n",
            "Step: 3177 ------------ Loss: 6727.2 ------------ Accuracy: 69.2%\n",
            "Step: 3178 ------------ Loss: 6726.98 ------------ Accuracy: 69.2%\n",
            "Step: 3179 ------------ Loss: 6726.77 ------------ Accuracy: 69.2%\n",
            "Step: 3180 ------------ Loss: 6726.55 ------------ Accuracy: 69.2%\n",
            "Step: 3181 ------------ Loss: 6726.33 ------------ Accuracy: 69.2%\n",
            "Step: 3182 ------------ Loss: 6726.11 ------------ Accuracy: 69.2%\n",
            "Step: 3183 ------------ Loss: 6725.89 ------------ Accuracy: 69.2%\n",
            "Step: 3184 ------------ Loss: 6725.67 ------------ Accuracy: 69.2%\n",
            "Step: 3185 ------------ Loss: 6725.45 ------------ Accuracy: 69.2%\n",
            "Step: 3186 ------------ Loss: 6725.24 ------------ Accuracy: 69.2%\n",
            "Step: 3187 ------------ Loss: 6725.02 ------------ Accuracy: 69.2%\n",
            "Step: 3188 ------------ Loss: 6724.8 ------------ Accuracy: 69.2%\n",
            "Step: 3189 ------------ Loss: 6724.58 ------------ Accuracy: 69.2%\n",
            "Step: 3190 ------------ Loss: 6724.36 ------------ Accuracy: 69.2%\n",
            "Step: 3191 ------------ Loss: 6724.15 ------------ Accuracy: 69.2%\n",
            "Step: 3192 ------------ Loss: 6723.93 ------------ Accuracy: 69.2%\n",
            "Step: 3193 ------------ Loss: 6723.71 ------------ Accuracy: 69.2%\n",
            "Step: 3194 ------------ Loss: 6723.49 ------------ Accuracy: 69.2%\n",
            "Step: 3195 ------------ Loss: 6723.28 ------------ Accuracy: 69.2%\n",
            "Step: 3196 ------------ Loss: 6723.06 ------------ Accuracy: 69.2%\n",
            "Step: 3197 ------------ Loss: 6722.84 ------------ Accuracy: 69.2%\n",
            "Step: 3198 ------------ Loss: 6722.62 ------------ Accuracy: 69.2%\n",
            "Step: 3199 ------------ Loss: 6722.41 ------------ Accuracy: 69.2%\n",
            "Step: 3200 ------------ Loss: 6722.19 ------------ Accuracy: 69.2%\n",
            "Step: 3201 ------------ Loss: 6721.97 ------------ Accuracy: 69.2%\n",
            "Step: 3202 ------------ Loss: 6721.76 ------------ Accuracy: 69.2%\n",
            "Step: 3203 ------------ Loss: 6721.54 ------------ Accuracy: 69.2%\n",
            "Step: 3204 ------------ Loss: 6721.32 ------------ Accuracy: 69.2%\n",
            "Step: 3205 ------------ Loss: 6721.11 ------------ Accuracy: 69.2%\n",
            "Step: 3206 ------------ Loss: 6720.89 ------------ Accuracy: 69.2%\n",
            "Step: 3207 ------------ Loss: 6720.67 ------------ Accuracy: 69.2%\n",
            "Step: 3208 ------------ Loss: 6720.46 ------------ Accuracy: 69.2%\n",
            "Step: 3209 ------------ Loss: 6720.24 ------------ Accuracy: 69.2%\n",
            "Step: 3210 ------------ Loss: 6720.02 ------------ Accuracy: 69.2%\n",
            "Step: 3211 ------------ Loss: 6719.81 ------------ Accuracy: 69.2%\n",
            "Step: 3212 ------------ Loss: 6719.59 ------------ Accuracy: 69.2%\n",
            "Step: 3213 ------------ Loss: 6719.38 ------------ Accuracy: 69.2%\n",
            "Step: 3214 ------------ Loss: 6719.16 ------------ Accuracy: 69.2%\n",
            "Step: 3215 ------------ Loss: 6718.94 ------------ Accuracy: 69.2%\n",
            "Step: 3216 ------------ Loss: 6718.73 ------------ Accuracy: 69.2%\n",
            "Step: 3217 ------------ Loss: 6718.51 ------------ Accuracy: 69.2%\n",
            "Step: 3218 ------------ Loss: 6718.3 ------------ Accuracy: 69.2%\n",
            "Step: 3219 ------------ Loss: 6718.08 ------------ Accuracy: 69.2%\n",
            "Step: 3220 ------------ Loss: 6717.87 ------------ Accuracy: 69.2%\n",
            "Step: 3221 ------------ Loss: 6717.65 ------------ Accuracy: 69.2%\n",
            "Step: 3222 ------------ Loss: 6717.44 ------------ Accuracy: 69.2%\n",
            "Step: 3223 ------------ Loss: 6717.22 ------------ Accuracy: 69.2%\n",
            "Step: 3224 ------------ Loss: 6717.01 ------------ Accuracy: 69.2%\n",
            "Step: 3225 ------------ Loss: 6716.79 ------------ Accuracy: 69.2%\n",
            "Step: 3226 ------------ Loss: 6716.58 ------------ Accuracy: 69.2%\n",
            "Step: 3227 ------------ Loss: 6716.36 ------------ Accuracy: 69.2%\n",
            "Step: 3228 ------------ Loss: 6716.15 ------------ Accuracy: 69.2%\n",
            "Step: 3229 ------------ Loss: 6715.93 ------------ Accuracy: 69.2%\n",
            "Step: 3230 ------------ Loss: 6715.72 ------------ Accuracy: 69.2%\n",
            "Step: 3231 ------------ Loss: 6715.5 ------------ Accuracy: 69.2%\n",
            "Step: 3232 ------------ Loss: 6715.29 ------------ Accuracy: 69.2%\n",
            "Step: 3233 ------------ Loss: 6715.08 ------------ Accuracy: 69.2%\n",
            "Step: 3234 ------------ Loss: 6714.86 ------------ Accuracy: 69.2%\n",
            "Step: 3235 ------------ Loss: 6714.65 ------------ Accuracy: 69.2%\n",
            "Step: 3236 ------------ Loss: 6714.43 ------------ Accuracy: 69.2%\n",
            "Step: 3237 ------------ Loss: 6714.22 ------------ Accuracy: 69.2%\n",
            "Step: 3238 ------------ Loss: 6714.01 ------------ Accuracy: 69.2%\n",
            "Step: 3239 ------------ Loss: 6713.79 ------------ Accuracy: 69.2%\n",
            "Step: 3240 ------------ Loss: 6713.58 ------------ Accuracy: 69.2%\n",
            "Step: 3241 ------------ Loss: 6713.37 ------------ Accuracy: 69.2%\n",
            "Step: 3242 ------------ Loss: 6713.15 ------------ Accuracy: 69.2%\n",
            "Step: 3243 ------------ Loss: 6712.94 ------------ Accuracy: 69.2%\n",
            "Step: 3244 ------------ Loss: 6712.72 ------------ Accuracy: 69.2%\n",
            "Step: 3245 ------------ Loss: 6712.51 ------------ Accuracy: 69.2%\n",
            "Step: 3246 ------------ Loss: 6712.3 ------------ Accuracy: 69.2%\n",
            "Step: 3247 ------------ Loss: 6712.09 ------------ Accuracy: 69.2%\n",
            "Step: 3248 ------------ Loss: 6711.87 ------------ Accuracy: 69.2%\n",
            "Step: 3249 ------------ Loss: 6711.66 ------------ Accuracy: 69.2%\n",
            "Step: 3250 ------------ Loss: 6711.45 ------------ Accuracy: 69.2%\n",
            "Step: 3251 ------------ Loss: 6711.23 ------------ Accuracy: 69.3%\n",
            "Step: 3252 ------------ Loss: 6711.02 ------------ Accuracy: 69.3%\n",
            "Step: 3253 ------------ Loss: 6710.81 ------------ Accuracy: 69.3%\n",
            "Step: 3254 ------------ Loss: 6710.6 ------------ Accuracy: 69.3%\n",
            "Step: 3255 ------------ Loss: 6710.38 ------------ Accuracy: 69.3%\n",
            "Step: 3256 ------------ Loss: 6710.17 ------------ Accuracy: 69.3%\n",
            "Step: 3257 ------------ Loss: 6709.96 ------------ Accuracy: 69.3%\n",
            "Step: 3258 ------------ Loss: 6709.75 ------------ Accuracy: 69.3%\n",
            "Step: 3259 ------------ Loss: 6709.54 ------------ Accuracy: 69.3%\n",
            "Step: 3260 ------------ Loss: 6709.32 ------------ Accuracy: 69.3%\n",
            "Step: 3261 ------------ Loss: 6709.11 ------------ Accuracy: 69.3%\n",
            "Step: 3262 ------------ Loss: 6708.9 ------------ Accuracy: 69.3%\n",
            "Step: 3263 ------------ Loss: 6708.69 ------------ Accuracy: 69.3%\n",
            "Step: 3264 ------------ Loss: 6708.48 ------------ Accuracy: 69.3%\n",
            "Step: 3265 ------------ Loss: 6708.26 ------------ Accuracy: 69.3%\n",
            "Step: 3266 ------------ Loss: 6708.05 ------------ Accuracy: 69.3%\n",
            "Step: 3267 ------------ Loss: 6707.84 ------------ Accuracy: 69.3%\n",
            "Step: 3268 ------------ Loss: 6707.63 ------------ Accuracy: 69.3%\n",
            "Step: 3269 ------------ Loss: 6707.42 ------------ Accuracy: 69.3%\n",
            "Step: 3270 ------------ Loss: 6707.21 ------------ Accuracy: 69.3%\n",
            "Step: 3271 ------------ Loss: 6707.0 ------------ Accuracy: 69.3%\n",
            "Step: 3272 ------------ Loss: 6706.79 ------------ Accuracy: 69.3%\n",
            "Step: 3273 ------------ Loss: 6706.58 ------------ Accuracy: 69.3%\n",
            "Step: 3274 ------------ Loss: 6706.36 ------------ Accuracy: 69.4%\n",
            "Step: 3275 ------------ Loss: 6706.15 ------------ Accuracy: 69.4%\n",
            "Step: 3276 ------------ Loss: 6705.94 ------------ Accuracy: 69.4%\n",
            "Step: 3277 ------------ Loss: 6705.73 ------------ Accuracy: 69.4%\n",
            "Step: 3278 ------------ Loss: 6705.52 ------------ Accuracy: 69.4%\n",
            "Step: 3279 ------------ Loss: 6705.31 ------------ Accuracy: 69.4%\n",
            "Step: 3280 ------------ Loss: 6705.1 ------------ Accuracy: 69.4%\n",
            "Step: 3281 ------------ Loss: 6704.89 ------------ Accuracy: 69.4%\n",
            "Step: 3282 ------------ Loss: 6704.68 ------------ Accuracy: 69.4%\n",
            "Step: 3283 ------------ Loss: 6704.47 ------------ Accuracy: 69.4%\n",
            "Step: 3284 ------------ Loss: 6704.26 ------------ Accuracy: 69.4%\n",
            "Step: 3285 ------------ Loss: 6704.05 ------------ Accuracy: 69.4%\n",
            "Step: 3286 ------------ Loss: 6703.84 ------------ Accuracy: 69.4%\n",
            "Step: 3287 ------------ Loss: 6703.63 ------------ Accuracy: 69.4%\n",
            "Step: 3288 ------------ Loss: 6703.42 ------------ Accuracy: 69.4%\n",
            "Step: 3289 ------------ Loss: 6703.21 ------------ Accuracy: 69.4%\n",
            "Step: 3290 ------------ Loss: 6703.0 ------------ Accuracy: 69.4%\n",
            "Step: 3291 ------------ Loss: 6702.79 ------------ Accuracy: 69.4%\n",
            "Step: 3292 ------------ Loss: 6702.58 ------------ Accuracy: 69.4%\n",
            "Step: 3293 ------------ Loss: 6702.37 ------------ Accuracy: 69.4%\n",
            "Step: 3294 ------------ Loss: 6702.17 ------------ Accuracy: 69.4%\n",
            "Step: 3295 ------------ Loss: 6701.96 ------------ Accuracy: 69.4%\n",
            "Step: 3296 ------------ Loss: 6701.75 ------------ Accuracy: 69.4%\n",
            "Step: 3297 ------------ Loss: 6701.54 ------------ Accuracy: 69.4%\n",
            "Step: 3298 ------------ Loss: 6701.33 ------------ Accuracy: 69.4%\n",
            "Step: 3299 ------------ Loss: 6701.12 ------------ Accuracy: 69.4%\n",
            "Step: 3300 ------------ Loss: 6700.91 ------------ Accuracy: 69.4%\n",
            "Step: 3301 ------------ Loss: 6700.7 ------------ Accuracy: 69.4%\n",
            "Step: 3302 ------------ Loss: 6700.5 ------------ Accuracy: 69.4%\n",
            "Step: 3303 ------------ Loss: 6700.29 ------------ Accuracy: 69.4%\n",
            "Step: 3304 ------------ Loss: 6700.08 ------------ Accuracy: 69.4%\n",
            "Step: 3305 ------------ Loss: 6699.87 ------------ Accuracy: 69.4%\n",
            "Step: 3306 ------------ Loss: 6699.66 ------------ Accuracy: 69.4%\n",
            "Step: 3307 ------------ Loss: 6699.45 ------------ Accuracy: 69.4%\n",
            "Step: 3308 ------------ Loss: 6699.25 ------------ Accuracy: 69.4%\n",
            "Step: 3309 ------------ Loss: 6699.04 ------------ Accuracy: 69.4%\n",
            "Step: 3310 ------------ Loss: 6698.83 ------------ Accuracy: 69.4%\n",
            "Step: 3311 ------------ Loss: 6698.62 ------------ Accuracy: 69.4%\n",
            "Step: 3312 ------------ Loss: 6698.41 ------------ Accuracy: 69.4%\n",
            "Step: 3313 ------------ Loss: 6698.21 ------------ Accuracy: 69.4%\n",
            "Step: 3314 ------------ Loss: 6698.0 ------------ Accuracy: 69.4%\n",
            "Step: 3315 ------------ Loss: 6697.79 ------------ Accuracy: 69.4%\n",
            "Step: 3316 ------------ Loss: 6697.58 ------------ Accuracy: 69.4%\n",
            "Step: 3317 ------------ Loss: 6697.38 ------------ Accuracy: 69.4%\n",
            "Step: 3318 ------------ Loss: 6697.17 ------------ Accuracy: 69.4%\n",
            "Step: 3319 ------------ Loss: 6696.96 ------------ Accuracy: 69.4%\n",
            "Step: 3320 ------------ Loss: 6696.76 ------------ Accuracy: 69.4%\n",
            "Step: 3321 ------------ Loss: 6696.55 ------------ Accuracy: 69.4%\n",
            "Step: 3322 ------------ Loss: 6696.34 ------------ Accuracy: 69.4%\n",
            "Step: 3323 ------------ Loss: 6696.13 ------------ Accuracy: 69.4%\n",
            "Step: 3324 ------------ Loss: 6695.93 ------------ Accuracy: 69.4%\n",
            "Step: 3325 ------------ Loss: 6695.72 ------------ Accuracy: 69.4%\n",
            "Step: 3326 ------------ Loss: 6695.51 ------------ Accuracy: 69.4%\n",
            "Step: 3327 ------------ Loss: 6695.31 ------------ Accuracy: 69.4%\n",
            "Step: 3328 ------------ Loss: 6695.1 ------------ Accuracy: 69.4%\n",
            "Step: 3329 ------------ Loss: 6694.9 ------------ Accuracy: 69.4%\n",
            "Step: 3330 ------------ Loss: 6694.69 ------------ Accuracy: 69.4%\n",
            "Step: 3331 ------------ Loss: 6694.48 ------------ Accuracy: 69.4%\n",
            "Step: 3332 ------------ Loss: 6694.28 ------------ Accuracy: 69.3%\n",
            "Step: 3333 ------------ Loss: 6694.07 ------------ Accuracy: 69.3%\n",
            "Step: 3334 ------------ Loss: 6693.86 ------------ Accuracy: 69.3%\n",
            "Step: 3335 ------------ Loss: 6693.66 ------------ Accuracy: 69.3%\n",
            "Step: 3336 ------------ Loss: 6693.45 ------------ Accuracy: 69.3%\n",
            "Step: 3337 ------------ Loss: 6693.25 ------------ Accuracy: 69.3%\n",
            "Step: 3338 ------------ Loss: 6693.04 ------------ Accuracy: 69.3%\n",
            "Step: 3339 ------------ Loss: 6692.84 ------------ Accuracy: 69.3%\n",
            "Step: 3340 ------------ Loss: 6692.63 ------------ Accuracy: 69.3%\n",
            "Step: 3341 ------------ Loss: 6692.43 ------------ Accuracy: 69.3%\n",
            "Step: 3342 ------------ Loss: 6692.22 ------------ Accuracy: 69.3%\n",
            "Step: 3343 ------------ Loss: 6692.01 ------------ Accuracy: 69.3%\n",
            "Step: 3344 ------------ Loss: 6691.81 ------------ Accuracy: 69.3%\n",
            "Step: 3345 ------------ Loss: 6691.6 ------------ Accuracy: 69.3%\n",
            "Step: 3346 ------------ Loss: 6691.4 ------------ Accuracy: 69.3%\n",
            "Step: 3347 ------------ Loss: 6691.19 ------------ Accuracy: 69.3%\n",
            "Step: 3348 ------------ Loss: 6690.99 ------------ Accuracy: 69.3%\n",
            "Step: 3349 ------------ Loss: 6690.78 ------------ Accuracy: 69.3%\n",
            "Step: 3350 ------------ Loss: 6690.58 ------------ Accuracy: 69.3%\n",
            "Step: 3351 ------------ Loss: 6690.38 ------------ Accuracy: 69.3%\n",
            "Step: 3352 ------------ Loss: 6690.17 ------------ Accuracy: 69.3%\n",
            "Step: 3353 ------------ Loss: 6689.97 ------------ Accuracy: 69.3%\n",
            "Step: 3354 ------------ Loss: 6689.76 ------------ Accuracy: 69.3%\n",
            "Step: 3355 ------------ Loss: 6689.56 ------------ Accuracy: 69.3%\n",
            "Step: 3356 ------------ Loss: 6689.35 ------------ Accuracy: 69.3%\n",
            "Step: 3357 ------------ Loss: 6689.15 ------------ Accuracy: 69.3%\n",
            "Step: 3358 ------------ Loss: 6688.95 ------------ Accuracy: 69.3%\n",
            "Step: 3359 ------------ Loss: 6688.74 ------------ Accuracy: 69.3%\n",
            "Step: 3360 ------------ Loss: 6688.54 ------------ Accuracy: 69.3%\n",
            "Step: 3361 ------------ Loss: 6688.33 ------------ Accuracy: 69.3%\n",
            "Step: 3362 ------------ Loss: 6688.13 ------------ Accuracy: 69.3%\n",
            "Step: 3363 ------------ Loss: 6687.93 ------------ Accuracy: 69.3%\n",
            "Step: 3364 ------------ Loss: 6687.72 ------------ Accuracy: 69.3%\n",
            "Step: 3365 ------------ Loss: 6687.52 ------------ Accuracy: 69.3%\n",
            "Step: 3366 ------------ Loss: 6687.32 ------------ Accuracy: 69.3%\n",
            "Step: 3367 ------------ Loss: 6687.11 ------------ Accuracy: 69.3%\n",
            "Step: 3368 ------------ Loss: 6686.91 ------------ Accuracy: 69.3%\n",
            "Step: 3369 ------------ Loss: 6686.71 ------------ Accuracy: 69.3%\n",
            "Step: 3370 ------------ Loss: 6686.5 ------------ Accuracy: 69.3%\n",
            "Step: 3371 ------------ Loss: 6686.3 ------------ Accuracy: 69.3%\n",
            "Step: 3372 ------------ Loss: 6686.1 ------------ Accuracy: 69.3%\n",
            "Step: 3373 ------------ Loss: 6685.89 ------------ Accuracy: 69.3%\n",
            "Step: 3374 ------------ Loss: 6685.69 ------------ Accuracy: 69.3%\n",
            "Step: 3375 ------------ Loss: 6685.49 ------------ Accuracy: 69.3%\n",
            "Step: 3376 ------------ Loss: 6685.29 ------------ Accuracy: 69.3%\n",
            "Step: 3377 ------------ Loss: 6685.08 ------------ Accuracy: 69.3%\n",
            "Step: 3378 ------------ Loss: 6684.88 ------------ Accuracy: 69.3%\n",
            "Step: 3379 ------------ Loss: 6684.68 ------------ Accuracy: 69.3%\n",
            "Step: 3380 ------------ Loss: 6684.48 ------------ Accuracy: 69.3%\n",
            "Step: 3381 ------------ Loss: 6684.27 ------------ Accuracy: 69.3%\n",
            "Step: 3382 ------------ Loss: 6684.07 ------------ Accuracy: 69.3%\n",
            "Step: 3383 ------------ Loss: 6683.87 ------------ Accuracy: 69.3%\n",
            "Step: 3384 ------------ Loss: 6683.67 ------------ Accuracy: 69.3%\n",
            "Step: 3385 ------------ Loss: 6683.46 ------------ Accuracy: 69.3%\n",
            "Step: 3386 ------------ Loss: 6683.26 ------------ Accuracy: 69.3%\n",
            "Step: 3387 ------------ Loss: 6683.06 ------------ Accuracy: 69.3%\n",
            "Step: 3388 ------------ Loss: 6682.86 ------------ Accuracy: 69.3%\n",
            "Step: 3389 ------------ Loss: 6682.66 ------------ Accuracy: 69.3%\n",
            "Step: 3390 ------------ Loss: 6682.46 ------------ Accuracy: 69.3%\n",
            "Step: 3391 ------------ Loss: 6682.25 ------------ Accuracy: 69.3%\n",
            "Step: 3392 ------------ Loss: 6682.05 ------------ Accuracy: 69.3%\n",
            "Step: 3393 ------------ Loss: 6681.85 ------------ Accuracy: 69.3%\n",
            "Step: 3394 ------------ Loss: 6681.65 ------------ Accuracy: 69.3%\n",
            "Step: 3395 ------------ Loss: 6681.45 ------------ Accuracy: 69.3%\n",
            "Step: 3396 ------------ Loss: 6681.25 ------------ Accuracy: 69.3%\n",
            "Step: 3397 ------------ Loss: 6681.05 ------------ Accuracy: 69.3%\n",
            "Step: 3398 ------------ Loss: 6680.85 ------------ Accuracy: 69.3%\n",
            "Step: 3399 ------------ Loss: 6680.64 ------------ Accuracy: 69.3%\n",
            "Step: 3400 ------------ Loss: 6680.44 ------------ Accuracy: 69.3%\n",
            "Step: 3401 ------------ Loss: 6680.24 ------------ Accuracy: 69.3%\n",
            "Step: 3402 ------------ Loss: 6680.04 ------------ Accuracy: 69.3%\n",
            "Step: 3403 ------------ Loss: 6679.84 ------------ Accuracy: 69.3%\n",
            "Step: 3404 ------------ Loss: 6679.64 ------------ Accuracy: 69.3%\n",
            "Step: 3405 ------------ Loss: 6679.44 ------------ Accuracy: 69.3%\n",
            "Step: 3406 ------------ Loss: 6679.24 ------------ Accuracy: 69.3%\n",
            "Step: 3407 ------------ Loss: 6679.04 ------------ Accuracy: 69.3%\n",
            "Step: 3408 ------------ Loss: 6678.84 ------------ Accuracy: 69.3%\n",
            "Step: 3409 ------------ Loss: 6678.64 ------------ Accuracy: 69.3%\n",
            "Step: 3410 ------------ Loss: 6678.44 ------------ Accuracy: 69.3%\n",
            "Step: 3411 ------------ Loss: 6678.24 ------------ Accuracy: 69.3%\n",
            "Step: 3412 ------------ Loss: 6678.04 ------------ Accuracy: 69.3%\n",
            "Step: 3413 ------------ Loss: 6677.84 ------------ Accuracy: 69.3%\n",
            "Step: 3414 ------------ Loss: 6677.64 ------------ Accuracy: 69.3%\n",
            "Step: 3415 ------------ Loss: 6677.44 ------------ Accuracy: 69.3%\n",
            "Step: 3416 ------------ Loss: 6677.24 ------------ Accuracy: 69.3%\n",
            "Step: 3417 ------------ Loss: 6677.04 ------------ Accuracy: 69.3%\n",
            "Step: 3418 ------------ Loss: 6676.84 ------------ Accuracy: 69.3%\n",
            "Step: 3419 ------------ Loss: 6676.64 ------------ Accuracy: 69.3%\n",
            "Step: 3420 ------------ Loss: 6676.44 ------------ Accuracy: 69.3%\n",
            "Step: 3421 ------------ Loss: 6676.24 ------------ Accuracy: 69.3%\n",
            "Step: 3422 ------------ Loss: 6676.04 ------------ Accuracy: 69.3%\n",
            "Step: 3423 ------------ Loss: 6675.85 ------------ Accuracy: 69.3%\n",
            "Step: 3424 ------------ Loss: 6675.65 ------------ Accuracy: 69.3%\n",
            "Step: 3425 ------------ Loss: 6675.45 ------------ Accuracy: 69.3%\n",
            "Step: 3426 ------------ Loss: 6675.25 ------------ Accuracy: 69.3%\n",
            "Step: 3427 ------------ Loss: 6675.05 ------------ Accuracy: 69.3%\n",
            "Step: 3428 ------------ Loss: 6674.85 ------------ Accuracy: 69.3%\n",
            "Step: 3429 ------------ Loss: 6674.65 ------------ Accuracy: 69.3%\n",
            "Step: 3430 ------------ Loss: 6674.45 ------------ Accuracy: 69.3%\n",
            "Step: 3431 ------------ Loss: 6674.26 ------------ Accuracy: 69.3%\n",
            "Step: 3432 ------------ Loss: 6674.06 ------------ Accuracy: 69.3%\n",
            "Step: 3433 ------------ Loss: 6673.86 ------------ Accuracy: 69.3%\n",
            "Step: 3434 ------------ Loss: 6673.66 ------------ Accuracy: 69.3%\n",
            "Step: 3435 ------------ Loss: 6673.46 ------------ Accuracy: 69.3%\n",
            "Step: 3436 ------------ Loss: 6673.26 ------------ Accuracy: 69.3%\n",
            "Step: 3437 ------------ Loss: 6673.07 ------------ Accuracy: 69.3%\n",
            "Step: 3438 ------------ Loss: 6672.87 ------------ Accuracy: 69.3%\n",
            "Step: 3439 ------------ Loss: 6672.67 ------------ Accuracy: 69.3%\n",
            "Step: 3440 ------------ Loss: 6672.47 ------------ Accuracy: 69.3%\n",
            "Step: 3441 ------------ Loss: 6672.27 ------------ Accuracy: 69.3%\n",
            "Step: 3442 ------------ Loss: 6672.08 ------------ Accuracy: 69.3%\n",
            "Step: 3443 ------------ Loss: 6671.88 ------------ Accuracy: 69.3%\n",
            "Step: 3444 ------------ Loss: 6671.68 ------------ Accuracy: 69.3%\n",
            "Step: 3445 ------------ Loss: 6671.48 ------------ Accuracy: 69.3%\n",
            "Step: 3446 ------------ Loss: 6671.29 ------------ Accuracy: 69.3%\n",
            "Step: 3447 ------------ Loss: 6671.09 ------------ Accuracy: 69.3%\n",
            "Step: 3448 ------------ Loss: 6670.89 ------------ Accuracy: 69.3%\n",
            "Step: 3449 ------------ Loss: 6670.7 ------------ Accuracy: 69.3%\n",
            "Step: 3450 ------------ Loss: 6670.5 ------------ Accuracy: 69.3%\n",
            "Step: 3451 ------------ Loss: 6670.3 ------------ Accuracy: 69.3%\n",
            "Step: 3452 ------------ Loss: 6670.1 ------------ Accuracy: 69.3%\n",
            "Step: 3453 ------------ Loss: 6669.91 ------------ Accuracy: 69.3%\n",
            "Step: 3454 ------------ Loss: 6669.71 ------------ Accuracy: 69.3%\n",
            "Step: 3455 ------------ Loss: 6669.51 ------------ Accuracy: 69.3%\n",
            "Step: 3456 ------------ Loss: 6669.32 ------------ Accuracy: 69.3%\n",
            "Step: 3457 ------------ Loss: 6669.12 ------------ Accuracy: 69.3%\n",
            "Step: 3458 ------------ Loss: 6668.92 ------------ Accuracy: 69.3%\n",
            "Step: 3459 ------------ Loss: 6668.73 ------------ Accuracy: 69.3%\n",
            "Step: 3460 ------------ Loss: 6668.53 ------------ Accuracy: 69.3%\n",
            "Step: 3461 ------------ Loss: 6668.33 ------------ Accuracy: 69.3%\n",
            "Step: 3462 ------------ Loss: 6668.14 ------------ Accuracy: 69.4%\n",
            "Step: 3463 ------------ Loss: 6667.94 ------------ Accuracy: 69.4%\n",
            "Step: 3464 ------------ Loss: 6667.75 ------------ Accuracy: 69.4%\n",
            "Step: 3465 ------------ Loss: 6667.55 ------------ Accuracy: 69.4%\n",
            "Step: 3466 ------------ Loss: 6667.35 ------------ Accuracy: 69.4%\n",
            "Step: 3467 ------------ Loss: 6667.16 ------------ Accuracy: 69.4%\n",
            "Step: 3468 ------------ Loss: 6666.96 ------------ Accuracy: 69.4%\n",
            "Step: 3469 ------------ Loss: 6666.77 ------------ Accuracy: 69.4%\n",
            "Step: 3470 ------------ Loss: 6666.57 ------------ Accuracy: 69.4%\n",
            "Step: 3471 ------------ Loss: 6666.38 ------------ Accuracy: 69.4%\n",
            "Step: 3472 ------------ Loss: 6666.18 ------------ Accuracy: 69.4%\n",
            "Step: 3473 ------------ Loss: 6665.99 ------------ Accuracy: 69.4%\n",
            "Step: 3474 ------------ Loss: 6665.79 ------------ Accuracy: 69.4%\n",
            "Step: 3475 ------------ Loss: 6665.59 ------------ Accuracy: 69.4%\n",
            "Step: 3476 ------------ Loss: 6665.4 ------------ Accuracy: 69.4%\n",
            "Step: 3477 ------------ Loss: 6665.2 ------------ Accuracy: 69.4%\n",
            "Step: 3478 ------------ Loss: 6665.01 ------------ Accuracy: 69.4%\n",
            "Step: 3479 ------------ Loss: 6664.81 ------------ Accuracy: 69.4%\n",
            "Step: 3480 ------------ Loss: 6664.62 ------------ Accuracy: 69.4%\n",
            "Step: 3481 ------------ Loss: 6664.42 ------------ Accuracy: 69.4%\n",
            "Step: 3482 ------------ Loss: 6664.23 ------------ Accuracy: 69.4%\n",
            "Step: 3483 ------------ Loss: 6664.04 ------------ Accuracy: 69.4%\n",
            "Step: 3484 ------------ Loss: 6663.84 ------------ Accuracy: 69.4%\n",
            "Step: 3485 ------------ Loss: 6663.65 ------------ Accuracy: 69.4%\n",
            "Step: 3486 ------------ Loss: 6663.45 ------------ Accuracy: 69.4%\n",
            "Step: 3487 ------------ Loss: 6663.26 ------------ Accuracy: 69.4%\n",
            "Step: 3488 ------------ Loss: 6663.06 ------------ Accuracy: 69.4%\n",
            "Step: 3489 ------------ Loss: 6662.87 ------------ Accuracy: 69.4%\n",
            "Step: 3490 ------------ Loss: 6662.67 ------------ Accuracy: 69.4%\n",
            "Step: 3491 ------------ Loss: 6662.48 ------------ Accuracy: 69.4%\n",
            "Step: 3492 ------------ Loss: 6662.29 ------------ Accuracy: 69.4%\n",
            "Step: 3493 ------------ Loss: 6662.09 ------------ Accuracy: 69.4%\n",
            "Step: 3494 ------------ Loss: 6661.9 ------------ Accuracy: 69.4%\n",
            "Step: 3495 ------------ Loss: 6661.7 ------------ Accuracy: 69.4%\n",
            "Step: 3496 ------------ Loss: 6661.51 ------------ Accuracy: 69.4%\n",
            "Step: 3497 ------------ Loss: 6661.32 ------------ Accuracy: 69.4%\n",
            "Step: 3498 ------------ Loss: 6661.12 ------------ Accuracy: 69.4%\n",
            "Step: 3499 ------------ Loss: 6660.93 ------------ Accuracy: 69.4%\n",
            "Step: 3500 ------------ Loss: 6660.74 ------------ Accuracy: 69.4%\n",
            "Step: 3501 ------------ Loss: 6660.54 ------------ Accuracy: 69.4%\n",
            "Step: 3502 ------------ Loss: 6660.35 ------------ Accuracy: 69.4%\n",
            "Step: 3503 ------------ Loss: 6660.16 ------------ Accuracy: 69.4%\n",
            "Step: 3504 ------------ Loss: 6659.96 ------------ Accuracy: 69.4%\n",
            "Step: 3505 ------------ Loss: 6659.77 ------------ Accuracy: 69.4%\n",
            "Step: 3506 ------------ Loss: 6659.58 ------------ Accuracy: 69.4%\n",
            "Step: 3507 ------------ Loss: 6659.38 ------------ Accuracy: 69.4%\n",
            "Step: 3508 ------------ Loss: 6659.19 ------------ Accuracy: 69.4%\n",
            "Step: 3509 ------------ Loss: 6659.0 ------------ Accuracy: 69.4%\n",
            "Step: 3510 ------------ Loss: 6658.81 ------------ Accuracy: 69.4%\n",
            "Step: 3511 ------------ Loss: 6658.61 ------------ Accuracy: 69.4%\n",
            "Step: 3512 ------------ Loss: 6658.42 ------------ Accuracy: 69.4%\n",
            "Step: 3513 ------------ Loss: 6658.23 ------------ Accuracy: 69.4%\n",
            "Step: 3514 ------------ Loss: 6658.04 ------------ Accuracy: 69.4%\n",
            "Step: 3515 ------------ Loss: 6657.84 ------------ Accuracy: 69.4%\n",
            "Step: 3516 ------------ Loss: 6657.65 ------------ Accuracy: 69.4%\n",
            "Step: 3517 ------------ Loss: 6657.46 ------------ Accuracy: 69.4%\n",
            "Step: 3518 ------------ Loss: 6657.27 ------------ Accuracy: 69.4%\n",
            "Step: 3519 ------------ Loss: 6657.07 ------------ Accuracy: 69.4%\n",
            "Step: 3520 ------------ Loss: 6656.88 ------------ Accuracy: 69.4%\n",
            "Step: 3521 ------------ Loss: 6656.69 ------------ Accuracy: 69.4%\n",
            "Step: 3522 ------------ Loss: 6656.5 ------------ Accuracy: 69.4%\n",
            "Step: 3523 ------------ Loss: 6656.31 ------------ Accuracy: 69.4%\n",
            "Step: 3524 ------------ Loss: 6656.12 ------------ Accuracy: 69.4%\n",
            "Step: 3525 ------------ Loss: 6655.92 ------------ Accuracy: 69.4%\n",
            "Step: 3526 ------------ Loss: 6655.73 ------------ Accuracy: 69.4%\n",
            "Step: 3527 ------------ Loss: 6655.54 ------------ Accuracy: 69.4%\n",
            "Step: 3528 ------------ Loss: 6655.35 ------------ Accuracy: 69.4%\n",
            "Step: 3529 ------------ Loss: 6655.16 ------------ Accuracy: 69.4%\n",
            "Step: 3530 ------------ Loss: 6654.97 ------------ Accuracy: 69.4%\n",
            "Step: 3531 ------------ Loss: 6654.78 ------------ Accuracy: 69.4%\n",
            "Step: 3532 ------------ Loss: 6654.58 ------------ Accuracy: 69.4%\n",
            "Step: 3533 ------------ Loss: 6654.39 ------------ Accuracy: 69.4%\n",
            "Step: 3534 ------------ Loss: 6654.2 ------------ Accuracy: 69.4%\n",
            "Step: 3535 ------------ Loss: 6654.01 ------------ Accuracy: 69.4%\n",
            "Step: 3536 ------------ Loss: 6653.82 ------------ Accuracy: 69.4%\n",
            "Step: 3537 ------------ Loss: 6653.63 ------------ Accuracy: 69.4%\n",
            "Step: 3538 ------------ Loss: 6653.44 ------------ Accuracy: 69.4%\n",
            "Step: 3539 ------------ Loss: 6653.25 ------------ Accuracy: 69.4%\n",
            "Step: 3540 ------------ Loss: 6653.06 ------------ Accuracy: 69.4%\n",
            "Step: 3541 ------------ Loss: 6652.87 ------------ Accuracy: 69.4%\n",
            "Step: 3542 ------------ Loss: 6652.68 ------------ Accuracy: 69.4%\n",
            "Step: 3543 ------------ Loss: 6652.49 ------------ Accuracy: 69.4%\n",
            "Step: 3544 ------------ Loss: 6652.3 ------------ Accuracy: 69.4%\n",
            "Step: 3545 ------------ Loss: 6652.11 ------------ Accuracy: 69.4%\n",
            "Step: 3546 ------------ Loss: 6651.91 ------------ Accuracy: 69.4%\n",
            "Step: 3547 ------------ Loss: 6651.72 ------------ Accuracy: 69.4%\n",
            "Step: 3548 ------------ Loss: 6651.53 ------------ Accuracy: 69.4%\n",
            "Step: 3549 ------------ Loss: 6651.34 ------------ Accuracy: 69.4%\n",
            "Step: 3550 ------------ Loss: 6651.15 ------------ Accuracy: 69.4%\n",
            "Step: 3551 ------------ Loss: 6650.96 ------------ Accuracy: 69.4%\n",
            "Step: 3552 ------------ Loss: 6650.78 ------------ Accuracy: 69.4%\n",
            "Step: 3553 ------------ Loss: 6650.59 ------------ Accuracy: 69.4%\n",
            "Step: 3554 ------------ Loss: 6650.4 ------------ Accuracy: 69.4%\n",
            "Step: 3555 ------------ Loss: 6650.21 ------------ Accuracy: 69.4%\n",
            "Step: 3556 ------------ Loss: 6650.02 ------------ Accuracy: 69.4%\n",
            "Step: 3557 ------------ Loss: 6649.83 ------------ Accuracy: 69.4%\n",
            "Step: 3558 ------------ Loss: 6649.64 ------------ Accuracy: 69.4%\n",
            "Step: 3559 ------------ Loss: 6649.45 ------------ Accuracy: 69.4%\n",
            "Step: 3560 ------------ Loss: 6649.26 ------------ Accuracy: 69.5%\n",
            "Step: 3561 ------------ Loss: 6649.07 ------------ Accuracy: 69.5%\n",
            "Step: 3562 ------------ Loss: 6648.88 ------------ Accuracy: 69.5%\n",
            "Step: 3563 ------------ Loss: 6648.69 ------------ Accuracy: 69.5%\n",
            "Step: 3564 ------------ Loss: 6648.5 ------------ Accuracy: 69.5%\n",
            "Step: 3565 ------------ Loss: 6648.31 ------------ Accuracy: 69.5%\n",
            "Step: 3566 ------------ Loss: 6648.13 ------------ Accuracy: 69.5%\n",
            "Step: 3567 ------------ Loss: 6647.94 ------------ Accuracy: 69.5%\n",
            "Step: 3568 ------------ Loss: 6647.75 ------------ Accuracy: 69.5%\n",
            "Step: 3569 ------------ Loss: 6647.56 ------------ Accuracy: 69.5%\n",
            "Step: 3570 ------------ Loss: 6647.37 ------------ Accuracy: 69.5%\n",
            "Step: 3571 ------------ Loss: 6647.18 ------------ Accuracy: 69.5%\n",
            "Step: 3572 ------------ Loss: 6646.99 ------------ Accuracy: 69.5%\n",
            "Step: 3573 ------------ Loss: 6646.81 ------------ Accuracy: 69.5%\n",
            "Step: 3574 ------------ Loss: 6646.62 ------------ Accuracy: 69.5%\n",
            "Step: 3575 ------------ Loss: 6646.43 ------------ Accuracy: 69.5%\n",
            "Step: 3576 ------------ Loss: 6646.24 ------------ Accuracy: 69.5%\n",
            "Step: 3577 ------------ Loss: 6646.05 ------------ Accuracy: 69.5%\n",
            "Step: 3578 ------------ Loss: 6645.87 ------------ Accuracy: 69.5%\n",
            "Step: 3579 ------------ Loss: 6645.68 ------------ Accuracy: 69.5%\n",
            "Step: 3580 ------------ Loss: 6645.49 ------------ Accuracy: 69.5%\n",
            "Step: 3581 ------------ Loss: 6645.3 ------------ Accuracy: 69.5%\n",
            "Step: 3582 ------------ Loss: 6645.11 ------------ Accuracy: 69.5%\n",
            "Step: 3583 ------------ Loss: 6644.93 ------------ Accuracy: 69.5%\n",
            "Step: 3584 ------------ Loss: 6644.74 ------------ Accuracy: 69.5%\n",
            "Step: 3585 ------------ Loss: 6644.55 ------------ Accuracy: 69.5%\n",
            "Step: 3586 ------------ Loss: 6644.36 ------------ Accuracy: 69.5%\n",
            "Step: 3587 ------------ Loss: 6644.18 ------------ Accuracy: 69.5%\n",
            "Step: 3588 ------------ Loss: 6643.99 ------------ Accuracy: 69.5%\n",
            "Step: 3589 ------------ Loss: 6643.8 ------------ Accuracy: 69.5%\n",
            "Step: 3590 ------------ Loss: 6643.61 ------------ Accuracy: 69.5%\n",
            "Step: 3591 ------------ Loss: 6643.43 ------------ Accuracy: 69.5%\n",
            "Step: 3592 ------------ Loss: 6643.24 ------------ Accuracy: 69.5%\n",
            "Step: 3593 ------------ Loss: 6643.05 ------------ Accuracy: 69.5%\n",
            "Step: 3594 ------------ Loss: 6642.87 ------------ Accuracy: 69.5%\n",
            "Step: 3595 ------------ Loss: 6642.68 ------------ Accuracy: 69.5%\n",
            "Step: 3596 ------------ Loss: 6642.49 ------------ Accuracy: 69.5%\n",
            "Step: 3597 ------------ Loss: 6642.31 ------------ Accuracy: 69.5%\n",
            "Step: 3598 ------------ Loss: 6642.12 ------------ Accuracy: 69.5%\n",
            "Step: 3599 ------------ Loss: 6641.93 ------------ Accuracy: 69.5%\n",
            "Step: 3600 ------------ Loss: 6641.75 ------------ Accuracy: 69.5%\n",
            "Step: 3601 ------------ Loss: 6641.56 ------------ Accuracy: 69.5%\n",
            "Step: 3602 ------------ Loss: 6641.37 ------------ Accuracy: 69.5%\n",
            "Step: 3603 ------------ Loss: 6641.19 ------------ Accuracy: 69.5%\n",
            "Step: 3604 ------------ Loss: 6641.0 ------------ Accuracy: 69.5%\n",
            "Step: 3605 ------------ Loss: 6640.82 ------------ Accuracy: 69.5%\n",
            "Step: 3606 ------------ Loss: 6640.63 ------------ Accuracy: 69.5%\n",
            "Step: 3607 ------------ Loss: 6640.44 ------------ Accuracy: 69.5%\n",
            "Step: 3608 ------------ Loss: 6640.26 ------------ Accuracy: 69.5%\n",
            "Step: 3609 ------------ Loss: 6640.07 ------------ Accuracy: 69.5%\n",
            "Step: 3610 ------------ Loss: 6639.89 ------------ Accuracy: 69.5%\n",
            "Step: 3611 ------------ Loss: 6639.7 ------------ Accuracy: 69.5%\n",
            "Step: 3612 ------------ Loss: 6639.51 ------------ Accuracy: 69.5%\n",
            "Step: 3613 ------------ Loss: 6639.33 ------------ Accuracy: 69.5%\n",
            "Step: 3614 ------------ Loss: 6639.14 ------------ Accuracy: 69.5%\n",
            "Step: 3615 ------------ Loss: 6638.96 ------------ Accuracy: 69.5%\n",
            "Step: 3616 ------------ Loss: 6638.77 ------------ Accuracy: 69.5%\n",
            "Step: 3617 ------------ Loss: 6638.59 ------------ Accuracy: 69.6%\n",
            "Step: 3618 ------------ Loss: 6638.4 ------------ Accuracy: 69.6%\n",
            "Step: 3619 ------------ Loss: 6638.22 ------------ Accuracy: 69.7%\n",
            "Step: 3620 ------------ Loss: 6638.03 ------------ Accuracy: 69.7%\n",
            "Step: 3621 ------------ Loss: 6637.85 ------------ Accuracy: 69.7%\n",
            "Step: 3622 ------------ Loss: 6637.66 ------------ Accuracy: 69.7%\n",
            "Step: 3623 ------------ Loss: 6637.48 ------------ Accuracy: 69.7%\n",
            "Step: 3624 ------------ Loss: 6637.29 ------------ Accuracy: 69.7%\n",
            "Step: 3625 ------------ Loss: 6637.11 ------------ Accuracy: 69.7%\n",
            "Step: 3626 ------------ Loss: 6636.92 ------------ Accuracy: 69.7%\n",
            "Step: 3627 ------------ Loss: 6636.74 ------------ Accuracy: 69.7%\n",
            "Step: 3628 ------------ Loss: 6636.55 ------------ Accuracy: 69.8%\n",
            "Step: 3629 ------------ Loss: 6636.37 ------------ Accuracy: 69.8%\n",
            "Step: 3630 ------------ Loss: 6636.18 ------------ Accuracy: 69.8%\n",
            "Step: 3631 ------------ Loss: 6636.0 ------------ Accuracy: 69.8%\n",
            "Step: 3632 ------------ Loss: 6635.82 ------------ Accuracy: 69.8%\n",
            "Step: 3633 ------------ Loss: 6635.63 ------------ Accuracy: 69.8%\n",
            "Step: 3634 ------------ Loss: 6635.45 ------------ Accuracy: 69.8%\n",
            "Step: 3635 ------------ Loss: 6635.26 ------------ Accuracy: 69.8%\n",
            "Step: 3636 ------------ Loss: 6635.08 ------------ Accuracy: 69.8%\n",
            "Step: 3637 ------------ Loss: 6634.89 ------------ Accuracy: 69.8%\n",
            "Step: 3638 ------------ Loss: 6634.71 ------------ Accuracy: 69.8%\n",
            "Step: 3639 ------------ Loss: 6634.53 ------------ Accuracy: 69.8%\n",
            "Step: 3640 ------------ Loss: 6634.34 ------------ Accuracy: 69.8%\n",
            "Step: 3641 ------------ Loss: 6634.16 ------------ Accuracy: 69.8%\n",
            "Step: 3642 ------------ Loss: 6633.98 ------------ Accuracy: 69.8%\n",
            "Step: 3643 ------------ Loss: 6633.79 ------------ Accuracy: 69.8%\n",
            "Step: 3644 ------------ Loss: 6633.61 ------------ Accuracy: 69.8%\n",
            "Step: 3645 ------------ Loss: 6633.42 ------------ Accuracy: 69.8%\n",
            "Step: 3646 ------------ Loss: 6633.24 ------------ Accuracy: 69.8%\n",
            "Step: 3647 ------------ Loss: 6633.06 ------------ Accuracy: 69.8%\n",
            "Step: 3648 ------------ Loss: 6632.87 ------------ Accuracy: 69.8%\n",
            "Step: 3649 ------------ Loss: 6632.69 ------------ Accuracy: 69.8%\n",
            "Step: 3650 ------------ Loss: 6632.51 ------------ Accuracy: 69.8%\n",
            "Step: 3651 ------------ Loss: 6632.33 ------------ Accuracy: 69.8%\n",
            "Step: 3652 ------------ Loss: 6632.14 ------------ Accuracy: 69.8%\n",
            "Step: 3653 ------------ Loss: 6631.96 ------------ Accuracy: 69.8%\n",
            "Step: 3654 ------------ Loss: 6631.78 ------------ Accuracy: 69.8%\n",
            "Step: 3655 ------------ Loss: 6631.59 ------------ Accuracy: 69.8%\n",
            "Step: 3656 ------------ Loss: 6631.41 ------------ Accuracy: 69.8%\n",
            "Step: 3657 ------------ Loss: 6631.23 ------------ Accuracy: 69.8%\n",
            "Step: 3658 ------------ Loss: 6631.05 ------------ Accuracy: 69.8%\n",
            "Step: 3659 ------------ Loss: 6630.86 ------------ Accuracy: 69.8%\n",
            "Step: 3660 ------------ Loss: 6630.68 ------------ Accuracy: 69.8%\n",
            "Step: 3661 ------------ Loss: 6630.5 ------------ Accuracy: 69.8%\n",
            "Step: 3662 ------------ Loss: 6630.32 ------------ Accuracy: 69.8%\n",
            "Step: 3663 ------------ Loss: 6630.13 ------------ Accuracy: 69.8%\n",
            "Step: 3664 ------------ Loss: 6629.95 ------------ Accuracy: 69.8%\n",
            "Step: 3665 ------------ Loss: 6629.77 ------------ Accuracy: 69.8%\n",
            "Step: 3666 ------------ Loss: 6629.59 ------------ Accuracy: 69.8%\n",
            "Step: 3667 ------------ Loss: 6629.4 ------------ Accuracy: 69.8%\n",
            "Step: 3668 ------------ Loss: 6629.22 ------------ Accuracy: 69.8%\n",
            "Step: 3669 ------------ Loss: 6629.04 ------------ Accuracy: 69.8%\n",
            "Step: 3670 ------------ Loss: 6628.86 ------------ Accuracy: 69.8%\n",
            "Step: 3671 ------------ Loss: 6628.68 ------------ Accuracy: 69.8%\n",
            "Step: 3672 ------------ Loss: 6628.5 ------------ Accuracy: 69.7%\n",
            "Step: 3673 ------------ Loss: 6628.31 ------------ Accuracy: 69.7%\n",
            "Step: 3674 ------------ Loss: 6628.13 ------------ Accuracy: 69.7%\n",
            "Step: 3675 ------------ Loss: 6627.95 ------------ Accuracy: 69.7%\n",
            "Step: 3676 ------------ Loss: 6627.77 ------------ Accuracy: 69.7%\n",
            "Step: 3677 ------------ Loss: 6627.59 ------------ Accuracy: 69.7%\n",
            "Step: 3678 ------------ Loss: 6627.41 ------------ Accuracy: 69.7%\n",
            "Step: 3679 ------------ Loss: 6627.23 ------------ Accuracy: 69.7%\n",
            "Step: 3680 ------------ Loss: 6627.04 ------------ Accuracy: 69.7%\n",
            "Step: 3681 ------------ Loss: 6626.86 ------------ Accuracy: 69.7%\n",
            "Step: 3682 ------------ Loss: 6626.68 ------------ Accuracy: 69.7%\n",
            "Step: 3683 ------------ Loss: 6626.5 ------------ Accuracy: 69.7%\n",
            "Step: 3684 ------------ Loss: 6626.32 ------------ Accuracy: 69.7%\n",
            "Step: 3685 ------------ Loss: 6626.14 ------------ Accuracy: 69.7%\n",
            "Step: 3686 ------------ Loss: 6625.96 ------------ Accuracy: 69.7%\n",
            "Step: 3687 ------------ Loss: 6625.78 ------------ Accuracy: 69.7%\n",
            "Step: 3688 ------------ Loss: 6625.6 ------------ Accuracy: 69.7%\n",
            "Step: 3689 ------------ Loss: 6625.42 ------------ Accuracy: 69.7%\n",
            "Step: 3690 ------------ Loss: 6625.24 ------------ Accuracy: 69.7%\n",
            "Step: 3691 ------------ Loss: 6625.06 ------------ Accuracy: 69.7%\n",
            "Step: 3692 ------------ Loss: 6624.88 ------------ Accuracy: 69.7%\n",
            "Step: 3693 ------------ Loss: 6624.69 ------------ Accuracy: 69.7%\n",
            "Step: 3694 ------------ Loss: 6624.51 ------------ Accuracy: 69.7%\n",
            "Step: 3695 ------------ Loss: 6624.33 ------------ Accuracy: 69.7%\n",
            "Step: 3696 ------------ Loss: 6624.15 ------------ Accuracy: 69.7%\n",
            "Step: 3697 ------------ Loss: 6623.97 ------------ Accuracy: 69.7%\n",
            "Step: 3698 ------------ Loss: 6623.79 ------------ Accuracy: 69.7%\n",
            "Step: 3699 ------------ Loss: 6623.61 ------------ Accuracy: 69.7%\n",
            "Step: 3700 ------------ Loss: 6623.43 ------------ Accuracy: 69.7%\n",
            "Step: 3701 ------------ Loss: 6623.25 ------------ Accuracy: 69.7%\n",
            "Step: 3702 ------------ Loss: 6623.07 ------------ Accuracy: 69.7%\n",
            "Step: 3703 ------------ Loss: 6622.89 ------------ Accuracy: 69.7%\n",
            "Step: 3704 ------------ Loss: 6622.72 ------------ Accuracy: 69.7%\n",
            "Step: 3705 ------------ Loss: 6622.54 ------------ Accuracy: 69.7%\n",
            "Step: 3706 ------------ Loss: 6622.36 ------------ Accuracy: 69.7%\n",
            "Step: 3707 ------------ Loss: 6622.18 ------------ Accuracy: 69.7%\n",
            "Step: 3708 ------------ Loss: 6622.0 ------------ Accuracy: 69.7%\n",
            "Step: 3709 ------------ Loss: 6621.82 ------------ Accuracy: 69.7%\n",
            "Step: 3710 ------------ Loss: 6621.64 ------------ Accuracy: 69.7%\n",
            "Step: 3711 ------------ Loss: 6621.46 ------------ Accuracy: 69.7%\n",
            "Step: 3712 ------------ Loss: 6621.28 ------------ Accuracy: 69.7%\n",
            "Step: 3713 ------------ Loss: 6621.1 ------------ Accuracy: 69.7%\n",
            "Step: 3714 ------------ Loss: 6620.92 ------------ Accuracy: 69.7%\n",
            "Step: 3715 ------------ Loss: 6620.74 ------------ Accuracy: 69.7%\n",
            "Step: 3716 ------------ Loss: 6620.56 ------------ Accuracy: 69.7%\n",
            "Step: 3717 ------------ Loss: 6620.39 ------------ Accuracy: 69.7%\n",
            "Step: 3718 ------------ Loss: 6620.21 ------------ Accuracy: 69.7%\n",
            "Step: 3719 ------------ Loss: 6620.03 ------------ Accuracy: 69.7%\n",
            "Step: 3720 ------------ Loss: 6619.85 ------------ Accuracy: 69.7%\n",
            "Step: 3721 ------------ Loss: 6619.67 ------------ Accuracy: 69.7%\n",
            "Step: 3722 ------------ Loss: 6619.49 ------------ Accuracy: 69.7%\n",
            "Step: 3723 ------------ Loss: 6619.31 ------------ Accuracy: 69.7%\n",
            "Step: 3724 ------------ Loss: 6619.14 ------------ Accuracy: 69.7%\n",
            "Step: 3725 ------------ Loss: 6618.96 ------------ Accuracy: 69.7%\n",
            "Step: 3726 ------------ Loss: 6618.78 ------------ Accuracy: 69.7%\n",
            "Step: 3727 ------------ Loss: 6618.6 ------------ Accuracy: 69.7%\n",
            "Step: 3728 ------------ Loss: 6618.42 ------------ Accuracy: 69.7%\n",
            "Step: 3729 ------------ Loss: 6618.24 ------------ Accuracy: 69.7%\n",
            "Step: 3730 ------------ Loss: 6618.07 ------------ Accuracy: 69.7%\n",
            "Step: 3731 ------------ Loss: 6617.89 ------------ Accuracy: 69.7%\n",
            "Step: 3732 ------------ Loss: 6617.71 ------------ Accuracy: 69.7%\n",
            "Step: 3733 ------------ Loss: 6617.53 ------------ Accuracy: 69.7%\n",
            "Step: 3734 ------------ Loss: 6617.36 ------------ Accuracy: 69.7%\n",
            "Step: 3735 ------------ Loss: 6617.18 ------------ Accuracy: 69.7%\n",
            "Step: 3736 ------------ Loss: 6617.0 ------------ Accuracy: 69.7%\n",
            "Step: 3737 ------------ Loss: 6616.82 ------------ Accuracy: 69.7%\n",
            "Step: 3738 ------------ Loss: 6616.64 ------------ Accuracy: 69.7%\n",
            "Step: 3739 ------------ Loss: 6616.47 ------------ Accuracy: 69.7%\n",
            "Step: 3740 ------------ Loss: 6616.29 ------------ Accuracy: 69.7%\n",
            "Step: 3741 ------------ Loss: 6616.11 ------------ Accuracy: 69.7%\n",
            "Step: 3742 ------------ Loss: 6615.94 ------------ Accuracy: 69.8%\n",
            "Step: 3743 ------------ Loss: 6615.76 ------------ Accuracy: 69.8%\n",
            "Step: 3744 ------------ Loss: 6615.58 ------------ Accuracy: 69.8%\n",
            "Step: 3745 ------------ Loss: 6615.4 ------------ Accuracy: 69.8%\n",
            "Step: 3746 ------------ Loss: 6615.23 ------------ Accuracy: 69.8%\n",
            "Step: 3747 ------------ Loss: 6615.05 ------------ Accuracy: 69.8%\n",
            "Step: 3748 ------------ Loss: 6614.87 ------------ Accuracy: 69.8%\n",
            "Step: 3749 ------------ Loss: 6614.7 ------------ Accuracy: 69.8%\n",
            "Step: 3750 ------------ Loss: 6614.52 ------------ Accuracy: 69.8%\n",
            "Step: 3751 ------------ Loss: 6614.34 ------------ Accuracy: 69.8%\n",
            "Step: 3752 ------------ Loss: 6614.17 ------------ Accuracy: 69.8%\n",
            "Step: 3753 ------------ Loss: 6613.99 ------------ Accuracy: 69.8%\n",
            "Step: 3754 ------------ Loss: 6613.81 ------------ Accuracy: 69.8%\n",
            "Step: 3755 ------------ Loss: 6613.64 ------------ Accuracy: 69.8%\n",
            "Step: 3756 ------------ Loss: 6613.46 ------------ Accuracy: 69.8%\n",
            "Step: 3757 ------------ Loss: 6613.28 ------------ Accuracy: 69.8%\n",
            "Step: 3758 ------------ Loss: 6613.11 ------------ Accuracy: 69.8%\n",
            "Step: 3759 ------------ Loss: 6612.93 ------------ Accuracy: 69.8%\n",
            "Step: 3760 ------------ Loss: 6612.76 ------------ Accuracy: 69.8%\n",
            "Step: 3761 ------------ Loss: 6612.58 ------------ Accuracy: 69.8%\n",
            "Step: 3762 ------------ Loss: 6612.4 ------------ Accuracy: 69.8%\n",
            "Step: 3763 ------------ Loss: 6612.23 ------------ Accuracy: 69.8%\n",
            "Step: 3764 ------------ Loss: 6612.05 ------------ Accuracy: 69.8%\n",
            "Step: 3765 ------------ Loss: 6611.88 ------------ Accuracy: 69.8%\n",
            "Step: 3766 ------------ Loss: 6611.7 ------------ Accuracy: 69.8%\n",
            "Step: 3767 ------------ Loss: 6611.52 ------------ Accuracy: 69.8%\n",
            "Step: 3768 ------------ Loss: 6611.35 ------------ Accuracy: 69.8%\n",
            "Step: 3769 ------------ Loss: 6611.17 ------------ Accuracy: 69.8%\n",
            "Step: 3770 ------------ Loss: 6611.0 ------------ Accuracy: 69.8%\n",
            "Step: 3771 ------------ Loss: 6610.82 ------------ Accuracy: 69.8%\n",
            "Step: 3772 ------------ Loss: 6610.65 ------------ Accuracy: 69.8%\n",
            "Step: 3773 ------------ Loss: 6610.47 ------------ Accuracy: 69.8%\n",
            "Step: 3774 ------------ Loss: 6610.3 ------------ Accuracy: 69.8%\n",
            "Step: 3775 ------------ Loss: 6610.12 ------------ Accuracy: 69.8%\n",
            "Step: 3776 ------------ Loss: 6609.95 ------------ Accuracy: 69.8%\n",
            "Step: 3777 ------------ Loss: 6609.77 ------------ Accuracy: 69.8%\n",
            "Step: 3778 ------------ Loss: 6609.6 ------------ Accuracy: 69.8%\n",
            "Step: 3779 ------------ Loss: 6609.42 ------------ Accuracy: 69.9%\n",
            "Step: 3780 ------------ Loss: 6609.25 ------------ Accuracy: 69.9%\n",
            "Step: 3781 ------------ Loss: 6609.07 ------------ Accuracy: 69.9%\n",
            "Step: 3782 ------------ Loss: 6608.9 ------------ Accuracy: 69.9%\n",
            "Step: 3783 ------------ Loss: 6608.72 ------------ Accuracy: 69.9%\n",
            "Step: 3784 ------------ Loss: 6608.55 ------------ Accuracy: 69.9%\n",
            "Step: 3785 ------------ Loss: 6608.37 ------------ Accuracy: 69.9%\n",
            "Step: 3786 ------------ Loss: 6608.2 ------------ Accuracy: 69.9%\n",
            "Step: 3787 ------------ Loss: 6608.02 ------------ Accuracy: 69.9%\n",
            "Step: 3788 ------------ Loss: 6607.85 ------------ Accuracy: 69.9%\n",
            "Step: 3789 ------------ Loss: 6607.67 ------------ Accuracy: 69.9%\n",
            "Step: 3790 ------------ Loss: 6607.5 ------------ Accuracy: 69.9%\n",
            "Step: 3791 ------------ Loss: 6607.33 ------------ Accuracy: 69.9%\n",
            "Step: 3792 ------------ Loss: 6607.15 ------------ Accuracy: 69.9%\n",
            "Step: 3793 ------------ Loss: 6606.98 ------------ Accuracy: 69.9%\n",
            "Step: 3794 ------------ Loss: 6606.8 ------------ Accuracy: 69.9%\n",
            "Step: 3795 ------------ Loss: 6606.63 ------------ Accuracy: 69.9%\n",
            "Step: 3796 ------------ Loss: 6606.46 ------------ Accuracy: 69.9%\n",
            "Step: 3797 ------------ Loss: 6606.28 ------------ Accuracy: 69.9%\n",
            "Step: 3798 ------------ Loss: 6606.11 ------------ Accuracy: 69.9%\n",
            "Step: 3799 ------------ Loss: 6605.93 ------------ Accuracy: 69.9%\n",
            "Step: 3800 ------------ Loss: 6605.76 ------------ Accuracy: 69.9%\n",
            "Step: 3801 ------------ Loss: 6605.59 ------------ Accuracy: 69.9%\n",
            "Step: 3802 ------------ Loss: 6605.41 ------------ Accuracy: 69.9%\n",
            "Step: 3803 ------------ Loss: 6605.24 ------------ Accuracy: 69.9%\n",
            "Step: 3804 ------------ Loss: 6605.07 ------------ Accuracy: 69.9%\n",
            "Step: 3805 ------------ Loss: 6604.89 ------------ Accuracy: 69.9%\n",
            "Step: 3806 ------------ Loss: 6604.72 ------------ Accuracy: 69.9%\n",
            "Step: 3807 ------------ Loss: 6604.55 ------------ Accuracy: 69.9%\n",
            "Step: 3808 ------------ Loss: 6604.37 ------------ Accuracy: 69.9%\n",
            "Step: 3809 ------------ Loss: 6604.2 ------------ Accuracy: 69.9%\n",
            "Step: 3810 ------------ Loss: 6604.03 ------------ Accuracy: 69.9%\n",
            "Step: 3811 ------------ Loss: 6603.85 ------------ Accuracy: 69.9%\n",
            "Step: 3812 ------------ Loss: 6603.68 ------------ Accuracy: 69.9%\n",
            "Step: 3813 ------------ Loss: 6603.51 ------------ Accuracy: 69.9%\n",
            "Step: 3814 ------------ Loss: 6603.34 ------------ Accuracy: 69.9%\n",
            "Step: 3815 ------------ Loss: 6603.16 ------------ Accuracy: 69.9%\n",
            "Step: 3816 ------------ Loss: 6602.99 ------------ Accuracy: 69.9%\n",
            "Step: 3817 ------------ Loss: 6602.82 ------------ Accuracy: 69.9%\n",
            "Step: 3818 ------------ Loss: 6602.64 ------------ Accuracy: 69.9%\n",
            "Step: 3819 ------------ Loss: 6602.47 ------------ Accuracy: 69.9%\n",
            "Step: 3820 ------------ Loss: 6602.3 ------------ Accuracy: 69.9%\n",
            "Step: 3821 ------------ Loss: 6602.13 ------------ Accuracy: 69.9%\n",
            "Step: 3822 ------------ Loss: 6601.95 ------------ Accuracy: 69.9%\n",
            "Step: 3823 ------------ Loss: 6601.78 ------------ Accuracy: 69.9%\n",
            "Step: 3824 ------------ Loss: 6601.61 ------------ Accuracy: 69.9%\n",
            "Step: 3825 ------------ Loss: 6601.44 ------------ Accuracy: 69.9%\n",
            "Step: 3826 ------------ Loss: 6601.27 ------------ Accuracy: 69.9%\n",
            "Step: 3827 ------------ Loss: 6601.09 ------------ Accuracy: 69.9%\n",
            "Step: 3828 ------------ Loss: 6600.92 ------------ Accuracy: 69.9%\n",
            "Step: 3829 ------------ Loss: 6600.75 ------------ Accuracy: 69.9%\n",
            "Step: 3830 ------------ Loss: 6600.58 ------------ Accuracy: 69.9%\n",
            "Step: 3831 ------------ Loss: 6600.41 ------------ Accuracy: 69.9%\n",
            "Step: 3832 ------------ Loss: 6600.23 ------------ Accuracy: 69.9%\n",
            "Step: 3833 ------------ Loss: 6600.06 ------------ Accuracy: 69.9%\n",
            "Step: 3834 ------------ Loss: 6599.89 ------------ Accuracy: 69.9%\n",
            "Step: 3835 ------------ Loss: 6599.72 ------------ Accuracy: 69.9%\n",
            "Step: 3836 ------------ Loss: 6599.55 ------------ Accuracy: 69.9%\n",
            "Step: 3837 ------------ Loss: 6599.38 ------------ Accuracy: 69.9%\n",
            "Step: 3838 ------------ Loss: 6599.2 ------------ Accuracy: 69.9%\n",
            "Step: 3839 ------------ Loss: 6599.03 ------------ Accuracy: 69.9%\n",
            "Step: 3840 ------------ Loss: 6598.86 ------------ Accuracy: 69.9%\n",
            "Step: 3841 ------------ Loss: 6598.69 ------------ Accuracy: 69.9%\n",
            "Step: 3842 ------------ Loss: 6598.52 ------------ Accuracy: 69.9%\n",
            "Step: 3843 ------------ Loss: 6598.35 ------------ Accuracy: 69.9%\n",
            "Step: 3844 ------------ Loss: 6598.18 ------------ Accuracy: 69.9%\n",
            "Step: 3845 ------------ Loss: 6598.01 ------------ Accuracy: 69.9%\n",
            "Step: 3846 ------------ Loss: 6597.84 ------------ Accuracy: 69.9%\n",
            "Step: 3847 ------------ Loss: 6597.66 ------------ Accuracy: 69.9%\n",
            "Step: 3848 ------------ Loss: 6597.49 ------------ Accuracy: 69.9%\n",
            "Step: 3849 ------------ Loss: 6597.32 ------------ Accuracy: 69.9%\n",
            "Step: 3850 ------------ Loss: 6597.15 ------------ Accuracy: 69.9%\n",
            "Step: 3851 ------------ Loss: 6596.98 ------------ Accuracy: 69.9%\n",
            "Step: 3852 ------------ Loss: 6596.81 ------------ Accuracy: 69.9%\n",
            "Step: 3853 ------------ Loss: 6596.64 ------------ Accuracy: 69.9%\n",
            "Step: 3854 ------------ Loss: 6596.47 ------------ Accuracy: 69.9%\n",
            "Step: 3855 ------------ Loss: 6596.3 ------------ Accuracy: 69.9%\n",
            "Step: 3856 ------------ Loss: 6596.13 ------------ Accuracy: 69.9%\n",
            "Step: 3857 ------------ Loss: 6595.96 ------------ Accuracy: 70.0%\n",
            "Step: 3858 ------------ Loss: 6595.79 ------------ Accuracy: 69.9%\n",
            "Step: 3859 ------------ Loss: 6595.62 ------------ Accuracy: 69.9%\n",
            "Step: 3860 ------------ Loss: 6595.45 ------------ Accuracy: 69.9%\n",
            "Step: 3861 ------------ Loss: 6595.28 ------------ Accuracy: 69.9%\n",
            "Step: 3862 ------------ Loss: 6595.11 ------------ Accuracy: 69.9%\n",
            "Step: 3863 ------------ Loss: 6594.94 ------------ Accuracy: 69.9%\n",
            "Step: 3864 ------------ Loss: 6594.77 ------------ Accuracy: 69.9%\n",
            "Step: 3865 ------------ Loss: 6594.6 ------------ Accuracy: 69.9%\n",
            "Step: 3866 ------------ Loss: 6594.43 ------------ Accuracy: 69.9%\n",
            "Step: 3867 ------------ Loss: 6594.26 ------------ Accuracy: 69.9%\n",
            "Step: 3868 ------------ Loss: 6594.09 ------------ Accuracy: 69.9%\n",
            "Step: 3869 ------------ Loss: 6593.92 ------------ Accuracy: 69.9%\n",
            "Step: 3870 ------------ Loss: 6593.75 ------------ Accuracy: 69.9%\n",
            "Step: 3871 ------------ Loss: 6593.58 ------------ Accuracy: 69.9%\n",
            "Step: 3872 ------------ Loss: 6593.41 ------------ Accuracy: 69.9%\n",
            "Step: 3873 ------------ Loss: 6593.24 ------------ Accuracy: 69.9%\n",
            "Step: 3874 ------------ Loss: 6593.07 ------------ Accuracy: 69.9%\n",
            "Step: 3875 ------------ Loss: 6592.9 ------------ Accuracy: 69.9%\n",
            "Step: 3876 ------------ Loss: 6592.73 ------------ Accuracy: 69.9%\n",
            "Step: 3877 ------------ Loss: 6592.57 ------------ Accuracy: 69.9%\n",
            "Step: 3878 ------------ Loss: 6592.4 ------------ Accuracy: 69.9%\n",
            "Step: 3879 ------------ Loss: 6592.23 ------------ Accuracy: 69.9%\n",
            "Step: 3880 ------------ Loss: 6592.06 ------------ Accuracy: 69.9%\n",
            "Step: 3881 ------------ Loss: 6591.89 ------------ Accuracy: 69.9%\n",
            "Step: 3882 ------------ Loss: 6591.72 ------------ Accuracy: 69.9%\n",
            "Step: 3883 ------------ Loss: 6591.55 ------------ Accuracy: 69.9%\n",
            "Step: 3884 ------------ Loss: 6591.38 ------------ Accuracy: 69.9%\n",
            "Step: 3885 ------------ Loss: 6591.21 ------------ Accuracy: 69.9%\n",
            "Step: 3886 ------------ Loss: 6591.05 ------------ Accuracy: 69.9%\n",
            "Step: 3887 ------------ Loss: 6590.88 ------------ Accuracy: 69.9%\n",
            "Step: 3888 ------------ Loss: 6590.71 ------------ Accuracy: 69.9%\n",
            "Step: 3889 ------------ Loss: 6590.54 ------------ Accuracy: 69.9%\n",
            "Step: 3890 ------------ Loss: 6590.37 ------------ Accuracy: 69.9%\n",
            "Step: 3891 ------------ Loss: 6590.2 ------------ Accuracy: 69.9%\n",
            "Step: 3892 ------------ Loss: 6590.04 ------------ Accuracy: 69.9%\n",
            "Step: 3893 ------------ Loss: 6589.87 ------------ Accuracy: 69.9%\n",
            "Step: 3894 ------------ Loss: 6589.7 ------------ Accuracy: 69.9%\n",
            "Step: 3895 ------------ Loss: 6589.53 ------------ Accuracy: 69.9%\n",
            "Step: 3896 ------------ Loss: 6589.36 ------------ Accuracy: 69.9%\n",
            "Step: 3897 ------------ Loss: 6589.19 ------------ Accuracy: 69.9%\n",
            "Step: 3898 ------------ Loss: 6589.03 ------------ Accuracy: 69.9%\n",
            "Step: 3899 ------------ Loss: 6588.86 ------------ Accuracy: 69.9%\n",
            "Step: 3900 ------------ Loss: 6588.69 ------------ Accuracy: 69.9%\n",
            "Step: 3901 ------------ Loss: 6588.52 ------------ Accuracy: 69.9%\n",
            "Step: 3902 ------------ Loss: 6588.36 ------------ Accuracy: 69.9%\n",
            "Step: 3903 ------------ Loss: 6588.19 ------------ Accuracy: 69.9%\n",
            "Step: 3904 ------------ Loss: 6588.02 ------------ Accuracy: 69.9%\n",
            "Step: 3905 ------------ Loss: 6587.85 ------------ Accuracy: 69.9%\n",
            "Step: 3906 ------------ Loss: 6587.69 ------------ Accuracy: 69.9%\n",
            "Step: 3907 ------------ Loss: 6587.52 ------------ Accuracy: 69.9%\n",
            "Step: 3908 ------------ Loss: 6587.35 ------------ Accuracy: 69.9%\n",
            "Step: 3909 ------------ Loss: 6587.18 ------------ Accuracy: 69.9%\n",
            "Step: 3910 ------------ Loss: 6587.02 ------------ Accuracy: 69.9%\n",
            "Step: 3911 ------------ Loss: 6586.85 ------------ Accuracy: 69.9%\n",
            "Step: 3912 ------------ Loss: 6586.68 ------------ Accuracy: 69.9%\n",
            "Step: 3913 ------------ Loss: 6586.51 ------------ Accuracy: 69.9%\n",
            "Step: 3914 ------------ Loss: 6586.35 ------------ Accuracy: 69.9%\n",
            "Step: 3915 ------------ Loss: 6586.18 ------------ Accuracy: 69.9%\n",
            "Step: 3916 ------------ Loss: 6586.01 ------------ Accuracy: 69.9%\n",
            "Step: 3917 ------------ Loss: 6585.85 ------------ Accuracy: 69.9%\n",
            "Step: 3918 ------------ Loss: 6585.68 ------------ Accuracy: 69.9%\n",
            "Step: 3919 ------------ Loss: 6585.51 ------------ Accuracy: 69.9%\n",
            "Step: 3920 ------------ Loss: 6585.35 ------------ Accuracy: 69.9%\n",
            "Step: 3921 ------------ Loss: 6585.18 ------------ Accuracy: 69.9%\n",
            "Step: 3922 ------------ Loss: 6585.01 ------------ Accuracy: 69.9%\n",
            "Step: 3923 ------------ Loss: 6584.85 ------------ Accuracy: 69.9%\n",
            "Step: 3924 ------------ Loss: 6584.68 ------------ Accuracy: 69.9%\n",
            "Step: 3925 ------------ Loss: 6584.51 ------------ Accuracy: 69.9%\n",
            "Step: 3926 ------------ Loss: 6584.35 ------------ Accuracy: 69.9%\n",
            "Step: 3927 ------------ Loss: 6584.18 ------------ Accuracy: 69.9%\n",
            "Step: 3928 ------------ Loss: 6584.02 ------------ Accuracy: 69.9%\n",
            "Step: 3929 ------------ Loss: 6583.85 ------------ Accuracy: 69.9%\n",
            "Step: 3930 ------------ Loss: 6583.68 ------------ Accuracy: 69.9%\n",
            "Step: 3931 ------------ Loss: 6583.52 ------------ Accuracy: 69.9%\n",
            "Step: 3932 ------------ Loss: 6583.35 ------------ Accuracy: 69.9%\n",
            "Step: 3933 ------------ Loss: 6583.19 ------------ Accuracy: 69.9%\n",
            "Step: 3934 ------------ Loss: 6583.02 ------------ Accuracy: 69.9%\n",
            "Step: 3935 ------------ Loss: 6582.85 ------------ Accuracy: 69.9%\n",
            "Step: 3936 ------------ Loss: 6582.69 ------------ Accuracy: 69.9%\n",
            "Step: 3937 ------------ Loss: 6582.52 ------------ Accuracy: 69.9%\n",
            "Step: 3938 ------------ Loss: 6582.36 ------------ Accuracy: 69.9%\n",
            "Step: 3939 ------------ Loss: 6582.19 ------------ Accuracy: 69.9%\n",
            "Step: 3940 ------------ Loss: 6582.03 ------------ Accuracy: 69.9%\n",
            "Step: 3941 ------------ Loss: 6581.86 ------------ Accuracy: 69.9%\n",
            "Step: 3942 ------------ Loss: 6581.69 ------------ Accuracy: 69.9%\n",
            "Step: 3943 ------------ Loss: 6581.53 ------------ Accuracy: 69.9%\n",
            "Step: 3944 ------------ Loss: 6581.36 ------------ Accuracy: 69.9%\n",
            "Step: 3945 ------------ Loss: 6581.2 ------------ Accuracy: 69.9%\n",
            "Step: 3946 ------------ Loss: 6581.03 ------------ Accuracy: 69.9%\n",
            "Step: 3947 ------------ Loss: 6580.87 ------------ Accuracy: 69.9%\n",
            "Step: 3948 ------------ Loss: 6580.7 ------------ Accuracy: 69.9%\n",
            "Step: 3949 ------------ Loss: 6580.54 ------------ Accuracy: 69.9%\n",
            "Step: 3950 ------------ Loss: 6580.37 ------------ Accuracy: 69.9%\n",
            "Step: 3951 ------------ Loss: 6580.21 ------------ Accuracy: 69.9%\n",
            "Step: 3952 ------------ Loss: 6580.04 ------------ Accuracy: 69.9%\n",
            "Step: 3953 ------------ Loss: 6579.88 ------------ Accuracy: 69.9%\n",
            "Step: 3954 ------------ Loss: 6579.71 ------------ Accuracy: 69.9%\n",
            "Step: 3955 ------------ Loss: 6579.55 ------------ Accuracy: 69.9%\n",
            "Step: 3956 ------------ Loss: 6579.38 ------------ Accuracy: 69.9%\n",
            "Step: 3957 ------------ Loss: 6579.22 ------------ Accuracy: 69.9%\n",
            "Step: 3958 ------------ Loss: 6579.06 ------------ Accuracy: 69.9%\n",
            "Step: 3959 ------------ Loss: 6578.89 ------------ Accuracy: 69.9%\n",
            "Step: 3960 ------------ Loss: 6578.73 ------------ Accuracy: 69.9%\n",
            "Step: 3961 ------------ Loss: 6578.56 ------------ Accuracy: 69.9%\n",
            "Step: 3962 ------------ Loss: 6578.4 ------------ Accuracy: 69.9%\n",
            "Step: 3963 ------------ Loss: 6578.23 ------------ Accuracy: 69.9%\n",
            "Step: 3964 ------------ Loss: 6578.07 ------------ Accuracy: 69.9%\n",
            "Step: 3965 ------------ Loss: 6577.9 ------------ Accuracy: 69.9%\n",
            "Step: 3966 ------------ Loss: 6577.74 ------------ Accuracy: 69.9%\n",
            "Step: 3967 ------------ Loss: 6577.58 ------------ Accuracy: 69.9%\n",
            "Step: 3968 ------------ Loss: 6577.41 ------------ Accuracy: 69.9%\n",
            "Step: 3969 ------------ Loss: 6577.25 ------------ Accuracy: 69.9%\n",
            "Step: 3970 ------------ Loss: 6577.09 ------------ Accuracy: 69.9%\n",
            "Step: 3971 ------------ Loss: 6576.92 ------------ Accuracy: 69.9%\n",
            "Step: 3972 ------------ Loss: 6576.76 ------------ Accuracy: 69.9%\n",
            "Step: 3973 ------------ Loss: 6576.59 ------------ Accuracy: 69.9%\n",
            "Step: 3974 ------------ Loss: 6576.43 ------------ Accuracy: 69.9%\n",
            "Step: 3975 ------------ Loss: 6576.27 ------------ Accuracy: 69.9%\n",
            "Step: 3976 ------------ Loss: 6576.1 ------------ Accuracy: 69.9%\n",
            "Step: 3977 ------------ Loss: 6575.94 ------------ Accuracy: 69.9%\n",
            "Step: 3978 ------------ Loss: 6575.78 ------------ Accuracy: 69.9%\n",
            "Step: 3979 ------------ Loss: 6575.61 ------------ Accuracy: 69.9%\n",
            "Step: 3980 ------------ Loss: 6575.45 ------------ Accuracy: 69.9%\n",
            "Step: 3981 ------------ Loss: 6575.29 ------------ Accuracy: 69.9%\n",
            "Step: 3982 ------------ Loss: 6575.12 ------------ Accuracy: 69.9%\n",
            "Step: 3983 ------------ Loss: 6574.96 ------------ Accuracy: 69.9%\n",
            "Step: 3984 ------------ Loss: 6574.8 ------------ Accuracy: 69.9%\n",
            "Step: 3985 ------------ Loss: 6574.63 ------------ Accuracy: 69.9%\n",
            "Step: 3986 ------------ Loss: 6574.47 ------------ Accuracy: 69.9%\n",
            "Step: 3987 ------------ Loss: 6574.31 ------------ Accuracy: 69.9%\n",
            "Step: 3988 ------------ Loss: 6574.14 ------------ Accuracy: 69.9%\n",
            "Step: 3989 ------------ Loss: 6573.98 ------------ Accuracy: 69.9%\n",
            "Step: 3990 ------------ Loss: 6573.82 ------------ Accuracy: 69.9%\n",
            "Step: 3991 ------------ Loss: 6573.66 ------------ Accuracy: 69.9%\n",
            "Step: 3992 ------------ Loss: 6573.49 ------------ Accuracy: 69.9%\n",
            "Step: 3993 ------------ Loss: 6573.33 ------------ Accuracy: 69.9%\n",
            "Step: 3994 ------------ Loss: 6573.17 ------------ Accuracy: 69.9%\n",
            "Step: 3995 ------------ Loss: 6573.01 ------------ Accuracy: 69.9%\n",
            "Step: 3996 ------------ Loss: 6572.84 ------------ Accuracy: 69.9%\n",
            "Step: 3997 ------------ Loss: 6572.68 ------------ Accuracy: 69.9%\n",
            "Step: 3998 ------------ Loss: 6572.52 ------------ Accuracy: 69.9%\n",
            "Step: 3999 ------------ Loss: 6572.36 ------------ Accuracy: 69.9%\n",
            "Step: 4000 ------------ Loss: 6572.19 ------------ Accuracy: 69.9%\n",
            "Step: 4001 ------------ Loss: 6572.03 ------------ Accuracy: 69.9%\n",
            "Step: 4002 ------------ Loss: 6571.87 ------------ Accuracy: 69.9%\n",
            "Step: 4003 ------------ Loss: 6571.71 ------------ Accuracy: 69.9%\n",
            "Step: 4004 ------------ Loss: 6571.55 ------------ Accuracy: 69.9%\n",
            "Step: 4005 ------------ Loss: 6571.38 ------------ Accuracy: 69.9%\n",
            "Step: 4006 ------------ Loss: 6571.22 ------------ Accuracy: 69.9%\n",
            "Step: 4007 ------------ Loss: 6571.06 ------------ Accuracy: 69.9%\n",
            "Step: 4008 ------------ Loss: 6570.9 ------------ Accuracy: 69.9%\n",
            "Step: 4009 ------------ Loss: 6570.74 ------------ Accuracy: 69.9%\n",
            "Step: 4010 ------------ Loss: 6570.57 ------------ Accuracy: 69.9%\n",
            "Step: 4011 ------------ Loss: 6570.41 ------------ Accuracy: 69.9%\n",
            "Step: 4012 ------------ Loss: 6570.25 ------------ Accuracy: 69.9%\n",
            "Step: 4013 ------------ Loss: 6570.09 ------------ Accuracy: 69.9%\n",
            "Step: 4014 ------------ Loss: 6569.93 ------------ Accuracy: 69.9%\n",
            "Step: 4015 ------------ Loss: 6569.77 ------------ Accuracy: 69.9%\n",
            "Step: 4016 ------------ Loss: 6569.61 ------------ Accuracy: 69.9%\n",
            "Step: 4017 ------------ Loss: 6569.44 ------------ Accuracy: 69.9%\n",
            "Step: 4018 ------------ Loss: 6569.28 ------------ Accuracy: 69.9%\n",
            "Step: 4019 ------------ Loss: 6569.12 ------------ Accuracy: 69.9%\n",
            "Step: 4020 ------------ Loss: 6568.96 ------------ Accuracy: 69.9%\n",
            "Step: 4021 ------------ Loss: 6568.8 ------------ Accuracy: 69.9%\n",
            "Step: 4022 ------------ Loss: 6568.64 ------------ Accuracy: 69.9%\n",
            "Step: 4023 ------------ Loss: 6568.48 ------------ Accuracy: 69.9%\n",
            "Step: 4024 ------------ Loss: 6568.32 ------------ Accuracy: 69.9%\n",
            "Step: 4025 ------------ Loss: 6568.16 ------------ Accuracy: 69.9%\n",
            "Step: 4026 ------------ Loss: 6567.99 ------------ Accuracy: 69.9%\n",
            "Step: 4027 ------------ Loss: 6567.83 ------------ Accuracy: 69.9%\n",
            "Step: 4028 ------------ Loss: 6567.67 ------------ Accuracy: 69.9%\n",
            "Step: 4029 ------------ Loss: 6567.51 ------------ Accuracy: 69.9%\n",
            "Step: 4030 ------------ Loss: 6567.35 ------------ Accuracy: 69.9%\n",
            "Step: 4031 ------------ Loss: 6567.19 ------------ Accuracy: 69.9%\n",
            "Step: 4032 ------------ Loss: 6567.03 ------------ Accuracy: 69.9%\n",
            "Step: 4033 ------------ Loss: 6566.87 ------------ Accuracy: 69.9%\n",
            "Step: 4034 ------------ Loss: 6566.71 ------------ Accuracy: 69.9%\n",
            "Step: 4035 ------------ Loss: 6566.55 ------------ Accuracy: 69.9%\n",
            "Step: 4036 ------------ Loss: 6566.39 ------------ Accuracy: 69.9%\n",
            "Step: 4037 ------------ Loss: 6566.23 ------------ Accuracy: 69.9%\n",
            "Step: 4038 ------------ Loss: 6566.07 ------------ Accuracy: 69.9%\n",
            "Step: 4039 ------------ Loss: 6565.91 ------------ Accuracy: 69.9%\n",
            "Step: 4040 ------------ Loss: 6565.75 ------------ Accuracy: 69.9%\n",
            "Step: 4041 ------------ Loss: 6565.59 ------------ Accuracy: 69.9%\n",
            "Step: 4042 ------------ Loss: 6565.43 ------------ Accuracy: 69.9%\n",
            "Step: 4043 ------------ Loss: 6565.27 ------------ Accuracy: 69.9%\n",
            "Step: 4044 ------------ Loss: 6565.11 ------------ Accuracy: 69.9%\n",
            "Step: 4045 ------------ Loss: 6564.95 ------------ Accuracy: 69.9%\n",
            "Step: 4046 ------------ Loss: 6564.79 ------------ Accuracy: 70.0%\n",
            "Step: 4047 ------------ Loss: 6564.63 ------------ Accuracy: 70.0%\n",
            "Step: 4048 ------------ Loss: 6564.47 ------------ Accuracy: 70.0%\n",
            "Step: 4049 ------------ Loss: 6564.31 ------------ Accuracy: 70.0%\n",
            "Step: 4050 ------------ Loss: 6564.15 ------------ Accuracy: 70.0%\n",
            "Step: 4051 ------------ Loss: 6563.99 ------------ Accuracy: 70.0%\n",
            "Step: 4052 ------------ Loss: 6563.83 ------------ Accuracy: 70.0%\n",
            "Step: 4053 ------------ Loss: 6563.67 ------------ Accuracy: 70.0%\n",
            "Step: 4054 ------------ Loss: 6563.51 ------------ Accuracy: 70.0%\n",
            "Step: 4055 ------------ Loss: 6563.35 ------------ Accuracy: 70.0%\n",
            "Step: 4056 ------------ Loss: 6563.19 ------------ Accuracy: 70.0%\n",
            "Step: 4057 ------------ Loss: 6563.04 ------------ Accuracy: 70.0%\n",
            "Step: 4058 ------------ Loss: 6562.88 ------------ Accuracy: 69.9%\n",
            "Step: 4059 ------------ Loss: 6562.72 ------------ Accuracy: 69.9%\n",
            "Step: 4060 ------------ Loss: 6562.56 ------------ Accuracy: 69.9%\n",
            "Step: 4061 ------------ Loss: 6562.4 ------------ Accuracy: 69.9%\n",
            "Step: 4062 ------------ Loss: 6562.24 ------------ Accuracy: 69.9%\n",
            "Step: 4063 ------------ Loss: 6562.08 ------------ Accuracy: 69.9%\n",
            "Step: 4064 ------------ Loss: 6561.92 ------------ Accuracy: 69.9%\n",
            "Step: 4065 ------------ Loss: 6561.76 ------------ Accuracy: 69.9%\n",
            "Step: 4066 ------------ Loss: 6561.6 ------------ Accuracy: 69.9%\n",
            "Step: 4067 ------------ Loss: 6561.45 ------------ Accuracy: 69.9%\n",
            "Step: 4068 ------------ Loss: 6561.29 ------------ Accuracy: 69.9%\n",
            "Step: 4069 ------------ Loss: 6561.13 ------------ Accuracy: 69.9%\n",
            "Step: 4070 ------------ Loss: 6560.97 ------------ Accuracy: 69.9%\n",
            "Step: 4071 ------------ Loss: 6560.81 ------------ Accuracy: 69.9%\n",
            "Step: 4072 ------------ Loss: 6560.65 ------------ Accuracy: 69.9%\n",
            "Step: 4073 ------------ Loss: 6560.5 ------------ Accuracy: 69.9%\n",
            "Step: 4074 ------------ Loss: 6560.34 ------------ Accuracy: 69.9%\n",
            "Step: 4075 ------------ Loss: 6560.18 ------------ Accuracy: 69.9%\n",
            "Step: 4076 ------------ Loss: 6560.02 ------------ Accuracy: 69.9%\n",
            "Step: 4077 ------------ Loss: 6559.86 ------------ Accuracy: 69.9%\n",
            "Step: 4078 ------------ Loss: 6559.7 ------------ Accuracy: 69.9%\n",
            "Step: 4079 ------------ Loss: 6559.55 ------------ Accuracy: 69.9%\n",
            "Step: 4080 ------------ Loss: 6559.39 ------------ Accuracy: 69.9%\n",
            "Step: 4081 ------------ Loss: 6559.23 ------------ Accuracy: 69.9%\n",
            "Step: 4082 ------------ Loss: 6559.07 ------------ Accuracy: 69.9%\n",
            "Step: 4083 ------------ Loss: 6558.91 ------------ Accuracy: 69.9%\n",
            "Step: 4084 ------------ Loss: 6558.76 ------------ Accuracy: 69.9%\n",
            "Step: 4085 ------------ Loss: 6558.6 ------------ Accuracy: 69.9%\n",
            "Step: 4086 ------------ Loss: 6558.44 ------------ Accuracy: 69.9%\n",
            "Step: 4087 ------------ Loss: 6558.28 ------------ Accuracy: 69.9%\n",
            "Step: 4088 ------------ Loss: 6558.13 ------------ Accuracy: 69.9%\n",
            "Step: 4089 ------------ Loss: 6557.97 ------------ Accuracy: 69.9%\n",
            "Step: 4090 ------------ Loss: 6557.81 ------------ Accuracy: 69.9%\n",
            "Step: 4091 ------------ Loss: 6557.65 ------------ Accuracy: 69.9%\n",
            "Step: 4092 ------------ Loss: 6557.5 ------------ Accuracy: 69.9%\n",
            "Step: 4093 ------------ Loss: 6557.34 ------------ Accuracy: 69.9%\n",
            "Step: 4094 ------------ Loss: 6557.18 ------------ Accuracy: 69.9%\n",
            "Step: 4095 ------------ Loss: 6557.02 ------------ Accuracy: 69.9%\n",
            "Step: 4096 ------------ Loss: 6556.87 ------------ Accuracy: 69.9%\n",
            "Step: 4097 ------------ Loss: 6556.71 ------------ Accuracy: 69.9%\n",
            "Step: 4098 ------------ Loss: 6556.55 ------------ Accuracy: 69.9%\n",
            "Step: 4099 ------------ Loss: 6556.4 ------------ Accuracy: 69.9%\n",
            "Step: 4100 ------------ Loss: 6556.24 ------------ Accuracy: 69.9%\n",
            "Step: 4101 ------------ Loss: 6556.08 ------------ Accuracy: 69.9%\n",
            "Step: 4102 ------------ Loss: 6555.93 ------------ Accuracy: 69.9%\n",
            "Step: 4103 ------------ Loss: 6555.77 ------------ Accuracy: 69.9%\n",
            "Step: 4104 ------------ Loss: 6555.61 ------------ Accuracy: 69.9%\n",
            "Step: 4105 ------------ Loss: 6555.46 ------------ Accuracy: 69.9%\n",
            "Step: 4106 ------------ Loss: 6555.3 ------------ Accuracy: 69.9%\n",
            "Step: 4107 ------------ Loss: 6555.14 ------------ Accuracy: 69.9%\n",
            "Step: 4108 ------------ Loss: 6554.99 ------------ Accuracy: 69.9%\n",
            "Step: 4109 ------------ Loss: 6554.83 ------------ Accuracy: 69.9%\n",
            "Step: 4110 ------------ Loss: 6554.67 ------------ Accuracy: 69.9%\n",
            "Step: 4111 ------------ Loss: 6554.52 ------------ Accuracy: 69.9%\n",
            "Step: 4112 ------------ Loss: 6554.36 ------------ Accuracy: 69.9%\n",
            "Step: 4113 ------------ Loss: 6554.2 ------------ Accuracy: 69.9%\n",
            "Step: 4114 ------------ Loss: 6554.05 ------------ Accuracy: 70.0%\n",
            "Step: 4115 ------------ Loss: 6553.89 ------------ Accuracy: 70.0%\n",
            "Step: 4116 ------------ Loss: 6553.73 ------------ Accuracy: 70.0%\n",
            "Step: 4117 ------------ Loss: 6553.58 ------------ Accuracy: 70.0%\n",
            "Step: 4118 ------------ Loss: 6553.42 ------------ Accuracy: 70.0%\n",
            "Step: 4119 ------------ Loss: 6553.27 ------------ Accuracy: 70.0%\n",
            "Step: 4120 ------------ Loss: 6553.11 ------------ Accuracy: 70.0%\n",
            "Step: 4121 ------------ Loss: 6552.95 ------------ Accuracy: 70.0%\n",
            "Step: 4122 ------------ Loss: 6552.8 ------------ Accuracy: 70.0%\n",
            "Step: 4123 ------------ Loss: 6552.64 ------------ Accuracy: 70.0%\n",
            "Step: 4124 ------------ Loss: 6552.49 ------------ Accuracy: 70.0%\n",
            "Step: 4125 ------------ Loss: 6552.33 ------------ Accuracy: 70.0%\n",
            "Step: 4126 ------------ Loss: 6552.18 ------------ Accuracy: 70.0%\n",
            "Step: 4127 ------------ Loss: 6552.02 ------------ Accuracy: 70.0%\n",
            "Step: 4128 ------------ Loss: 6551.87 ------------ Accuracy: 70.0%\n",
            "Step: 4129 ------------ Loss: 6551.71 ------------ Accuracy: 70.0%\n",
            "Step: 4130 ------------ Loss: 6551.55 ------------ Accuracy: 70.0%\n",
            "Step: 4131 ------------ Loss: 6551.4 ------------ Accuracy: 70.0%\n",
            "Step: 4132 ------------ Loss: 6551.24 ------------ Accuracy: 70.0%\n",
            "Step: 4133 ------------ Loss: 6551.09 ------------ Accuracy: 70.0%\n",
            "Step: 4134 ------------ Loss: 6550.93 ------------ Accuracy: 70.0%\n",
            "Step: 4135 ------------ Loss: 6550.78 ------------ Accuracy: 70.0%\n",
            "Step: 4136 ------------ Loss: 6550.62 ------------ Accuracy: 70.0%\n",
            "Step: 4137 ------------ Loss: 6550.47 ------------ Accuracy: 70.0%\n",
            "Step: 4138 ------------ Loss: 6550.31 ------------ Accuracy: 70.0%\n",
            "Step: 4139 ------------ Loss: 6550.16 ------------ Accuracy: 70.0%\n",
            "Step: 4140 ------------ Loss: 6550.0 ------------ Accuracy: 70.0%\n",
            "Step: 4141 ------------ Loss: 6549.85 ------------ Accuracy: 70.0%\n",
            "Step: 4142 ------------ Loss: 6549.69 ------------ Accuracy: 70.0%\n",
            "Step: 4143 ------------ Loss: 6549.54 ------------ Accuracy: 70.0%\n",
            "Step: 4144 ------------ Loss: 6549.38 ------------ Accuracy: 70.0%\n",
            "Step: 4145 ------------ Loss: 6549.23 ------------ Accuracy: 70.0%\n",
            "Step: 4146 ------------ Loss: 6549.07 ------------ Accuracy: 70.0%\n",
            "Step: 4147 ------------ Loss: 6548.92 ------------ Accuracy: 70.0%\n",
            "Step: 4148 ------------ Loss: 6548.77 ------------ Accuracy: 70.0%\n",
            "Step: 4149 ------------ Loss: 6548.61 ------------ Accuracy: 70.0%\n",
            "Step: 4150 ------------ Loss: 6548.46 ------------ Accuracy: 70.0%\n",
            "Step: 4151 ------------ Loss: 6548.3 ------------ Accuracy: 70.0%\n",
            "Step: 4152 ------------ Loss: 6548.15 ------------ Accuracy: 70.0%\n",
            "Step: 4153 ------------ Loss: 6547.99 ------------ Accuracy: 70.0%\n",
            "Step: 4154 ------------ Loss: 6547.84 ------------ Accuracy: 70.0%\n",
            "Step: 4155 ------------ Loss: 6547.68 ------------ Accuracy: 70.0%\n",
            "Step: 4156 ------------ Loss: 6547.53 ------------ Accuracy: 70.0%\n",
            "Step: 4157 ------------ Loss: 6547.38 ------------ Accuracy: 70.0%\n",
            "Step: 4158 ------------ Loss: 6547.22 ------------ Accuracy: 70.0%\n",
            "Step: 4159 ------------ Loss: 6547.07 ------------ Accuracy: 70.0%\n",
            "Step: 4160 ------------ Loss: 6546.91 ------------ Accuracy: 70.0%\n",
            "Step: 4161 ------------ Loss: 6546.76 ------------ Accuracy: 70.0%\n",
            "Step: 4162 ------------ Loss: 6546.61 ------------ Accuracy: 70.0%\n",
            "Step: 4163 ------------ Loss: 6546.45 ------------ Accuracy: 70.0%\n",
            "Step: 4164 ------------ Loss: 6546.3 ------------ Accuracy: 70.0%\n",
            "Step: 4165 ------------ Loss: 6546.15 ------------ Accuracy: 70.0%\n",
            "Step: 4166 ------------ Loss: 6545.99 ------------ Accuracy: 70.0%\n",
            "Step: 4167 ------------ Loss: 6545.84 ------------ Accuracy: 70.0%\n",
            "Step: 4168 ------------ Loss: 6545.69 ------------ Accuracy: 70.0%\n",
            "Step: 4169 ------------ Loss: 6545.53 ------------ Accuracy: 70.0%\n",
            "Step: 4170 ------------ Loss: 6545.38 ------------ Accuracy: 70.0%\n",
            "Step: 4171 ------------ Loss: 6545.22 ------------ Accuracy: 70.0%\n",
            "Step: 4172 ------------ Loss: 6545.07 ------------ Accuracy: 70.0%\n",
            "Step: 4173 ------------ Loss: 6544.92 ------------ Accuracy: 70.0%\n",
            "Step: 4174 ------------ Loss: 6544.76 ------------ Accuracy: 70.0%\n",
            "Step: 4175 ------------ Loss: 6544.61 ------------ Accuracy: 70.0%\n",
            "Step: 4176 ------------ Loss: 6544.46 ------------ Accuracy: 70.0%\n",
            "Step: 4177 ------------ Loss: 6544.31 ------------ Accuracy: 70.0%\n",
            "Step: 4178 ------------ Loss: 6544.15 ------------ Accuracy: 70.0%\n",
            "Step: 4179 ------------ Loss: 6544.0 ------------ Accuracy: 70.0%\n",
            "Step: 4180 ------------ Loss: 6543.85 ------------ Accuracy: 70.0%\n",
            "Step: 4181 ------------ Loss: 6543.69 ------------ Accuracy: 70.0%\n",
            "Step: 4182 ------------ Loss: 6543.54 ------------ Accuracy: 70.0%\n",
            "Step: 4183 ------------ Loss: 6543.39 ------------ Accuracy: 70.0%\n",
            "Step: 4184 ------------ Loss: 6543.24 ------------ Accuracy: 70.0%\n",
            "Step: 4185 ------------ Loss: 6543.08 ------------ Accuracy: 70.0%\n",
            "Step: 4186 ------------ Loss: 6542.93 ------------ Accuracy: 70.0%\n",
            "Step: 4187 ------------ Loss: 6542.78 ------------ Accuracy: 70.0%\n",
            "Step: 4188 ------------ Loss: 6542.62 ------------ Accuracy: 70.1%\n",
            "Step: 4189 ------------ Loss: 6542.47 ------------ Accuracy: 70.1%\n",
            "Step: 4190 ------------ Loss: 6542.32 ------------ Accuracy: 70.1%\n",
            "Step: 4191 ------------ Loss: 6542.17 ------------ Accuracy: 70.1%\n",
            "Step: 4192 ------------ Loss: 6542.02 ------------ Accuracy: 70.1%\n",
            "Step: 4193 ------------ Loss: 6541.86 ------------ Accuracy: 70.1%\n",
            "Step: 4194 ------------ Loss: 6541.71 ------------ Accuracy: 70.1%\n",
            "Step: 4195 ------------ Loss: 6541.56 ------------ Accuracy: 70.1%\n",
            "Step: 4196 ------------ Loss: 6541.41 ------------ Accuracy: 70.1%\n",
            "Step: 4197 ------------ Loss: 6541.25 ------------ Accuracy: 70.1%\n",
            "Step: 4198 ------------ Loss: 6541.1 ------------ Accuracy: 70.1%\n",
            "Step: 4199 ------------ Loss: 6540.95 ------------ Accuracy: 70.1%\n",
            "Step: 4200 ------------ Loss: 6540.8 ------------ Accuracy: 70.1%\n",
            "Step: 4201 ------------ Loss: 6540.65 ------------ Accuracy: 70.1%\n",
            "Step: 4202 ------------ Loss: 6540.49 ------------ Accuracy: 70.1%\n",
            "Step: 4203 ------------ Loss: 6540.34 ------------ Accuracy: 70.1%\n",
            "Step: 4204 ------------ Loss: 6540.19 ------------ Accuracy: 70.1%\n",
            "Step: 4205 ------------ Loss: 6540.04 ------------ Accuracy: 70.1%\n",
            "Step: 4206 ------------ Loss: 6539.89 ------------ Accuracy: 70.1%\n",
            "Step: 4207 ------------ Loss: 6539.74 ------------ Accuracy: 70.1%\n",
            "Step: 4208 ------------ Loss: 6539.58 ------------ Accuracy: 70.1%\n",
            "Step: 4209 ------------ Loss: 6539.43 ------------ Accuracy: 70.1%\n",
            "Step: 4210 ------------ Loss: 6539.28 ------------ Accuracy: 70.1%\n",
            "Step: 4211 ------------ Loss: 6539.13 ------------ Accuracy: 70.1%\n",
            "Step: 4212 ------------ Loss: 6538.98 ------------ Accuracy: 70.1%\n",
            "Step: 4213 ------------ Loss: 6538.83 ------------ Accuracy: 70.1%\n",
            "Step: 4214 ------------ Loss: 6538.68 ------------ Accuracy: 70.1%\n",
            "Step: 4215 ------------ Loss: 6538.52 ------------ Accuracy: 70.1%\n",
            "Step: 4216 ------------ Loss: 6538.37 ------------ Accuracy: 70.1%\n",
            "Step: 4217 ------------ Loss: 6538.22 ------------ Accuracy: 70.1%\n",
            "Step: 4218 ------------ Loss: 6538.07 ------------ Accuracy: 70.1%\n",
            "Step: 4219 ------------ Loss: 6537.92 ------------ Accuracy: 70.1%\n",
            "Step: 4220 ------------ Loss: 6537.77 ------------ Accuracy: 70.1%\n",
            "Step: 4221 ------------ Loss: 6537.62 ------------ Accuracy: 70.1%\n",
            "Step: 4222 ------------ Loss: 6537.47 ------------ Accuracy: 70.1%\n",
            "Step: 4223 ------------ Loss: 6537.32 ------------ Accuracy: 70.1%\n",
            "Step: 4224 ------------ Loss: 6537.17 ------------ Accuracy: 70.1%\n",
            "Step: 4225 ------------ Loss: 6537.02 ------------ Accuracy: 70.1%\n",
            "Step: 4226 ------------ Loss: 6536.86 ------------ Accuracy: 70.1%\n",
            "Step: 4227 ------------ Loss: 6536.71 ------------ Accuracy: 70.1%\n",
            "Step: 4228 ------------ Loss: 6536.56 ------------ Accuracy: 70.1%\n",
            "Step: 4229 ------------ Loss: 6536.41 ------------ Accuracy: 70.1%\n",
            "Step: 4230 ------------ Loss: 6536.26 ------------ Accuracy: 70.1%\n",
            "Step: 4231 ------------ Loss: 6536.11 ------------ Accuracy: 70.1%\n",
            "Step: 4232 ------------ Loss: 6535.96 ------------ Accuracy: 70.1%\n",
            "Step: 4233 ------------ Loss: 6535.81 ------------ Accuracy: 70.1%\n",
            "Step: 4234 ------------ Loss: 6535.66 ------------ Accuracy: 70.1%\n",
            "Step: 4235 ------------ Loss: 6535.51 ------------ Accuracy: 70.1%\n",
            "Step: 4236 ------------ Loss: 6535.36 ------------ Accuracy: 70.1%\n",
            "Step: 4237 ------------ Loss: 6535.21 ------------ Accuracy: 70.1%\n",
            "Step: 4238 ------------ Loss: 6535.06 ------------ Accuracy: 70.1%\n",
            "Step: 4239 ------------ Loss: 6534.91 ------------ Accuracy: 70.1%\n",
            "Step: 4240 ------------ Loss: 6534.76 ------------ Accuracy: 70.1%\n",
            "Step: 4241 ------------ Loss: 6534.61 ------------ Accuracy: 70.1%\n",
            "Step: 4242 ------------ Loss: 6534.46 ------------ Accuracy: 70.1%\n",
            "Step: 4243 ------------ Loss: 6534.31 ------------ Accuracy: 70.1%\n",
            "Step: 4244 ------------ Loss: 6534.16 ------------ Accuracy: 70.1%\n",
            "Step: 4245 ------------ Loss: 6534.01 ------------ Accuracy: 70.1%\n",
            "Step: 4246 ------------ Loss: 6533.86 ------------ Accuracy: 70.1%\n",
            "Step: 4247 ------------ Loss: 6533.71 ------------ Accuracy: 70.1%\n",
            "Step: 4248 ------------ Loss: 6533.56 ------------ Accuracy: 70.1%\n",
            "Step: 4249 ------------ Loss: 6533.41 ------------ Accuracy: 70.1%\n",
            "Step: 4250 ------------ Loss: 6533.26 ------------ Accuracy: 70.1%\n",
            "Step: 4251 ------------ Loss: 6533.11 ------------ Accuracy: 70.1%\n",
            "Step: 4252 ------------ Loss: 6532.96 ------------ Accuracy: 70.1%\n",
            "Step: 4253 ------------ Loss: 6532.81 ------------ Accuracy: 70.1%\n",
            "Step: 4254 ------------ Loss: 6532.66 ------------ Accuracy: 70.1%\n",
            "Step: 4255 ------------ Loss: 6532.52 ------------ Accuracy: 70.1%\n",
            "Step: 4256 ------------ Loss: 6532.37 ------------ Accuracy: 70.1%\n",
            "Step: 4257 ------------ Loss: 6532.22 ------------ Accuracy: 70.1%\n",
            "Step: 4258 ------------ Loss: 6532.07 ------------ Accuracy: 70.1%\n",
            "Step: 4259 ------------ Loss: 6531.92 ------------ Accuracy: 70.1%\n",
            "Step: 4260 ------------ Loss: 6531.77 ------------ Accuracy: 70.1%\n",
            "Step: 4261 ------------ Loss: 6531.62 ------------ Accuracy: 70.1%\n",
            "Step: 4262 ------------ Loss: 6531.47 ------------ Accuracy: 70.1%\n",
            "Step: 4263 ------------ Loss: 6531.32 ------------ Accuracy: 70.1%\n",
            "Step: 4264 ------------ Loss: 6531.17 ------------ Accuracy: 70.1%\n",
            "Step: 4265 ------------ Loss: 6531.02 ------------ Accuracy: 70.1%\n",
            "Step: 4266 ------------ Loss: 6530.88 ------------ Accuracy: 70.1%\n",
            "Step: 4267 ------------ Loss: 6530.73 ------------ Accuracy: 70.1%\n",
            "Step: 4268 ------------ Loss: 6530.58 ------------ Accuracy: 70.1%\n",
            "Step: 4269 ------------ Loss: 6530.43 ------------ Accuracy: 70.1%\n",
            "Step: 4270 ------------ Loss: 6530.28 ------------ Accuracy: 70.1%\n",
            "Step: 4271 ------------ Loss: 6530.13 ------------ Accuracy: 70.1%\n",
            "Step: 4272 ------------ Loss: 6529.98 ------------ Accuracy: 70.1%\n",
            "Step: 4273 ------------ Loss: 6529.84 ------------ Accuracy: 70.1%\n",
            "Step: 4274 ------------ Loss: 6529.69 ------------ Accuracy: 70.1%\n",
            "Step: 4275 ------------ Loss: 6529.54 ------------ Accuracy: 70.1%\n",
            "Step: 4276 ------------ Loss: 6529.39 ------------ Accuracy: 70.1%\n",
            "Step: 4277 ------------ Loss: 6529.24 ------------ Accuracy: 70.1%\n",
            "Step: 4278 ------------ Loss: 6529.09 ------------ Accuracy: 70.1%\n",
            "Step: 4279 ------------ Loss: 6528.95 ------------ Accuracy: 70.1%\n",
            "Step: 4280 ------------ Loss: 6528.8 ------------ Accuracy: 70.1%\n",
            "Step: 4281 ------------ Loss: 6528.65 ------------ Accuracy: 70.1%\n",
            "Step: 4282 ------------ Loss: 6528.5 ------------ Accuracy: 70.1%\n",
            "Step: 4283 ------------ Loss: 6528.35 ------------ Accuracy: 70.1%\n",
            "Step: 4284 ------------ Loss: 6528.21 ------------ Accuracy: 70.1%\n",
            "Step: 4285 ------------ Loss: 6528.06 ------------ Accuracy: 70.1%\n",
            "Step: 4286 ------------ Loss: 6527.91 ------------ Accuracy: 70.1%\n",
            "Step: 4287 ------------ Loss: 6527.76 ------------ Accuracy: 70.1%\n",
            "Step: 4288 ------------ Loss: 6527.61 ------------ Accuracy: 70.1%\n",
            "Step: 4289 ------------ Loss: 6527.47 ------------ Accuracy: 70.1%\n",
            "Step: 4290 ------------ Loss: 6527.32 ------------ Accuracy: 70.1%\n",
            "Step: 4291 ------------ Loss: 6527.17 ------------ Accuracy: 70.1%\n",
            "Step: 4292 ------------ Loss: 6527.02 ------------ Accuracy: 70.1%\n",
            "Step: 4293 ------------ Loss: 6526.88 ------------ Accuracy: 70.1%\n",
            "Step: 4294 ------------ Loss: 6526.73 ------------ Accuracy: 70.1%\n",
            "Step: 4295 ------------ Loss: 6526.58 ------------ Accuracy: 70.1%\n",
            "Step: 4296 ------------ Loss: 6526.43 ------------ Accuracy: 70.1%\n",
            "Step: 4297 ------------ Loss: 6526.29 ------------ Accuracy: 70.1%\n",
            "Step: 4298 ------------ Loss: 6526.14 ------------ Accuracy: 70.1%\n",
            "Step: 4299 ------------ Loss: 6525.99 ------------ Accuracy: 70.1%\n",
            "Step: 4300 ------------ Loss: 6525.85 ------------ Accuracy: 70.1%\n",
            "Step: 4301 ------------ Loss: 6525.7 ------------ Accuracy: 70.1%\n",
            "Step: 4302 ------------ Loss: 6525.55 ------------ Accuracy: 70.1%\n",
            "Step: 4303 ------------ Loss: 6525.4 ------------ Accuracy: 70.1%\n",
            "Step: 4304 ------------ Loss: 6525.26 ------------ Accuracy: 70.1%\n",
            "Step: 4305 ------------ Loss: 6525.11 ------------ Accuracy: 70.1%\n",
            "Step: 4306 ------------ Loss: 6524.96 ------------ Accuracy: 70.1%\n",
            "Step: 4307 ------------ Loss: 6524.82 ------------ Accuracy: 70.1%\n",
            "Step: 4308 ------------ Loss: 6524.67 ------------ Accuracy: 70.1%\n",
            "Step: 4309 ------------ Loss: 6524.52 ------------ Accuracy: 70.1%\n",
            "Step: 4310 ------------ Loss: 6524.38 ------------ Accuracy: 70.1%\n",
            "Step: 4311 ------------ Loss: 6524.23 ------------ Accuracy: 70.1%\n",
            "Step: 4312 ------------ Loss: 6524.08 ------------ Accuracy: 70.1%\n",
            "Step: 4313 ------------ Loss: 6523.94 ------------ Accuracy: 70.1%\n",
            "Step: 4314 ------------ Loss: 6523.79 ------------ Accuracy: 70.1%\n",
            "Step: 4315 ------------ Loss: 6523.64 ------------ Accuracy: 70.1%\n",
            "Step: 4316 ------------ Loss: 6523.5 ------------ Accuracy: 70.1%\n",
            "Step: 4317 ------------ Loss: 6523.35 ------------ Accuracy: 70.1%\n",
            "Step: 4318 ------------ Loss: 6523.2 ------------ Accuracy: 70.1%\n",
            "Step: 4319 ------------ Loss: 6523.06 ------------ Accuracy: 70.1%\n",
            "Step: 4320 ------------ Loss: 6522.91 ------------ Accuracy: 70.1%\n",
            "Step: 4321 ------------ Loss: 6522.76 ------------ Accuracy: 70.1%\n",
            "Step: 4322 ------------ Loss: 6522.62 ------------ Accuracy: 70.1%\n",
            "Step: 4323 ------------ Loss: 6522.47 ------------ Accuracy: 70.1%\n",
            "Step: 4324 ------------ Loss: 6522.33 ------------ Accuracy: 70.1%\n",
            "Step: 4325 ------------ Loss: 6522.18 ------------ Accuracy: 70.1%\n",
            "Step: 4326 ------------ Loss: 6522.03 ------------ Accuracy: 70.1%\n",
            "Step: 4327 ------------ Loss: 6521.89 ------------ Accuracy: 70.1%\n",
            "Step: 4328 ------------ Loss: 6521.74 ------------ Accuracy: 70.1%\n",
            "Step: 4329 ------------ Loss: 6521.6 ------------ Accuracy: 70.1%\n",
            "Step: 4330 ------------ Loss: 6521.45 ------------ Accuracy: 70.1%\n",
            "Step: 4331 ------------ Loss: 6521.31 ------------ Accuracy: 70.1%\n",
            "Step: 4332 ------------ Loss: 6521.16 ------------ Accuracy: 70.1%\n",
            "Step: 4333 ------------ Loss: 6521.01 ------------ Accuracy: 70.1%\n",
            "Step: 4334 ------------ Loss: 6520.87 ------------ Accuracy: 70.1%\n",
            "Step: 4335 ------------ Loss: 6520.72 ------------ Accuracy: 70.1%\n",
            "Step: 4336 ------------ Loss: 6520.58 ------------ Accuracy: 70.1%\n",
            "Step: 4337 ------------ Loss: 6520.43 ------------ Accuracy: 70.1%\n",
            "Step: 4338 ------------ Loss: 6520.29 ------------ Accuracy: 70.1%\n",
            "Step: 4339 ------------ Loss: 6520.14 ------------ Accuracy: 70.1%\n",
            "Step: 4340 ------------ Loss: 6520.0 ------------ Accuracy: 70.1%\n",
            "Step: 4341 ------------ Loss: 6519.85 ------------ Accuracy: 70.1%\n",
            "Step: 4342 ------------ Loss: 6519.7 ------------ Accuracy: 70.1%\n",
            "Step: 4343 ------------ Loss: 6519.56 ------------ Accuracy: 70.1%\n",
            "Step: 4344 ------------ Loss: 6519.41 ------------ Accuracy: 70.1%\n",
            "Step: 4345 ------------ Loss: 6519.27 ------------ Accuracy: 70.1%\n",
            "Step: 4346 ------------ Loss: 6519.12 ------------ Accuracy: 70.1%\n",
            "Step: 4347 ------------ Loss: 6518.98 ------------ Accuracy: 70.1%\n",
            "Step: 4348 ------------ Loss: 6518.83 ------------ Accuracy: 70.1%\n",
            "Step: 4349 ------------ Loss: 6518.69 ------------ Accuracy: 70.1%\n",
            "Step: 4350 ------------ Loss: 6518.54 ------------ Accuracy: 70.1%\n",
            "Step: 4351 ------------ Loss: 6518.4 ------------ Accuracy: 70.1%\n",
            "Step: 4352 ------------ Loss: 6518.25 ------------ Accuracy: 70.1%\n",
            "Step: 4353 ------------ Loss: 6518.11 ------------ Accuracy: 70.1%\n",
            "Step: 4354 ------------ Loss: 6517.96 ------------ Accuracy: 70.1%\n",
            "Step: 4355 ------------ Loss: 6517.82 ------------ Accuracy: 70.1%\n",
            "Step: 4356 ------------ Loss: 6517.68 ------------ Accuracy: 70.1%\n",
            "Step: 4357 ------------ Loss: 6517.53 ------------ Accuracy: 70.1%\n",
            "Step: 4358 ------------ Loss: 6517.39 ------------ Accuracy: 70.1%\n",
            "Step: 4359 ------------ Loss: 6517.24 ------------ Accuracy: 70.1%\n",
            "Step: 4360 ------------ Loss: 6517.1 ------------ Accuracy: 70.1%\n",
            "Step: 4361 ------------ Loss: 6516.95 ------------ Accuracy: 70.1%\n",
            "Step: 4362 ------------ Loss: 6516.81 ------------ Accuracy: 70.1%\n",
            "Step: 4363 ------------ Loss: 6516.66 ------------ Accuracy: 70.1%\n",
            "Step: 4364 ------------ Loss: 6516.52 ------------ Accuracy: 70.1%\n",
            "Step: 4365 ------------ Loss: 6516.38 ------------ Accuracy: 70.1%\n",
            "Step: 4366 ------------ Loss: 6516.23 ------------ Accuracy: 70.1%\n",
            "Step: 4367 ------------ Loss: 6516.09 ------------ Accuracy: 70.1%\n",
            "Step: 4368 ------------ Loss: 6515.94 ------------ Accuracy: 70.1%\n",
            "Step: 4369 ------------ Loss: 6515.8 ------------ Accuracy: 70.1%\n",
            "Step: 4370 ------------ Loss: 6515.66 ------------ Accuracy: 70.1%\n",
            "Step: 4371 ------------ Loss: 6515.51 ------------ Accuracy: 70.1%\n",
            "Step: 4372 ------------ Loss: 6515.37 ------------ Accuracy: 70.1%\n",
            "Step: 4373 ------------ Loss: 6515.22 ------------ Accuracy: 70.1%\n",
            "Step: 4374 ------------ Loss: 6515.08 ------------ Accuracy: 70.1%\n",
            "Step: 4375 ------------ Loss: 6514.94 ------------ Accuracy: 70.1%\n",
            "Step: 4376 ------------ Loss: 6514.79 ------------ Accuracy: 70.1%\n",
            "Step: 4377 ------------ Loss: 6514.65 ------------ Accuracy: 70.1%\n",
            "Step: 4378 ------------ Loss: 6514.5 ------------ Accuracy: 70.1%\n",
            "Step: 4379 ------------ Loss: 6514.36 ------------ Accuracy: 70.1%\n",
            "Step: 4380 ------------ Loss: 6514.22 ------------ Accuracy: 70.1%\n",
            "Step: 4381 ------------ Loss: 6514.07 ------------ Accuracy: 70.1%\n",
            "Step: 4382 ------------ Loss: 6513.93 ------------ Accuracy: 70.1%\n",
            "Step: 4383 ------------ Loss: 6513.79 ------------ Accuracy: 70.1%\n",
            "Step: 4384 ------------ Loss: 6513.64 ------------ Accuracy: 70.1%\n",
            "Step: 4385 ------------ Loss: 6513.5 ------------ Accuracy: 70.1%\n",
            "Step: 4386 ------------ Loss: 6513.36 ------------ Accuracy: 70.1%\n",
            "Step: 4387 ------------ Loss: 6513.21 ------------ Accuracy: 70.1%\n",
            "Step: 4388 ------------ Loss: 6513.07 ------------ Accuracy: 70.1%\n",
            "Step: 4389 ------------ Loss: 6512.93 ------------ Accuracy: 70.1%\n",
            "Step: 4390 ------------ Loss: 6512.78 ------------ Accuracy: 70.1%\n",
            "Step: 4391 ------------ Loss: 6512.64 ------------ Accuracy: 70.1%\n",
            "Step: 4392 ------------ Loss: 6512.5 ------------ Accuracy: 70.1%\n",
            "Step: 4393 ------------ Loss: 6512.36 ------------ Accuracy: 70.1%\n",
            "Step: 4394 ------------ Loss: 6512.21 ------------ Accuracy: 70.1%\n",
            "Step: 4395 ------------ Loss: 6512.07 ------------ Accuracy: 70.1%\n",
            "Step: 4396 ------------ Loss: 6511.93 ------------ Accuracy: 70.1%\n",
            "Step: 4397 ------------ Loss: 6511.78 ------------ Accuracy: 70.1%\n",
            "Step: 4398 ------------ Loss: 6511.64 ------------ Accuracy: 70.1%\n",
            "Step: 4399 ------------ Loss: 6511.5 ------------ Accuracy: 70.1%\n",
            "Step: 4400 ------------ Loss: 6511.36 ------------ Accuracy: 70.1%\n",
            "Step: 4401 ------------ Loss: 6511.21 ------------ Accuracy: 70.1%\n",
            "Step: 4402 ------------ Loss: 6511.07 ------------ Accuracy: 70.1%\n",
            "Step: 4403 ------------ Loss: 6510.93 ------------ Accuracy: 70.1%\n",
            "Step: 4404 ------------ Loss: 6510.79 ------------ Accuracy: 70.1%\n",
            "Step: 4405 ------------ Loss: 6510.64 ------------ Accuracy: 70.1%\n",
            "Step: 4406 ------------ Loss: 6510.5 ------------ Accuracy: 70.1%\n",
            "Step: 4407 ------------ Loss: 6510.36 ------------ Accuracy: 70.1%\n",
            "Step: 4408 ------------ Loss: 6510.22 ------------ Accuracy: 70.1%\n",
            "Step: 4409 ------------ Loss: 6510.07 ------------ Accuracy: 70.1%\n",
            "Step: 4410 ------------ Loss: 6509.93 ------------ Accuracy: 70.1%\n",
            "Step: 4411 ------------ Loss: 6509.79 ------------ Accuracy: 70.1%\n",
            "Step: 4412 ------------ Loss: 6509.65 ------------ Accuracy: 70.1%\n",
            "Step: 4413 ------------ Loss: 6509.51 ------------ Accuracy: 70.1%\n",
            "Step: 4414 ------------ Loss: 6509.36 ------------ Accuracy: 70.1%\n",
            "Step: 4415 ------------ Loss: 6509.22 ------------ Accuracy: 70.1%\n",
            "Step: 4416 ------------ Loss: 6509.08 ------------ Accuracy: 70.1%\n",
            "Step: 4417 ------------ Loss: 6508.94 ------------ Accuracy: 70.1%\n",
            "Step: 4418 ------------ Loss: 6508.8 ------------ Accuracy: 70.1%\n",
            "Step: 4419 ------------ Loss: 6508.65 ------------ Accuracy: 70.1%\n",
            "Step: 4420 ------------ Loss: 6508.51 ------------ Accuracy: 70.1%\n",
            "Step: 4421 ------------ Loss: 6508.37 ------------ Accuracy: 70.1%\n",
            "Step: 4422 ------------ Loss: 6508.23 ------------ Accuracy: 70.1%\n",
            "Step: 4423 ------------ Loss: 6508.09 ------------ Accuracy: 70.1%\n",
            "Step: 4424 ------------ Loss: 6507.94 ------------ Accuracy: 70.1%\n",
            "Step: 4425 ------------ Loss: 6507.8 ------------ Accuracy: 70.1%\n",
            "Step: 4426 ------------ Loss: 6507.66 ------------ Accuracy: 70.1%\n",
            "Step: 4427 ------------ Loss: 6507.52 ------------ Accuracy: 70.1%\n",
            "Step: 4428 ------------ Loss: 6507.38 ------------ Accuracy: 70.1%\n",
            "Step: 4429 ------------ Loss: 6507.24 ------------ Accuracy: 70.1%\n",
            "Step: 4430 ------------ Loss: 6507.1 ------------ Accuracy: 70.1%\n",
            "Step: 4431 ------------ Loss: 6506.95 ------------ Accuracy: 70.1%\n",
            "Step: 4432 ------------ Loss: 6506.81 ------------ Accuracy: 70.1%\n",
            "Step: 4433 ------------ Loss: 6506.67 ------------ Accuracy: 70.1%\n",
            "Step: 4434 ------------ Loss: 6506.53 ------------ Accuracy: 70.1%\n",
            "Step: 4435 ------------ Loss: 6506.39 ------------ Accuracy: 70.1%\n",
            "Step: 4436 ------------ Loss: 6506.25 ------------ Accuracy: 70.1%\n",
            "Step: 4437 ------------ Loss: 6506.11 ------------ Accuracy: 70.1%\n",
            "Step: 4438 ------------ Loss: 6505.97 ------------ Accuracy: 70.1%\n",
            "Step: 4439 ------------ Loss: 6505.83 ------------ Accuracy: 70.1%\n",
            "Step: 4440 ------------ Loss: 6505.68 ------------ Accuracy: 70.1%\n",
            "Step: 4441 ------------ Loss: 6505.54 ------------ Accuracy: 70.1%\n",
            "Step: 4442 ------------ Loss: 6505.4 ------------ Accuracy: 70.1%\n",
            "Step: 4443 ------------ Loss: 6505.26 ------------ Accuracy: 70.1%\n",
            "Step: 4444 ------------ Loss: 6505.12 ------------ Accuracy: 70.1%\n",
            "Step: 4445 ------------ Loss: 6504.98 ------------ Accuracy: 70.1%\n",
            "Step: 4446 ------------ Loss: 6504.84 ------------ Accuracy: 70.1%\n",
            "Step: 4447 ------------ Loss: 6504.7 ------------ Accuracy: 70.1%\n",
            "Step: 4448 ------------ Loss: 6504.56 ------------ Accuracy: 70.1%\n",
            "Step: 4449 ------------ Loss: 6504.42 ------------ Accuracy: 70.1%\n",
            "Step: 4450 ------------ Loss: 6504.28 ------------ Accuracy: 70.1%\n",
            "Step: 4451 ------------ Loss: 6504.14 ------------ Accuracy: 70.1%\n",
            "Step: 4452 ------------ Loss: 6504.0 ------------ Accuracy: 70.1%\n",
            "Step: 4453 ------------ Loss: 6503.86 ------------ Accuracy: 70.1%\n",
            "Step: 4454 ------------ Loss: 6503.72 ------------ Accuracy: 70.1%\n",
            "Step: 4455 ------------ Loss: 6503.58 ------------ Accuracy: 70.1%\n",
            "Step: 4456 ------------ Loss: 6503.44 ------------ Accuracy: 70.1%\n",
            "Step: 4457 ------------ Loss: 6503.3 ------------ Accuracy: 70.1%\n",
            "Step: 4458 ------------ Loss: 6503.16 ------------ Accuracy: 70.1%\n",
            "Step: 4459 ------------ Loss: 6503.02 ------------ Accuracy: 70.1%\n",
            "Step: 4460 ------------ Loss: 6502.88 ------------ Accuracy: 70.1%\n",
            "Step: 4461 ------------ Loss: 6502.74 ------------ Accuracy: 70.1%\n",
            "Step: 4462 ------------ Loss: 6502.6 ------------ Accuracy: 70.1%\n",
            "Step: 4463 ------------ Loss: 6502.46 ------------ Accuracy: 70.1%\n",
            "Step: 4464 ------------ Loss: 6502.32 ------------ Accuracy: 70.1%\n",
            "Step: 4465 ------------ Loss: 6502.18 ------------ Accuracy: 70.1%\n",
            "Step: 4466 ------------ Loss: 6502.04 ------------ Accuracy: 70.1%\n",
            "Step: 4467 ------------ Loss: 6501.9 ------------ Accuracy: 70.1%\n",
            "Step: 4468 ------------ Loss: 6501.76 ------------ Accuracy: 70.1%\n",
            "Step: 4469 ------------ Loss: 6501.62 ------------ Accuracy: 70.1%\n",
            "Step: 4470 ------------ Loss: 6501.48 ------------ Accuracy: 70.1%\n",
            "Step: 4471 ------------ Loss: 6501.34 ------------ Accuracy: 70.1%\n",
            "Step: 4472 ------------ Loss: 6501.2 ------------ Accuracy: 70.1%\n",
            "Step: 4473 ------------ Loss: 6501.06 ------------ Accuracy: 70.1%\n",
            "Step: 4474 ------------ Loss: 6500.92 ------------ Accuracy: 70.1%\n",
            "Step: 4475 ------------ Loss: 6500.78 ------------ Accuracy: 70.1%\n",
            "Step: 4476 ------------ Loss: 6500.64 ------------ Accuracy: 70.1%\n",
            "Step: 4477 ------------ Loss: 6500.5 ------------ Accuracy: 70.1%\n",
            "Step: 4478 ------------ Loss: 6500.36 ------------ Accuracy: 70.1%\n",
            "Step: 4479 ------------ Loss: 6500.22 ------------ Accuracy: 70.1%\n",
            "Step: 4480 ------------ Loss: 6500.08 ------------ Accuracy: 70.1%\n",
            "Step: 4481 ------------ Loss: 6499.94 ------------ Accuracy: 70.1%\n",
            "Step: 4482 ------------ Loss: 6499.8 ------------ Accuracy: 70.1%\n",
            "Step: 4483 ------------ Loss: 6499.67 ------------ Accuracy: 70.1%\n",
            "Step: 4484 ------------ Loss: 6499.53 ------------ Accuracy: 70.1%\n",
            "Step: 4485 ------------ Loss: 6499.39 ------------ Accuracy: 70.1%\n",
            "Step: 4486 ------------ Loss: 6499.25 ------------ Accuracy: 70.1%\n",
            "Step: 4487 ------------ Loss: 6499.11 ------------ Accuracy: 70.1%\n",
            "Step: 4488 ------------ Loss: 6498.97 ------------ Accuracy: 70.1%\n",
            "Step: 4489 ------------ Loss: 6498.83 ------------ Accuracy: 70.1%\n",
            "Step: 4490 ------------ Loss: 6498.69 ------------ Accuracy: 70.1%\n",
            "Step: 4491 ------------ Loss: 6498.55 ------------ Accuracy: 70.1%\n",
            "Step: 4492 ------------ Loss: 6498.42 ------------ Accuracy: 70.1%\n",
            "Step: 4493 ------------ Loss: 6498.28 ------------ Accuracy: 70.1%\n",
            "Step: 4494 ------------ Loss: 6498.14 ------------ Accuracy: 70.1%\n",
            "Step: 4495 ------------ Loss: 6498.0 ------------ Accuracy: 70.1%\n",
            "Step: 4496 ------------ Loss: 6497.86 ------------ Accuracy: 70.1%\n",
            "Step: 4497 ------------ Loss: 6497.72 ------------ Accuracy: 70.1%\n",
            "Step: 4498 ------------ Loss: 6497.58 ------------ Accuracy: 70.1%\n",
            "Step: 4499 ------------ Loss: 6497.45 ------------ Accuracy: 70.1%\n",
            "Step: 4500 ------------ Loss: 6497.31 ------------ Accuracy: 70.2%\n",
            "Step: 4501 ------------ Loss: 6497.17 ------------ Accuracy: 70.2%\n",
            "Step: 4502 ------------ Loss: 6497.03 ------------ Accuracy: 70.2%\n",
            "Step: 4503 ------------ Loss: 6496.89 ------------ Accuracy: 70.2%\n",
            "Step: 4504 ------------ Loss: 6496.75 ------------ Accuracy: 70.2%\n",
            "Step: 4505 ------------ Loss: 6496.62 ------------ Accuracy: 70.2%\n",
            "Step: 4506 ------------ Loss: 6496.48 ------------ Accuracy: 70.2%\n",
            "Step: 4507 ------------ Loss: 6496.34 ------------ Accuracy: 70.2%\n",
            "Step: 4508 ------------ Loss: 6496.2 ------------ Accuracy: 70.2%\n",
            "Step: 4509 ------------ Loss: 6496.06 ------------ Accuracy: 70.2%\n",
            "Step: 4510 ------------ Loss: 6495.93 ------------ Accuracy: 70.2%\n",
            "Step: 4511 ------------ Loss: 6495.79 ------------ Accuracy: 70.2%\n",
            "Step: 4512 ------------ Loss: 6495.65 ------------ Accuracy: 70.2%\n",
            "Step: 4513 ------------ Loss: 6495.51 ------------ Accuracy: 70.2%\n",
            "Step: 4514 ------------ Loss: 6495.37 ------------ Accuracy: 70.2%\n",
            "Step: 4515 ------------ Loss: 6495.24 ------------ Accuracy: 70.2%\n",
            "Step: 4516 ------------ Loss: 6495.1 ------------ Accuracy: 70.2%\n",
            "Step: 4517 ------------ Loss: 6494.96 ------------ Accuracy: 70.2%\n",
            "Step: 4518 ------------ Loss: 6494.82 ------------ Accuracy: 70.2%\n",
            "Step: 4519 ------------ Loss: 6494.69 ------------ Accuracy: 70.2%\n",
            "Step: 4520 ------------ Loss: 6494.55 ------------ Accuracy: 70.2%\n",
            "Step: 4521 ------------ Loss: 6494.41 ------------ Accuracy: 70.2%\n",
            "Step: 4522 ------------ Loss: 6494.27 ------------ Accuracy: 70.2%\n",
            "Step: 4523 ------------ Loss: 6494.14 ------------ Accuracy: 70.2%\n",
            "Step: 4524 ------------ Loss: 6494.0 ------------ Accuracy: 70.2%\n",
            "Step: 4525 ------------ Loss: 6493.86 ------------ Accuracy: 70.2%\n",
            "Step: 4526 ------------ Loss: 6493.72 ------------ Accuracy: 70.2%\n",
            "Step: 4527 ------------ Loss: 6493.59 ------------ Accuracy: 70.2%\n",
            "Step: 4528 ------------ Loss: 6493.45 ------------ Accuracy: 70.2%\n",
            "Step: 4529 ------------ Loss: 6493.31 ------------ Accuracy: 70.2%\n",
            "Step: 4530 ------------ Loss: 6493.18 ------------ Accuracy: 70.2%\n",
            "Step: 4531 ------------ Loss: 6493.04 ------------ Accuracy: 70.2%\n",
            "Step: 4532 ------------ Loss: 6492.9 ------------ Accuracy: 70.2%\n",
            "Step: 4533 ------------ Loss: 6492.76 ------------ Accuracy: 70.2%\n",
            "Step: 4534 ------------ Loss: 6492.63 ------------ Accuracy: 70.2%\n",
            "Step: 4535 ------------ Loss: 6492.49 ------------ Accuracy: 70.2%\n",
            "Step: 4536 ------------ Loss: 6492.35 ------------ Accuracy: 70.2%\n",
            "Step: 4537 ------------ Loss: 6492.22 ------------ Accuracy: 70.2%\n",
            "Step: 4538 ------------ Loss: 6492.08 ------------ Accuracy: 70.2%\n",
            "Step: 4539 ------------ Loss: 6491.94 ------------ Accuracy: 70.2%\n",
            "Step: 4540 ------------ Loss: 6491.81 ------------ Accuracy: 70.2%\n",
            "Step: 4541 ------------ Loss: 6491.67 ------------ Accuracy: 70.2%\n",
            "Step: 4542 ------------ Loss: 6491.53 ------------ Accuracy: 70.2%\n",
            "Step: 4543 ------------ Loss: 6491.4 ------------ Accuracy: 70.2%\n",
            "Step: 4544 ------------ Loss: 6491.26 ------------ Accuracy: 70.2%\n",
            "Step: 4545 ------------ Loss: 6491.12 ------------ Accuracy: 70.2%\n",
            "Step: 4546 ------------ Loss: 6490.99 ------------ Accuracy: 70.2%\n",
            "Step: 4547 ------------ Loss: 6490.85 ------------ Accuracy: 70.2%\n",
            "Step: 4548 ------------ Loss: 6490.71 ------------ Accuracy: 70.2%\n",
            "Step: 4549 ------------ Loss: 6490.58 ------------ Accuracy: 70.0%\n",
            "Step: 4550 ------------ Loss: 6490.44 ------------ Accuracy: 70.0%\n",
            "Step: 4551 ------------ Loss: 6490.3 ------------ Accuracy: 70.0%\n",
            "Step: 4552 ------------ Loss: 6490.17 ------------ Accuracy: 70.0%\n",
            "Step: 4553 ------------ Loss: 6490.03 ------------ Accuracy: 70.0%\n",
            "Step: 4554 ------------ Loss: 6489.9 ------------ Accuracy: 70.0%\n",
            "Step: 4555 ------------ Loss: 6489.76 ------------ Accuracy: 70.0%\n",
            "Step: 4556 ------------ Loss: 6489.62 ------------ Accuracy: 70.0%\n",
            "Step: 4557 ------------ Loss: 6489.49 ------------ Accuracy: 70.0%\n",
            "Step: 4558 ------------ Loss: 6489.35 ------------ Accuracy: 70.0%\n",
            "Step: 4559 ------------ Loss: 6489.22 ------------ Accuracy: 70.0%\n",
            "Step: 4560 ------------ Loss: 6489.08 ------------ Accuracy: 70.0%\n",
            "Step: 4561 ------------ Loss: 6488.94 ------------ Accuracy: 70.0%\n",
            "Step: 4562 ------------ Loss: 6488.81 ------------ Accuracy: 70.0%\n",
            "Step: 4563 ------------ Loss: 6488.67 ------------ Accuracy: 70.0%\n",
            "Step: 4564 ------------ Loss: 6488.54 ------------ Accuracy: 70.0%\n",
            "Step: 4565 ------------ Loss: 6488.4 ------------ Accuracy: 70.0%\n",
            "Step: 4566 ------------ Loss: 6488.27 ------------ Accuracy: 70.0%\n",
            "Step: 4567 ------------ Loss: 6488.13 ------------ Accuracy: 70.0%\n",
            "Step: 4568 ------------ Loss: 6487.99 ------------ Accuracy: 70.0%\n",
            "Step: 4569 ------------ Loss: 6487.86 ------------ Accuracy: 70.0%\n",
            "Step: 4570 ------------ Loss: 6487.72 ------------ Accuracy: 70.0%\n",
            "Step: 4571 ------------ Loss: 6487.59 ------------ Accuracy: 70.0%\n",
            "Step: 4572 ------------ Loss: 6487.45 ------------ Accuracy: 70.0%\n",
            "Step: 4573 ------------ Loss: 6487.32 ------------ Accuracy: 70.0%\n",
            "Step: 4574 ------------ Loss: 6487.18 ------------ Accuracy: 70.0%\n",
            "Step: 4575 ------------ Loss: 6487.05 ------------ Accuracy: 70.0%\n",
            "Step: 4576 ------------ Loss: 6486.91 ------------ Accuracy: 70.0%\n",
            "Step: 4577 ------------ Loss: 6486.78 ------------ Accuracy: 70.0%\n",
            "Step: 4578 ------------ Loss: 6486.64 ------------ Accuracy: 70.0%\n",
            "Step: 4579 ------------ Loss: 6486.51 ------------ Accuracy: 70.0%\n",
            "Step: 4580 ------------ Loss: 6486.37 ------------ Accuracy: 70.0%\n",
            "Step: 4581 ------------ Loss: 6486.24 ------------ Accuracy: 70.0%\n",
            "Step: 4582 ------------ Loss: 6486.1 ------------ Accuracy: 70.0%\n",
            "Step: 4583 ------------ Loss: 6485.97 ------------ Accuracy: 70.0%\n",
            "Step: 4584 ------------ Loss: 6485.83 ------------ Accuracy: 70.0%\n",
            "Step: 4585 ------------ Loss: 6485.7 ------------ Accuracy: 70.0%\n",
            "Step: 4586 ------------ Loss: 6485.56 ------------ Accuracy: 70.0%\n",
            "Step: 4587 ------------ Loss: 6485.43 ------------ Accuracy: 70.0%\n",
            "Step: 4588 ------------ Loss: 6485.29 ------------ Accuracy: 70.0%\n",
            "Step: 4589 ------------ Loss: 6485.16 ------------ Accuracy: 70.0%\n",
            "Step: 4590 ------------ Loss: 6485.02 ------------ Accuracy: 70.0%\n",
            "Step: 4591 ------------ Loss: 6484.89 ------------ Accuracy: 70.0%\n",
            "Step: 4592 ------------ Loss: 6484.75 ------------ Accuracy: 70.0%\n",
            "Step: 4593 ------------ Loss: 6484.62 ------------ Accuracy: 70.0%\n",
            "Step: 4594 ------------ Loss: 6484.48 ------------ Accuracy: 70.0%\n",
            "Step: 4595 ------------ Loss: 6484.35 ------------ Accuracy: 70.0%\n",
            "Step: 4596 ------------ Loss: 6484.22 ------------ Accuracy: 70.0%\n",
            "Step: 4597 ------------ Loss: 6484.08 ------------ Accuracy: 70.0%\n",
            "Step: 4598 ------------ Loss: 6483.95 ------------ Accuracy: 70.0%\n",
            "Step: 4599 ------------ Loss: 6483.81 ------------ Accuracy: 70.0%\n",
            "Step: 4600 ------------ Loss: 6483.68 ------------ Accuracy: 70.0%\n",
            "Step: 4601 ------------ Loss: 6483.54 ------------ Accuracy: 70.0%\n",
            "Step: 4602 ------------ Loss: 6483.41 ------------ Accuracy: 70.0%\n",
            "Step: 4603 ------------ Loss: 6483.28 ------------ Accuracy: 70.0%\n",
            "Step: 4604 ------------ Loss: 6483.14 ------------ Accuracy: 70.0%\n",
            "Step: 4605 ------------ Loss: 6483.01 ------------ Accuracy: 70.0%\n",
            "Step: 4606 ------------ Loss: 6482.87 ------------ Accuracy: 70.0%\n",
            "Step: 4607 ------------ Loss: 6482.74 ------------ Accuracy: 70.0%\n",
            "Step: 4608 ------------ Loss: 6482.6 ------------ Accuracy: 70.0%\n",
            "Step: 4609 ------------ Loss: 6482.47 ------------ Accuracy: 70.0%\n",
            "Step: 4610 ------------ Loss: 6482.34 ------------ Accuracy: 70.0%\n",
            "Step: 4611 ------------ Loss: 6482.2 ------------ Accuracy: 70.0%\n",
            "Step: 4612 ------------ Loss: 6482.07 ------------ Accuracy: 70.0%\n",
            "Step: 4613 ------------ Loss: 6481.94 ------------ Accuracy: 70.0%\n",
            "Step: 4614 ------------ Loss: 6481.8 ------------ Accuracy: 70.0%\n",
            "Step: 4615 ------------ Loss: 6481.67 ------------ Accuracy: 70.0%\n",
            "Step: 4616 ------------ Loss: 6481.53 ------------ Accuracy: 70.0%\n",
            "Step: 4617 ------------ Loss: 6481.4 ------------ Accuracy: 70.0%\n",
            "Step: 4618 ------------ Loss: 6481.27 ------------ Accuracy: 70.0%\n",
            "Step: 4619 ------------ Loss: 6481.13 ------------ Accuracy: 70.0%\n",
            "Step: 4620 ------------ Loss: 6481.0 ------------ Accuracy: 70.0%\n",
            "Step: 4621 ------------ Loss: 6480.87 ------------ Accuracy: 70.0%\n",
            "Step: 4622 ------------ Loss: 6480.73 ------------ Accuracy: 70.0%\n",
            "Step: 4623 ------------ Loss: 6480.6 ------------ Accuracy: 70.0%\n",
            "Step: 4624 ------------ Loss: 6480.47 ------------ Accuracy: 70.0%\n",
            "Step: 4625 ------------ Loss: 6480.33 ------------ Accuracy: 70.0%\n",
            "Step: 4626 ------------ Loss: 6480.2 ------------ Accuracy: 70.0%\n",
            "Step: 4627 ------------ Loss: 6480.07 ------------ Accuracy: 70.0%\n",
            "Step: 4628 ------------ Loss: 6479.93 ------------ Accuracy: 70.0%\n",
            "Step: 4629 ------------ Loss: 6479.8 ------------ Accuracy: 70.0%\n",
            "Step: 4630 ------------ Loss: 6479.67 ------------ Accuracy: 70.0%\n",
            "Step: 4631 ------------ Loss: 6479.53 ------------ Accuracy: 70.0%\n",
            "Step: 4632 ------------ Loss: 6479.4 ------------ Accuracy: 70.0%\n",
            "Step: 4633 ------------ Loss: 6479.27 ------------ Accuracy: 70.0%\n",
            "Step: 4634 ------------ Loss: 6479.14 ------------ Accuracy: 70.0%\n",
            "Step: 4635 ------------ Loss: 6479.0 ------------ Accuracy: 70.0%\n",
            "Step: 4636 ------------ Loss: 6478.87 ------------ Accuracy: 70.0%\n",
            "Step: 4637 ------------ Loss: 6478.74 ------------ Accuracy: 70.0%\n",
            "Step: 4638 ------------ Loss: 6478.6 ------------ Accuracy: 70.0%\n",
            "Step: 4639 ------------ Loss: 6478.47 ------------ Accuracy: 70.0%\n",
            "Step: 4640 ------------ Loss: 6478.34 ------------ Accuracy: 70.0%\n",
            "Step: 4641 ------------ Loss: 6478.21 ------------ Accuracy: 70.0%\n",
            "Step: 4642 ------------ Loss: 6478.07 ------------ Accuracy: 70.0%\n",
            "Step: 4643 ------------ Loss: 6477.94 ------------ Accuracy: 70.0%\n",
            "Step: 4644 ------------ Loss: 6477.81 ------------ Accuracy: 70.0%\n",
            "Step: 4645 ------------ Loss: 6477.68 ------------ Accuracy: 70.0%\n",
            "Step: 4646 ------------ Loss: 6477.54 ------------ Accuracy: 70.0%\n",
            "Step: 4647 ------------ Loss: 6477.41 ------------ Accuracy: 70.0%\n",
            "Step: 4648 ------------ Loss: 6477.28 ------------ Accuracy: 70.0%\n",
            "Step: 4649 ------------ Loss: 6477.15 ------------ Accuracy: 70.0%\n",
            "Step: 4650 ------------ Loss: 6477.01 ------------ Accuracy: 70.0%\n",
            "Step: 4651 ------------ Loss: 6476.88 ------------ Accuracy: 70.0%\n",
            "Step: 4652 ------------ Loss: 6476.75 ------------ Accuracy: 70.0%\n",
            "Step: 4653 ------------ Loss: 6476.62 ------------ Accuracy: 70.0%\n",
            "Step: 4654 ------------ Loss: 6476.49 ------------ Accuracy: 70.0%\n",
            "Step: 4655 ------------ Loss: 6476.35 ------------ Accuracy: 70.0%\n",
            "Step: 4656 ------------ Loss: 6476.22 ------------ Accuracy: 70.0%\n",
            "Step: 4657 ------------ Loss: 6476.09 ------------ Accuracy: 70.0%\n",
            "Step: 4658 ------------ Loss: 6475.96 ------------ Accuracy: 70.0%\n",
            "Step: 4659 ------------ Loss: 6475.82 ------------ Accuracy: 70.0%\n",
            "Step: 4660 ------------ Loss: 6475.69 ------------ Accuracy: 70.0%\n",
            "Step: 4661 ------------ Loss: 6475.56 ------------ Accuracy: 70.0%\n",
            "Step: 4662 ------------ Loss: 6475.43 ------------ Accuracy: 70.0%\n",
            "Step: 4663 ------------ Loss: 6475.3 ------------ Accuracy: 70.0%\n",
            "Step: 4664 ------------ Loss: 6475.17 ------------ Accuracy: 70.0%\n",
            "Step: 4665 ------------ Loss: 6475.03 ------------ Accuracy: 70.0%\n",
            "Step: 4666 ------------ Loss: 6474.9 ------------ Accuracy: 70.0%\n",
            "Step: 4667 ------------ Loss: 6474.77 ------------ Accuracy: 70.0%\n",
            "Step: 4668 ------------ Loss: 6474.64 ------------ Accuracy: 70.0%\n",
            "Step: 4669 ------------ Loss: 6474.51 ------------ Accuracy: 70.0%\n",
            "Step: 4670 ------------ Loss: 6474.38 ------------ Accuracy: 70.0%\n",
            "Step: 4671 ------------ Loss: 6474.24 ------------ Accuracy: 70.0%\n",
            "Step: 4672 ------------ Loss: 6474.11 ------------ Accuracy: 70.0%\n",
            "Step: 4673 ------------ Loss: 6473.98 ------------ Accuracy: 70.0%\n",
            "Step: 4674 ------------ Loss: 6473.85 ------------ Accuracy: 70.0%\n",
            "Step: 4675 ------------ Loss: 6473.72 ------------ Accuracy: 70.0%\n",
            "Step: 4676 ------------ Loss: 6473.59 ------------ Accuracy: 70.0%\n",
            "Step: 4677 ------------ Loss: 6473.46 ------------ Accuracy: 70.0%\n",
            "Step: 4678 ------------ Loss: 6473.33 ------------ Accuracy: 70.0%\n",
            "Step: 4679 ------------ Loss: 6473.19 ------------ Accuracy: 70.0%\n",
            "Step: 4680 ------------ Loss: 6473.06 ------------ Accuracy: 70.0%\n",
            "Step: 4681 ------------ Loss: 6472.93 ------------ Accuracy: 70.0%\n",
            "Step: 4682 ------------ Loss: 6472.8 ------------ Accuracy: 70.0%\n",
            "Step: 4683 ------------ Loss: 6472.67 ------------ Accuracy: 70.0%\n",
            "Step: 4684 ------------ Loss: 6472.54 ------------ Accuracy: 70.0%\n",
            "Step: 4685 ------------ Loss: 6472.41 ------------ Accuracy: 70.0%\n",
            "Step: 4686 ------------ Loss: 6472.28 ------------ Accuracy: 70.0%\n",
            "Step: 4687 ------------ Loss: 6472.15 ------------ Accuracy: 70.0%\n",
            "Step: 4688 ------------ Loss: 6472.01 ------------ Accuracy: 70.0%\n",
            "Step: 4689 ------------ Loss: 6471.88 ------------ Accuracy: 70.0%\n",
            "Step: 4690 ------------ Loss: 6471.75 ------------ Accuracy: 70.0%\n",
            "Step: 4691 ------------ Loss: 6471.62 ------------ Accuracy: 70.0%\n",
            "Step: 4692 ------------ Loss: 6471.49 ------------ Accuracy: 70.0%\n",
            "Step: 4693 ------------ Loss: 6471.36 ------------ Accuracy: 70.0%\n",
            "Step: 4694 ------------ Loss: 6471.23 ------------ Accuracy: 70.0%\n",
            "Step: 4695 ------------ Loss: 6471.1 ------------ Accuracy: 70.0%\n",
            "Step: 4696 ------------ Loss: 6470.97 ------------ Accuracy: 70.0%\n",
            "Step: 4697 ------------ Loss: 6470.84 ------------ Accuracy: 70.0%\n",
            "Step: 4698 ------------ Loss: 6470.71 ------------ Accuracy: 70.0%\n",
            "Step: 4699 ------------ Loss: 6470.58 ------------ Accuracy: 70.0%\n",
            "Step: 4700 ------------ Loss: 6470.45 ------------ Accuracy: 70.0%\n",
            "Step: 4701 ------------ Loss: 6470.32 ------------ Accuracy: 70.0%\n",
            "Step: 4702 ------------ Loss: 6470.19 ------------ Accuracy: 70.0%\n",
            "Step: 4703 ------------ Loss: 6470.06 ------------ Accuracy: 70.0%\n",
            "Step: 4704 ------------ Loss: 6469.93 ------------ Accuracy: 70.0%\n",
            "Step: 4705 ------------ Loss: 6469.8 ------------ Accuracy: 70.0%\n",
            "Step: 4706 ------------ Loss: 6469.67 ------------ Accuracy: 70.0%\n",
            "Step: 4707 ------------ Loss: 6469.54 ------------ Accuracy: 70.0%\n",
            "Step: 4708 ------------ Loss: 6469.41 ------------ Accuracy: 70.0%\n",
            "Step: 4709 ------------ Loss: 6469.28 ------------ Accuracy: 70.0%\n",
            "Step: 4710 ------------ Loss: 6469.15 ------------ Accuracy: 70.0%\n",
            "Step: 4711 ------------ Loss: 6469.02 ------------ Accuracy: 70.0%\n",
            "Step: 4712 ------------ Loss: 6468.89 ------------ Accuracy: 70.0%\n",
            "Step: 4713 ------------ Loss: 6468.76 ------------ Accuracy: 70.0%\n",
            "Step: 4714 ------------ Loss: 6468.63 ------------ Accuracy: 70.0%\n",
            "Step: 4715 ------------ Loss: 6468.5 ------------ Accuracy: 70.0%\n",
            "Step: 4716 ------------ Loss: 6468.37 ------------ Accuracy: 70.0%\n",
            "Step: 4717 ------------ Loss: 6468.24 ------------ Accuracy: 70.0%\n",
            "Step: 4718 ------------ Loss: 6468.11 ------------ Accuracy: 70.0%\n",
            "Step: 4719 ------------ Loss: 6467.98 ------------ Accuracy: 70.0%\n",
            "Step: 4720 ------------ Loss: 6467.85 ------------ Accuracy: 70.0%\n",
            "Step: 4721 ------------ Loss: 6467.72 ------------ Accuracy: 70.0%\n",
            "Step: 4722 ------------ Loss: 6467.59 ------------ Accuracy: 70.0%\n",
            "Step: 4723 ------------ Loss: 6467.46 ------------ Accuracy: 70.0%\n",
            "Step: 4724 ------------ Loss: 6467.33 ------------ Accuracy: 70.0%\n",
            "Step: 4725 ------------ Loss: 6467.2 ------------ Accuracy: 70.0%\n",
            "Step: 4726 ------------ Loss: 6467.07 ------------ Accuracy: 70.0%\n",
            "Step: 4727 ------------ Loss: 6466.94 ------------ Accuracy: 70.0%\n",
            "Step: 4728 ------------ Loss: 6466.81 ------------ Accuracy: 70.0%\n",
            "Step: 4729 ------------ Loss: 6466.68 ------------ Accuracy: 70.0%\n",
            "Step: 4730 ------------ Loss: 6466.55 ------------ Accuracy: 70.0%\n",
            "Step: 4731 ------------ Loss: 6466.42 ------------ Accuracy: 70.0%\n",
            "Step: 4732 ------------ Loss: 6466.3 ------------ Accuracy: 70.0%\n",
            "Step: 4733 ------------ Loss: 6466.17 ------------ Accuracy: 70.0%\n",
            "Step: 4734 ------------ Loss: 6466.04 ------------ Accuracy: 70.0%\n",
            "Step: 4735 ------------ Loss: 6465.91 ------------ Accuracy: 70.0%\n",
            "Step: 4736 ------------ Loss: 6465.78 ------------ Accuracy: 70.0%\n",
            "Step: 4737 ------------ Loss: 6465.65 ------------ Accuracy: 70.0%\n",
            "Step: 4738 ------------ Loss: 6465.52 ------------ Accuracy: 70.0%\n",
            "Step: 4739 ------------ Loss: 6465.39 ------------ Accuracy: 70.0%\n",
            "Step: 4740 ------------ Loss: 6465.26 ------------ Accuracy: 70.0%\n",
            "Step: 4741 ------------ Loss: 6465.13 ------------ Accuracy: 70.0%\n",
            "Step: 4742 ------------ Loss: 6465.01 ------------ Accuracy: 70.0%\n",
            "Step: 4743 ------------ Loss: 6464.88 ------------ Accuracy: 70.0%\n",
            "Step: 4744 ------------ Loss: 6464.75 ------------ Accuracy: 70.0%\n",
            "Step: 4745 ------------ Loss: 6464.62 ------------ Accuracy: 70.0%\n",
            "Step: 4746 ------------ Loss: 6464.49 ------------ Accuracy: 70.0%\n",
            "Step: 4747 ------------ Loss: 6464.36 ------------ Accuracy: 70.0%\n",
            "Step: 4748 ------------ Loss: 6464.23 ------------ Accuracy: 70.0%\n",
            "Step: 4749 ------------ Loss: 6464.11 ------------ Accuracy: 70.0%\n",
            "Step: 4750 ------------ Loss: 6463.98 ------------ Accuracy: 70.0%\n",
            "Step: 4751 ------------ Loss: 6463.85 ------------ Accuracy: 70.0%\n",
            "Step: 4752 ------------ Loss: 6463.72 ------------ Accuracy: 70.0%\n",
            "Step: 4753 ------------ Loss: 6463.59 ------------ Accuracy: 70.0%\n",
            "Step: 4754 ------------ Loss: 6463.46 ------------ Accuracy: 70.0%\n",
            "Step: 4755 ------------ Loss: 6463.33 ------------ Accuracy: 70.0%\n",
            "Step: 4756 ------------ Loss: 6463.21 ------------ Accuracy: 70.0%\n",
            "Step: 4757 ------------ Loss: 6463.08 ------------ Accuracy: 70.0%\n",
            "Step: 4758 ------------ Loss: 6462.95 ------------ Accuracy: 70.0%\n",
            "Step: 4759 ------------ Loss: 6462.82 ------------ Accuracy: 70.0%\n",
            "Step: 4760 ------------ Loss: 6462.69 ------------ Accuracy: 70.0%\n",
            "Step: 4761 ------------ Loss: 6462.57 ------------ Accuracy: 70.0%\n",
            "Step: 4762 ------------ Loss: 6462.44 ------------ Accuracy: 70.0%\n",
            "Step: 4763 ------------ Loss: 6462.31 ------------ Accuracy: 70.0%\n",
            "Step: 4764 ------------ Loss: 6462.18 ------------ Accuracy: 70.0%\n",
            "Step: 4765 ------------ Loss: 6462.05 ------------ Accuracy: 70.0%\n",
            "Step: 4766 ------------ Loss: 6461.93 ------------ Accuracy: 70.0%\n",
            "Step: 4767 ------------ Loss: 6461.8 ------------ Accuracy: 70.0%\n",
            "Step: 4768 ------------ Loss: 6461.67 ------------ Accuracy: 70.0%\n",
            "Step: 4769 ------------ Loss: 6461.54 ------------ Accuracy: 70.0%\n",
            "Step: 4770 ------------ Loss: 6461.41 ------------ Accuracy: 70.0%\n",
            "Step: 4771 ------------ Loss: 6461.29 ------------ Accuracy: 70.0%\n",
            "Step: 4772 ------------ Loss: 6461.16 ------------ Accuracy: 70.0%\n",
            "Step: 4773 ------------ Loss: 6461.03 ------------ Accuracy: 70.0%\n",
            "Step: 4774 ------------ Loss: 6460.9 ------------ Accuracy: 70.0%\n",
            "Step: 4775 ------------ Loss: 6460.78 ------------ Accuracy: 70.0%\n",
            "Step: 4776 ------------ Loss: 6460.65 ------------ Accuracy: 70.0%\n",
            "Step: 4777 ------------ Loss: 6460.52 ------------ Accuracy: 70.0%\n",
            "Step: 4778 ------------ Loss: 6460.39 ------------ Accuracy: 70.0%\n",
            "Step: 4779 ------------ Loss: 6460.27 ------------ Accuracy: 70.0%\n",
            "Step: 4780 ------------ Loss: 6460.14 ------------ Accuracy: 70.0%\n",
            "Step: 4781 ------------ Loss: 6460.01 ------------ Accuracy: 70.0%\n",
            "Step: 4782 ------------ Loss: 6459.88 ------------ Accuracy: 70.0%\n",
            "Step: 4783 ------------ Loss: 6459.76 ------------ Accuracy: 70.0%\n",
            "Step: 4784 ------------ Loss: 6459.63 ------------ Accuracy: 70.0%\n",
            "Step: 4785 ------------ Loss: 6459.5 ------------ Accuracy: 70.0%\n",
            "Step: 4786 ------------ Loss: 6459.37 ------------ Accuracy: 70.0%\n",
            "Step: 4787 ------------ Loss: 6459.25 ------------ Accuracy: 70.0%\n",
            "Step: 4788 ------------ Loss: 6459.12 ------------ Accuracy: 70.0%\n",
            "Step: 4789 ------------ Loss: 6458.99 ------------ Accuracy: 70.0%\n",
            "Step: 4790 ------------ Loss: 6458.87 ------------ Accuracy: 70.0%\n",
            "Step: 4791 ------------ Loss: 6458.74 ------------ Accuracy: 70.0%\n",
            "Step: 4792 ------------ Loss: 6458.61 ------------ Accuracy: 70.0%\n",
            "Step: 4793 ------------ Loss: 6458.49 ------------ Accuracy: 70.0%\n",
            "Step: 4794 ------------ Loss: 6458.36 ------------ Accuracy: 70.0%\n",
            "Step: 4795 ------------ Loss: 6458.23 ------------ Accuracy: 70.0%\n",
            "Step: 4796 ------------ Loss: 6458.11 ------------ Accuracy: 70.0%\n",
            "Step: 4797 ------------ Loss: 6457.98 ------------ Accuracy: 70.0%\n",
            "Step: 4798 ------------ Loss: 6457.85 ------------ Accuracy: 70.0%\n",
            "Step: 4799 ------------ Loss: 6457.72 ------------ Accuracy: 70.0%\n",
            "Step: 4800 ------------ Loss: 6457.6 ------------ Accuracy: 70.0%\n",
            "Step: 4801 ------------ Loss: 6457.47 ------------ Accuracy: 70.0%\n",
            "Step: 4802 ------------ Loss: 6457.35 ------------ Accuracy: 70.0%\n",
            "Step: 4803 ------------ Loss: 6457.22 ------------ Accuracy: 70.0%\n",
            "Step: 4804 ------------ Loss: 6457.09 ------------ Accuracy: 70.0%\n",
            "Step: 4805 ------------ Loss: 6456.97 ------------ Accuracy: 70.0%\n",
            "Step: 4806 ------------ Loss: 6456.84 ------------ Accuracy: 70.0%\n",
            "Step: 4807 ------------ Loss: 6456.71 ------------ Accuracy: 70.0%\n",
            "Step: 4808 ------------ Loss: 6456.59 ------------ Accuracy: 70.0%\n",
            "Step: 4809 ------------ Loss: 6456.46 ------------ Accuracy: 70.0%\n",
            "Step: 4810 ------------ Loss: 6456.33 ------------ Accuracy: 70.0%\n",
            "Step: 4811 ------------ Loss: 6456.21 ------------ Accuracy: 70.0%\n",
            "Step: 4812 ------------ Loss: 6456.08 ------------ Accuracy: 70.0%\n",
            "Step: 4813 ------------ Loss: 6455.95 ------------ Accuracy: 70.0%\n",
            "Step: 4814 ------------ Loss: 6455.83 ------------ Accuracy: 70.0%\n",
            "Step: 4815 ------------ Loss: 6455.7 ------------ Accuracy: 70.0%\n",
            "Step: 4816 ------------ Loss: 6455.58 ------------ Accuracy: 70.0%\n",
            "Step: 4817 ------------ Loss: 6455.45 ------------ Accuracy: 70.0%\n",
            "Step: 4818 ------------ Loss: 6455.32 ------------ Accuracy: 70.0%\n",
            "Step: 4819 ------------ Loss: 6455.2 ------------ Accuracy: 70.0%\n",
            "Step: 4820 ------------ Loss: 6455.07 ------------ Accuracy: 70.0%\n",
            "Step: 4821 ------------ Loss: 6454.95 ------------ Accuracy: 70.0%\n",
            "Step: 4822 ------------ Loss: 6454.82 ------------ Accuracy: 70.0%\n",
            "Step: 4823 ------------ Loss: 6454.69 ------------ Accuracy: 70.0%\n",
            "Step: 4824 ------------ Loss: 6454.57 ------------ Accuracy: 70.0%\n",
            "Step: 4825 ------------ Loss: 6454.44 ------------ Accuracy: 70.0%\n",
            "Step: 4826 ------------ Loss: 6454.32 ------------ Accuracy: 70.0%\n",
            "Step: 4827 ------------ Loss: 6454.19 ------------ Accuracy: 70.0%\n",
            "Step: 4828 ------------ Loss: 6454.07 ------------ Accuracy: 70.0%\n",
            "Step: 4829 ------------ Loss: 6453.94 ------------ Accuracy: 70.0%\n",
            "Step: 4830 ------------ Loss: 6453.82 ------------ Accuracy: 70.0%\n",
            "Step: 4831 ------------ Loss: 6453.69 ------------ Accuracy: 70.0%\n",
            "Step: 4832 ------------ Loss: 6453.56 ------------ Accuracy: 70.0%\n",
            "Step: 4833 ------------ Loss: 6453.44 ------------ Accuracy: 70.0%\n",
            "Step: 4834 ------------ Loss: 6453.31 ------------ Accuracy: 70.0%\n",
            "Step: 4835 ------------ Loss: 6453.19 ------------ Accuracy: 70.0%\n",
            "Step: 4836 ------------ Loss: 6453.06 ------------ Accuracy: 70.0%\n",
            "Step: 4837 ------------ Loss: 6452.94 ------------ Accuracy: 70.0%\n",
            "Step: 4838 ------------ Loss: 6452.81 ------------ Accuracy: 70.0%\n",
            "Step: 4839 ------------ Loss: 6452.69 ------------ Accuracy: 70.0%\n",
            "Step: 4840 ------------ Loss: 6452.56 ------------ Accuracy: 70.0%\n",
            "Step: 4841 ------------ Loss: 6452.44 ------------ Accuracy: 70.0%\n",
            "Step: 4842 ------------ Loss: 6452.31 ------------ Accuracy: 70.0%\n",
            "Step: 4843 ------------ Loss: 6452.19 ------------ Accuracy: 70.0%\n",
            "Step: 4844 ------------ Loss: 6452.06 ------------ Accuracy: 70.0%\n",
            "Step: 4845 ------------ Loss: 6451.94 ------------ Accuracy: 70.0%\n",
            "Step: 4846 ------------ Loss: 6451.81 ------------ Accuracy: 70.0%\n",
            "Step: 4847 ------------ Loss: 6451.69 ------------ Accuracy: 70.0%\n",
            "Step: 4848 ------------ Loss: 6451.56 ------------ Accuracy: 70.0%\n",
            "Step: 4849 ------------ Loss: 6451.44 ------------ Accuracy: 70.0%\n",
            "Step: 4850 ------------ Loss: 6451.31 ------------ Accuracy: 70.0%\n",
            "Step: 4851 ------------ Loss: 6451.19 ------------ Accuracy: 70.0%\n",
            "Step: 4852 ------------ Loss: 6451.06 ------------ Accuracy: 70.0%\n",
            "Step: 4853 ------------ Loss: 6450.94 ------------ Accuracy: 70.0%\n",
            "Step: 4854 ------------ Loss: 6450.81 ------------ Accuracy: 70.0%\n",
            "Step: 4855 ------------ Loss: 6450.69 ------------ Accuracy: 70.0%\n",
            "Step: 4856 ------------ Loss: 6450.56 ------------ Accuracy: 70.0%\n",
            "Step: 4857 ------------ Loss: 6450.44 ------------ Accuracy: 70.0%\n",
            "Step: 4858 ------------ Loss: 6450.31 ------------ Accuracy: 70.0%\n",
            "Step: 4859 ------------ Loss: 6450.19 ------------ Accuracy: 70.0%\n",
            "Step: 4860 ------------ Loss: 6450.06 ------------ Accuracy: 70.0%\n",
            "Step: 4861 ------------ Loss: 6449.94 ------------ Accuracy: 70.0%\n",
            "Step: 4862 ------------ Loss: 6449.82 ------------ Accuracy: 70.1%\n",
            "Step: 4863 ------------ Loss: 6449.69 ------------ Accuracy: 70.1%\n",
            "Step: 4864 ------------ Loss: 6449.57 ------------ Accuracy: 70.1%\n",
            "Step: 4865 ------------ Loss: 6449.44 ------------ Accuracy: 70.1%\n",
            "Step: 4866 ------------ Loss: 6449.32 ------------ Accuracy: 70.1%\n",
            "Step: 4867 ------------ Loss: 6449.19 ------------ Accuracy: 70.1%\n",
            "Step: 4868 ------------ Loss: 6449.07 ------------ Accuracy: 70.1%\n",
            "Step: 4869 ------------ Loss: 6448.94 ------------ Accuracy: 70.1%\n",
            "Step: 4870 ------------ Loss: 6448.82 ------------ Accuracy: 70.1%\n",
            "Step: 4871 ------------ Loss: 6448.7 ------------ Accuracy: 70.1%\n",
            "Step: 4872 ------------ Loss: 6448.57 ------------ Accuracy: 70.1%\n",
            "Step: 4873 ------------ Loss: 6448.45 ------------ Accuracy: 70.1%\n",
            "Step: 4874 ------------ Loss: 6448.32 ------------ Accuracy: 70.1%\n",
            "Step: 4875 ------------ Loss: 6448.2 ------------ Accuracy: 70.1%\n",
            "Step: 4876 ------------ Loss: 6448.08 ------------ Accuracy: 70.1%\n",
            "Step: 4877 ------------ Loss: 6447.95 ------------ Accuracy: 70.1%\n",
            "Step: 4878 ------------ Loss: 6447.83 ------------ Accuracy: 70.1%\n",
            "Step: 4879 ------------ Loss: 6447.7 ------------ Accuracy: 70.1%\n",
            "Step: 4880 ------------ Loss: 6447.58 ------------ Accuracy: 70.1%\n",
            "Step: 4881 ------------ Loss: 6447.46 ------------ Accuracy: 70.1%\n",
            "Step: 4882 ------------ Loss: 6447.33 ------------ Accuracy: 70.1%\n",
            "Step: 4883 ------------ Loss: 6447.21 ------------ Accuracy: 70.1%\n",
            "Step: 4884 ------------ Loss: 6447.09 ------------ Accuracy: 70.1%\n",
            "Step: 4885 ------------ Loss: 6446.96 ------------ Accuracy: 70.1%\n",
            "Step: 4886 ------------ Loss: 6446.84 ------------ Accuracy: 70.1%\n",
            "Step: 4887 ------------ Loss: 6446.72 ------------ Accuracy: 70.1%\n",
            "Step: 4888 ------------ Loss: 6446.59 ------------ Accuracy: 70.1%\n",
            "Step: 4889 ------------ Loss: 6446.47 ------------ Accuracy: 70.1%\n",
            "Step: 4890 ------------ Loss: 6446.34 ------------ Accuracy: 70.1%\n",
            "Step: 4891 ------------ Loss: 6446.22 ------------ Accuracy: 70.1%\n",
            "Step: 4892 ------------ Loss: 6446.1 ------------ Accuracy: 70.1%\n",
            "Step: 4893 ------------ Loss: 6445.97 ------------ Accuracy: 70.1%\n",
            "Step: 4894 ------------ Loss: 6445.85 ------------ Accuracy: 70.1%\n",
            "Step: 4895 ------------ Loss: 6445.73 ------------ Accuracy: 70.1%\n",
            "Step: 4896 ------------ Loss: 6445.6 ------------ Accuracy: 70.1%\n",
            "Step: 4897 ------------ Loss: 6445.48 ------------ Accuracy: 70.1%\n",
            "Step: 4898 ------------ Loss: 6445.36 ------------ Accuracy: 70.1%\n",
            "Step: 4899 ------------ Loss: 6445.23 ------------ Accuracy: 70.1%\n",
            "Step: 4900 ------------ Loss: 6445.11 ------------ Accuracy: 70.1%\n",
            "Step: 4901 ------------ Loss: 6444.99 ------------ Accuracy: 70.1%\n",
            "Step: 4902 ------------ Loss: 6444.87 ------------ Accuracy: 70.1%\n",
            "Step: 4903 ------------ Loss: 6444.74 ------------ Accuracy: 70.1%\n",
            "Step: 4904 ------------ Loss: 6444.62 ------------ Accuracy: 70.1%\n",
            "Step: 4905 ------------ Loss: 6444.5 ------------ Accuracy: 70.1%\n",
            "Step: 4906 ------------ Loss: 6444.37 ------------ Accuracy: 70.1%\n",
            "Step: 4907 ------------ Loss: 6444.25 ------------ Accuracy: 70.1%\n",
            "Step: 4908 ------------ Loss: 6444.13 ------------ Accuracy: 70.1%\n",
            "Step: 4909 ------------ Loss: 6444.01 ------------ Accuracy: 70.1%\n",
            "Step: 4910 ------------ Loss: 6443.88 ------------ Accuracy: 70.1%\n",
            "Step: 4911 ------------ Loss: 6443.76 ------------ Accuracy: 70.1%\n",
            "Step: 4912 ------------ Loss: 6443.64 ------------ Accuracy: 70.1%\n",
            "Step: 4913 ------------ Loss: 6443.51 ------------ Accuracy: 70.1%\n",
            "Step: 4914 ------------ Loss: 6443.39 ------------ Accuracy: 70.1%\n",
            "Step: 4915 ------------ Loss: 6443.27 ------------ Accuracy: 70.1%\n",
            "Step: 4916 ------------ Loss: 6443.15 ------------ Accuracy: 70.1%\n",
            "Step: 4917 ------------ Loss: 6443.02 ------------ Accuracy: 70.1%\n",
            "Step: 4918 ------------ Loss: 6442.9 ------------ Accuracy: 70.1%\n",
            "Step: 4919 ------------ Loss: 6442.78 ------------ Accuracy: 70.1%\n",
            "Step: 4920 ------------ Loss: 6442.66 ------------ Accuracy: 70.1%\n",
            "Step: 4921 ------------ Loss: 6442.53 ------------ Accuracy: 70.1%\n",
            "Step: 4922 ------------ Loss: 6442.41 ------------ Accuracy: 70.1%\n",
            "Step: 4923 ------------ Loss: 6442.29 ------------ Accuracy: 70.1%\n",
            "Step: 4924 ------------ Loss: 6442.17 ------------ Accuracy: 70.1%\n",
            "Step: 4925 ------------ Loss: 6442.04 ------------ Accuracy: 70.1%\n",
            "Step: 4926 ------------ Loss: 6441.92 ------------ Accuracy: 70.1%\n",
            "Step: 4927 ------------ Loss: 6441.8 ------------ Accuracy: 70.1%\n",
            "Step: 4928 ------------ Loss: 6441.68 ------------ Accuracy: 70.1%\n",
            "Step: 4929 ------------ Loss: 6441.56 ------------ Accuracy: 70.1%\n",
            "Step: 4930 ------------ Loss: 6441.43 ------------ Accuracy: 70.1%\n",
            "Step: 4931 ------------ Loss: 6441.31 ------------ Accuracy: 70.1%\n",
            "Step: 4932 ------------ Loss: 6441.19 ------------ Accuracy: 70.1%\n",
            "Step: 4933 ------------ Loss: 6441.07 ------------ Accuracy: 70.1%\n",
            "Step: 4934 ------------ Loss: 6440.95 ------------ Accuracy: 70.1%\n",
            "Step: 4935 ------------ Loss: 6440.82 ------------ Accuracy: 70.1%\n",
            "Step: 4936 ------------ Loss: 6440.7 ------------ Accuracy: 70.1%\n",
            "Step: 4937 ------------ Loss: 6440.58 ------------ Accuracy: 70.1%\n",
            "Step: 4938 ------------ Loss: 6440.46 ------------ Accuracy: 70.1%\n",
            "Step: 4939 ------------ Loss: 6440.34 ------------ Accuracy: 70.1%\n",
            "Step: 4940 ------------ Loss: 6440.22 ------------ Accuracy: 70.1%\n",
            "Step: 4941 ------------ Loss: 6440.09 ------------ Accuracy: 70.1%\n",
            "Step: 4942 ------------ Loss: 6439.97 ------------ Accuracy: 70.1%\n",
            "Step: 4943 ------------ Loss: 6439.85 ------------ Accuracy: 70.1%\n",
            "Step: 4944 ------------ Loss: 6439.73 ------------ Accuracy: 70.1%\n",
            "Step: 4945 ------------ Loss: 6439.61 ------------ Accuracy: 70.1%\n",
            "Step: 4946 ------------ Loss: 6439.49 ------------ Accuracy: 70.1%\n",
            "Step: 4947 ------------ Loss: 6439.36 ------------ Accuracy: 70.1%\n",
            "Step: 4948 ------------ Loss: 6439.24 ------------ Accuracy: 70.1%\n",
            "Step: 4949 ------------ Loss: 6439.12 ------------ Accuracy: 70.1%\n",
            "Step: 4950 ------------ Loss: 6439.0 ------------ Accuracy: 70.1%\n",
            "Step: 4951 ------------ Loss: 6438.88 ------------ Accuracy: 70.1%\n",
            "Step: 4952 ------------ Loss: 6438.76 ------------ Accuracy: 70.1%\n",
            "Step: 4953 ------------ Loss: 6438.64 ------------ Accuracy: 70.1%\n",
            "Step: 4954 ------------ Loss: 6438.51 ------------ Accuracy: 70.1%\n",
            "Step: 4955 ------------ Loss: 6438.39 ------------ Accuracy: 70.1%\n",
            "Step: 4956 ------------ Loss: 6438.27 ------------ Accuracy: 70.1%\n",
            "Step: 4957 ------------ Loss: 6438.15 ------------ Accuracy: 70.1%\n",
            "Step: 4958 ------------ Loss: 6438.03 ------------ Accuracy: 70.1%\n",
            "Step: 4959 ------------ Loss: 6437.91 ------------ Accuracy: 70.1%\n",
            "Step: 4960 ------------ Loss: 6437.79 ------------ Accuracy: 70.1%\n",
            "Step: 4961 ------------ Loss: 6437.67 ------------ Accuracy: 70.1%\n",
            "Step: 4962 ------------ Loss: 6437.55 ------------ Accuracy: 70.1%\n",
            "Step: 4963 ------------ Loss: 6437.42 ------------ Accuracy: 70.1%\n",
            "Step: 4964 ------------ Loss: 6437.3 ------------ Accuracy: 70.1%\n",
            "Step: 4965 ------------ Loss: 6437.18 ------------ Accuracy: 70.1%\n",
            "Step: 4966 ------------ Loss: 6437.06 ------------ Accuracy: 70.1%\n",
            "Step: 4967 ------------ Loss: 6436.94 ------------ Accuracy: 70.1%\n",
            "Step: 4968 ------------ Loss: 6436.82 ------------ Accuracy: 70.1%\n",
            "Step: 4969 ------------ Loss: 6436.7 ------------ Accuracy: 70.1%\n",
            "Step: 4970 ------------ Loss: 6436.58 ------------ Accuracy: 70.1%\n",
            "Step: 4971 ------------ Loss: 6436.46 ------------ Accuracy: 70.1%\n",
            "Step: 4972 ------------ Loss: 6436.34 ------------ Accuracy: 70.1%\n",
            "Step: 4973 ------------ Loss: 6436.22 ------------ Accuracy: 70.1%\n",
            "Step: 4974 ------------ Loss: 6436.1 ------------ Accuracy: 70.1%\n",
            "Step: 4975 ------------ Loss: 6435.98 ------------ Accuracy: 70.1%\n",
            "Step: 4976 ------------ Loss: 6435.85 ------------ Accuracy: 70.1%\n",
            "Step: 4977 ------------ Loss: 6435.73 ------------ Accuracy: 70.1%\n",
            "Step: 4978 ------------ Loss: 6435.61 ------------ Accuracy: 70.1%\n",
            "Step: 4979 ------------ Loss: 6435.49 ------------ Accuracy: 70.1%\n",
            "Step: 4980 ------------ Loss: 6435.37 ------------ Accuracy: 70.1%\n",
            "Step: 4981 ------------ Loss: 6435.25 ------------ Accuracy: 70.1%\n",
            "Step: 4982 ------------ Loss: 6435.13 ------------ Accuracy: 70.1%\n",
            "Step: 4983 ------------ Loss: 6435.01 ------------ Accuracy: 70.1%\n",
            "Step: 4984 ------------ Loss: 6434.89 ------------ Accuracy: 70.1%\n",
            "Step: 4985 ------------ Loss: 6434.77 ------------ Accuracy: 70.1%\n",
            "Step: 4986 ------------ Loss: 6434.65 ------------ Accuracy: 70.1%\n",
            "Step: 4987 ------------ Loss: 6434.53 ------------ Accuracy: 70.1%\n",
            "Step: 4988 ------------ Loss: 6434.41 ------------ Accuracy: 70.1%\n",
            "Step: 4989 ------------ Loss: 6434.29 ------------ Accuracy: 70.1%\n",
            "Step: 4990 ------------ Loss: 6434.17 ------------ Accuracy: 70.1%\n",
            "Step: 4991 ------------ Loss: 6434.05 ------------ Accuracy: 70.1%\n",
            "Step: 4992 ------------ Loss: 6433.93 ------------ Accuracy: 70.1%\n",
            "Step: 4993 ------------ Loss: 6433.81 ------------ Accuracy: 70.1%\n",
            "Step: 4994 ------------ Loss: 6433.69 ------------ Accuracy: 70.1%\n",
            "Step: 4995 ------------ Loss: 6433.57 ------------ Accuracy: 70.1%\n",
            "Step: 4996 ------------ Loss: 6433.45 ------------ Accuracy: 70.1%\n",
            "Step: 4997 ------------ Loss: 6433.33 ------------ Accuracy: 70.1%\n",
            "Step: 4998 ------------ Loss: 6433.21 ------------ Accuracy: 70.1%\n",
            "Step: 4999 ------------ Loss: 6433.09 ------------ Accuracy: 70.1%\n",
            "Step: 5000 ------------ Loss: 6432.97 ------------ Accuracy: 70.1%\n",
            "\n",
            " Time taken: 2570.6 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "# fit model\n",
        "model.fit(X_train, Y_train, type=\"GD\", alpha=0.0001, max_iter=5000, threshold=100)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"\\n Time taken: {np.round(end_time - start_time,2)} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UJv8ORqvaxA9",
        "outputId": "ea935627-9eae-449f-ea0a-7459f00dc288"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Produce plots\n",
        "args = [\"Loss\", \"Accuracy\", \"CPU\"]\n",
        "for a in args: model.plot(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eknGZcLgqn2",
        "outputId": "8beaa921-4520-4033-bdb6-a1d4b314fec6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score on test set: 69.04\n"
          ]
        }
      ],
      "source": [
        "# check accuracy on test set\n",
        "print(f\"Accuracy score on test set: {np.round(np.sum(model.predict(X_test) == Y_test) / X_test.shape[0] * 100,2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6v5lyGj3G3r"
      },
      "outputs": [],
      "source": [
        "# save the data for later comparison\n",
        "df_gd = model.backup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MSJ19tHi8kO"
      },
      "source": [
        "## 3) BCGD Randomized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "r_cw0IDvjLdv",
        "collapsed": true,
        "outputId": "cdab4996-8275-4835-dd93-3545901e3785"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Step: 3 ------------ Loss: 13239.67 ------------ Accuracy: 34.9%\n",
            "Step: 4 ------------ Loss: 13236.19 ------------ Accuracy: 35.5%\n",
            "Step: 5 ------------ Loss: 13230.28 ------------ Accuracy: 35.6%\n",
            "Step: 6 ------------ Loss: 13224.71 ------------ Accuracy: 35.4%\n",
            "Step: 7 ------------ Loss: 13036.34 ------------ Accuracy: 34.5%\n",
            "Step: 8 ------------ Loss: 13008.68 ------------ Accuracy: 34.5%\n",
            "Step: 9 ------------ Loss: 12961.85 ------------ Accuracy: 34.5%\n",
            "Step: 10 ------------ Loss: 12960.19 ------------ Accuracy: 34.5%\n",
            "Step: 11 ------------ Loss: 12917.58 ------------ Accuracy: 34.5%\n",
            "Step: 12 ------------ Loss: 12880.39 ------------ Accuracy: 34.5%\n",
            "Step: 13 ------------ Loss: 12817.29 ------------ Accuracy: 34.5%\n",
            "Step: 14 ------------ Loss: 12814.55 ------------ Accuracy: 34.5%\n",
            "Step: 15 ------------ Loss: 12799.07 ------------ Accuracy: 34.5%\n",
            "Step: 16 ------------ Loss: 12783.89 ------------ Accuracy: 34.5%\n",
            "Step: 17 ------------ Loss: 12755.06 ------------ Accuracy: 34.5%\n",
            "Step: 18 ------------ Loss: 12667.6 ------------ Accuracy: 34.5%\n",
            "Step: 19 ------------ Loss: 12666.71 ------------ Accuracy: 34.5%\n",
            "Step: 20 ------------ Loss: 12642.78 ------------ Accuracy: 34.5%\n",
            "Step: 21 ------------ Loss: 12592.09 ------------ Accuracy: 34.5%\n",
            "Step: 22 ------------ Loss: 12590.75 ------------ Accuracy: 34.5%\n",
            "Step: 23 ------------ Loss: 12583.17 ------------ Accuracy: 34.5%\n",
            "Step: 24 ------------ Loss: 12579.11 ------------ Accuracy: 34.5%\n",
            "Step: 25 ------------ Loss: 12577.81 ------------ Accuracy: 34.5%\n",
            "Step: 26 ------------ Loss: 12566.69 ------------ Accuracy: 34.5%\n",
            "Step: 27 ------------ Loss: 12549.13 ------------ Accuracy: 34.5%\n",
            "Step: 28 ------------ Loss: 12541.87 ------------ Accuracy: 34.5%\n",
            "Step: 29 ------------ Loss: 12468.1 ------------ Accuracy: 34.5%\n",
            "Step: 30 ------------ Loss: 12401.24 ------------ Accuracy: 34.5%\n",
            "Step: 31 ------------ Loss: 12390.59 ------------ Accuracy: 34.5%\n",
            "Step: 32 ------------ Loss: 12387.36 ------------ Accuracy: 34.5%\n",
            "Step: 33 ------------ Loss: 12353.52 ------------ Accuracy: 34.5%\n",
            "Step: 34 ------------ Loss: 12314.71 ------------ Accuracy: 34.5%\n",
            "Step: 35 ------------ Loss: 12291.53 ------------ Accuracy: 34.5%\n",
            "Step: 36 ------------ Loss: 12282.71 ------------ Accuracy: 34.5%\n",
            "Step: 37 ------------ Loss: 12278.7 ------------ Accuracy: 34.5%\n",
            "Step: 38 ------------ Loss: 12247.26 ------------ Accuracy: 34.6%\n",
            "Step: 39 ------------ Loss: 12246.27 ------------ Accuracy: 34.6%\n",
            "Step: 40 ------------ Loss: 12217.52 ------------ Accuracy: 35.8%\n",
            "Step: 41 ------------ Loss: 12200.48 ------------ Accuracy: 37.8%\n",
            "Step: 42 ------------ Loss: 12196.43 ------------ Accuracy: 37.7%\n",
            "Step: 43 ------------ Loss: 12193.12 ------------ Accuracy: 37.8%\n",
            "Step: 44 ------------ Loss: 12191.8 ------------ Accuracy: 37.8%\n",
            "Step: 45 ------------ Loss: 12190.79 ------------ Accuracy: 37.8%\n",
            "Step: 46 ------------ Loss: 12188.29 ------------ Accuracy: 37.8%\n",
            "Step: 47 ------------ Loss: 12184.89 ------------ Accuracy: 37.8%\n",
            "Step: 48 ------------ Loss: 12180.64 ------------ Accuracy: 37.8%\n",
            "Step: 49 ------------ Loss: 12164.01 ------------ Accuracy: 35.8%\n",
            "Step: 50 ------------ Loss: 12160.6 ------------ Accuracy: 35.8%\n",
            "Step: 51 ------------ Loss: 12154.18 ------------ Accuracy: 36.0%\n",
            "Step: 52 ------------ Loss: 12153.25 ------------ Accuracy: 36.0%\n",
            "Step: 53 ------------ Loss: 12151.6 ------------ Accuracy: 36.0%\n",
            "Step: 54 ------------ Loss: 12149.32 ------------ Accuracy: 36.0%\n",
            "Step: 55 ------------ Loss: 12140.12 ------------ Accuracy: 36.0%\n",
            "Step: 56 ------------ Loss: 12137.66 ------------ Accuracy: 36.0%\n",
            "Step: 57 ------------ Loss: 12134.4 ------------ Accuracy: 36.0%\n",
            "Step: 58 ------------ Loss: 12133.18 ------------ Accuracy: 36.0%\n",
            "Step: 59 ------------ Loss: 12131.66 ------------ Accuracy: 36.7%\n",
            "Step: 60 ------------ Loss: 12121.41 ------------ Accuracy: 35.2%\n",
            "Step: 61 ------------ Loss: 12071.96 ------------ Accuracy: 35.2%\n",
            "Step: 62 ------------ Loss: 12069.48 ------------ Accuracy: 35.2%\n",
            "Step: 63 ------------ Loss: 12054.96 ------------ Accuracy: 37.8%\n",
            "Step: 64 ------------ Loss: 12053.95 ------------ Accuracy: 37.8%\n",
            "Step: 65 ------------ Loss: 12052.01 ------------ Accuracy: 37.8%\n",
            "Step: 66 ------------ Loss: 12050.02 ------------ Accuracy: 38.8%\n",
            "Step: 67 ------------ Loss: 12048.31 ------------ Accuracy: 39.1%\n",
            "Step: 68 ------------ Loss: 12040.01 ------------ Accuracy: 39.0%\n",
            "Step: 69 ------------ Loss: 12038.22 ------------ Accuracy: 39.5%\n",
            "Step: 70 ------------ Loss: 12037.77 ------------ Accuracy: 39.5%\n",
            "Step: 71 ------------ Loss: 12035.89 ------------ Accuracy: 39.6%\n",
            "Step: 72 ------------ Loss: 12029.58 ------------ Accuracy: 38.5%\n",
            "Step: 73 ------------ Loss: 12016.56 ------------ Accuracy: 40.7%\n",
            "Step: 74 ------------ Loss: 12013.53 ------------ Accuracy: 40.7%\n",
            "Step: 75 ------------ Loss: 12012.93 ------------ Accuracy: 40.9%\n",
            "Step: 76 ------------ Loss: 12011.63 ------------ Accuracy: 40.9%\n",
            "Step: 77 ------------ Loss: 12009.75 ------------ Accuracy: 40.9%\n",
            "Step: 78 ------------ Loss: 12008.46 ------------ Accuracy: 40.9%\n",
            "Step: 79 ------------ Loss: 12007.19 ------------ Accuracy: 41.1%\n",
            "Step: 80 ------------ Loss: 12005.52 ------------ Accuracy: 41.4%\n",
            "Step: 81 ------------ Loss: 12005.23 ------------ Accuracy: 41.4%\n",
            "Step: 82 ------------ Loss: 12004.83 ------------ Accuracy: 41.7%\n",
            "Step: 83 ------------ Loss: 12003.68 ------------ Accuracy: 41.7%\n",
            "Step: 84 ------------ Loss: 12002.24 ------------ Accuracy: 41.9%\n",
            "Step: 85 ------------ Loss: 12001.42 ------------ Accuracy: 41.9%\n",
            "Step: 86 ------------ Loss: 12000.54 ------------ Accuracy: 41.9%\n",
            "Step: 87 ------------ Loss: 11989.87 ------------ Accuracy: 42.6%\n",
            "Step: 88 ------------ Loss: 11989.1 ------------ Accuracy: 42.8%\n",
            "Step: 89 ------------ Loss: 11988.81 ------------ Accuracy: 42.8%\n",
            "Step: 90 ------------ Loss: 11988.02 ------------ Accuracy: 42.8%\n",
            "Step: 91 ------------ Loss: 11987.73 ------------ Accuracy: 42.8%\n",
            "Step: 92 ------------ Loss: 11986.88 ------------ Accuracy: 42.8%\n",
            "Step: 93 ------------ Loss: 11986.71 ------------ Accuracy: 42.8%\n",
            "Step: 94 ------------ Loss: 11985.26 ------------ Accuracy: 42.9%\n",
            "Step: 95 ------------ Loss: 11971.26 ------------ Accuracy: 43.4%\n",
            "Step: 96 ------------ Loss: 11970.71 ------------ Accuracy: 43.1%\n",
            "Step: 97 ------------ Loss: 11970.07 ------------ Accuracy: 43.3%\n",
            "Step: 98 ------------ Loss: 11961.46 ------------ Accuracy: 43.6%\n",
            "Step: 99 ------------ Loss: 11952.41 ------------ Accuracy: 43.6%\n",
            "Step: 100 ------------ Loss: 11951.99 ------------ Accuracy: 43.6%\n",
            "Step: 101 ------------ Loss: 11951.6 ------------ Accuracy: 43.6%\n",
            "Step: 102 ------------ Loss: 11948.28 ------------ Accuracy: 43.6%\n",
            "Step: 103 ------------ Loss: 11947.85 ------------ Accuracy: 43.6%\n",
            "Step: 104 ------------ Loss: 11947.0 ------------ Accuracy: 43.6%\n",
            "Step: 105 ------------ Loss: 11946.59 ------------ Accuracy: 43.6%\n",
            "Step: 106 ------------ Loss: 11944.24 ------------ Accuracy: 44.8%\n",
            "Step: 107 ------------ Loss: 11942.88 ------------ Accuracy: 44.8%\n",
            "Step: 108 ------------ Loss: 11942.42 ------------ Accuracy: 44.8%\n",
            "Step: 109 ------------ Loss: 11930.86 ------------ Accuracy: 45.8%\n",
            "Step: 110 ------------ Loss: 11929.99 ------------ Accuracy: 45.8%\n",
            "Step: 111 ------------ Loss: 11928.78 ------------ Accuracy: 46.0%\n",
            "Step: 112 ------------ Loss: 11926.84 ------------ Accuracy: 46.0%\n",
            "Step: 113 ------------ Loss: 11923.43 ------------ Accuracy: 46.0%\n",
            "Step: 114 ------------ Loss: 11922.57 ------------ Accuracy: 46.0%\n",
            "Step: 115 ------------ Loss: 11922.27 ------------ Accuracy: 46.0%\n",
            "Step: 116 ------------ Loss: 11911.57 ------------ Accuracy: 46.9%\n",
            "Step: 117 ------------ Loss: 11911.22 ------------ Accuracy: 46.9%\n",
            "Step: 118 ------------ Loss: 11910.74 ------------ Accuracy: 46.9%\n",
            "Step: 119 ------------ Loss: 11910.42 ------------ Accuracy: 46.9%\n",
            "Step: 120 ------------ Loss: 11899.61 ------------ Accuracy: 44.5%\n",
            "Step: 121 ------------ Loss: 11899.28 ------------ Accuracy: 44.5%\n",
            "Step: 122 ------------ Loss: 11896.82 ------------ Accuracy: 45.1%\n",
            "Step: 123 ------------ Loss: 11894.82 ------------ Accuracy: 45.1%\n",
            "Step: 124 ------------ Loss: 11894.55 ------------ Accuracy: 45.1%\n",
            "Step: 125 ------------ Loss: 11892.57 ------------ Accuracy: 44.9%\n",
            "Step: 126 ------------ Loss: 11891.86 ------------ Accuracy: 44.8%\n",
            "Step: 127 ------------ Loss: 11891.31 ------------ Accuracy: 44.6%\n",
            "Step: 128 ------------ Loss: 11890.88 ------------ Accuracy: 44.6%\n",
            "Step: 129 ------------ Loss: 11890.54 ------------ Accuracy: 44.6%\n",
            "Step: 130 ------------ Loss: 11890.11 ------------ Accuracy: 44.6%\n",
            "Step: 131 ------------ Loss: 11889.83 ------------ Accuracy: 44.6%\n",
            "Step: 132 ------------ Loss: 11889.55 ------------ Accuracy: 44.6%\n",
            "Step: 133 ------------ Loss: 11889.23 ------------ Accuracy: 44.6%\n",
            "Step: 134 ------------ Loss: 11887.91 ------------ Accuracy: 44.6%\n",
            "Step: 135 ------------ Loss: 11887.49 ------------ Accuracy: 44.6%\n",
            "Step: 136 ------------ Loss: 11887.06 ------------ Accuracy: 44.6%\n",
            "Step: 137 ------------ Loss: 11886.78 ------------ Accuracy: 44.6%\n",
            "Step: 138 ------------ Loss: 11885.62 ------------ Accuracy: 44.9%\n",
            "Step: 139 ------------ Loss: 11836.54 ------------ Accuracy: 44.8%\n",
            "Step: 140 ------------ Loss: 11836.05 ------------ Accuracy: 44.8%\n",
            "Step: 141 ------------ Loss: 11835.42 ------------ Accuracy: 45.0%\n",
            "Step: 142 ------------ Loss: 11790.45 ------------ Accuracy: 44.8%\n",
            "Step: 143 ------------ Loss: 11789.56 ------------ Accuracy: 45.3%\n",
            "Step: 144 ------------ Loss: 11786.37 ------------ Accuracy: 46.0%\n",
            "Step: 145 ------------ Loss: 11785.79 ------------ Accuracy: 46.4%\n",
            "Step: 146 ------------ Loss: 11785.6 ------------ Accuracy: 46.4%\n",
            "Step: 147 ------------ Loss: 11742.88 ------------ Accuracy: 45.9%\n",
            "Step: 148 ------------ Loss: 11741.97 ------------ Accuracy: 46.9%\n",
            "Step: 149 ------------ Loss: 11741.09 ------------ Accuracy: 47.0%\n",
            "Step: 150 ------------ Loss: 11737.11 ------------ Accuracy: 47.0%\n",
            "Step: 151 ------------ Loss: 11733.17 ------------ Accuracy: 47.0%\n",
            "Step: 152 ------------ Loss: 11724.26 ------------ Accuracy: 48.4%\n",
            "Step: 153 ------------ Loss: 11723.93 ------------ Accuracy: 48.4%\n",
            "Step: 154 ------------ Loss: 11722.59 ------------ Accuracy: 48.4%\n",
            "Step: 155 ------------ Loss: 11721.86 ------------ Accuracy: 48.4%\n",
            "Step: 156 ------------ Loss: 11717.58 ------------ Accuracy: 46.7%\n",
            "Step: 157 ------------ Loss: 11714.96 ------------ Accuracy: 46.7%\n",
            "Step: 158 ------------ Loss: 11713.77 ------------ Accuracy: 46.7%\n",
            "Step: 159 ------------ Loss: 11713.01 ------------ Accuracy: 47.0%\n",
            "Step: 160 ------------ Loss: 11712.69 ------------ Accuracy: 47.0%\n",
            "Step: 161 ------------ Loss: 11709.36 ------------ Accuracy: 48.4%\n",
            "Step: 162 ------------ Loss: 11707.73 ------------ Accuracy: 48.4%\n",
            "Step: 163 ------------ Loss: 11707.16 ------------ Accuracy: 48.4%\n",
            "Step: 164 ------------ Loss: 11704.6 ------------ Accuracy: 49.3%\n",
            "Step: 165 ------------ Loss: 11703.93 ------------ Accuracy: 49.3%\n",
            "Step: 166 ------------ Loss: 11702.39 ------------ Accuracy: 49.3%\n",
            "Step: 167 ------------ Loss: 11694.51 ------------ Accuracy: 49.6%\n",
            "Step: 168 ------------ Loss: 11694.01 ------------ Accuracy: 49.6%\n",
            "Step: 169 ------------ Loss: 11689.93 ------------ Accuracy: 49.6%\n",
            "Step: 170 ------------ Loss: 11689.46 ------------ Accuracy: 49.6%\n",
            "Step: 171 ------------ Loss: 11678.51 ------------ Accuracy: 50.8%\n",
            "Step: 172 ------------ Loss: 11675.69 ------------ Accuracy: 50.8%\n",
            "Step: 173 ------------ Loss: 11675.5 ------------ Accuracy: 50.6%\n",
            "Step: 174 ------------ Loss: 11675.13 ------------ Accuracy: 50.6%\n",
            "Step: 175 ------------ Loss: 11632.6 ------------ Accuracy: 49.9%\n",
            "Step: 176 ------------ Loss: 11631.98 ------------ Accuracy: 49.9%\n",
            "Step: 177 ------------ Loss: 11625.13 ------------ Accuracy: 49.8%\n",
            "Step: 178 ------------ Loss: 11624.66 ------------ Accuracy: 49.8%\n",
            "Step: 179 ------------ Loss: 11623.28 ------------ Accuracy: 49.8%\n",
            "Step: 180 ------------ Loss: 11622.69 ------------ Accuracy: 50.6%\n",
            "Step: 181 ------------ Loss: 11620.19 ------------ Accuracy: 50.9%\n",
            "Step: 182 ------------ Loss: 11619.69 ------------ Accuracy: 51.1%\n",
            "Step: 183 ------------ Loss: 11619.47 ------------ Accuracy: 51.1%\n",
            "Step: 184 ------------ Loss: 11619.08 ------------ Accuracy: 51.1%\n",
            "Step: 185 ------------ Loss: 11612.04 ------------ Accuracy: 51.2%\n",
            "Step: 186 ------------ Loss: 11611.84 ------------ Accuracy: 51.2%\n",
            "Step: 187 ------------ Loss: 11611.52 ------------ Accuracy: 51.2%\n",
            "Step: 188 ------------ Loss: 11610.38 ------------ Accuracy: 51.2%\n",
            "Step: 189 ------------ Loss: 11600.3 ------------ Accuracy: 51.8%\n",
            "Step: 190 ------------ Loss: 11599.94 ------------ Accuracy: 51.8%\n",
            "Step: 191 ------------ Loss: 11592.65 ------------ Accuracy: 51.8%\n",
            "Step: 192 ------------ Loss: 11588.75 ------------ Accuracy: 51.8%\n",
            "Step: 193 ------------ Loss: 11588.45 ------------ Accuracy: 51.8%\n",
            "Step: 194 ------------ Loss: 11582.36 ------------ Accuracy: 52.0%\n",
            "Step: 195 ------------ Loss: 11541.22 ------------ Accuracy: 51.8%\n",
            "Step: 196 ------------ Loss: 11541.0 ------------ Accuracy: 51.8%\n",
            "Step: 197 ------------ Loss: 11540.42 ------------ Accuracy: 51.8%\n",
            "Step: 198 ------------ Loss: 11539.98 ------------ Accuracy: 51.8%\n",
            "Step: 199 ------------ Loss: 11502.42 ------------ Accuracy: 51.5%\n",
            "Step: 200 ------------ Loss: 11499.52 ------------ Accuracy: 50.8%\n",
            "Step: 201 ------------ Loss: 11497.41 ------------ Accuracy: 49.9%\n",
            "Step: 202 ------------ Loss: 11494.82 ------------ Accuracy: 50.5%\n",
            "Step: 203 ------------ Loss: 11483.38 ------------ Accuracy: 51.0%\n",
            "Step: 204 ------------ Loss: 11482.96 ------------ Accuracy: 51.2%\n",
            "Step: 205 ------------ Loss: 11482.27 ------------ Accuracy: 51.1%\n",
            "Step: 206 ------------ Loss: 11481.63 ------------ Accuracy: 51.4%\n",
            "Step: 207 ------------ Loss: 11481.16 ------------ Accuracy: 51.3%\n",
            "Step: 208 ------------ Loss: 11479.41 ------------ Accuracy: 51.4%\n",
            "Step: 209 ------------ Loss: 11478.9 ------------ Accuracy: 51.6%\n",
            "Step: 210 ------------ Loss: 11478.68 ------------ Accuracy: 51.6%\n",
            "Step: 211 ------------ Loss: 11477.19 ------------ Accuracy: 51.9%\n",
            "Step: 212 ------------ Loss: 11442.04 ------------ Accuracy: 51.8%\n",
            "Step: 213 ------------ Loss: 11409.95 ------------ Accuracy: 51.6%\n",
            "Step: 214 ------------ Loss: 11407.85 ------------ Accuracy: 52.0%\n",
            "Step: 215 ------------ Loss: 11407.64 ------------ Accuracy: 52.0%\n",
            "Step: 216 ------------ Loss: 11406.83 ------------ Accuracy: 52.0%\n",
            "Step: 217 ------------ Loss: 11406.09 ------------ Accuracy: 52.0%\n",
            "Step: 218 ------------ Loss: 11405.88 ------------ Accuracy: 52.0%\n",
            "Step: 219 ------------ Loss: 11375.43 ------------ Accuracy: 51.7%\n",
            "Step: 220 ------------ Loss: 11374.3 ------------ Accuracy: 52.1%\n",
            "Step: 221 ------------ Loss: 11373.21 ------------ Accuracy: 52.0%\n",
            "Step: 222 ------------ Loss: 11373.01 ------------ Accuracy: 52.0%\n",
            "Step: 223 ------------ Loss: 11372.55 ------------ Accuracy: 52.0%\n",
            "Step: 224 ------------ Loss: 11371.5 ------------ Accuracy: 52.0%\n",
            "Step: 225 ------------ Loss: 11360.12 ------------ Accuracy: 51.9%\n",
            "Step: 226 ------------ Loss: 11358.3 ------------ Accuracy: 52.1%\n",
            "Step: 227 ------------ Loss: 11356.74 ------------ Accuracy: 52.2%\n",
            "Step: 228 ------------ Loss: 11356.07 ------------ Accuracy: 52.6%\n",
            "Step: 229 ------------ Loss: 11355.77 ------------ Accuracy: 52.6%\n",
            "Step: 230 ------------ Loss: 11354.98 ------------ Accuracy: 52.8%\n",
            "Step: 231 ------------ Loss: 11354.76 ------------ Accuracy: 52.8%\n",
            "Step: 232 ------------ Loss: 11344.82 ------------ Accuracy: 53.0%\n",
            "Step: 233 ------------ Loss: 11343.78 ------------ Accuracy: 53.0%\n",
            "Step: 234 ------------ Loss: 11341.37 ------------ Accuracy: 53.2%\n",
            "Step: 235 ------------ Loss: 11308.97 ------------ Accuracy: 53.0%\n",
            "Step: 236 ------------ Loss: 11308.36 ------------ Accuracy: 53.1%\n",
            "Step: 237 ------------ Loss: 11305.45 ------------ Accuracy: 53.1%\n",
            "Step: 238 ------------ Loss: 11305.16 ------------ Accuracy: 53.1%\n",
            "Step: 239 ------------ Loss: 11304.61 ------------ Accuracy: 53.1%\n",
            "Step: 240 ------------ Loss: 11304.1 ------------ Accuracy: 53.1%\n",
            "Step: 241 ------------ Loss: 11301.18 ------------ Accuracy: 53.1%\n",
            "Step: 242 ------------ Loss: 11299.98 ------------ Accuracy: 53.3%\n",
            "Step: 243 ------------ Loss: 11294.5 ------------ Accuracy: 53.3%\n",
            "Step: 244 ------------ Loss: 11293.54 ------------ Accuracy: 53.3%\n",
            "Step: 245 ------------ Loss: 11291.03 ------------ Accuracy: 53.5%\n",
            "Step: 246 ------------ Loss: 11290.82 ------------ Accuracy: 53.5%\n",
            "Step: 247 ------------ Loss: 11287.92 ------------ Accuracy: 53.5%\n",
            "Step: 248 ------------ Loss: 11284.96 ------------ Accuracy: 52.9%\n",
            "Step: 249 ------------ Loss: 11283.71 ------------ Accuracy: 53.2%\n",
            "Step: 250 ------------ Loss: 11283.51 ------------ Accuracy: 53.2%\n",
            "Step: 251 ------------ Loss: 11282.88 ------------ Accuracy: 53.3%\n",
            "Step: 252 ------------ Loss: 11282.34 ------------ Accuracy: 53.3%\n",
            "Step: 253 ------------ Loss: 11281.9 ------------ Accuracy: 53.3%\n",
            "Step: 254 ------------ Loss: 11281.49 ------------ Accuracy: 53.3%\n",
            "Step: 255 ------------ Loss: 11281.28 ------------ Accuracy: 53.3%\n",
            "Step: 256 ------------ Loss: 11280.26 ------------ Accuracy: 53.3%\n",
            "Step: 257 ------------ Loss: 11279.77 ------------ Accuracy: 53.5%\n",
            "Step: 258 ------------ Loss: 11279.32 ------------ Accuracy: 53.5%\n",
            "Step: 259 ------------ Loss: 11277.25 ------------ Accuracy: 53.5%\n",
            "Step: 260 ------------ Loss: 11277.04 ------------ Accuracy: 53.5%\n",
            "Step: 261 ------------ Loss: 11276.56 ------------ Accuracy: 53.5%\n",
            "Step: 262 ------------ Loss: 11276.37 ------------ Accuracy: 53.5%\n",
            "Step: 263 ------------ Loss: 11270.35 ------------ Accuracy: 53.4%\n",
            "Step: 264 ------------ Loss: 11270.16 ------------ Accuracy: 53.4%\n",
            "Step: 265 ------------ Loss: 11269.85 ------------ Accuracy: 53.4%\n",
            "Step: 266 ------------ Loss: 11238.96 ------------ Accuracy: 53.5%\n",
            "Step: 267 ------------ Loss: 11238.07 ------------ Accuracy: 53.3%\n",
            "Step: 268 ------------ Loss: 11237.07 ------------ Accuracy: 53.3%\n",
            "Step: 269 ------------ Loss: 11236.68 ------------ Accuracy: 53.5%\n",
            "Step: 270 ------------ Loss: 11227.09 ------------ Accuracy: 53.6%\n",
            "Step: 271 ------------ Loss: 11221.56 ------------ Accuracy: 53.6%\n",
            "Step: 272 ------------ Loss: 11221.22 ------------ Accuracy: 53.6%\n",
            "Step: 273 ------------ Loss: 11220.94 ------------ Accuracy: 53.6%\n",
            "Step: 274 ------------ Loss: 11217.74 ------------ Accuracy: 53.3%\n",
            "Step: 275 ------------ Loss: 11217.43 ------------ Accuracy: 53.3%\n",
            "Step: 276 ------------ Loss: 11208.78 ------------ Accuracy: 53.2%\n",
            "Step: 277 ------------ Loss: 11208.59 ------------ Accuracy: 53.2%\n",
            "Step: 278 ------------ Loss: 11206.05 ------------ Accuracy: 53.6%\n",
            "Step: 279 ------------ Loss: 11205.85 ------------ Accuracy: 53.6%\n",
            "Step: 280 ------------ Loss: 11203.76 ------------ Accuracy: 53.6%\n",
            "Step: 281 ------------ Loss: 11203.55 ------------ Accuracy: 53.6%\n",
            "Step: 282 ------------ Loss: 11201.97 ------------ Accuracy: 53.7%\n",
            "Step: 283 ------------ Loss: 11197.09 ------------ Accuracy: 53.4%\n",
            "Step: 284 ------------ Loss: 11192.58 ------------ Accuracy: 53.5%\n",
            "Step: 285 ------------ Loss: 11190.77 ------------ Accuracy: 53.5%\n",
            "Step: 286 ------------ Loss: 11190.43 ------------ Accuracy: 53.5%\n",
            "Step: 287 ------------ Loss: 11190.12 ------------ Accuracy: 53.5%\n",
            "Step: 288 ------------ Loss: 11189.15 ------------ Accuracy: 53.5%\n",
            "Step: 289 ------------ Loss: 11186.27 ------------ Accuracy: 53.5%\n",
            "Step: 290 ------------ Loss: 11186.07 ------------ Accuracy: 53.5%\n",
            "Step: 291 ------------ Loss: 11185.06 ------------ Accuracy: 53.5%\n",
            "Step: 292 ------------ Loss: 11184.8 ------------ Accuracy: 53.6%\n",
            "Step: 293 ------------ Loss: 11183.58 ------------ Accuracy: 53.5%\n",
            "Step: 294 ------------ Loss: 11183.4 ------------ Accuracy: 53.5%\n",
            "Step: 295 ------------ Loss: 11183.22 ------------ Accuracy: 53.5%\n",
            "Step: 296 ------------ Loss: 11183.02 ------------ Accuracy: 53.5%\n",
            "Step: 297 ------------ Loss: 11182.08 ------------ Accuracy: 53.5%\n",
            "Step: 298 ------------ Loss: 11179.25 ------------ Accuracy: 53.6%\n",
            "Step: 299 ------------ Loss: 11179.07 ------------ Accuracy: 53.6%\n",
            "Step: 300 ------------ Loss: 11178.84 ------------ Accuracy: 53.6%\n",
            "Step: 301 ------------ Loss: 11178.62 ------------ Accuracy: 53.6%\n",
            "Step: 302 ------------ Loss: 11178.19 ------------ Accuracy: 53.6%\n",
            "Step: 303 ------------ Loss: 11177.94 ------------ Accuracy: 53.6%\n",
            "Step: 304 ------------ Loss: 11177.02 ------------ Accuracy: 53.6%\n",
            "Step: 305 ------------ Loss: 11176.7 ------------ Accuracy: 53.6%\n",
            "Step: 306 ------------ Loss: 11175.7 ------------ Accuracy: 53.5%\n",
            "Step: 307 ------------ Loss: 11175.41 ------------ Accuracy: 53.5%\n",
            "Step: 308 ------------ Loss: 11174.49 ------------ Accuracy: 53.6%\n",
            "Step: 309 ------------ Loss: 11174.32 ------------ Accuracy: 53.6%\n",
            "Step: 310 ------------ Loss: 11174.12 ------------ Accuracy: 53.6%\n",
            "Step: 311 ------------ Loss: 11172.12 ------------ Accuracy: 53.6%\n",
            "Step: 312 ------------ Loss: 11171.84 ------------ Accuracy: 53.6%\n",
            "Step: 313 ------------ Loss: 11171.68 ------------ Accuracy: 53.6%\n",
            "Step: 314 ------------ Loss: 11171.26 ------------ Accuracy: 53.6%\n",
            "Step: 315 ------------ Loss: 11165.91 ------------ Accuracy: 53.6%\n",
            "Step: 316 ------------ Loss: 11157.7 ------------ Accuracy: 53.5%\n",
            "Step: 317 ------------ Loss: 11157.28 ------------ Accuracy: 53.5%\n",
            "Step: 318 ------------ Loss: 11157.09 ------------ Accuracy: 53.5%\n",
            "Step: 319 ------------ Loss: 11156.85 ------------ Accuracy: 53.5%\n",
            "Step: 320 ------------ Loss: 11155.8 ------------ Accuracy: 53.5%\n",
            "Step: 321 ------------ Loss: 11155.55 ------------ Accuracy: 53.5%\n",
            "Step: 322 ------------ Loss: 11152.78 ------------ Accuracy: 53.5%\n",
            "Step: 323 ------------ Loss: 11152.61 ------------ Accuracy: 53.6%\n",
            "Step: 324 ------------ Loss: 11148.69 ------------ Accuracy: 53.5%\n",
            "Step: 325 ------------ Loss: 11147.85 ------------ Accuracy: 53.5%\n",
            "Step: 326 ------------ Loss: 11119.34 ------------ Accuracy: 53.2%\n",
            "Step: 327 ------------ Loss: 11119.16 ------------ Accuracy: 53.2%\n",
            "Step: 328 ------------ Loss: 11117.69 ------------ Accuracy: 53.4%\n",
            "Step: 329 ------------ Loss: 11116.87 ------------ Accuracy: 53.4%\n",
            "Step: 330 ------------ Loss: 11108.14 ------------ Accuracy: 53.8%\n",
            "Step: 331 ------------ Loss: 11107.97 ------------ Accuracy: 53.8%\n",
            "Step: 332 ------------ Loss: 11107.13 ------------ Accuracy: 53.8%\n",
            "Step: 333 ------------ Loss: 11106.75 ------------ Accuracy: 53.8%\n",
            "Step: 334 ------------ Loss: 11079.7 ------------ Accuracy: 53.2%\n",
            "Step: 335 ------------ Loss: 11079.32 ------------ Accuracy: 53.6%\n",
            "Step: 336 ------------ Loss: 11078.97 ------------ Accuracy: 53.7%\n",
            "Step: 337 ------------ Loss: 11077.98 ------------ Accuracy: 53.6%\n",
            "Step: 338 ------------ Loss: 11077.38 ------------ Accuracy: 53.7%\n",
            "Step: 339 ------------ Loss: 11072.67 ------------ Accuracy: 53.8%\n",
            "Step: 340 ------------ Loss: 11070.4 ------------ Accuracy: 53.7%\n",
            "Step: 341 ------------ Loss: 11069.03 ------------ Accuracy: 53.6%\n",
            "Step: 342 ------------ Loss: 11068.26 ------------ Accuracy: 53.6%\n",
            "Step: 343 ------------ Loss: 11067.55 ------------ Accuracy: 53.6%\n",
            "Step: 344 ------------ Loss: 11062.27 ------------ Accuracy: 53.7%\n",
            "Step: 345 ------------ Loss: 11061.97 ------------ Accuracy: 53.6%\n",
            "Step: 346 ------------ Loss: 11059.82 ------------ Accuracy: 53.4%\n",
            "Step: 347 ------------ Loss: 11059.49 ------------ Accuracy: 53.5%\n",
            "Step: 348 ------------ Loss: 11058.18 ------------ Accuracy: 53.8%\n",
            "Step: 349 ------------ Loss: 11053.68 ------------ Accuracy: 53.6%\n",
            "Step: 350 ------------ Loss: 11053.35 ------------ Accuracy: 53.6%\n",
            "Step: 351 ------------ Loss: 11028.27 ------------ Accuracy: 53.6%\n",
            "Step: 352 ------------ Loss: 11028.12 ------------ Accuracy: 53.6%\n",
            "Step: 353 ------------ Loss: 11005.03 ------------ Accuracy: 53.1%\n",
            "Step: 354 ------------ Loss: 11004.86 ------------ Accuracy: 53.1%\n",
            "Step: 355 ------------ Loss: 11003.97 ------------ Accuracy: 53.1%\n",
            "Step: 356 ------------ Loss: 11000.11 ------------ Accuracy: 53.1%\n",
            "Step: 357 ------------ Loss: 10999.39 ------------ Accuracy: 53.3%\n",
            "Step: 358 ------------ Loss: 10995.54 ------------ Accuracy: 53.3%\n",
            "Step: 359 ------------ Loss: 10992.46 ------------ Accuracy: 53.6%\n",
            "Step: 360 ------------ Loss: 10991.77 ------------ Accuracy: 53.6%\n",
            "Step: 361 ------------ Loss: 10991.63 ------------ Accuracy: 53.6%\n",
            "Step: 362 ------------ Loss: 10990.83 ------------ Accuracy: 53.3%\n",
            "Step: 363 ------------ Loss: 10989.26 ------------ Accuracy: 53.3%\n",
            "Step: 364 ------------ Loss: 10988.49 ------------ Accuracy: 53.2%\n",
            "Step: 365 ------------ Loss: 10987.94 ------------ Accuracy: 53.4%\n",
            "Step: 366 ------------ Loss: 10987.23 ------------ Accuracy: 53.1%\n",
            "Step: 367 ------------ Loss: 10986.56 ------------ Accuracy: 53.4%\n",
            "Step: 368 ------------ Loss: 10984.58 ------------ Accuracy: 53.4%\n",
            "Step: 369 ------------ Loss: 10978.72 ------------ Accuracy: 53.4%\n",
            "Step: 370 ------------ Loss: 10956.96 ------------ Accuracy: 53.3%\n",
            "Step: 371 ------------ Loss: 10956.46 ------------ Accuracy: 53.4%\n",
            "Step: 372 ------------ Loss: 10954.19 ------------ Accuracy: 53.6%\n",
            "Step: 373 ------------ Loss: 10953.92 ------------ Accuracy: 53.6%\n",
            "Step: 374 ------------ Loss: 10952.61 ------------ Accuracy: 53.5%\n",
            "Step: 375 ------------ Loss: 10951.74 ------------ Accuracy: 53.5%\n",
            "Step: 376 ------------ Loss: 10951.44 ------------ Accuracy: 53.5%\n",
            "Step: 377 ------------ Loss: 10951.14 ------------ Accuracy: 53.5%\n",
            "Step: 378 ------------ Loss: 10950.47 ------------ Accuracy: 53.5%\n",
            "Step: 379 ------------ Loss: 10950.31 ------------ Accuracy: 53.5%\n",
            "Step: 380 ------------ Loss: 10950.15 ------------ Accuracy: 53.5%\n",
            "Step: 381 ------------ Loss: 10950.02 ------------ Accuracy: 53.5%\n",
            "Step: 382 ------------ Loss: 10949.59 ------------ Accuracy: 53.4%\n",
            "Step: 383 ------------ Loss: 10927.32 ------------ Accuracy: 53.6%\n",
            "Step: 384 ------------ Loss: 10927.05 ------------ Accuracy: 53.6%\n",
            "Step: 385 ------------ Loss: 10925.54 ------------ Accuracy: 53.6%\n",
            "Step: 386 ------------ Loss: 10924.09 ------------ Accuracy: 53.5%\n",
            "Step: 387 ------------ Loss: 10920.3 ------------ Accuracy: 53.5%\n",
            "Step: 388 ------------ Loss: 10920.15 ------------ Accuracy: 53.5%\n",
            "Step: 389 ------------ Loss: 10919.87 ------------ Accuracy: 53.5%\n",
            "Step: 390 ------------ Loss: 10919.72 ------------ Accuracy: 53.5%\n",
            "Step: 391 ------------ Loss: 10918.23 ------------ Accuracy: 53.5%\n",
            "Step: 392 ------------ Loss: 10917.98 ------------ Accuracy: 53.5%\n",
            "Step: 393 ------------ Loss: 10916.51 ------------ Accuracy: 53.5%\n",
            "Step: 394 ------------ Loss: 10914.61 ------------ Accuracy: 53.5%\n",
            "Step: 395 ------------ Loss: 10914.07 ------------ Accuracy: 53.5%\n",
            "Step: 396 ------------ Loss: 10913.58 ------------ Accuracy: 53.5%\n",
            "Step: 397 ------------ Loss: 10912.29 ------------ Accuracy: 53.5%\n",
            "Step: 398 ------------ Loss: 10911.66 ------------ Accuracy: 53.5%\n",
            "Step: 399 ------------ Loss: 10890.44 ------------ Accuracy: 53.6%\n",
            "Step: 400 ------------ Loss: 10889.81 ------------ Accuracy: 53.5%\n",
            "Step: 401 ------------ Loss: 10889.66 ------------ Accuracy: 53.5%\n",
            "Step: 402 ------------ Loss: 10888.23 ------------ Accuracy: 53.5%\n",
            "Step: 403 ------------ Loss: 10884.67 ------------ Accuracy: 53.6%\n",
            "Step: 404 ------------ Loss: 10883.25 ------------ Accuracy: 53.5%\n",
            "Step: 405 ------------ Loss: 10882.99 ------------ Accuracy: 53.5%\n",
            "Step: 406 ------------ Loss: 10882.43 ------------ Accuracy: 53.5%\n",
            "Step: 407 ------------ Loss: 10881.27 ------------ Accuracy: 53.4%\n",
            "Step: 408 ------------ Loss: 10879.85 ------------ Accuracy: 53.4%\n",
            "Step: 409 ------------ Loss: 10879.7 ------------ Accuracy: 53.4%\n",
            "Step: 410 ------------ Loss: 10877.85 ------------ Accuracy: 53.4%\n",
            "Step: 411 ------------ Loss: 10877.59 ------------ Accuracy: 53.4%\n",
            "Step: 412 ------------ Loss: 10877.33 ------------ Accuracy: 53.4%\n",
            "Step: 413 ------------ Loss: 10868.18 ------------ Accuracy: 53.4%\n",
            "Step: 414 ------------ Loss: 10867.56 ------------ Accuracy: 53.4%\n",
            "Step: 415 ------------ Loss: 10866.88 ------------ Accuracy: 53.3%\n",
            "Step: 416 ------------ Loss: 10866.51 ------------ Accuracy: 53.3%\n",
            "Step: 417 ------------ Loss: 10866.39 ------------ Accuracy: 53.3%\n",
            "Step: 418 ------------ Loss: 10865.57 ------------ Accuracy: 53.3%\n",
            "Step: 419 ------------ Loss: 10865.3 ------------ Accuracy: 53.3%\n",
            "Step: 420 ------------ Loss: 10865.16 ------------ Accuracy: 53.3%\n",
            "Step: 421 ------------ Loss: 10864.79 ------------ Accuracy: 53.3%\n",
            "Step: 422 ------------ Loss: 10864.18 ------------ Accuracy: 53.3%\n",
            "Step: 423 ------------ Loss: 10863.9 ------------ Accuracy: 53.3%\n",
            "Step: 424 ------------ Loss: 10863.78 ------------ Accuracy: 53.3%\n",
            "Step: 425 ------------ Loss: 10862.88 ------------ Accuracy: 53.3%\n",
            "Step: 426 ------------ Loss: 10858.39 ------------ Accuracy: 53.4%\n",
            "Step: 427 ------------ Loss: 10858.11 ------------ Accuracy: 53.4%\n",
            "Step: 428 ------------ Loss: 10857.82 ------------ Accuracy: 53.5%\n",
            "Step: 429 ------------ Loss: 10857.69 ------------ Accuracy: 53.5%\n",
            "Step: 430 ------------ Loss: 10857.47 ------------ Accuracy: 53.5%\n",
            "Step: 431 ------------ Loss: 10856.66 ------------ Accuracy: 53.4%\n",
            "Step: 432 ------------ Loss: 10856.39 ------------ Accuracy: 53.4%\n",
            "Step: 433 ------------ Loss: 10856.25 ------------ Accuracy: 53.4%\n",
            "Step: 434 ------------ Loss: 10852.28 ------------ Accuracy: 53.4%\n",
            "Step: 435 ------------ Loss: 10851.54 ------------ Accuracy: 53.4%\n",
            "Step: 436 ------------ Loss: 10851.4 ------------ Accuracy: 53.4%\n",
            "Step: 437 ------------ Loss: 10850.76 ------------ Accuracy: 53.4%\n",
            "Step: 438 ------------ Loss: 10850.64 ------------ Accuracy: 53.4%\n",
            "Step: 439 ------------ Loss: 10848.63 ------------ Accuracy: 53.4%\n",
            "Step: 440 ------------ Loss: 10847.82 ------------ Accuracy: 53.4%\n",
            "Step: 441 ------------ Loss: 10845.22 ------------ Accuracy: 53.4%\n",
            "Step: 442 ------------ Loss: 10844.89 ------------ Accuracy: 53.5%\n",
            "Step: 443 ------------ Loss: 10844.78 ------------ Accuracy: 53.5%\n",
            "Step: 444 ------------ Loss: 10844.69 ------------ Accuracy: 53.5%\n",
            "Step: 445 ------------ Loss: 10844.48 ------------ Accuracy: 53.4%\n",
            "Step: 446 ------------ Loss: 10844.23 ------------ Accuracy: 53.4%\n",
            "Step: 447 ------------ Loss: 10842.26 ------------ Accuracy: 53.4%\n",
            "Step: 448 ------------ Loss: 10840.31 ------------ Accuracy: 53.5%\n",
            "Step: 449 ------------ Loss: 10839.6 ------------ Accuracy: 53.4%\n",
            "Step: 450 ------------ Loss: 10839.33 ------------ Accuracy: 53.4%\n",
            "Step: 451 ------------ Loss: 10835.12 ------------ Accuracy: 53.4%\n",
            "Step: 452 ------------ Loss: 10834.86 ------------ Accuracy: 53.4%\n",
            "Step: 453 ------------ Loss: 10834.63 ------------ Accuracy: 53.4%\n",
            "Step: 454 ------------ Loss: 10834.39 ------------ Accuracy: 53.4%\n",
            "Step: 455 ------------ Loss: 10834.28 ------------ Accuracy: 53.4%\n",
            "Step: 456 ------------ Loss: 10834.14 ------------ Accuracy: 53.4%\n",
            "Step: 457 ------------ Loss: 10834.02 ------------ Accuracy: 53.4%\n",
            "Step: 458 ------------ Loss: 10830.06 ------------ Accuracy: 53.4%\n",
            "Step: 459 ------------ Loss: 10827.44 ------------ Accuracy: 53.5%\n",
            "Step: 460 ------------ Loss: 10827.17 ------------ Accuracy: 53.5%\n",
            "Step: 461 ------------ Loss: 10825.27 ------------ Accuracy: 53.5%\n",
            "Step: 462 ------------ Loss: 10823.86 ------------ Accuracy: 53.4%\n",
            "Step: 463 ------------ Loss: 10823.24 ------------ Accuracy: 53.4%\n",
            "Step: 464 ------------ Loss: 10822.97 ------------ Accuracy: 53.4%\n",
            "Step: 465 ------------ Loss: 10819.1 ------------ Accuracy: 53.5%\n",
            "Step: 466 ------------ Loss: 10818.92 ------------ Accuracy: 53.5%\n",
            "Step: 467 ------------ Loss: 10818.31 ------------ Accuracy: 53.5%\n",
            "Step: 468 ------------ Loss: 10817.8 ------------ Accuracy: 53.5%\n",
            "Step: 469 ------------ Loss: 10816.99 ------------ Accuracy: 53.5%\n",
            "Step: 470 ------------ Loss: 10816.38 ------------ Accuracy: 53.5%\n",
            "Step: 471 ------------ Loss: 10816.18 ------------ Accuracy: 53.5%\n",
            "Step: 472 ------------ Loss: 10814.88 ------------ Accuracy: 53.4%\n",
            "Step: 473 ------------ Loss: 10814.7 ------------ Accuracy: 53.4%\n",
            "Step: 474 ------------ Loss: 10814.61 ------------ Accuracy: 53.4%\n",
            "Step: 475 ------------ Loss: 10814.35 ------------ Accuracy: 53.4%\n",
            "Step: 476 ------------ Loss: 10813.74 ------------ Accuracy: 53.4%\n",
            "Step: 477 ------------ Loss: 10813.63 ------------ Accuracy: 53.4%\n",
            "Step: 478 ------------ Loss: 10813.43 ------------ Accuracy: 53.4%\n",
            "Step: 479 ------------ Loss: 10809.59 ------------ Accuracy: 53.5%\n",
            "Step: 480 ------------ Loss: 10808.15 ------------ Accuracy: 53.5%\n",
            "Step: 481 ------------ Loss: 10806.29 ------------ Accuracy: 53.5%\n",
            "Step: 482 ------------ Loss: 10805.49 ------------ Accuracy: 53.5%\n",
            "Step: 483 ------------ Loss: 10805.38 ------------ Accuracy: 53.5%\n",
            "Step: 484 ------------ Loss: 10805.18 ------------ Accuracy: 53.5%\n",
            "Step: 485 ------------ Loss: 10805.12 ------------ Accuracy: 53.5%\n",
            "Step: 486 ------------ Loss: 10801.37 ------------ Accuracy: 53.5%\n",
            "Step: 487 ------------ Loss: 10801.26 ------------ Accuracy: 53.5%\n",
            "Step: 488 ------------ Loss: 10801.01 ------------ Accuracy: 53.5%\n",
            "Step: 489 ------------ Loss: 10800.16 ------------ Accuracy: 53.5%\n",
            "Step: 490 ------------ Loss: 10799.98 ------------ Accuracy: 53.5%\n",
            "Step: 491 ------------ Loss: 10792.49 ------------ Accuracy: 53.4%\n",
            "Step: 492 ------------ Loss: 10791.74 ------------ Accuracy: 53.4%\n",
            "Step: 493 ------------ Loss: 10791.48 ------------ Accuracy: 53.4%\n",
            "Step: 494 ------------ Loss: 10791.38 ------------ Accuracy: 53.4%\n",
            "Step: 495 ------------ Loss: 10791.21 ------------ Accuracy: 53.4%\n",
            "Step: 496 ------------ Loss: 10790.62 ------------ Accuracy: 53.4%\n",
            "Step: 497 ------------ Loss: 10788.73 ------------ Accuracy: 53.4%\n",
            "Step: 498 ------------ Loss: 10788.61 ------------ Accuracy: 53.4%\n",
            "Step: 499 ------------ Loss: 10788.49 ------------ Accuracy: 53.4%\n",
            "Step: 500 ------------ Loss: 10784.83 ------------ Accuracy: 53.1%\n",
            "Step: 501 ------------ Loss: 10784.24 ------------ Accuracy: 53.1%\n",
            "Step: 502 ------------ Loss: 10784.03 ------------ Accuracy: 53.2%\n",
            "Step: 503 ------------ Loss: 10783.92 ------------ Accuracy: 53.2%\n",
            "Step: 504 ------------ Loss: 10783.72 ------------ Accuracy: 53.2%\n",
            "Step: 505 ------------ Loss: 10783.55 ------------ Accuracy: 53.2%\n",
            "Step: 506 ------------ Loss: 10783.42 ------------ Accuracy: 53.2%\n",
            "Step: 507 ------------ Loss: 10783.32 ------------ Accuracy: 53.2%\n",
            "Step: 508 ------------ Loss: 10779.83 ------------ Accuracy: 53.2%\n",
            "Step: 509 ------------ Loss: 10779.28 ------------ Accuracy: 53.2%\n",
            "Step: 510 ------------ Loss: 10776.03 ------------ Accuracy: 53.3%\n",
            "Step: 511 ------------ Loss: 10775.86 ------------ Accuracy: 53.2%\n",
            "Step: 512 ------------ Loss: 10773.92 ------------ Accuracy: 53.2%\n",
            "Step: 513 ------------ Loss: 10769.98 ------------ Accuracy: 53.2%\n",
            "Step: 514 ------------ Loss: 10769.47 ------------ Accuracy: 53.2%\n",
            "Step: 515 ------------ Loss: 10769.22 ------------ Accuracy: 53.2%\n",
            "Step: 516 ------------ Loss: 10767.79 ------------ Accuracy: 53.2%\n",
            "Step: 517 ------------ Loss: 10767.68 ------------ Accuracy: 53.2%\n",
            "Step: 518 ------------ Loss: 10766.81 ------------ Accuracy: 53.3%\n",
            "Step: 519 ------------ Loss: 10766.35 ------------ Accuracy: 53.4%\n",
            "Step: 520 ------------ Loss: 10765.58 ------------ Accuracy: 53.4%\n",
            "Step: 521 ------------ Loss: 10763.67 ------------ Accuracy: 53.4%\n",
            "Step: 522 ------------ Loss: 10763.38 ------------ Accuracy: 53.3%\n",
            "Step: 523 ------------ Loss: 10763.12 ------------ Accuracy: 53.2%\n",
            "Step: 524 ------------ Loss: 10762.62 ------------ Accuracy: 53.2%\n",
            "Step: 525 ------------ Loss: 10756.01 ------------ Accuracy: 53.3%\n",
            "Step: 526 ------------ Loss: 10755.8 ------------ Accuracy: 53.2%\n",
            "Step: 527 ------------ Loss: 10755.61 ------------ Accuracy: 53.2%\n",
            "Step: 528 ------------ Loss: 10755.46 ------------ Accuracy: 53.2%\n",
            "Step: 529 ------------ Loss: 10755.34 ------------ Accuracy: 53.2%\n",
            "Step: 530 ------------ Loss: 10754.82 ------------ Accuracy: 53.2%\n",
            "Step: 531 ------------ Loss: 10754.71 ------------ Accuracy: 53.2%\n",
            "Step: 532 ------------ Loss: 10754.25 ------------ Accuracy: 53.3%\n",
            "Step: 533 ------------ Loss: 10753.85 ------------ Accuracy: 53.4%\n",
            "Step: 534 ------------ Loss: 10753.6 ------------ Accuracy: 53.2%\n",
            "Step: 535 ------------ Loss: 10753.48 ------------ Accuracy: 53.2%\n",
            "Step: 536 ------------ Loss: 10750.31 ------------ Accuracy: 53.3%\n",
            "Step: 537 ------------ Loss: 10748.93 ------------ Accuracy: 53.3%\n",
            "Step: 538 ------------ Loss: 10746.69 ------------ Accuracy: 53.6%\n",
            "Step: 539 ------------ Loss: 10746.54 ------------ Accuracy: 53.6%\n",
            "Step: 540 ------------ Loss: 10744.92 ------------ Accuracy: 53.5%\n",
            "Step: 541 ------------ Loss: 10744.69 ------------ Accuracy: 53.5%\n",
            "Step: 542 ------------ Loss: 10743.01 ------------ Accuracy: 53.5%\n",
            "Step: 543 ------------ Loss: 10742.12 ------------ Accuracy: 53.7%\n",
            "Step: 544 ------------ Loss: 10741.35 ------------ Accuracy: 53.7%\n",
            "Step: 545 ------------ Loss: 10740.0 ------------ Accuracy: 53.7%\n",
            "Step: 546 ------------ Loss: 10738.5 ------------ Accuracy: 53.7%\n",
            "Step: 547 ------------ Loss: 10737.81 ------------ Accuracy: 53.7%\n",
            "Step: 548 ------------ Loss: 10737.38 ------------ Accuracy: 53.7%\n",
            "Step: 549 ------------ Loss: 10736.05 ------------ Accuracy: 53.7%\n",
            "Step: 550 ------------ Loss: 10736.0 ------------ Accuracy: 53.7%\n",
            "Step: 551 ------------ Loss: 10735.57 ------------ Accuracy: 53.7%\n",
            "Step: 552 ------------ Loss: 10735.47 ------------ Accuracy: 53.7%\n",
            "Step: 553 ------------ Loss: 10734.1 ------------ Accuracy: 53.7%\n",
            "Step: 554 ------------ Loss: 10732.79 ------------ Accuracy: 53.7%\n",
            "Step: 555 ------------ Loss: 10732.39 ------------ Accuracy: 53.7%\n",
            "Step: 556 ------------ Loss: 10732.21 ------------ Accuracy: 53.7%\n",
            "Step: 557 ------------ Loss: 10730.79 ------------ Accuracy: 53.7%\n",
            "Step: 558 ------------ Loss: 10726.91 ------------ Accuracy: 53.6%\n",
            "Step: 559 ------------ Loss: 10726.76 ------------ Accuracy: 53.7%\n",
            "Step: 560 ------------ Loss: 10725.35 ------------ Accuracy: 53.7%\n",
            "Step: 561 ------------ Loss: 10725.17 ------------ Accuracy: 53.6%\n",
            "Step: 562 ------------ Loss: 10724.99 ------------ Accuracy: 53.6%\n",
            "Step: 563 ------------ Loss: 10724.44 ------------ Accuracy: 53.6%\n",
            "Step: 564 ------------ Loss: 10724.31 ------------ Accuracy: 53.6%\n",
            "Step: 565 ------------ Loss: 10724.17 ------------ Accuracy: 53.7%\n",
            "Step: 566 ------------ Loss: 10723.76 ------------ Accuracy: 53.7%\n",
            "Step: 567 ------------ Loss: 10720.36 ------------ Accuracy: 53.6%\n",
            "Step: 568 ------------ Loss: 10719.83 ------------ Accuracy: 53.6%\n",
            "Step: 569 ------------ Loss: 10719.29 ------------ Accuracy: 53.6%\n",
            "Step: 570 ------------ Loss: 10715.52 ------------ Accuracy: 53.7%\n",
            "Step: 571 ------------ Loss: 10715.37 ------------ Accuracy: 53.7%\n",
            "Step: 572 ------------ Loss: 10714.97 ------------ Accuracy: 53.7%\n",
            "Step: 573 ------------ Loss: 10714.84 ------------ Accuracy: 53.7%\n",
            "Step: 574 ------------ Loss: 10714.74 ------------ Accuracy: 53.7%\n",
            "Step: 575 ------------ Loss: 10714.6 ------------ Accuracy: 53.7%\n",
            "Step: 576 ------------ Loss: 10694.53 ------------ Accuracy: 53.7%\n",
            "Step: 577 ------------ Loss: 10694.0 ------------ Accuracy: 53.7%\n",
            "Step: 578 ------------ Loss: 10693.24 ------------ Accuracy: 53.7%\n",
            "Step: 579 ------------ Loss: 10692.08 ------------ Accuracy: 53.7%\n",
            "Step: 580 ------------ Loss: 10691.95 ------------ Accuracy: 53.7%\n",
            "Step: 581 ------------ Loss: 10685.02 ------------ Accuracy: 53.6%\n",
            "Step: 582 ------------ Loss: 10684.26 ------------ Accuracy: 53.6%\n",
            "Step: 583 ------------ Loss: 10683.18 ------------ Accuracy: 53.7%\n",
            "Step: 584 ------------ Loss: 10682.97 ------------ Accuracy: 53.7%\n",
            "Step: 585 ------------ Loss: 10664.26 ------------ Accuracy: 53.5%\n",
            "Step: 586 ------------ Loss: 10664.16 ------------ Accuracy: 53.5%\n",
            "Step: 587 ------------ Loss: 10657.33 ------------ Accuracy: 53.5%\n",
            "Step: 588 ------------ Loss: 10656.0 ------------ Accuracy: 53.5%\n",
            "Step: 589 ------------ Loss: 10649.78 ------------ Accuracy: 53.6%\n",
            "Step: 590 ------------ Loss: 10648.66 ------------ Accuracy: 53.3%\n",
            "Step: 591 ------------ Loss: 10648.52 ------------ Accuracy: 53.3%\n",
            "Step: 592 ------------ Loss: 10648.39 ------------ Accuracy: 53.3%\n",
            "Step: 593 ------------ Loss: 10648.2 ------------ Accuracy: 53.3%\n",
            "Step: 594 ------------ Loss: 10647.93 ------------ Accuracy: 53.3%\n",
            "Step: 595 ------------ Loss: 10647.76 ------------ Accuracy: 53.3%\n",
            "Step: 596 ------------ Loss: 10647.55 ------------ Accuracy: 53.3%\n",
            "Step: 597 ------------ Loss: 10646.26 ------------ Accuracy: 53.3%\n",
            "Step: 598 ------------ Loss: 10645.74 ------------ Accuracy: 53.3%\n",
            "Step: 599 ------------ Loss: 10644.46 ------------ Accuracy: 53.3%\n",
            "Step: 600 ------------ Loss: 10643.19 ------------ Accuracy: 53.3%\n",
            "Step: 601 ------------ Loss: 10643.05 ------------ Accuracy: 53.4%\n",
            "Step: 602 ------------ Loss: 10642.85 ------------ Accuracy: 53.4%\n",
            "Step: 603 ------------ Loss: 10641.7 ------------ Accuracy: 53.4%\n",
            "Step: 604 ------------ Loss: 10638.51 ------------ Accuracy: 53.4%\n",
            "Step: 605 ------------ Loss: 10638.35 ------------ Accuracy: 53.4%\n",
            "Step: 606 ------------ Loss: 10636.82 ------------ Accuracy: 53.4%\n",
            "Step: 607 ------------ Loss: 10633.63 ------------ Accuracy: 53.4%\n",
            "Step: 608 ------------ Loss: 10633.12 ------------ Accuracy: 53.4%\n",
            "Step: 609 ------------ Loss: 10632.77 ------------ Accuracy: 53.4%\n",
            "Step: 610 ------------ Loss: 10632.6 ------------ Accuracy: 53.4%\n",
            "Step: 611 ------------ Loss: 10632.1 ------------ Accuracy: 53.4%\n",
            "Step: 612 ------------ Loss: 10631.89 ------------ Accuracy: 53.4%\n",
            "Step: 613 ------------ Loss: 10631.77 ------------ Accuracy: 53.4%\n",
            "Step: 614 ------------ Loss: 10630.52 ------------ Accuracy: 53.4%\n",
            "Step: 615 ------------ Loss: 10629.78 ------------ Accuracy: 53.4%\n",
            "Step: 616 ------------ Loss: 10629.43 ------------ Accuracy: 53.4%\n",
            "Step: 617 ------------ Loss: 10626.29 ------------ Accuracy: 53.5%\n",
            "Step: 618 ------------ Loss: 10625.96 ------------ Accuracy: 53.5%\n",
            "Step: 619 ------------ Loss: 10625.87 ------------ Accuracy: 53.5%\n",
            "Step: 620 ------------ Loss: 10624.9 ------------ Accuracy: 53.4%\n",
            "Step: 621 ------------ Loss: 10624.75 ------------ Accuracy: 53.4%\n",
            "Step: 622 ------------ Loss: 10623.53 ------------ Accuracy: 53.4%\n",
            "Step: 623 ------------ Loss: 10623.41 ------------ Accuracy: 53.4%\n",
            "Step: 624 ------------ Loss: 10623.3 ------------ Accuracy: 53.4%\n",
            "Step: 625 ------------ Loss: 10623.18 ------------ Accuracy: 53.4%\n",
            "Step: 626 ------------ Loss: 10623.08 ------------ Accuracy: 53.4%\n",
            "Step: 627 ------------ Loss: 10622.28 ------------ Accuracy: 53.4%\n",
            "Step: 628 ------------ Loss: 10622.17 ------------ Accuracy: 53.4%\n",
            "Step: 629 ------------ Loss: 10603.6 ------------ Accuracy: 53.4%\n",
            "Step: 630 ------------ Loss: 10603.47 ------------ Accuracy: 53.4%\n",
            "Step: 631 ------------ Loss: 10600.19 ------------ Accuracy: 53.4%\n",
            "Step: 632 ------------ Loss: 10599.0 ------------ Accuracy: 53.4%\n",
            "Step: 633 ------------ Loss: 10597.66 ------------ Accuracy: 53.4%\n",
            "Step: 634 ------------ Loss: 10596.95 ------------ Accuracy: 53.3%\n",
            "Step: 635 ------------ Loss: 10596.84 ------------ Accuracy: 53.3%\n",
            "Step: 636 ------------ Loss: 10590.79 ------------ Accuracy: 53.3%\n",
            "Step: 637 ------------ Loss: 10590.31 ------------ Accuracy: 53.3%\n",
            "Step: 638 ------------ Loss: 10590.21 ------------ Accuracy: 53.3%\n",
            "Step: 639 ------------ Loss: 10590.07 ------------ Accuracy: 53.3%\n",
            "Step: 640 ------------ Loss: 10571.83 ------------ Accuracy: 53.4%\n",
            "Step: 641 ------------ Loss: 10571.71 ------------ Accuracy: 53.4%\n",
            "Step: 642 ------------ Loss: 10571.54 ------------ Accuracy: 53.4%\n",
            "Step: 643 ------------ Loss: 10571.45 ------------ Accuracy: 53.4%\n",
            "Step: 644 ------------ Loss: 10570.51 ------------ Accuracy: 53.4%\n",
            "Step: 645 ------------ Loss: 10569.82 ------------ Accuracy: 53.3%\n",
            "Step: 646 ------------ Loss: 10569.71 ------------ Accuracy: 53.3%\n",
            "Step: 647 ------------ Loss: 10569.62 ------------ Accuracy: 53.3%\n",
            "Step: 648 ------------ Loss: 10569.17 ------------ Accuracy: 53.3%\n",
            "Step: 649 ------------ Loss: 10551.75 ------------ Accuracy: 53.5%\n",
            "Step: 650 ------------ Loss: 10548.59 ------------ Accuracy: 53.3%\n",
            "Step: 651 ------------ Loss: 10548.43 ------------ Accuracy: 53.3%\n",
            "Step: 652 ------------ Loss: 10548.13 ------------ Accuracy: 53.3%\n",
            "Step: 653 ------------ Loss: 10547.0 ------------ Accuracy: 53.3%\n",
            "Step: 654 ------------ Loss: 10546.81 ------------ Accuracy: 53.3%\n",
            "Step: 655 ------------ Loss: 10546.66 ------------ Accuracy: 53.3%\n",
            "Step: 656 ------------ Loss: 10530.1 ------------ Accuracy: 53.4%\n",
            "Step: 657 ------------ Loss: 10530.02 ------------ Accuracy: 53.4%\n",
            "Step: 658 ------------ Loss: 10526.86 ------------ Accuracy: 53.2%\n",
            "Step: 659 ------------ Loss: 10520.99 ------------ Accuracy: 53.1%\n",
            "Step: 660 ------------ Loss: 10518.33 ------------ Accuracy: 53.3%\n",
            "Step: 661 ------------ Loss: 10517.62 ------------ Accuracy: 53.3%\n",
            "Step: 662 ------------ Loss: 10516.72 ------------ Accuracy: 53.1%\n",
            "Step: 663 ------------ Loss: 10516.64 ------------ Accuracy: 53.1%\n",
            "Step: 664 ------------ Loss: 10515.65 ------------ Accuracy: 53.3%\n",
            "Step: 665 ------------ Loss: 10515.5 ------------ Accuracy: 53.3%\n",
            "Step: 666 ------------ Loss: 10510.15 ------------ Accuracy: 53.3%\n",
            "Step: 667 ------------ Loss: 10509.24 ------------ Accuracy: 53.3%\n",
            "Step: 668 ------------ Loss: 10508.78 ------------ Accuracy: 53.3%\n",
            "Step: 669 ------------ Loss: 10508.06 ------------ Accuracy: 53.3%\n",
            "Step: 670 ------------ Loss: 10507.6 ------------ Accuracy: 53.3%\n",
            "Step: 671 ------------ Loss: 10507.42 ------------ Accuracy: 53.4%\n",
            "Step: 672 ------------ Loss: 10507.24 ------------ Accuracy: 53.4%\n",
            "Step: 673 ------------ Loss: 10507.11 ------------ Accuracy: 53.4%\n",
            "Step: 674 ------------ Loss: 10505.77 ------------ Accuracy: 53.3%\n",
            "Step: 675 ------------ Loss: 10504.94 ------------ Accuracy: 53.3%\n",
            "Step: 676 ------------ Loss: 10503.81 ------------ Accuracy: 53.3%\n",
            "Step: 677 ------------ Loss: 10487.25 ------------ Accuracy: 53.3%\n",
            "Step: 678 ------------ Loss: 10487.03 ------------ Accuracy: 53.3%\n",
            "Step: 679 ------------ Loss: 10486.9 ------------ Accuracy: 53.3%\n",
            "Step: 680 ------------ Loss: 10486.17 ------------ Accuracy: 53.4%\n",
            "Step: 681 ------------ Loss: 10485.75 ------------ Accuracy: 53.4%\n",
            "Step: 682 ------------ Loss: 10483.15 ------------ Accuracy: 53.4%\n",
            "Step: 683 ------------ Loss: 10483.03 ------------ Accuracy: 53.4%\n",
            "Step: 684 ------------ Loss: 10482.61 ------------ Accuracy: 53.4%\n",
            "Step: 685 ------------ Loss: 10482.44 ------------ Accuracy: 53.4%\n",
            "Step: 686 ------------ Loss: 10482.3 ------------ Accuracy: 53.4%\n",
            "Step: 687 ------------ Loss: 10482.22 ------------ Accuracy: 53.4%\n",
            "Step: 688 ------------ Loss: 10481.24 ------------ Accuracy: 53.4%\n",
            "Step: 689 ------------ Loss: 10481.11 ------------ Accuracy: 53.4%\n",
            "Step: 690 ------------ Loss: 10480.7 ------------ Accuracy: 53.4%\n",
            "Step: 691 ------------ Loss: 10479.36 ------------ Accuracy: 53.4%\n",
            "Step: 692 ------------ Loss: 10463.29 ------------ Accuracy: 53.3%\n",
            "Step: 693 ------------ Loss: 10463.13 ------------ Accuracy: 53.3%\n",
            "Step: 694 ------------ Loss: 10462.24 ------------ Accuracy: 53.3%\n",
            "Step: 695 ------------ Loss: 10461.84 ------------ Accuracy: 53.3%\n",
            "Step: 696 ------------ Loss: 10461.17 ------------ Accuracy: 53.3%\n",
            "Step: 697 ------------ Loss: 10460.77 ------------ Accuracy: 53.3%\n",
            "Step: 698 ------------ Loss: 10460.1 ------------ Accuracy: 53.3%\n",
            "Step: 699 ------------ Loss: 10459.54 ------------ Accuracy: 53.5%\n",
            "Step: 700 ------------ Loss: 10458.64 ------------ Accuracy: 53.5%\n",
            "Step: 701 ------------ Loss: 10458.46 ------------ Accuracy: 53.5%\n",
            "Step: 702 ------------ Loss: 10458.3 ------------ Accuracy: 53.5%\n",
            "Step: 703 ------------ Loss: 10458.04 ------------ Accuracy: 53.5%\n",
            "Step: 704 ------------ Loss: 10457.9 ------------ Accuracy: 53.5%\n",
            "Step: 705 ------------ Loss: 10457.76 ------------ Accuracy: 53.5%\n",
            "Step: 706 ------------ Loss: 10457.65 ------------ Accuracy: 53.5%\n",
            "Step: 707 ------------ Loss: 10456.6 ------------ Accuracy: 53.3%\n",
            "Step: 708 ------------ Loss: 10455.61 ------------ Accuracy: 53.5%\n",
            "Step: 709 ------------ Loss: 10455.08 ------------ Accuracy: 53.5%\n",
            "Step: 710 ------------ Loss: 10449.49 ------------ Accuracy: 53.5%\n",
            "Step: 711 ------------ Loss: 10449.05 ------------ Accuracy: 53.5%\n",
            "Step: 712 ------------ Loss: 10448.94 ------------ Accuracy: 53.5%\n",
            "Step: 713 ------------ Loss: 10448.84 ------------ Accuracy: 53.5%\n",
            "Step: 714 ------------ Loss: 10447.77 ------------ Accuracy: 53.5%\n",
            "Step: 715 ------------ Loss: 10447.67 ------------ Accuracy: 53.5%\n",
            "Step: 716 ------------ Loss: 10447.04 ------------ Accuracy: 53.6%\n",
            "Step: 717 ------------ Loss: 10445.71 ------------ Accuracy: 53.6%\n",
            "Step: 718 ------------ Loss: 10445.62 ------------ Accuracy: 53.6%\n",
            "Step: 719 ------------ Loss: 10445.53 ------------ Accuracy: 53.6%\n",
            "Step: 720 ------------ Loss: 10445.14 ------------ Accuracy: 53.6%\n",
            "Step: 721 ------------ Loss: 10444.6 ------------ Accuracy: 53.6%\n",
            "Step: 722 ------------ Loss: 10444.41 ------------ Accuracy: 53.6%\n",
            "Step: 723 ------------ Loss: 10444.13 ------------ Accuracy: 53.6%\n",
            "Step: 724 ------------ Loss: 10443.97 ------------ Accuracy: 53.6%\n",
            "Step: 725 ------------ Loss: 10443.8 ------------ Accuracy: 53.6%\n",
            "Step: 726 ------------ Loss: 10443.73 ------------ Accuracy: 53.6%\n",
            "Step: 727 ------------ Loss: 10443.63 ------------ Accuracy: 53.6%\n",
            "Step: 728 ------------ Loss: 10443.07 ------------ Accuracy: 53.6%\n",
            "Step: 729 ------------ Loss: 10442.91 ------------ Accuracy: 53.6%\n",
            "Step: 730 ------------ Loss: 10440.58 ------------ Accuracy: 53.7%\n",
            "Step: 731 ------------ Loss: 10440.42 ------------ Accuracy: 53.7%\n",
            "Step: 732 ------------ Loss: 10440.28 ------------ Accuracy: 53.8%\n",
            "Step: 733 ------------ Loss: 10440.18 ------------ Accuracy: 53.8%\n",
            "Step: 734 ------------ Loss: 10440.01 ------------ Accuracy: 53.8%\n",
            "Step: 735 ------------ Loss: 10439.9 ------------ Accuracy: 53.8%\n",
            "Step: 736 ------------ Loss: 10439.79 ------------ Accuracy: 53.8%\n",
            "Step: 737 ------------ Loss: 10434.58 ------------ Accuracy: 53.7%\n",
            "Step: 738 ------------ Loss: 10432.54 ------------ Accuracy: 53.6%\n",
            "Step: 739 ------------ Loss: 10430.86 ------------ Accuracy: 53.4%\n",
            "Step: 740 ------------ Loss: 10430.13 ------------ Accuracy: 53.7%\n",
            "Step: 741 ------------ Loss: 10430.04 ------------ Accuracy: 53.7%\n",
            "Step: 742 ------------ Loss: 10429.92 ------------ Accuracy: 53.7%\n",
            "Step: 743 ------------ Loss: 10425.13 ------------ Accuracy: 53.6%\n",
            "Step: 744 ------------ Loss: 10424.96 ------------ Accuracy: 53.6%\n",
            "Step: 745 ------------ Loss: 10408.54 ------------ Accuracy: 53.5%\n",
            "Step: 746 ------------ Loss: 10407.71 ------------ Accuracy: 53.5%\n",
            "Step: 747 ------------ Loss: 10404.96 ------------ Accuracy: 53.5%\n",
            "Step: 748 ------------ Loss: 10404.87 ------------ Accuracy: 53.5%\n",
            "Step: 749 ------------ Loss: 10404.79 ------------ Accuracy: 53.5%\n",
            "Step: 750 ------------ Loss: 10404.03 ------------ Accuracy: 53.6%\n",
            "Step: 751 ------------ Loss: 10403.95 ------------ Accuracy: 53.6%\n",
            "Step: 752 ------------ Loss: 10403.87 ------------ Accuracy: 53.6%\n",
            "Step: 753 ------------ Loss: 10403.8 ------------ Accuracy: 53.6%\n",
            "Step: 754 ------------ Loss: 10403.73 ------------ Accuracy: 53.6%\n",
            "Step: 755 ------------ Loss: 10403.3 ------------ Accuracy: 53.8%\n",
            "Step: 756 ------------ Loss: 10403.14 ------------ Accuracy: 53.8%\n",
            "Step: 757 ------------ Loss: 10401.97 ------------ Accuracy: 53.5%\n",
            "Step: 758 ------------ Loss: 10399.76 ------------ Accuracy: 53.6%\n",
            "Step: 759 ------------ Loss: 10399.04 ------------ Accuracy: 53.8%\n",
            "Step: 760 ------------ Loss: 10397.0 ------------ Accuracy: 53.8%\n",
            "Step: 761 ------------ Loss: 10396.57 ------------ Accuracy: 53.8%\n",
            "Step: 762 ------------ Loss: 10396.49 ------------ Accuracy: 53.8%\n",
            "Step: 763 ------------ Loss: 10396.38 ------------ Accuracy: 53.8%\n",
            "Step: 764 ------------ Loss: 10395.14 ------------ Accuracy: 53.6%\n",
            "Step: 765 ------------ Loss: 10394.41 ------------ Accuracy: 53.7%\n",
            "Step: 766 ------------ Loss: 10394.16 ------------ Accuracy: 53.7%\n",
            "Step: 767 ------------ Loss: 10394.1 ------------ Accuracy: 53.7%\n",
            "Step: 768 ------------ Loss: 10393.71 ------------ Accuracy: 53.7%\n",
            "Step: 769 ------------ Loss: 10391.0 ------------ Accuracy: 53.7%\n",
            "Step: 770 ------------ Loss: 10388.32 ------------ Accuracy: 53.7%\n",
            "Step: 771 ------------ Loss: 10388.25 ------------ Accuracy: 53.7%\n",
            "Step: 772 ------------ Loss: 10388.2 ------------ Accuracy: 53.7%\n",
            "Step: 773 ------------ Loss: 10387.17 ------------ Accuracy: 53.7%\n",
            "Step: 774 ------------ Loss: 10386.48 ------------ Accuracy: 53.8%\n",
            "Step: 775 ------------ Loss: 10386.43 ------------ Accuracy: 53.8%\n",
            "Step: 776 ------------ Loss: 10386.33 ------------ Accuracy: 53.8%\n",
            "Step: 777 ------------ Loss: 10383.66 ------------ Accuracy: 53.8%\n",
            "Step: 778 ------------ Loss: 10382.72 ------------ Accuracy: 53.7%\n",
            "Step: 779 ------------ Loss: 10381.53 ------------ Accuracy: 53.8%\n",
            "Step: 780 ------------ Loss: 10381.47 ------------ Accuracy: 53.7%\n",
            "Step: 781 ------------ Loss: 10380.82 ------------ Accuracy: 53.8%\n",
            "Step: 782 ------------ Loss: 10380.75 ------------ Accuracy: 53.8%\n",
            "Step: 783 ------------ Loss: 10380.38 ------------ Accuracy: 53.8%\n",
            "Step: 784 ------------ Loss: 10380.34 ------------ Accuracy: 53.8%\n",
            "Step: 785 ------------ Loss: 10379.13 ------------ Accuracy: 53.8%\n",
            "Step: 786 ------------ Loss: 10379.05 ------------ Accuracy: 53.8%\n",
            "Step: 787 ------------ Loss: 10379.03 ------------ Accuracy: 53.8%\n",
            "Step: 788 ------------ Loss: 10378.98 ------------ Accuracy: 53.8%\n",
            "Step: 789 ------------ Loss: 10378.35 ------------ Accuracy: 54.0%\n",
            "Step: 790 ------------ Loss: 10378.2 ------------ Accuracy: 54.0%\n",
            "Step: 791 ------------ Loss: 10377.96 ------------ Accuracy: 53.8%\n",
            "Step: 792 ------------ Loss: 10377.61 ------------ Accuracy: 53.9%\n",
            "Step: 793 ------------ Loss: 10376.62 ------------ Accuracy: 53.9%\n",
            "Step: 794 ------------ Loss: 10376.39 ------------ Accuracy: 53.9%\n",
            "Step: 795 ------------ Loss: 10375.12 ------------ Accuracy: 53.8%\n",
            "Step: 796 ------------ Loss: 10374.53 ------------ Accuracy: 54.0%\n",
            "Step: 797 ------------ Loss: 10374.3 ------------ Accuracy: 54.0%\n",
            "Step: 798 ------------ Loss: 10374.15 ------------ Accuracy: 54.0%\n",
            "Step: 799 ------------ Loss: 10374.1 ------------ Accuracy: 53.8%\n",
            "Step: 800 ------------ Loss: 10373.99 ------------ Accuracy: 53.8%\n",
            "Step: 801 ------------ Loss: 10373.93 ------------ Accuracy: 54.0%\n",
            "Step: 802 ------------ Loss: 10372.95 ------------ Accuracy: 54.0%\n",
            "Step: 803 ------------ Loss: 10371.76 ------------ Accuracy: 53.8%\n",
            "Step: 804 ------------ Loss: 10371.68 ------------ Accuracy: 53.8%\n",
            "Step: 805 ------------ Loss: 10371.63 ------------ Accuracy: 53.8%\n",
            "Step: 806 ------------ Loss: 10371.49 ------------ Accuracy: 53.8%\n",
            "Step: 807 ------------ Loss: 10366.24 ------------ Accuracy: 53.9%\n",
            "Step: 808 ------------ Loss: 10366.16 ------------ Accuracy: 53.9%\n",
            "Step: 809 ------------ Loss: 10363.54 ------------ Accuracy: 54.0%\n",
            "Step: 810 ------------ Loss: 10362.57 ------------ Accuracy: 53.8%\n",
            "Step: 811 ------------ Loss: 10362.46 ------------ Accuracy: 53.8%\n",
            "Step: 812 ------------ Loss: 10360.3 ------------ Accuracy: 53.8%\n",
            "Step: 813 ------------ Loss: 10360.23 ------------ Accuracy: 53.8%\n",
            "Step: 814 ------------ Loss: 10357.67 ------------ Accuracy: 53.8%\n",
            "Step: 815 ------------ Loss: 10357.45 ------------ Accuracy: 53.8%\n",
            "Step: 816 ------------ Loss: 10356.81 ------------ Accuracy: 53.8%\n",
            "Step: 817 ------------ Loss: 10356.76 ------------ Accuracy: 53.8%\n",
            "Step: 818 ------------ Loss: 10356.02 ------------ Accuracy: 53.8%\n",
            "Step: 819 ------------ Loss: 10355.96 ------------ Accuracy: 53.8%\n",
            "Step: 820 ------------ Loss: 10355.91 ------------ Accuracy: 53.8%\n",
            "Step: 821 ------------ Loss: 10355.34 ------------ Accuracy: 53.7%\n",
            "Step: 822 ------------ Loss: 10355.17 ------------ Accuracy: 53.7%\n",
            "Step: 823 ------------ Loss: 10355.1 ------------ Accuracy: 53.7%\n",
            "Step: 824 ------------ Loss: 10354.99 ------------ Accuracy: 53.7%\n",
            "Step: 825 ------------ Loss: 10354.52 ------------ Accuracy: 53.7%\n",
            "Step: 826 ------------ Loss: 10354.18 ------------ Accuracy: 53.8%\n",
            "Step: 827 ------------ Loss: 10349.13 ------------ Accuracy: 53.7%\n",
            "Step: 828 ------------ Loss: 10348.93 ------------ Accuracy: 53.7%\n",
            "Step: 829 ------------ Loss: 10348.85 ------------ Accuracy: 53.7%\n",
            "Step: 830 ------------ Loss: 10348.53 ------------ Accuracy: 53.7%\n",
            "Step: 831 ------------ Loss: 10347.12 ------------ Accuracy: 53.6%\n",
            "Step: 832 ------------ Loss: 10346.14 ------------ Accuracy: 53.6%\n",
            "Step: 833 ------------ Loss: 10341.38 ------------ Accuracy: 53.6%\n",
            "Step: 834 ------------ Loss: 10341.33 ------------ Accuracy: 53.6%\n",
            "Step: 835 ------------ Loss: 10340.41 ------------ Accuracy: 53.6%\n",
            "Step: 836 ------------ Loss: 10338.53 ------------ Accuracy: 53.6%\n",
            "Step: 837 ------------ Loss: 10338.47 ------------ Accuracy: 53.6%\n",
            "Step: 838 ------------ Loss: 10338.31 ------------ Accuracy: 53.6%\n",
            "Step: 839 ------------ Loss: 10338.17 ------------ Accuracy: 53.6%\n",
            "Step: 840 ------------ Loss: 10338.03 ------------ Accuracy: 53.6%\n",
            "Step: 841 ------------ Loss: 10337.04 ------------ Accuracy: 53.6%\n",
            "Step: 842 ------------ Loss: 10336.61 ------------ Accuracy: 53.7%\n",
            "Step: 843 ------------ Loss: 10334.07 ------------ Accuracy: 53.7%\n",
            "Step: 844 ------------ Loss: 10331.56 ------------ Accuracy: 53.7%\n",
            "Step: 845 ------------ Loss: 10317.12 ------------ Accuracy: 53.8%\n",
            "Step: 846 ------------ Loss: 10316.93 ------------ Accuracy: 53.8%\n",
            "Step: 847 ------------ Loss: 10314.91 ------------ Accuracy: 53.7%\n",
            "Step: 848 ------------ Loss: 10314.82 ------------ Accuracy: 53.7%\n",
            "Step: 849 ------------ Loss: 10312.94 ------------ Accuracy: 53.6%\n",
            "Step: 850 ------------ Loss: 10312.83 ------------ Accuracy: 53.6%\n",
            "Step: 851 ------------ Loss: 10308.57 ------------ Accuracy: 53.6%\n",
            "Step: 852 ------------ Loss: 10308.43 ------------ Accuracy: 53.6%\n",
            "Step: 853 ------------ Loss: 10308.32 ------------ Accuracy: 53.6%\n",
            "Step: 854 ------------ Loss: 10307.35 ------------ Accuracy: 53.6%\n",
            "Step: 855 ------------ Loss: 10306.26 ------------ Accuracy: 53.6%\n",
            "Step: 856 ------------ Loss: 10304.64 ------------ Accuracy: 53.6%\n",
            "Step: 857 ------------ Loss: 10303.89 ------------ Accuracy: 53.7%\n",
            "Step: 858 ------------ Loss: 10303.09 ------------ Accuracy: 53.6%\n",
            "Step: 859 ------------ Loss: 10302.48 ------------ Accuracy: 53.6%\n",
            "Step: 860 ------------ Loss: 10300.11 ------------ Accuracy: 53.6%\n",
            "Step: 861 ------------ Loss: 10299.25 ------------ Accuracy: 53.7%\n",
            "Step: 862 ------------ Loss: 10298.73 ------------ Accuracy: 53.8%\n",
            "Step: 863 ------------ Loss: 10298.67 ------------ Accuracy: 53.8%\n",
            "Step: 864 ------------ Loss: 10298.6 ------------ Accuracy: 53.8%\n",
            "Step: 865 ------------ Loss: 10298.54 ------------ Accuracy: 53.8%\n",
            "Step: 866 ------------ Loss: 10297.91 ------------ Accuracy: 53.8%\n",
            "Step: 867 ------------ Loss: 10295.52 ------------ Accuracy: 53.8%\n",
            "Step: 868 ------------ Loss: 10295.41 ------------ Accuracy: 53.8%\n",
            "Step: 869 ------------ Loss: 10295.36 ------------ Accuracy: 53.8%\n",
            "Step: 870 ------------ Loss: 10294.67 ------------ Accuracy: 53.8%\n",
            "Step: 871 ------------ Loss: 10294.62 ------------ Accuracy: 53.8%\n",
            "Step: 872 ------------ Loss: 10294.27 ------------ Accuracy: 53.8%\n",
            "Step: 873 ------------ Loss: 10293.9 ------------ Accuracy: 54.0%\n",
            "Step: 874 ------------ Loss: 10293.71 ------------ Accuracy: 54.0%\n",
            "Step: 875 ------------ Loss: 10293.15 ------------ Accuracy: 54.0%\n",
            "Step: 876 ------------ Loss: 10291.43 ------------ Accuracy: 54.0%\n",
            "Step: 877 ------------ Loss: 10289.82 ------------ Accuracy: 54.3%\n",
            "Step: 878 ------------ Loss: 10289.75 ------------ Accuracy: 54.3%\n",
            "Step: 879 ------------ Loss: 10289.13 ------------ Accuracy: 54.3%\n",
            "Step: 880 ------------ Loss: 10289.06 ------------ Accuracy: 54.3%\n",
            "Step: 881 ------------ Loss: 10286.61 ------------ Accuracy: 54.1%\n",
            "Step: 882 ------------ Loss: 10286.55 ------------ Accuracy: 54.1%\n",
            "Step: 883 ------------ Loss: 10286.43 ------------ Accuracy: 54.1%\n",
            "Step: 884 ------------ Loss: 10286.37 ------------ Accuracy: 54.1%\n",
            "Step: 885 ------------ Loss: 10285.71 ------------ Accuracy: 54.3%\n",
            "Step: 886 ------------ Loss: 10285.65 ------------ Accuracy: 54.1%\n",
            "Step: 887 ------------ Loss: 10284.79 ------------ Accuracy: 54.1%\n",
            "Step: 888 ------------ Loss: 10284.75 ------------ Accuracy: 54.1%\n",
            "Step: 889 ------------ Loss: 10282.37 ------------ Accuracy: 54.1%\n",
            "Step: 890 ------------ Loss: 10281.8 ------------ Accuracy: 54.1%\n",
            "Step: 891 ------------ Loss: 10281.3 ------------ Accuracy: 54.0%\n",
            "Step: 892 ------------ Loss: 10281.2 ------------ Accuracy: 54.0%\n",
            "Step: 893 ------------ Loss: 10280.94 ------------ Accuracy: 54.1%\n",
            "Step: 894 ------------ Loss: 10280.35 ------------ Accuracy: 54.3%\n",
            "Step: 895 ------------ Loss: 10280.29 ------------ Accuracy: 54.3%\n",
            "Step: 896 ------------ Loss: 10280.09 ------------ Accuracy: 54.3%\n",
            "Step: 897 ------------ Loss: 10279.99 ------------ Accuracy: 54.3%\n",
            "Step: 898 ------------ Loss: 10277.58 ------------ Accuracy: 54.3%\n",
            "Step: 899 ------------ Loss: 10276.51 ------------ Accuracy: 54.3%\n",
            "Step: 900 ------------ Loss: 10274.14 ------------ Accuracy: 54.3%\n",
            "Step: 901 ------------ Loss: 10273.75 ------------ Accuracy: 54.3%\n",
            "Step: 902 ------------ Loss: 10273.68 ------------ Accuracy: 54.3%\n",
            "Step: 903 ------------ Loss: 10269.2 ------------ Accuracy: 54.3%\n",
            "Step: 904 ------------ Loss: 10269.14 ------------ Accuracy: 54.3%\n",
            "Step: 905 ------------ Loss: 10269.09 ------------ Accuracy: 54.3%\n",
            "Step: 906 ------------ Loss: 10269.04 ------------ Accuracy: 54.3%\n",
            "Step: 907 ------------ Loss: 10268.99 ------------ Accuracy: 54.3%\n",
            "Step: 908 ------------ Loss: 10268.91 ------------ Accuracy: 54.3%\n",
            "Step: 909 ------------ Loss: 10268.01 ------------ Accuracy: 54.3%\n",
            "Step: 910 ------------ Loss: 10267.89 ------------ Accuracy: 54.3%\n",
            "Step: 911 ------------ Loss: 10267.5 ------------ Accuracy: 54.3%\n",
            "Step: 912 ------------ Loss: 10266.42 ------------ Accuracy: 54.3%\n",
            "Step: 913 ------------ Loss: 10266.38 ------------ Accuracy: 54.3%\n",
            "Step: 914 ------------ Loss: 10266.07 ------------ Accuracy: 54.3%\n",
            "Step: 915 ------------ Loss: 10251.93 ------------ Accuracy: 54.1%\n",
            "Step: 916 ------------ Loss: 10251.62 ------------ Accuracy: 54.1%\n",
            "Step: 917 ------------ Loss: 10251.45 ------------ Accuracy: 54.1%\n",
            "Step: 918 ------------ Loss: 10251.21 ------------ Accuracy: 54.2%\n",
            "Step: 919 ------------ Loss: 10251.09 ------------ Accuracy: 54.2%\n",
            "Step: 920 ------------ Loss: 10251.02 ------------ Accuracy: 54.2%\n",
            "Step: 921 ------------ Loss: 10251.0 ------------ Accuracy: 54.2%\n",
            "Step: 922 ------------ Loss: 10237.74 ------------ Accuracy: 54.1%\n",
            "Step: 923 ------------ Loss: 10237.68 ------------ Accuracy: 54.1%\n",
            "Step: 924 ------------ Loss: 10237.57 ------------ Accuracy: 54.1%\n",
            "Step: 925 ------------ Loss: 10235.7 ------------ Accuracy: 54.1%\n",
            "Step: 926 ------------ Loss: 10235.59 ------------ Accuracy: 54.1%\n",
            "Step: 927 ------------ Loss: 10234.62 ------------ Accuracy: 54.1%\n",
            "Step: 928 ------------ Loss: 10234.31 ------------ Accuracy: 54.1%\n",
            "Step: 929 ------------ Loss: 10234.01 ------------ Accuracy: 54.1%\n",
            "Step: 930 ------------ Loss: 10233.55 ------------ Accuracy: 54.0%\n",
            "Step: 931 ------------ Loss: 10233.22 ------------ Accuracy: 54.0%\n",
            "Step: 932 ------------ Loss: 10231.36 ------------ Accuracy: 54.0%\n",
            "Step: 933 ------------ Loss: 10230.96 ------------ Accuracy: 54.1%\n",
            "Step: 934 ------------ Loss: 10230.13 ------------ Accuracy: 54.1%\n",
            "Step: 935 ------------ Loss: 10229.83 ------------ Accuracy: 54.1%\n",
            "Step: 936 ------------ Loss: 10229.31 ------------ Accuracy: 54.2%\n",
            "Step: 937 ------------ Loss: 10229.21 ------------ Accuracy: 54.2%\n",
            "Step: 938 ------------ Loss: 10229.15 ------------ Accuracy: 54.2%\n",
            "Step: 939 ------------ Loss: 10226.96 ------------ Accuracy: 54.2%\n",
            "Step: 940 ------------ Loss: 10226.74 ------------ Accuracy: 54.2%\n",
            "Step: 941 ------------ Loss: 10225.03 ------------ Accuracy: 54.2%\n",
            "Step: 942 ------------ Loss: 10224.45 ------------ Accuracy: 54.2%\n",
            "Step: 943 ------------ Loss: 10223.61 ------------ Accuracy: 54.2%\n",
            "Step: 944 ------------ Loss: 10223.03 ------------ Accuracy: 54.2%\n",
            "Step: 945 ------------ Loss: 10223.0 ------------ Accuracy: 54.2%\n",
            "Step: 946 ------------ Loss: 10222.93 ------------ Accuracy: 54.2%\n",
            "Step: 947 ------------ Loss: 10222.1 ------------ Accuracy: 54.2%\n",
            "Step: 948 ------------ Loss: 10209.17 ------------ Accuracy: 54.2%\n",
            "Step: 949 ------------ Loss: 10209.1 ------------ Accuracy: 54.2%\n",
            "Step: 950 ------------ Loss: 10208.99 ------------ Accuracy: 54.2%\n",
            "Step: 951 ------------ Loss: 10208.9 ------------ Accuracy: 54.2%\n",
            "Step: 952 ------------ Loss: 10208.82 ------------ Accuracy: 54.2%\n",
            "Step: 953 ------------ Loss: 10208.75 ------------ Accuracy: 54.2%\n",
            "Step: 954 ------------ Loss: 10208.69 ------------ Accuracy: 54.2%\n",
            "Step: 955 ------------ Loss: 10206.98 ------------ Accuracy: 54.2%\n",
            "Step: 956 ------------ Loss: 10206.92 ------------ Accuracy: 54.2%\n",
            "Step: 957 ------------ Loss: 10205.97 ------------ Accuracy: 54.2%\n",
            "Step: 958 ------------ Loss: 10205.46 ------------ Accuracy: 54.1%\n",
            "Step: 959 ------------ Loss: 10204.54 ------------ Accuracy: 54.1%\n",
            "Step: 960 ------------ Loss: 10204.46 ------------ Accuracy: 54.1%\n",
            "Step: 961 ------------ Loss: 10203.87 ------------ Accuracy: 54.1%\n",
            "Step: 962 ------------ Loss: 10203.28 ------------ Accuracy: 54.1%\n",
            "Step: 963 ------------ Loss: 10203.21 ------------ Accuracy: 54.1%\n",
            "Step: 964 ------------ Loss: 10202.93 ------------ Accuracy: 54.0%\n",
            "Step: 965 ------------ Loss: 10200.84 ------------ Accuracy: 54.1%\n",
            "Step: 966 ------------ Loss: 10199.92 ------------ Accuracy: 54.1%\n",
            "Step: 967 ------------ Loss: 10199.86 ------------ Accuracy: 54.1%\n",
            "Step: 968 ------------ Loss: 10199.79 ------------ Accuracy: 54.1%\n",
            "Step: 969 ------------ Loss: 10199.53 ------------ Accuracy: 54.2%\n",
            "Step: 970 ------------ Loss: 10199.47 ------------ Accuracy: 54.2%\n",
            "Step: 971 ------------ Loss: 10199.37 ------------ Accuracy: 54.2%\n",
            "Step: 972 ------------ Loss: 10187.14 ------------ Accuracy: 54.0%\n",
            "Step: 973 ------------ Loss: 10186.36 ------------ Accuracy: 54.0%\n",
            "Step: 974 ------------ Loss: 10186.23 ------------ Accuracy: 54.0%\n",
            "Step: 975 ------------ Loss: 10185.65 ------------ Accuracy: 54.0%\n",
            "Step: 976 ------------ Loss: 10185.37 ------------ Accuracy: 54.0%\n",
            "Step: 977 ------------ Loss: 10184.79 ------------ Accuracy: 54.0%\n",
            "Step: 978 ------------ Loss: 10173.37 ------------ Accuracy: 54.1%\n",
            "Step: 979 ------------ Loss: 10173.31 ------------ Accuracy: 54.1%\n",
            "Step: 980 ------------ Loss: 10173.19 ------------ Accuracy: 54.1%\n",
            "Step: 981 ------------ Loss: 10173.08 ------------ Accuracy: 54.1%\n",
            "Step: 982 ------------ Loss: 10172.96 ------------ Accuracy: 54.1%\n",
            "Step: 983 ------------ Loss: 10171.05 ------------ Accuracy: 54.1%\n",
            "Step: 984 ------------ Loss: 10166.61 ------------ Accuracy: 54.0%\n",
            "Step: 985 ------------ Loss: 10166.52 ------------ Accuracy: 54.0%\n",
            "Step: 986 ------------ Loss: 10166.39 ------------ Accuracy: 54.0%\n",
            "Step: 987 ------------ Loss: 10165.54 ------------ Accuracy: 54.1%\n",
            "Step: 988 ------------ Loss: 10165.43 ------------ Accuracy: 54.1%\n",
            "Step: 989 ------------ Loss: 10165.35 ------------ Accuracy: 54.1%\n",
            "Step: 990 ------------ Loss: 10165.28 ------------ Accuracy: 54.1%\n",
            "Step: 991 ------------ Loss: 10164.5 ------------ Accuracy: 54.1%\n",
            "Step: 992 ------------ Loss: 10163.78 ------------ Accuracy: 54.0%\n",
            "Step: 993 ------------ Loss: 10163.68 ------------ Accuracy: 54.0%\n",
            "Step: 994 ------------ Loss: 10163.6 ------------ Accuracy: 54.0%\n",
            "Step: 995 ------------ Loss: 10163.54 ------------ Accuracy: 54.0%\n",
            "Step: 996 ------------ Loss: 10161.55 ------------ Accuracy: 54.0%\n",
            "Step: 997 ------------ Loss: 10161.45 ------------ Accuracy: 54.0%\n",
            "Step: 998 ------------ Loss: 10150.11 ------------ Accuracy: 54.2%\n",
            "Step: 999 ------------ Loss: 10149.32 ------------ Accuracy: 54.1%\n",
            "Step: 1000 ------------ Loss: 10148.48 ------------ Accuracy: 54.2%\n",
            "Step: 1001 ------------ Loss: 10147.79 ------------ Accuracy: 54.2%\n",
            "Step: 1002 ------------ Loss: 10147.72 ------------ Accuracy: 54.2%\n",
            "Step: 1003 ------------ Loss: 10147.17 ------------ Accuracy: 54.2%\n",
            "Step: 1004 ------------ Loss: 10147.07 ------------ Accuracy: 54.2%\n",
            "Step: 1005 ------------ Loss: 10147.0 ------------ Accuracy: 54.2%\n",
            "Step: 1006 ------------ Loss: 10146.95 ------------ Accuracy: 54.2%\n",
            "Step: 1007 ------------ Loss: 10146.69 ------------ Accuracy: 54.2%\n",
            "Step: 1008 ------------ Loss: 10146.61 ------------ Accuracy: 54.2%\n",
            "Step: 1009 ------------ Loss: 10146.49 ------------ Accuracy: 54.2%\n",
            "Step: 1010 ------------ Loss: 10145.83 ------------ Accuracy: 54.2%\n",
            "Step: 1011 ------------ Loss: 10145.76 ------------ Accuracy: 54.2%\n",
            "Step: 1012 ------------ Loss: 10134.26 ------------ Accuracy: 54.2%\n",
            "Step: 1013 ------------ Loss: 10134.17 ------------ Accuracy: 54.2%\n",
            "Step: 1014 ------------ Loss: 10134.06 ------------ Accuracy: 54.2%\n",
            "Step: 1015 ------------ Loss: 10133.96 ------------ Accuracy: 54.2%\n",
            "Step: 1016 ------------ Loss: 10133.89 ------------ Accuracy: 54.2%\n",
            "Step: 1017 ------------ Loss: 10133.63 ------------ Accuracy: 54.2%\n",
            "Step: 1018 ------------ Loss: 10133.07 ------------ Accuracy: 54.2%\n",
            "Step: 1019 ------------ Loss: 10132.51 ------------ Accuracy: 54.2%\n",
            "Step: 1020 ------------ Loss: 10132.39 ------------ Accuracy: 54.2%\n",
            "Step: 1021 ------------ Loss: 10131.94 ------------ Accuracy: 54.2%\n",
            "Step: 1022 ------------ Loss: 10131.87 ------------ Accuracy: 54.2%\n",
            "Step: 1023 ------------ Loss: 10131.78 ------------ Accuracy: 54.2%\n",
            "Step: 1024 ------------ Loss: 10131.2 ------------ Accuracy: 54.2%\n",
            "Step: 1025 ------------ Loss: 10131.14 ------------ Accuracy: 54.2%\n",
            "Step: 1026 ------------ Loss: 10130.72 ------------ Accuracy: 54.2%\n",
            "Step: 1027 ------------ Loss: 10130.45 ------------ Accuracy: 54.2%\n",
            "Step: 1028 ------------ Loss: 10130.14 ------------ Accuracy: 54.1%\n",
            "Step: 1029 ------------ Loss: 10130.03 ------------ Accuracy: 54.1%\n",
            "Step: 1030 ------------ Loss: 10129.96 ------------ Accuracy: 54.1%\n",
            "Step: 1031 ------------ Loss: 10129.73 ------------ Accuracy: 54.1%\n",
            "Step: 1032 ------------ Loss: 10128.54 ------------ Accuracy: 54.1%\n",
            "Step: 1033 ------------ Loss: 10124.24 ------------ Accuracy: 54.0%\n",
            "Step: 1034 ------------ Loss: 10124.15 ------------ Accuracy: 54.0%\n",
            "Step: 1035 ------------ Loss: 10123.32 ------------ Accuracy: 54.0%\n",
            "Step: 1036 ------------ Loss: 10119.33 ------------ Accuracy: 54.0%\n",
            "Step: 1037 ------------ Loss: 10118.81 ------------ Accuracy: 54.2%\n",
            "Step: 1038 ------------ Loss: 10115.1 ------------ Accuracy: 54.2%\n",
            "Step: 1039 ------------ Loss: 10115.04 ------------ Accuracy: 54.2%\n",
            "Step: 1040 ------------ Loss: 10114.21 ------------ Accuracy: 54.2%\n",
            "Step: 1041 ------------ Loss: 10113.66 ------------ Accuracy: 54.3%\n",
            "Step: 1042 ------------ Loss: 10113.61 ------------ Accuracy: 54.3%\n",
            "Step: 1043 ------------ Loss: 10112.87 ------------ Accuracy: 54.2%\n",
            "Step: 1044 ------------ Loss: 10110.87 ------------ Accuracy: 54.2%\n",
            "Step: 1045 ------------ Loss: 10110.1 ------------ Accuracy: 54.3%\n",
            "Step: 1046 ------------ Loss: 10110.05 ------------ Accuracy: 54.3%\n",
            "Step: 1047 ------------ Loss: 10109.55 ------------ Accuracy: 54.2%\n",
            "Step: 1048 ------------ Loss: 10109.52 ------------ Accuracy: 54.2%\n",
            "Step: 1049 ------------ Loss: 10109.41 ------------ Accuracy: 54.2%\n",
            "Step: 1050 ------------ Loss: 10109.3 ------------ Accuracy: 54.2%\n",
            "Step: 1051 ------------ Loss: 10109.02 ------------ Accuracy: 54.2%\n",
            "Step: 1052 ------------ Loss: 10108.18 ------------ Accuracy: 54.2%\n",
            "Step: 1053 ------------ Loss: 10108.06 ------------ Accuracy: 54.2%\n",
            "Step: 1054 ------------ Loss: 10096.95 ------------ Accuracy: 54.1%\n",
            "Step: 1055 ------------ Loss: 10096.89 ------------ Accuracy: 54.1%\n",
            "Step: 1056 ------------ Loss: 10096.61 ------------ Accuracy: 54.1%\n",
            "Step: 1057 ------------ Loss: 10095.15 ------------ Accuracy: 54.1%\n",
            "Step: 1058 ------------ Loss: 10094.87 ------------ Accuracy: 54.0%\n",
            "Step: 1059 ------------ Loss: 10094.8 ------------ Accuracy: 54.0%\n",
            "Step: 1060 ------------ Loss: 10094.63 ------------ Accuracy: 54.0%\n",
            "Step: 1061 ------------ Loss: 10084.11 ------------ Accuracy: 54.2%\n",
            "Step: 1062 ------------ Loss: 10083.37 ------------ Accuracy: 54.2%\n",
            "Step: 1063 ------------ Loss: 10081.85 ------------ Accuracy: 54.0%\n",
            "Step: 1064 ------------ Loss: 10081.08 ------------ Accuracy: 54.1%\n",
            "Step: 1065 ------------ Loss: 10080.31 ------------ Accuracy: 54.1%\n",
            "Step: 1066 ------------ Loss: 10080.04 ------------ Accuracy: 54.1%\n",
            "Step: 1067 ------------ Loss: 10079.37 ------------ Accuracy: 54.2%\n",
            "Step: 1068 ------------ Loss: 10069.16 ------------ Accuracy: 54.2%\n",
            "Step: 1069 ------------ Loss: 10069.07 ------------ Accuracy: 54.2%\n",
            "Step: 1070 ------------ Loss: 10067.84 ------------ Accuracy: 54.2%\n",
            "Step: 1071 ------------ Loss: 10067.35 ------------ Accuracy: 54.3%\n",
            "Step: 1072 ------------ Loss: 10067.29 ------------ Accuracy: 54.3%\n",
            "Step: 1073 ------------ Loss: 10067.23 ------------ Accuracy: 54.3%\n",
            "Step: 1074 ------------ Loss: 10066.83 ------------ Accuracy: 54.2%\n",
            "Step: 1075 ------------ Loss: 10065.41 ------------ Accuracy: 54.2%\n",
            "Step: 1076 ------------ Loss: 10065.35 ------------ Accuracy: 54.2%\n",
            "Step: 1077 ------------ Loss: 10064.56 ------------ Accuracy: 54.3%\n",
            "Step: 1078 ------------ Loss: 10064.51 ------------ Accuracy: 54.3%\n",
            "Step: 1079 ------------ Loss: 10064.43 ------------ Accuracy: 54.3%\n",
            "Step: 1080 ------------ Loss: 10064.25 ------------ Accuracy: 54.2%\n",
            "Step: 1081 ------------ Loss: 10064.0 ------------ Accuracy: 54.2%\n",
            "Step: 1082 ------------ Loss: 10063.93 ------------ Accuracy: 54.4%\n",
            "Step: 1083 ------------ Loss: 10063.38 ------------ Accuracy: 54.2%\n",
            "Step: 1084 ------------ Loss: 10062.89 ------------ Accuracy: 54.2%\n",
            "Step: 1085 ------------ Loss: 10052.49 ------------ Accuracy: 54.2%\n",
            "Step: 1086 ------------ Loss: 10050.75 ------------ Accuracy: 54.2%\n",
            "Step: 1087 ------------ Loss: 10050.68 ------------ Accuracy: 54.2%\n",
            "Step: 1088 ------------ Loss: 10050.64 ------------ Accuracy: 54.3%\n",
            "Step: 1089 ------------ Loss: 10050.57 ------------ Accuracy: 54.2%\n",
            "Step: 1090 ------------ Loss: 10049.78 ------------ Accuracy: 54.3%\n",
            "Step: 1091 ------------ Loss: 10049.54 ------------ Accuracy: 54.3%\n",
            "Step: 1092 ------------ Loss: 10049.48 ------------ Accuracy: 54.3%\n",
            "Step: 1093 ------------ Loss: 10049.41 ------------ Accuracy: 54.3%\n",
            "Step: 1094 ------------ Loss: 10048.92 ------------ Accuracy: 54.3%\n",
            "Step: 1095 ------------ Loss: 10044.92 ------------ Accuracy: 54.2%\n",
            "Step: 1096 ------------ Loss: 10044.87 ------------ Accuracy: 54.2%\n",
            "Step: 1097 ------------ Loss: 10044.84 ------------ Accuracy: 54.2%\n",
            "Step: 1098 ------------ Loss: 10044.8 ------------ Accuracy: 54.2%\n",
            "Step: 1099 ------------ Loss: 10044.11 ------------ Accuracy: 54.3%\n",
            "Step: 1100 ------------ Loss: 10043.6 ------------ Accuracy: 54.3%\n",
            "Step: 1101 ------------ Loss: 10043.0 ------------ Accuracy: 54.3%\n",
            "Step: 1102 ------------ Loss: 10041.16 ------------ Accuracy: 54.3%\n",
            "Step: 1103 ------------ Loss: 10041.12 ------------ Accuracy: 54.3%\n",
            "Step: 1104 ------------ Loss: 10041.04 ------------ Accuracy: 54.3%\n",
            "Step: 1105 ------------ Loss: 10040.98 ------------ Accuracy: 54.3%\n",
            "Step: 1106 ------------ Loss: 10040.54 ------------ Accuracy: 54.4%\n",
            "Step: 1107 ------------ Loss: 10040.26 ------------ Accuracy: 54.4%\n",
            "Step: 1108 ------------ Loss: 10040.07 ------------ Accuracy: 54.5%\n",
            "Step: 1109 ------------ Loss: 10039.98 ------------ Accuracy: 54.4%\n",
            "Step: 1110 ------------ Loss: 10035.99 ------------ Accuracy: 54.5%\n",
            "Step: 1111 ------------ Loss: 10035.79 ------------ Accuracy: 54.5%\n",
            "Step: 1112 ------------ Loss: 10035.6 ------------ Accuracy: 54.5%\n",
            "Step: 1113 ------------ Loss: 10035.51 ------------ Accuracy: 54.4%\n",
            "Step: 1114 ------------ Loss: 10034.67 ------------ Accuracy: 54.4%\n",
            "Step: 1115 ------------ Loss: 10033.84 ------------ Accuracy: 54.4%\n",
            "Step: 1116 ------------ Loss: 10033.14 ------------ Accuracy: 54.4%\n",
            "Step: 1117 ------------ Loss: 10032.29 ------------ Accuracy: 54.4%\n",
            "Step: 1118 ------------ Loss: 10032.04 ------------ Accuracy: 54.4%\n",
            "Step: 1119 ------------ Loss: 10031.34 ------------ Accuracy: 54.4%\n",
            "Step: 1120 ------------ Loss: 10031.08 ------------ Accuracy: 54.4%\n",
            "Step: 1121 ------------ Loss: 10030.26 ------------ Accuracy: 54.4%\n",
            "Step: 1122 ------------ Loss: 10030.22 ------------ Accuracy: 54.4%\n",
            "Step: 1123 ------------ Loss: 10030.04 ------------ Accuracy: 54.4%\n",
            "Step: 1124 ------------ Loss: 10029.95 ------------ Accuracy: 54.4%\n",
            "Step: 1125 ------------ Loss: 10029.09 ------------ Accuracy: 54.4%\n",
            "Step: 1126 ------------ Loss: 10029.06 ------------ Accuracy: 54.4%\n",
            "Step: 1127 ------------ Loss: 10029.04 ------------ Accuracy: 54.4%\n",
            "Step: 1128 ------------ Loss: 10028.24 ------------ Accuracy: 54.4%\n",
            "Step: 1129 ------------ Loss: 10017.71 ------------ Accuracy: 54.4%\n",
            "Step: 1130 ------------ Loss: 10017.24 ------------ Accuracy: 54.4%\n",
            "Step: 1131 ------------ Loss: 10015.48 ------------ Accuracy: 54.4%\n",
            "Step: 1132 ------------ Loss: 10015.41 ------------ Accuracy: 54.4%\n",
            "Step: 1133 ------------ Loss: 10014.99 ------------ Accuracy: 54.2%\n",
            "Step: 1134 ------------ Loss: 10013.66 ------------ Accuracy: 54.4%\n",
            "Step: 1135 ------------ Loss: 10003.86 ------------ Accuracy: 54.2%\n",
            "Step: 1136 ------------ Loss: 10003.39 ------------ Accuracy: 54.3%\n",
            "Step: 1137 ------------ Loss: 10003.35 ------------ Accuracy: 54.3%\n",
            "Step: 1138 ------------ Loss: 10002.94 ------------ Accuracy: 54.4%\n",
            "Step: 1139 ------------ Loss: 10002.84 ------------ Accuracy: 54.4%\n",
            "Step: 1140 ------------ Loss: 10002.65 ------------ Accuracy: 54.4%\n",
            "Step: 1141 ------------ Loss: 10002.57 ------------ Accuracy: 54.4%\n",
            "Step: 1142 ------------ Loss: 10002.09 ------------ Accuracy: 54.4%\n",
            "Step: 1143 ------------ Loss: 9992.49 ------------ Accuracy: 54.2%\n",
            "Step: 1144 ------------ Loss: 9990.87 ------------ Accuracy: 54.2%\n",
            "Step: 1145 ------------ Loss: 9990.76 ------------ Accuracy: 54.2%\n",
            "Step: 1146 ------------ Loss: 9990.7 ------------ Accuracy: 54.2%\n",
            "Step: 1147 ------------ Loss: 9989.89 ------------ Accuracy: 54.4%\n",
            "Step: 1148 ------------ Loss: 9989.82 ------------ Accuracy: 54.4%\n",
            "Step: 1149 ------------ Loss: 9989.77 ------------ Accuracy: 54.4%\n",
            "Step: 1150 ------------ Loss: 9989.76 ------------ Accuracy: 54.4%\n",
            "Step: 1151 ------------ Loss: 9989.75 ------------ Accuracy: 54.4%\n",
            "Step: 1152 ------------ Loss: 9988.08 ------------ Accuracy: 54.4%\n",
            "Step: 1153 ------------ Loss: 9988.07 ------------ Accuracy: 54.4%\n",
            "Step: 1154 ------------ Loss: 9988.03 ------------ Accuracy: 54.4%\n",
            "Step: 1155 ------------ Loss: 9986.37 ------------ Accuracy: 54.4%\n",
            "Step: 1156 ------------ Loss: 9985.02 ------------ Accuracy: 54.4%\n",
            "Step: 1157 ------------ Loss: 9984.95 ------------ Accuracy: 54.4%\n",
            "Step: 1158 ------------ Loss: 9984.24 ------------ Accuracy: 54.4%\n",
            "Step: 1159 ------------ Loss: 9983.7 ------------ Accuracy: 54.4%\n",
            "Step: 1160 ------------ Loss: 9982.44 ------------ Accuracy: 54.4%\n",
            "Step: 1161 ------------ Loss: 9982.2 ------------ Accuracy: 54.4%\n",
            "Step: 1162 ------------ Loss: 9981.54 ------------ Accuracy: 54.4%\n",
            "Step: 1163 ------------ Loss: 9981.48 ------------ Accuracy: 54.4%\n",
            "Step: 1164 ------------ Loss: 9981.41 ------------ Accuracy: 54.4%\n",
            "Step: 1165 ------------ Loss: 9981.39 ------------ Accuracy: 54.4%\n",
            "Step: 1166 ------------ Loss: 9981.33 ------------ Accuracy: 54.4%\n",
            "Step: 1167 ------------ Loss: 9981.27 ------------ Accuracy: 54.4%\n",
            "Step: 1168 ------------ Loss: 9981.04 ------------ Accuracy: 54.4%\n",
            "Step: 1169 ------------ Loss: 9981.0 ------------ Accuracy: 54.4%\n",
            "Step: 1170 ------------ Loss: 9980.48 ------------ Accuracy: 54.4%\n",
            "Step: 1171 ------------ Loss: 9980.14 ------------ Accuracy: 54.4%\n",
            "Step: 1172 ------------ Loss: 9978.43 ------------ Accuracy: 54.4%\n",
            "Step: 1173 ------------ Loss: 9978.12 ------------ Accuracy: 54.4%\n",
            "Step: 1174 ------------ Loss: 9977.86 ------------ Accuracy: 54.4%\n",
            "Step: 1175 ------------ Loss: 9977.64 ------------ Accuracy: 54.4%\n",
            "Step: 1176 ------------ Loss: 9977.55 ------------ Accuracy: 54.4%\n",
            "Step: 1177 ------------ Loss: 9976.75 ------------ Accuracy: 54.4%\n",
            "Step: 1178 ------------ Loss: 9976.67 ------------ Accuracy: 54.4%\n",
            "Step: 1179 ------------ Loss: 9976.58 ------------ Accuracy: 54.4%\n",
            "Step: 1180 ------------ Loss: 9966.94 ------------ Accuracy: 54.4%\n",
            "Step: 1181 ------------ Loss: 9966.83 ------------ Accuracy: 54.4%\n",
            "Step: 1182 ------------ Loss: 9966.77 ------------ Accuracy: 54.4%\n",
            "Step: 1183 ------------ Loss: 9966.7 ------------ Accuracy: 54.4%\n",
            "Step: 1184 ------------ Loss: 9966.65 ------------ Accuracy: 54.4%\n",
            "Step: 1185 ------------ Loss: 9966.6 ------------ Accuracy: 54.4%\n",
            "Step: 1186 ------------ Loss: 9966.18 ------------ Accuracy: 54.4%\n",
            "Step: 1187 ------------ Loss: 9962.37 ------------ Accuracy: 54.4%\n",
            "Step: 1188 ------------ Loss: 9961.72 ------------ Accuracy: 54.4%\n",
            "Step: 1189 ------------ Loss: 9952.74 ------------ Accuracy: 54.2%\n",
            "Step: 1190 ------------ Loss: 9952.67 ------------ Accuracy: 54.2%\n",
            "Step: 1191 ------------ Loss: 9944.23 ------------ Accuracy: 54.3%\n",
            "Step: 1192 ------------ Loss: 9936.27 ------------ Accuracy: 54.3%\n",
            "Step: 1193 ------------ Loss: 9936.15 ------------ Accuracy: 54.3%\n",
            "Step: 1194 ------------ Loss: 9935.49 ------------ Accuracy: 54.3%\n",
            "Step: 1195 ------------ Loss: 9934.77 ------------ Accuracy: 54.3%\n",
            "Step: 1196 ------------ Loss: 9934.14 ------------ Accuracy: 54.3%\n",
            "Step: 1197 ------------ Loss: 9933.91 ------------ Accuracy: 54.3%\n",
            "Step: 1198 ------------ Loss: 9933.66 ------------ Accuracy: 54.3%\n",
            "Step: 1199 ------------ Loss: 9933.56 ------------ Accuracy: 54.3%\n",
            "Step: 1200 ------------ Loss: 9933.37 ------------ Accuracy: 54.3%\n",
            "Step: 1201 ------------ Loss: 9933.3 ------------ Accuracy: 54.3%\n",
            "Step: 1202 ------------ Loss: 9931.85 ------------ Accuracy: 54.3%\n",
            "Step: 1203 ------------ Loss: 9930.43 ------------ Accuracy: 54.3%\n",
            "Step: 1204 ------------ Loss: 9922.72 ------------ Accuracy: 54.3%\n",
            "Step: 1205 ------------ Loss: 9922.38 ------------ Accuracy: 54.3%\n",
            "Step: 1206 ------------ Loss: 9921.84 ------------ Accuracy: 54.3%\n",
            "Step: 1207 ------------ Loss: 9921.3 ------------ Accuracy: 54.3%\n",
            "Step: 1208 ------------ Loss: 9921.13 ------------ Accuracy: 54.3%\n",
            "Step: 1209 ------------ Loss: 9919.56 ------------ Accuracy: 54.4%\n",
            "Step: 1210 ------------ Loss: 9919.5 ------------ Accuracy: 54.4%\n",
            "Step: 1211 ------------ Loss: 9919.03 ------------ Accuracy: 54.5%\n",
            "Step: 1212 ------------ Loss: 9918.96 ------------ Accuracy: 54.5%\n",
            "Step: 1213 ------------ Loss: 9918.9 ------------ Accuracy: 54.4%\n",
            "Step: 1214 ------------ Loss: 9918.83 ------------ Accuracy: 54.4%\n",
            "Step: 1215 ------------ Loss: 9918.76 ------------ Accuracy: 54.4%\n",
            "Step: 1216 ------------ Loss: 9918.27 ------------ Accuracy: 54.4%\n",
            "Step: 1217 ------------ Loss: 9918.2 ------------ Accuracy: 54.4%\n",
            "Step: 1218 ------------ Loss: 9918.14 ------------ Accuracy: 54.4%\n",
            "Step: 1219 ------------ Loss: 9918.08 ------------ Accuracy: 54.4%\n",
            "Step: 1220 ------------ Loss: 9918.02 ------------ Accuracy: 54.4%\n",
            "Step: 1221 ------------ Loss: 9917.95 ------------ Accuracy: 54.4%\n",
            "Step: 1222 ------------ Loss: 9917.89 ------------ Accuracy: 54.4%\n",
            "Step: 1223 ------------ Loss: 9917.52 ------------ Accuracy: 54.2%\n",
            "Step: 1224 ------------ Loss: 9917.18 ------------ Accuracy: 54.3%\n",
            "Step: 1225 ------------ Loss: 9916.93 ------------ Accuracy: 54.4%\n",
            "Step: 1226 ------------ Loss: 9916.78 ------------ Accuracy: 54.4%\n",
            "Step: 1227 ------------ Loss: 9916.65 ------------ Accuracy: 54.4%\n",
            "Step: 1228 ------------ Loss: 9916.6 ------------ Accuracy: 54.4%\n",
            "Step: 1229 ------------ Loss: 9908.52 ------------ Accuracy: 54.4%\n",
            "Step: 1230 ------------ Loss: 9908.46 ------------ Accuracy: 54.4%\n",
            "Step: 1231 ------------ Loss: 9908.4 ------------ Accuracy: 54.4%\n",
            "Step: 1232 ------------ Loss: 9908.19 ------------ Accuracy: 54.4%\n",
            "Step: 1233 ------------ Loss: 9906.77 ------------ Accuracy: 54.4%\n",
            "Step: 1234 ------------ Loss: 9906.72 ------------ Accuracy: 54.4%\n",
            "Step: 1235 ------------ Loss: 9906.49 ------------ Accuracy: 54.4%\n",
            "Step: 1236 ------------ Loss: 9906.44 ------------ Accuracy: 54.4%\n",
            "Step: 1237 ------------ Loss: 9906.37 ------------ Accuracy: 54.4%\n",
            "Step: 1238 ------------ Loss: 9898.62 ------------ Accuracy: 54.4%\n",
            "Step: 1239 ------------ Loss: 9897.23 ------------ Accuracy: 54.4%\n",
            "Step: 1240 ------------ Loss: 9897.18 ------------ Accuracy: 54.4%\n",
            "Step: 1241 ------------ Loss: 9897.0 ------------ Accuracy: 54.4%\n",
            "Step: 1242 ------------ Loss: 9896.89 ------------ Accuracy: 54.4%\n",
            "Step: 1243 ------------ Loss: 9896.82 ------------ Accuracy: 54.4%\n",
            "Step: 1244 ------------ Loss: 9895.79 ------------ Accuracy: 54.2%\n",
            "Step: 1245 ------------ Loss: 9895.72 ------------ Accuracy: 54.2%\n",
            "Step: 1246 ------------ Loss: 9895.51 ------------ Accuracy: 54.2%\n",
            "Step: 1247 ------------ Loss: 9895.46 ------------ Accuracy: 54.2%\n",
            "Step: 1248 ------------ Loss: 9895.44 ------------ Accuracy: 54.2%\n",
            "Step: 1249 ------------ Loss: 9895.11 ------------ Accuracy: 54.4%\n",
            "Step: 1250 ------------ Loss: 9895.04 ------------ Accuracy: 54.4%\n",
            "Step: 1251 ------------ Loss: 9895.02 ------------ Accuracy: 54.4%\n",
            "Step: 1252 ------------ Loss: 9894.25 ------------ Accuracy: 54.2%\n",
            "Step: 1253 ------------ Loss: 9893.66 ------------ Accuracy: 54.3%\n",
            "Step: 1254 ------------ Loss: 9893.4 ------------ Accuracy: 54.4%\n",
            "Step: 1255 ------------ Loss: 9893.35 ------------ Accuracy: 54.4%\n",
            "Step: 1256 ------------ Loss: 9893.3 ------------ Accuracy: 54.4%\n",
            "Step: 1257 ------------ Loss: 9892.96 ------------ Accuracy: 54.4%\n",
            "Step: 1258 ------------ Loss: 9892.89 ------------ Accuracy: 54.4%\n",
            "Step: 1259 ------------ Loss: 9892.86 ------------ Accuracy: 54.4%\n",
            "Step: 1260 ------------ Loss: 9892.77 ------------ Accuracy: 54.4%\n",
            "Step: 1261 ------------ Loss: 9892.13 ------------ Accuracy: 54.4%\n",
            "Step: 1262 ------------ Loss: 9891.55 ------------ Accuracy: 54.4%\n",
            "Step: 1263 ------------ Loss: 9891.54 ------------ Accuracy: 54.4%\n",
            "Step: 1264 ------------ Loss: 9883.38 ------------ Accuracy: 54.3%\n",
            "Step: 1265 ------------ Loss: 9883.26 ------------ Accuracy: 54.3%\n",
            "Step: 1266 ------------ Loss: 9883.06 ------------ Accuracy: 54.3%\n",
            "Step: 1267 ------------ Loss: 9879.16 ------------ Accuracy: 54.3%\n",
            "Step: 1268 ------------ Loss: 9871.39 ------------ Accuracy: 54.3%\n",
            "Step: 1269 ------------ Loss: 9870.81 ------------ Accuracy: 54.3%\n",
            "Step: 1270 ------------ Loss: 9870.77 ------------ Accuracy: 54.3%\n",
            "Step: 1271 ------------ Loss: 9870.25 ------------ Accuracy: 54.3%\n",
            "Step: 1272 ------------ Loss: 9869.98 ------------ Accuracy: 54.4%\n",
            "Step: 1273 ------------ Loss: 9866.34 ------------ Accuracy: 54.4%\n",
            "Step: 1274 ------------ Loss: 9865.74 ------------ Accuracy: 54.4%\n",
            "Step: 1275 ------------ Loss: 9865.69 ------------ Accuracy: 54.4%\n",
            "Step: 1276 ------------ Loss: 9862.29 ------------ Accuracy: 54.4%\n",
            "Step: 1277 ------------ Loss: 9862.24 ------------ Accuracy: 54.4%\n",
            "Step: 1278 ------------ Loss: 9862.18 ------------ Accuracy: 54.4%\n",
            "Step: 1279 ------------ Loss: 9861.79 ------------ Accuracy: 54.4%\n",
            "Step: 1280 ------------ Loss: 9861.58 ------------ Accuracy: 54.4%\n",
            "Step: 1281 ------------ Loss: 9861.51 ------------ Accuracy: 54.4%\n",
            "Step: 1282 ------------ Loss: 9860.91 ------------ Accuracy: 54.4%\n",
            "Step: 1283 ------------ Loss: 9860.8 ------------ Accuracy: 54.4%\n",
            "Step: 1284 ------------ Loss: 9860.73 ------------ Accuracy: 54.4%\n",
            "Step: 1285 ------------ Loss: 9860.69 ------------ Accuracy: 54.4%\n",
            "Step: 1286 ------------ Loss: 9860.21 ------------ Accuracy: 54.4%\n",
            "Step: 1287 ------------ Loss: 9852.66 ------------ Accuracy: 54.4%\n",
            "Step: 1288 ------------ Loss: 9852.61 ------------ Accuracy: 54.4%\n",
            "Step: 1289 ------------ Loss: 9852.43 ------------ Accuracy: 54.4%\n",
            "Step: 1290 ------------ Loss: 9852.2 ------------ Accuracy: 54.4%\n",
            "Step: 1291 ------------ Loss: 9852.17 ------------ Accuracy: 54.4%\n",
            "Step: 1292 ------------ Loss: 9851.17 ------------ Accuracy: 54.3%\n",
            "Step: 1293 ------------ Loss: 9851.06 ------------ Accuracy: 54.3%\n",
            "Step: 1294 ------------ Loss: 9850.99 ------------ Accuracy: 54.3%\n",
            "Step: 1295 ------------ Loss: 9850.96 ------------ Accuracy: 54.3%\n",
            "Step: 1296 ------------ Loss: 9850.9 ------------ Accuracy: 54.3%\n",
            "Step: 1297 ------------ Loss: 9847.5 ------------ Accuracy: 54.4%\n",
            "Step: 1298 ------------ Loss: 9847.46 ------------ Accuracy: 54.4%\n",
            "Step: 1299 ------------ Loss: 9847.09 ------------ Accuracy: 54.4%\n",
            "Step: 1300 ------------ Loss: 9846.48 ------------ Accuracy: 54.4%\n",
            "Step: 1301 ------------ Loss: 9838.9 ------------ Accuracy: 54.4%\n",
            "Step: 1302 ------------ Loss: 9838.55 ------------ Accuracy: 54.3%\n",
            "Step: 1303 ------------ Loss: 9838.51 ------------ Accuracy: 54.3%\n",
            "Step: 1304 ------------ Loss: 9838.25 ------------ Accuracy: 54.4%\n",
            "Step: 1305 ------------ Loss: 9838.2 ------------ Accuracy: 54.4%\n",
            "Step: 1306 ------------ Loss: 9838.15 ------------ Accuracy: 54.4%\n",
            "Step: 1307 ------------ Loss: 9838.04 ------------ Accuracy: 54.4%\n",
            "Step: 1308 ------------ Loss: 9837.97 ------------ Accuracy: 54.4%\n",
            "Step: 1309 ------------ Loss: 9837.39 ------------ Accuracy: 54.4%\n",
            "Step: 1310 ------------ Loss: 9837.35 ------------ Accuracy: 54.4%\n",
            "Step: 1311 ------------ Loss: 9834.1 ------------ Accuracy: 54.4%\n",
            "Step: 1312 ------------ Loss: 9834.06 ------------ Accuracy: 54.4%\n",
            "Step: 1313 ------------ Loss: 9834.01 ------------ Accuracy: 54.4%\n",
            "Step: 1314 ------------ Loss: 9833.96 ------------ Accuracy: 54.4%\n",
            "Step: 1315 ------------ Loss: 9833.9 ------------ Accuracy: 54.4%\n",
            "Step: 1316 ------------ Loss: 9833.76 ------------ Accuracy: 54.4%\n",
            "Step: 1317 ------------ Loss: 9833.53 ------------ Accuracy: 54.4%\n",
            "Step: 1318 ------------ Loss: 9830.44 ------------ Accuracy: 54.4%\n",
            "Step: 1319 ------------ Loss: 9830.39 ------------ Accuracy: 54.4%\n",
            "Step: 1320 ------------ Loss: 9829.97 ------------ Accuracy: 54.4%\n",
            "Step: 1321 ------------ Loss: 9829.14 ------------ Accuracy: 54.3%\n",
            "Step: 1322 ------------ Loss: 9829.04 ------------ Accuracy: 54.3%\n",
            "Step: 1323 ------------ Loss: 9828.99 ------------ Accuracy: 54.3%\n",
            "Step: 1324 ------------ Loss: 9828.46 ------------ Accuracy: 54.4%\n",
            "Step: 1325 ------------ Loss: 9828.32 ------------ Accuracy: 54.4%\n",
            "Step: 1326 ------------ Loss: 9828.27 ------------ Accuracy: 54.4%\n",
            "Step: 1327 ------------ Loss: 9828.22 ------------ Accuracy: 54.4%\n",
            "Step: 1328 ------------ Loss: 9827.7 ------------ Accuracy: 54.4%\n",
            "Step: 1329 ------------ Loss: 9827.65 ------------ Accuracy: 54.4%\n",
            "Step: 1330 ------------ Loss: 9827.61 ------------ Accuracy: 54.4%\n",
            "Step: 1331 ------------ Loss: 9826.19 ------------ Accuracy: 54.4%\n",
            "Step: 1332 ------------ Loss: 9825.61 ------------ Accuracy: 54.4%\n",
            "Step: 1333 ------------ Loss: 9825.49 ------------ Accuracy: 54.4%\n",
            "Step: 1334 ------------ Loss: 9825.44 ------------ Accuracy: 54.4%\n",
            "Step: 1335 ------------ Loss: 9824.93 ------------ Accuracy: 54.4%\n",
            "Step: 1336 ------------ Loss: 9823.52 ------------ Accuracy: 54.4%\n",
            "Step: 1337 ------------ Loss: 9823.47 ------------ Accuracy: 54.4%\n",
            "Step: 1338 ------------ Loss: 9823.44 ------------ Accuracy: 54.4%\n",
            "Step: 1339 ------------ Loss: 9823.18 ------------ Accuracy: 54.4%\n",
            "Step: 1340 ------------ Loss: 9823.08 ------------ Accuracy: 54.4%\n",
            "Step: 1341 ------------ Loss: 9823.05 ------------ Accuracy: 54.4%\n",
            "Step: 1342 ------------ Loss: 9823.02 ------------ Accuracy: 54.4%\n",
            "Step: 1343 ------------ Loss: 9823.0 ------------ Accuracy: 54.4%\n",
            "Step: 1344 ------------ Loss: 9822.88 ------------ Accuracy: 54.4%\n",
            "Step: 1345 ------------ Loss: 9822.86 ------------ Accuracy: 54.4%\n",
            "Step: 1346 ------------ Loss: 9822.84 ------------ Accuracy: 54.4%\n",
            "Step: 1347 ------------ Loss: 9822.74 ------------ Accuracy: 54.4%\n",
            "Step: 1348 ------------ Loss: 9822.67 ------------ Accuracy: 54.4%\n",
            "Step: 1349 ------------ Loss: 9822.46 ------------ Accuracy: 54.3%\n",
            "Step: 1350 ------------ Loss: 9822.45 ------------ Accuracy: 54.3%\n",
            "Step: 1351 ------------ Loss: 9815.16 ------------ Accuracy: 54.3%\n",
            "Step: 1352 ------------ Loss: 9813.85 ------------ Accuracy: 54.3%\n",
            "Step: 1353 ------------ Loss: 9812.68 ------------ Accuracy: 54.4%\n",
            "Step: 1354 ------------ Loss: 9805.56 ------------ Accuracy: 54.4%\n",
            "Step: 1355 ------------ Loss: 9805.53 ------------ Accuracy: 54.4%\n",
            "Step: 1356 ------------ Loss: 9802.27 ------------ Accuracy: 54.4%\n",
            "Step: 1357 ------------ Loss: 9802.22 ------------ Accuracy: 54.4%\n",
            "Step: 1358 ------------ Loss: 9801.84 ------------ Accuracy: 54.4%\n",
            "Step: 1359 ------------ Loss: 9801.79 ------------ Accuracy: 54.4%\n",
            "Step: 1360 ------------ Loss: 9801.76 ------------ Accuracy: 54.4%\n",
            "Step: 1361 ------------ Loss: 9801.73 ------------ Accuracy: 54.4%\n",
            "Step: 1362 ------------ Loss: 9801.22 ------------ Accuracy: 54.4%\n",
            "Step: 1363 ------------ Loss: 9799.9 ------------ Accuracy: 54.4%\n",
            "Step: 1364 ------------ Loss: 9796.83 ------------ Accuracy: 54.4%\n",
            "Step: 1365 ------------ Loss: 9796.26 ------------ Accuracy: 54.4%\n",
            "Step: 1366 ------------ Loss: 9795.75 ------------ Accuracy: 54.4%\n",
            "Step: 1367 ------------ Loss: 9795.71 ------------ Accuracy: 54.4%\n",
            "Step: 1368 ------------ Loss: 9795.57 ------------ Accuracy: 54.4%\n",
            "Step: 1369 ------------ Loss: 9795.54 ------------ Accuracy: 54.4%\n",
            "Step: 1370 ------------ Loss: 9795.52 ------------ Accuracy: 54.4%\n",
            "Step: 1371 ------------ Loss: 9795.3 ------------ Accuracy: 54.4%\n",
            "Step: 1372 ------------ Loss: 9795.2 ------------ Accuracy: 54.4%\n",
            "Step: 1373 ------------ Loss: 9795.02 ------------ Accuracy: 54.4%\n",
            "Step: 1374 ------------ Loss: 9794.99 ------------ Accuracy: 54.4%\n",
            "Step: 1375 ------------ Loss: 9794.77 ------------ Accuracy: 54.4%\n",
            "Step: 1376 ------------ Loss: 9794.6 ------------ Accuracy: 54.4%\n",
            "Step: 1377 ------------ Loss: 9794.58 ------------ Accuracy: 54.4%\n",
            "Step: 1378 ------------ Loss: 9794.57 ------------ Accuracy: 54.4%\n",
            "Step: 1379 ------------ Loss: 9794.5 ------------ Accuracy: 54.4%\n",
            "Step: 1380 ------------ Loss: 9794.29 ------------ Accuracy: 54.4%\n",
            "Step: 1381 ------------ Loss: 9794.07 ------------ Accuracy: 54.4%\n",
            "Step: 1382 ------------ Loss: 9793.87 ------------ Accuracy: 54.4%\n",
            "Step: 1383 ------------ Loss: 9793.85 ------------ Accuracy: 54.4%\n",
            "Step: 1384 ------------ Loss: 9786.91 ------------ Accuracy: 54.3%\n",
            "Step: 1385 ------------ Loss: 9786.41 ------------ Accuracy: 54.3%\n",
            "Step: 1386 ------------ Loss: 9785.9 ------------ Accuracy: 54.3%\n",
            "Step: 1387 ------------ Loss: 9785.88 ------------ Accuracy: 54.3%\n",
            "Step: 1388 ------------ Loss: 9785.38 ------------ Accuracy: 54.3%\n",
            "Step: 1389 ------------ Loss: 9785.35 ------------ Accuracy: 54.3%\n",
            "Step: 1390 ------------ Loss: 9778.75 ------------ Accuracy: 54.5%\n",
            "Step: 1391 ------------ Loss: 9777.72 ------------ Accuracy: 54.4%\n",
            "Step: 1392 ------------ Loss: 9771.41 ------------ Accuracy: 54.4%\n",
            "Step: 1393 ------------ Loss: 9771.34 ------------ Accuracy: 54.4%\n",
            "Step: 1394 ------------ Loss: 9770.8 ------------ Accuracy: 54.4%\n",
            "Step: 1395 ------------ Loss: 9770.73 ------------ Accuracy: 54.4%\n",
            "Step: 1396 ------------ Loss: 9770.68 ------------ Accuracy: 54.5%\n",
            "Step: 1397 ------------ Loss: 9770.56 ------------ Accuracy: 54.3%\n",
            "Step: 1398 ------------ Loss: 9770.46 ------------ Accuracy: 54.3%\n",
            "Step: 1399 ------------ Loss: 9770.41 ------------ Accuracy: 54.3%\n",
            "Step: 1400 ------------ Loss: 9770.36 ------------ Accuracy: 54.5%\n",
            "Step: 1401 ------------ Loss: 9770.15 ------------ Accuracy: 54.5%\n",
            "Step: 1402 ------------ Loss: 9770.11 ------------ Accuracy: 54.5%\n",
            "Step: 1403 ------------ Loss: 9770.06 ------------ Accuracy: 54.4%\n",
            "Step: 1404 ------------ Loss: 9769.55 ------------ Accuracy: 54.4%\n",
            "Step: 1405 ------------ Loss: 9769.45 ------------ Accuracy: 54.4%\n",
            "Step: 1406 ------------ Loss: 9768.92 ------------ Accuracy: 54.4%\n",
            "Step: 1407 ------------ Loss: 9767.91 ------------ Accuracy: 54.4%\n",
            "Step: 1408 ------------ Loss: 9767.36 ------------ Accuracy: 54.4%\n",
            "Step: 1409 ------------ Loss: 9767.11 ------------ Accuracy: 54.4%\n",
            "Step: 1410 ------------ Loss: 9766.92 ------------ Accuracy: 54.4%\n",
            "Step: 1411 ------------ Loss: 9765.68 ------------ Accuracy: 54.4%\n",
            "Step: 1412 ------------ Loss: 9765.64 ------------ Accuracy: 54.4%\n",
            "Step: 1413 ------------ Loss: 9765.62 ------------ Accuracy: 54.4%\n",
            "Step: 1414 ------------ Loss: 9765.6 ------------ Accuracy: 54.4%\n",
            "Step: 1415 ------------ Loss: 9765.44 ------------ Accuracy: 54.4%\n",
            "Step: 1416 ------------ Loss: 9764.92 ------------ Accuracy: 54.4%\n",
            "Step: 1417 ------------ Loss: 9764.44 ------------ Accuracy: 54.4%\n",
            "Step: 1418 ------------ Loss: 9763.91 ------------ Accuracy: 54.4%\n",
            "Step: 1419 ------------ Loss: 9763.79 ------------ Accuracy: 54.4%\n",
            "Step: 1420 ------------ Loss: 9763.61 ------------ Accuracy: 54.3%\n",
            "Step: 1421 ------------ Loss: 9762.37 ------------ Accuracy: 54.3%\n",
            "Step: 1422 ------------ Loss: 9755.97 ------------ Accuracy: 54.5%\n",
            "Step: 1423 ------------ Loss: 9755.79 ------------ Accuracy: 54.5%\n",
            "Step: 1424 ------------ Loss: 9749.73 ------------ Accuracy: 54.4%\n",
            "Step: 1425 ------------ Loss: 9749.69 ------------ Accuracy: 54.4%\n",
            "Step: 1426 ------------ Loss: 9749.62 ------------ Accuracy: 54.4%\n",
            "Step: 1427 ------------ Loss: 9749.13 ------------ Accuracy: 54.4%\n",
            "Step: 1428 ------------ Loss: 9749.09 ------------ Accuracy: 54.4%\n",
            "Step: 1429 ------------ Loss: 9748.54 ------------ Accuracy: 54.3%\n",
            "Step: 1430 ------------ Loss: 9742.73 ------------ Accuracy: 54.4%\n",
            "Step: 1431 ------------ Loss: 9741.64 ------------ Accuracy: 54.4%\n",
            "Step: 1432 ------------ Loss: 9741.1 ------------ Accuracy: 54.3%\n",
            "Step: 1433 ------------ Loss: 9737.93 ------------ Accuracy: 54.4%\n",
            "Step: 1434 ------------ Loss: 9737.02 ------------ Accuracy: 54.4%\n",
            "Step: 1435 ------------ Loss: 9736.83 ------------ Accuracy: 54.4%\n",
            "Step: 1436 ------------ Loss: 9736.77 ------------ Accuracy: 54.4%\n",
            "Step: 1437 ------------ Loss: 9736.51 ------------ Accuracy: 54.5%\n",
            "Step: 1438 ------------ Loss: 9736.32 ------------ Accuracy: 54.5%\n",
            "Step: 1439 ------------ Loss: 9736.18 ------------ Accuracy: 54.4%\n",
            "Step: 1440 ------------ Loss: 9735.95 ------------ Accuracy: 54.5%\n",
            "Step: 1441 ------------ Loss: 9730.05 ------------ Accuracy: 54.4%\n",
            "Step: 1442 ------------ Loss: 9729.87 ------------ Accuracy: 54.4%\n",
            "Step: 1443 ------------ Loss: 9728.47 ------------ Accuracy: 54.5%\n",
            "Step: 1444 ------------ Loss: 9728.42 ------------ Accuracy: 54.5%\n",
            "Step: 1445 ------------ Loss: 9728.38 ------------ Accuracy: 54.5%\n",
            "Step: 1446 ------------ Loss: 9727.88 ------------ Accuracy: 54.4%\n",
            "Step: 1447 ------------ Loss: 9727.4 ------------ Accuracy: 54.4%\n",
            "Step: 1448 ------------ Loss: 9727.14 ------------ Accuracy: 54.2%\n",
            "Step: 1449 ------------ Loss: 9727.1 ------------ Accuracy: 54.2%\n",
            "Step: 1450 ------------ Loss: 9721.25 ------------ Accuracy: 54.3%\n",
            "Step: 1451 ------------ Loss: 9720.77 ------------ Accuracy: 54.2%\n",
            "Step: 1452 ------------ Loss: 9720.73 ------------ Accuracy: 54.2%\n",
            "Step: 1453 ------------ Loss: 9720.28 ------------ Accuracy: 54.2%\n",
            "Step: 1454 ------------ Loss: 9720.23 ------------ Accuracy: 54.2%\n",
            "Step: 1455 ------------ Loss: 9720.19 ------------ Accuracy: 54.2%\n",
            "Step: 1456 ------------ Loss: 9720.12 ------------ Accuracy: 54.2%\n",
            "Step: 1457 ------------ Loss: 9719.91 ------------ Accuracy: 54.2%\n",
            "Step: 1458 ------------ Loss: 9719.51 ------------ Accuracy: 54.2%\n",
            "Step: 1459 ------------ Loss: 9718.4 ------------ Accuracy: 54.4%\n",
            "Step: 1460 ------------ Loss: 9718.37 ------------ Accuracy: 54.4%\n",
            "Step: 1461 ------------ Loss: 9718.34 ------------ Accuracy: 54.4%\n",
            "Step: 1462 ------------ Loss: 9717.83 ------------ Accuracy: 54.4%\n",
            "Step: 1463 ------------ Loss: 9717.8 ------------ Accuracy: 54.4%\n",
            "Step: 1464 ------------ Loss: 9717.53 ------------ Accuracy: 54.4%\n",
            "Step: 1465 ------------ Loss: 9717.06 ------------ Accuracy: 54.4%\n",
            "Step: 1466 ------------ Loss: 9716.59 ------------ Accuracy: 54.4%\n",
            "Step: 1467 ------------ Loss: 9716.48 ------------ Accuracy: 54.4%\n",
            "Step: 1468 ------------ Loss: 9715.98 ------------ Accuracy: 54.4%\n",
            "Step: 1469 ------------ Loss: 9715.47 ------------ Accuracy: 54.4%\n",
            "Step: 1470 ------------ Loss: 9715.44 ------------ Accuracy: 54.4%\n",
            "Step: 1471 ------------ Loss: 9714.26 ------------ Accuracy: 54.4%\n",
            "Step: 1472 ------------ Loss: 9714.23 ------------ Accuracy: 54.4%\n",
            "Step: 1473 ------------ Loss: 9714.17 ------------ Accuracy: 54.4%\n",
            "Step: 1474 ------------ Loss: 9714.14 ------------ Accuracy: 54.4%\n",
            "Step: 1475 ------------ Loss: 9714.07 ------------ Accuracy: 54.4%\n",
            "Step: 1476 ------------ Loss: 9714.06 ------------ Accuracy: 54.4%\n",
            "Step: 1477 ------------ Loss: 9713.15 ------------ Accuracy: 54.4%\n",
            "Step: 1478 ------------ Loss: 9712.47 ------------ Accuracy: 54.4%\n",
            "Step: 1479 ------------ Loss: 9712.43 ------------ Accuracy: 54.4%\n",
            "Step: 1480 ------------ Loss: 9712.39 ------------ Accuracy: 54.4%\n",
            "Step: 1481 ------------ Loss: 9712.32 ------------ Accuracy: 54.4%\n",
            "Step: 1482 ------------ Loss: 9712.29 ------------ Accuracy: 54.4%\n",
            "Step: 1483 ------------ Loss: 9712.25 ------------ Accuracy: 54.4%\n",
            "Step: 1484 ------------ Loss: 9711.73 ------------ Accuracy: 54.4%\n",
            "Step: 1485 ------------ Loss: 9711.69 ------------ Accuracy: 54.4%\n",
            "Step: 1486 ------------ Loss: 9711.65 ------------ Accuracy: 54.4%\n",
            "Step: 1487 ------------ Loss: 9711.56 ------------ Accuracy: 54.4%\n",
            "Step: 1488 ------------ Loss: 9711.33 ------------ Accuracy: 54.4%\n",
            "Step: 1489 ------------ Loss: 9711.26 ------------ Accuracy: 54.4%\n",
            "Step: 1490 ------------ Loss: 9711.23 ------------ Accuracy: 54.4%\n",
            "Step: 1491 ------------ Loss: 9711.07 ------------ Accuracy: 54.4%\n",
            "Step: 1492 ------------ Loss: 9710.21 ------------ Accuracy: 54.4%\n",
            "Step: 1493 ------------ Loss: 9710.17 ------------ Accuracy: 54.4%\n",
            "Step: 1494 ------------ Loss: 9709.35 ------------ Accuracy: 54.4%\n",
            "Step: 1495 ------------ Loss: 9709.33 ------------ Accuracy: 54.4%\n",
            "Step: 1496 ------------ Loss: 9709.3 ------------ Accuracy: 54.4%\n",
            "Step: 1497 ------------ Loss: 9708.79 ------------ Accuracy: 54.4%\n",
            "Step: 1498 ------------ Loss: 9708.28 ------------ Accuracy: 54.4%\n",
            "Step: 1499 ------------ Loss: 9708.25 ------------ Accuracy: 54.4%\n",
            "Step: 1500 ------------ Loss: 9702.03 ------------ Accuracy: 54.5%\n",
            "Step: 1501 ------------ Loss: 9701.57 ------------ Accuracy: 54.5%\n",
            "Step: 1502 ------------ Loss: 9701.1 ------------ Accuracy: 54.5%\n",
            "Step: 1503 ------------ Loss: 9700.64 ------------ Accuracy: 54.5%\n",
            "Step: 1504 ------------ Loss: 9699.91 ------------ Accuracy: 54.4%\n",
            "Step: 1505 ------------ Loss: 9699.88 ------------ Accuracy: 54.4%\n",
            "Step: 1506 ------------ Loss: 9699.43 ------------ Accuracy: 54.4%\n",
            "Step: 1507 ------------ Loss: 9698.98 ------------ Accuracy: 54.4%\n",
            "Step: 1508 ------------ Loss: 9692.9 ------------ Accuracy: 54.5%\n",
            "Step: 1509 ------------ Loss: 9692.86 ------------ Accuracy: 54.5%\n",
            "Step: 1510 ------------ Loss: 9692.81 ------------ Accuracy: 54.5%\n",
            "Step: 1511 ------------ Loss: 9691.94 ------------ Accuracy: 54.5%\n",
            "Step: 1512 ------------ Loss: 9691.93 ------------ Accuracy: 54.5%\n",
            "Step: 1513 ------------ Loss: 9691.71 ------------ Accuracy: 54.4%\n",
            "Step: 1514 ------------ Loss: 9691.61 ------------ Accuracy: 54.4%\n",
            "Step: 1515 ------------ Loss: 9691.16 ------------ Accuracy: 54.4%\n",
            "Step: 1516 ------------ Loss: 9691.14 ------------ Accuracy: 54.4%\n",
            "Step: 1517 ------------ Loss: 9691.1 ------------ Accuracy: 54.4%\n",
            "Step: 1518 ------------ Loss: 9691.01 ------------ Accuracy: 54.4%\n",
            "Step: 1519 ------------ Loss: 9690.98 ------------ Accuracy: 54.4%\n",
            "Step: 1520 ------------ Loss: 9690.94 ------------ Accuracy: 54.4%\n",
            "Step: 1521 ------------ Loss: 9685.06 ------------ Accuracy: 54.5%\n",
            "Step: 1522 ------------ Loss: 9684.6 ------------ Accuracy: 54.5%\n",
            "Step: 1523 ------------ Loss: 9684.57 ------------ Accuracy: 54.5%\n",
            "Step: 1524 ------------ Loss: 9684.53 ------------ Accuracy: 54.5%\n",
            "Step: 1525 ------------ Loss: 9683.42 ------------ Accuracy: 54.5%\n",
            "Step: 1526 ------------ Loss: 9682.96 ------------ Accuracy: 54.5%\n",
            "Step: 1527 ------------ Loss: 9682.93 ------------ Accuracy: 54.5%\n",
            "Step: 1528 ------------ Loss: 9682.82 ------------ Accuracy: 54.5%\n",
            "Step: 1529 ------------ Loss: 9682.78 ------------ Accuracy: 54.5%\n",
            "Step: 1530 ------------ Loss: 9682.54 ------------ Accuracy: 54.5%\n",
            "Step: 1531 ------------ Loss: 9682.32 ------------ Accuracy: 54.4%\n",
            "Step: 1532 ------------ Loss: 9682.27 ------------ Accuracy: 54.4%\n",
            "Step: 1533 ------------ Loss: 9682.2 ------------ Accuracy: 54.4%\n",
            "Step: 1534 ------------ Loss: 9682.16 ------------ Accuracy: 54.4%\n",
            "Step: 1535 ------------ Loss: 9681.72 ------------ Accuracy: 54.4%\n",
            "Step: 1536 ------------ Loss: 9681.63 ------------ Accuracy: 54.4%\n",
            "Step: 1537 ------------ Loss: 9681.04 ------------ Accuracy: 54.4%\n",
            "Step: 1538 ------------ Loss: 9680.99 ------------ Accuracy: 54.4%\n",
            "Step: 1539 ------------ Loss: 9680.85 ------------ Accuracy: 54.4%\n",
            "Step: 1540 ------------ Loss: 9680.79 ------------ Accuracy: 54.4%\n",
            "Step: 1541 ------------ Loss: 9680.74 ------------ Accuracy: 54.4%\n",
            "Step: 1542 ------------ Loss: 9677.54 ------------ Accuracy: 54.4%\n",
            "Step: 1543 ------------ Loss: 9677.48 ------------ Accuracy: 54.4%\n",
            "Step: 1544 ------------ Loss: 9677.03 ------------ Accuracy: 54.4%\n",
            "Step: 1545 ------------ Loss: 9677.0 ------------ Accuracy: 54.4%\n",
            "Step: 1546 ------------ Loss: 9676.95 ------------ Accuracy: 54.4%\n",
            "Step: 1547 ------------ Loss: 9676.79 ------------ Accuracy: 54.4%\n",
            "Step: 1548 ------------ Loss: 9676.3 ------------ Accuracy: 54.4%\n",
            "Step: 1549 ------------ Loss: 9676.28 ------------ Accuracy: 54.4%\n",
            "Step: 1550 ------------ Loss: 9676.13 ------------ Accuracy: 54.4%\n",
            "Step: 1551 ------------ Loss: 9676.1 ------------ Accuracy: 54.4%\n",
            "Step: 1552 ------------ Loss: 9675.96 ------------ Accuracy: 54.4%\n",
            "Step: 1553 ------------ Loss: 9675.92 ------------ Accuracy: 54.4%\n",
            "Step: 1554 ------------ Loss: 9675.5 ------------ Accuracy: 54.7%\n",
            "Step: 1555 ------------ Loss: 9675.42 ------------ Accuracy: 54.7%\n",
            "Step: 1556 ------------ Loss: 9675.35 ------------ Accuracy: 54.7%\n",
            "Step: 1557 ------------ Loss: 9675.19 ------------ Accuracy: 54.7%\n",
            "Step: 1558 ------------ Loss: 9669.03 ------------ Accuracy: 54.5%\n",
            "Step: 1559 ------------ Loss: 9669.0 ------------ Accuracy: 54.5%\n",
            "Step: 1560 ------------ Loss: 9668.96 ------------ Accuracy: 54.5%\n",
            "Step: 1561 ------------ Loss: 9668.92 ------------ Accuracy: 54.5%\n",
            "Step: 1562 ------------ Loss: 9668.49 ------------ Accuracy: 54.5%\n",
            "Step: 1563 ------------ Loss: 9667.33 ------------ Accuracy: 54.5%\n",
            "Step: 1564 ------------ Loss: 9667.3 ------------ Accuracy: 54.5%\n",
            "Step: 1565 ------------ Loss: 9666.87 ------------ Accuracy: 54.6%\n",
            "Step: 1566 ------------ Loss: 9666.73 ------------ Accuracy: 54.7%\n",
            "Step: 1567 ------------ Loss: 9666.6 ------------ Accuracy: 54.7%\n",
            "Step: 1568 ------------ Loss: 9666.1 ------------ Accuracy: 54.5%\n",
            "Step: 1569 ------------ Loss: 9666.07 ------------ Accuracy: 54.5%\n",
            "Step: 1570 ------------ Loss: 9665.63 ------------ Accuracy: 54.5%\n",
            "Step: 1571 ------------ Loss: 9665.56 ------------ Accuracy: 54.5%\n",
            "Step: 1572 ------------ Loss: 9665.13 ------------ Accuracy: 54.5%\n",
            "Step: 1573 ------------ Loss: 9663.99 ------------ Accuracy: 54.5%\n",
            "Step: 1574 ------------ Loss: 9662.85 ------------ Accuracy: 54.6%\n",
            "Step: 1575 ------------ Loss: 9662.82 ------------ Accuracy: 54.6%\n",
            "Step: 1576 ------------ Loss: 9657.15 ------------ Accuracy: 54.6%\n",
            "Step: 1577 ------------ Loss: 9657.06 ------------ Accuracy: 54.6%\n",
            "Step: 1578 ------------ Loss: 9656.62 ------------ Accuracy: 54.6%\n",
            "Step: 1579 ------------ Loss: 9656.59 ------------ Accuracy: 54.6%\n",
            "Step: 1580 ------------ Loss: 9651.19 ------------ Accuracy: 54.5%\n",
            "Step: 1581 ------------ Loss: 9651.09 ------------ Accuracy: 54.5%\n",
            "Step: 1582 ------------ Loss: 9651.06 ------------ Accuracy: 54.5%\n",
            "Step: 1583 ------------ Loss: 9650.81 ------------ Accuracy: 54.6%\n",
            "Step: 1584 ------------ Loss: 9650.79 ------------ Accuracy: 54.6%\n",
            "Step: 1585 ------------ Loss: 9650.49 ------------ Accuracy: 54.7%\n",
            "Step: 1586 ------------ Loss: 9650.42 ------------ Accuracy: 54.7%\n",
            "Step: 1587 ------------ Loss: 9650.39 ------------ Accuracy: 54.7%\n",
            "Step: 1588 ------------ Loss: 9650.36 ------------ Accuracy: 54.7%\n",
            "Step: 1589 ------------ Loss: 9649.91 ------------ Accuracy: 54.7%\n",
            "Step: 1590 ------------ Loss: 9649.76 ------------ Accuracy: 54.7%\n",
            "Step: 1591 ------------ Loss: 9649.34 ------------ Accuracy: 54.7%\n",
            "Step: 1592 ------------ Loss: 9649.27 ------------ Accuracy: 54.7%\n",
            "Step: 1593 ------------ Loss: 9649.19 ------------ Accuracy: 54.7%\n",
            "Step: 1594 ------------ Loss: 9646.08 ------------ Accuracy: 54.6%\n",
            "Step: 1595 ------------ Loss: 9645.82 ------------ Accuracy: 54.6%\n",
            "Step: 1596 ------------ Loss: 9645.4 ------------ Accuracy: 54.7%\n",
            "Step: 1597 ------------ Loss: 9644.99 ------------ Accuracy: 54.7%\n",
            "Step: 1598 ------------ Loss: 9644.97 ------------ Accuracy: 54.7%\n",
            "Step: 1599 ------------ Loss: 9644.9 ------------ Accuracy: 54.7%\n",
            "Step: 1600 ------------ Loss: 9644.81 ------------ Accuracy: 54.7%\n",
            "Step: 1601 ------------ Loss: 9644.67 ------------ Accuracy: 54.7%\n",
            "Step: 1602 ------------ Loss: 9644.23 ------------ Accuracy: 54.7%\n",
            "Step: 1603 ------------ Loss: 9644.2 ------------ Accuracy: 54.7%\n",
            "Step: 1604 ------------ Loss: 9643.53 ------------ Accuracy: 54.8%\n",
            "Step: 1605 ------------ Loss: 9637.98 ------------ Accuracy: 54.7%\n",
            "Step: 1606 ------------ Loss: 9637.95 ------------ Accuracy: 54.7%\n",
            "Step: 1607 ------------ Loss: 9637.92 ------------ Accuracy: 54.7%\n",
            "Step: 1608 ------------ Loss: 9634.92 ------------ Accuracy: 54.7%\n",
            "Step: 1609 ------------ Loss: 9634.69 ------------ Accuracy: 54.8%\n",
            "Step: 1610 ------------ Loss: 9634.6 ------------ Accuracy: 54.8%\n",
            "Step: 1611 ------------ Loss: 9634.58 ------------ Accuracy: 54.8%\n",
            "Step: 1612 ------------ Loss: 9634.56 ------------ Accuracy: 54.8%\n",
            "Step: 1613 ------------ Loss: 9631.74 ------------ Accuracy: 54.7%\n",
            "Step: 1614 ------------ Loss: 9626.41 ------------ Accuracy: 54.5%\n",
            "Step: 1615 ------------ Loss: 9626.15 ------------ Accuracy: 54.2%\n",
            "Step: 1616 ------------ Loss: 9625.72 ------------ Accuracy: 54.2%\n",
            "Step: 1617 ------------ Loss: 9625.29 ------------ Accuracy: 54.2%\n",
            "Step: 1618 ------------ Loss: 9624.85 ------------ Accuracy: 54.2%\n",
            "Step: 1619 ------------ Loss: 9624.8 ------------ Accuracy: 54.2%\n",
            "Step: 1620 ------------ Loss: 9619.78 ------------ Accuracy: 54.3%\n",
            "Step: 1621 ------------ Loss: 9619.34 ------------ Accuracy: 54.3%\n",
            "Step: 1622 ------------ Loss: 9618.92 ------------ Accuracy: 54.3%\n",
            "Step: 1623 ------------ Loss: 9618.5 ------------ Accuracy: 54.3%\n",
            "Step: 1624 ------------ Loss: 9618.05 ------------ Accuracy: 54.3%\n",
            "Step: 1625 ------------ Loss: 9618.01 ------------ Accuracy: 54.3%\n",
            "Step: 1626 ------------ Loss: 9617.57 ------------ Accuracy: 54.3%\n",
            "Step: 1627 ------------ Loss: 9617.54 ------------ Accuracy: 54.3%\n",
            "Step: 1628 ------------ Loss: 9617.25 ------------ Accuracy: 54.5%\n",
            "Step: 1629 ------------ Loss: 9616.5 ------------ Accuracy: 54.4%\n",
            "Step: 1630 ------------ Loss: 9615.49 ------------ Accuracy: 54.4%\n",
            "Step: 1631 ------------ Loss: 9615.36 ------------ Accuracy: 54.4%\n",
            "Step: 1632 ------------ Loss: 9614.92 ------------ Accuracy: 54.4%\n",
            "Step: 1633 ------------ Loss: 9614.67 ------------ Accuracy: 54.4%\n",
            "Step: 1634 ------------ Loss: 9614.65 ------------ Accuracy: 54.4%\n",
            "Step: 1635 ------------ Loss: 9614.62 ------------ Accuracy: 54.4%\n",
            "Step: 1636 ------------ Loss: 9614.42 ------------ Accuracy: 54.3%\n",
            "Step: 1637 ------------ Loss: 9614.33 ------------ Accuracy: 54.3%\n",
            "Step: 1638 ------------ Loss: 9613.89 ------------ Accuracy: 54.3%\n",
            "Step: 1639 ------------ Loss: 9613.86 ------------ Accuracy: 54.3%\n",
            "Step: 1640 ------------ Loss: 9613.83 ------------ Accuracy: 54.3%\n",
            "Step: 1641 ------------ Loss: 9613.74 ------------ Accuracy: 54.3%\n",
            "Step: 1642 ------------ Loss: 9613.71 ------------ Accuracy: 54.3%\n",
            "Step: 1643 ------------ Loss: 9613.58 ------------ Accuracy: 54.3%\n",
            "Step: 1644 ------------ Loss: 9613.56 ------------ Accuracy: 54.3%\n",
            "Step: 1645 ------------ Loss: 9612.84 ------------ Accuracy: 54.2%\n",
            "Step: 1646 ------------ Loss: 9612.55 ------------ Accuracy: 54.3%\n",
            "Step: 1647 ------------ Loss: 9612.52 ------------ Accuracy: 54.3%\n",
            "Step: 1648 ------------ Loss: 9612.5 ------------ Accuracy: 54.3%\n",
            "Step: 1649 ------------ Loss: 9611.82 ------------ Accuracy: 54.4%\n",
            "Step: 1650 ------------ Loss: 9609.25 ------------ Accuracy: 54.5%\n",
            "Step: 1651 ------------ Loss: 9608.81 ------------ Accuracy: 54.5%\n",
            "Step: 1652 ------------ Loss: 9608.38 ------------ Accuracy: 54.5%\n",
            "Step: 1653 ------------ Loss: 9608.34 ------------ Accuracy: 54.5%\n",
            "Step: 1654 ------------ Loss: 9608.25 ------------ Accuracy: 54.5%\n",
            "Step: 1655 ------------ Loss: 9608.22 ------------ Accuracy: 54.4%\n",
            "Step: 1656 ------------ Loss: 9608.07 ------------ Accuracy: 54.5%\n",
            "Step: 1657 ------------ Loss: 9607.97 ------------ Accuracy: 54.5%\n",
            "Step: 1658 ------------ Loss: 9607.94 ------------ Accuracy: 54.5%\n",
            "Step: 1659 ------------ Loss: 9607.9 ------------ Accuracy: 54.6%\n",
            "Step: 1660 ------------ Loss: 9607.88 ------------ Accuracy: 54.6%\n",
            "Step: 1661 ------------ Loss: 9607.86 ------------ Accuracy: 54.6%\n",
            "Step: 1662 ------------ Loss: 9607.84 ------------ Accuracy: 54.6%\n",
            "Step: 1663 ------------ Loss: 9607.61 ------------ Accuracy: 54.6%\n",
            "Step: 1664 ------------ Loss: 9607.59 ------------ Accuracy: 54.6%\n",
            "Step: 1665 ------------ Loss: 9607.57 ------------ Accuracy: 54.6%\n",
            "Step: 1666 ------------ Loss: 9605.03 ------------ Accuracy: 54.5%\n",
            "Step: 1667 ------------ Loss: 9604.88 ------------ Accuracy: 54.5%\n",
            "Step: 1668 ------------ Loss: 9604.85 ------------ Accuracy: 54.5%\n",
            "Step: 1669 ------------ Loss: 9604.75 ------------ Accuracy: 54.5%\n",
            "Step: 1670 ------------ Loss: 9604.32 ------------ Accuracy: 54.5%\n",
            "Step: 1671 ------------ Loss: 9604.11 ------------ Accuracy: 54.6%\n",
            "Step: 1672 ------------ Loss: 9603.85 ------------ Accuracy: 54.5%\n",
            "Step: 1673 ------------ Loss: 9603.7 ------------ Accuracy: 54.5%\n",
            "Step: 1674 ------------ Loss: 9603.27 ------------ Accuracy: 54.5%\n",
            "Step: 1675 ------------ Loss: 9603.18 ------------ Accuracy: 54.5%\n",
            "Step: 1676 ------------ Loss: 9602.98 ------------ Accuracy: 54.5%\n",
            "Step: 1677 ------------ Loss: 9602.96 ------------ Accuracy: 54.5%\n",
            "Step: 1678 ------------ Loss: 9602.54 ------------ Accuracy: 54.5%\n",
            "Step: 1679 ------------ Loss: 9602.45 ------------ Accuracy: 54.5%\n",
            "Step: 1680 ------------ Loss: 9602.44 ------------ Accuracy: 54.5%\n",
            "Step: 1681 ------------ Loss: 9602.01 ------------ Accuracy: 54.5%\n",
            "Step: 1682 ------------ Loss: 9601.92 ------------ Accuracy: 54.5%\n",
            "Step: 1683 ------------ Loss: 9601.83 ------------ Accuracy: 54.5%\n",
            "Step: 1684 ------------ Loss: 9601.23 ------------ Accuracy: 54.5%\n",
            "Step: 1685 ------------ Loss: 9600.66 ------------ Accuracy: 54.5%\n",
            "Step: 1686 ------------ Loss: 9600.63 ------------ Accuracy: 54.5%\n",
            "Step: 1687 ------------ Loss: 9598.31 ------------ Accuracy: 54.5%\n",
            "Step: 1688 ------------ Loss: 9598.18 ------------ Accuracy: 54.5%\n",
            "Step: 1689 ------------ Loss: 9597.75 ------------ Accuracy: 54.5%\n",
            "Step: 1690 ------------ Loss: 9596.68 ------------ Accuracy: 54.5%\n",
            "Step: 1691 ------------ Loss: 9596.57 ------------ Accuracy: 54.5%\n",
            "Step: 1692 ------------ Loss: 9596.54 ------------ Accuracy: 54.5%\n",
            "Step: 1693 ------------ Loss: 9595.48 ------------ Accuracy: 54.5%\n",
            "Step: 1694 ------------ Loss: 9595.41 ------------ Accuracy: 54.5%\n",
            "Step: 1695 ------------ Loss: 9595.38 ------------ Accuracy: 54.5%\n",
            "Step: 1696 ------------ Loss: 9595.35 ------------ Accuracy: 54.5%\n",
            "Step: 1697 ------------ Loss: 9590.2 ------------ Accuracy: 54.2%\n",
            "Step: 1698 ------------ Loss: 9589.07 ------------ Accuracy: 54.6%\n",
            "Step: 1699 ------------ Loss: 9589.05 ------------ Accuracy: 54.6%\n",
            "Step: 1700 ------------ Loss: 9588.86 ------------ Accuracy: 54.8%\n",
            "Step: 1701 ------------ Loss: 9588.43 ------------ Accuracy: 54.6%\n",
            "Step: 1702 ------------ Loss: 9586.01 ------------ Accuracy: 54.8%\n",
            "Step: 1703 ------------ Loss: 9585.98 ------------ Accuracy: 54.8%\n",
            "Step: 1704 ------------ Loss: 9585.79 ------------ Accuracy: 54.8%\n",
            "Step: 1705 ------------ Loss: 9585.75 ------------ Accuracy: 54.8%\n",
            "Step: 1706 ------------ Loss: 9585.32 ------------ Accuracy: 54.8%\n",
            "Step: 1707 ------------ Loss: 9585.18 ------------ Accuracy: 54.8%\n",
            "Step: 1708 ------------ Loss: 9585.09 ------------ Accuracy: 54.8%\n",
            "Step: 1709 ------------ Loss: 9584.91 ------------ Accuracy: 54.8%\n",
            "Step: 1710 ------------ Loss: 9582.59 ------------ Accuracy: 54.8%\n",
            "Step: 1711 ------------ Loss: 9582.16 ------------ Accuracy: 54.8%\n",
            "Step: 1712 ------------ Loss: 9581.35 ------------ Accuracy: 54.8%\n",
            "Step: 1713 ------------ Loss: 9579.05 ------------ Accuracy: 54.8%\n",
            "Step: 1714 ------------ Loss: 9578.99 ------------ Accuracy: 54.8%\n",
            "Step: 1715 ------------ Loss: 9578.96 ------------ Accuracy: 54.8%\n",
            "Step: 1716 ------------ Loss: 9578.88 ------------ Accuracy: 54.8%\n",
            "Step: 1717 ------------ Loss: 9578.72 ------------ Accuracy: 54.8%\n",
            "Step: 1718 ------------ Loss: 9578.69 ------------ Accuracy: 54.8%\n",
            "Step: 1719 ------------ Loss: 9578.27 ------------ Accuracy: 54.8%\n",
            "Step: 1720 ------------ Loss: 9577.18 ------------ Accuracy: 54.8%\n",
            "Step: 1721 ------------ Loss: 9577.13 ------------ Accuracy: 54.8%\n",
            "Step: 1722 ------------ Loss: 9576.99 ------------ Accuracy: 54.8%\n",
            "Step: 1723 ------------ Loss: 9576.92 ------------ Accuracy: 54.8%\n",
            "Step: 1724 ------------ Loss: 9576.87 ------------ Accuracy: 54.8%\n",
            "Step: 1725 ------------ Loss: 9576.83 ------------ Accuracy: 54.8%\n",
            "Step: 1726 ------------ Loss: 9576.79 ------------ Accuracy: 54.8%\n",
            "Step: 1727 ------------ Loss: 9576.31 ------------ Accuracy: 54.8%\n",
            "Step: 1728 ------------ Loss: 9576.26 ------------ Accuracy: 54.8%\n",
            "Step: 1729 ------------ Loss: 9576.15 ------------ Accuracy: 54.8%\n",
            "Step: 1730 ------------ Loss: 9576.12 ------------ Accuracy: 54.8%\n",
            "Step: 1731 ------------ Loss: 9575.48 ------------ Accuracy: 54.8%\n",
            "Step: 1732 ------------ Loss: 9575.45 ------------ Accuracy: 54.8%\n",
            "Step: 1733 ------------ Loss: 9574.35 ------------ Accuracy: 54.8%\n",
            "Step: 1734 ------------ Loss: 9573.9 ------------ Accuracy: 54.8%\n",
            "Step: 1735 ------------ Loss: 9573.79 ------------ Accuracy: 55.0%\n",
            "Step: 1736 ------------ Loss: 9573.68 ------------ Accuracy: 55.0%\n",
            "Step: 1737 ------------ Loss: 9573.29 ------------ Accuracy: 55.0%\n",
            "Step: 1738 ------------ Loss: 9573.19 ------------ Accuracy: 55.0%\n",
            "Step: 1739 ------------ Loss: 9572.68 ------------ Accuracy: 54.9%\n",
            "Step: 1740 ------------ Loss: 9570.34 ------------ Accuracy: 54.9%\n",
            "Step: 1741 ------------ Loss: 9569.23 ------------ Accuracy: 54.9%\n",
            "Step: 1742 ------------ Loss: 9567.04 ------------ Accuracy: 54.9%\n",
            "Step: 1743 ------------ Loss: 9566.67 ------------ Accuracy: 54.8%\n",
            "Step: 1744 ------------ Loss: 9566.64 ------------ Accuracy: 54.8%\n",
            "Step: 1745 ------------ Loss: 9566.57 ------------ Accuracy: 54.8%\n",
            "Step: 1746 ------------ Loss: 9566.43 ------------ Accuracy: 54.8%\n",
            "Step: 1747 ------------ Loss: 9566.27 ------------ Accuracy: 54.8%\n",
            "Step: 1748 ------------ Loss: 9565.87 ------------ Accuracy: 54.8%\n",
            "Step: 1749 ------------ Loss: 9565.73 ------------ Accuracy: 54.9%\n",
            "Step: 1750 ------------ Loss: 9565.68 ------------ Accuracy: 54.8%\n",
            "Step: 1751 ------------ Loss: 9565.62 ------------ Accuracy: 54.8%\n",
            "Step: 1752 ------------ Loss: 9565.51 ------------ Accuracy: 55.0%\n",
            "Step: 1753 ------------ Loss: 9565.07 ------------ Accuracy: 54.8%\n",
            "Step: 1754 ------------ Loss: 9565.02 ------------ Accuracy: 54.8%\n",
            "Step: 1755 ------------ Loss: 9564.99 ------------ Accuracy: 54.8%\n",
            "Step: 1756 ------------ Loss: 9564.59 ------------ Accuracy: 54.8%\n",
            "Step: 1757 ------------ Loss: 9564.56 ------------ Accuracy: 54.8%\n",
            "Step: 1758 ------------ Loss: 9563.94 ------------ Accuracy: 55.1%\n",
            "Step: 1759 ------------ Loss: 9558.48 ------------ Accuracy: 54.9%\n",
            "Step: 1760 ------------ Loss: 9553.31 ------------ Accuracy: 54.8%\n",
            "Step: 1761 ------------ Loss: 9553.22 ------------ Accuracy: 54.8%\n",
            "Step: 1762 ------------ Loss: 9552.55 ------------ Accuracy: 55.0%\n",
            "Step: 1763 ------------ Loss: 9552.12 ------------ Accuracy: 55.0%\n",
            "Step: 1764 ------------ Loss: 9552.07 ------------ Accuracy: 55.0%\n",
            "Step: 1765 ------------ Loss: 9551.99 ------------ Accuracy: 55.0%\n",
            "Step: 1766 ------------ Loss: 9551.95 ------------ Accuracy: 55.0%\n",
            "Step: 1767 ------------ Loss: 9550.92 ------------ Accuracy: 55.0%\n",
            "Step: 1768 ------------ Loss: 9550.42 ------------ Accuracy: 55.1%\n",
            "Step: 1769 ------------ Loss: 9550.31 ------------ Accuracy: 55.2%\n",
            "Step: 1770 ------------ Loss: 9550.27 ------------ Accuracy: 55.1%\n",
            "Step: 1771 ------------ Loss: 9545.08 ------------ Accuracy: 54.9%\n",
            "Step: 1772 ------------ Loss: 9544.6 ------------ Accuracy: 55.1%\n",
            "Step: 1773 ------------ Loss: 9544.25 ------------ Accuracy: 55.1%\n",
            "Step: 1774 ------------ Loss: 9543.67 ------------ Accuracy: 55.1%\n",
            "Step: 1775 ------------ Loss: 9543.59 ------------ Accuracy: 55.1%\n",
            "Step: 1776 ------------ Loss: 9543.21 ------------ Accuracy: 55.1%\n",
            "Step: 1777 ------------ Loss: 9543.17 ------------ Accuracy: 55.1%\n",
            "Step: 1778 ------------ Loss: 9543.14 ------------ Accuracy: 55.1%\n",
            "Step: 1779 ------------ Loss: 9543.1 ------------ Accuracy: 55.1%\n",
            "Step: 1780 ------------ Loss: 9542.76 ------------ Accuracy: 55.1%\n",
            "Step: 1781 ------------ Loss: 9542.73 ------------ Accuracy: 55.1%\n",
            "Step: 1782 ------------ Loss: 9542.65 ------------ Accuracy: 55.1%\n",
            "Step: 1783 ------------ Loss: 9542.08 ------------ Accuracy: 55.1%\n",
            "Step: 1784 ------------ Loss: 9542.03 ------------ Accuracy: 55.1%\n",
            "Step: 1785 ------------ Loss: 9541.98 ------------ Accuracy: 55.1%\n",
            "Step: 1786 ------------ Loss: 9541.95 ------------ Accuracy: 55.1%\n",
            "Step: 1787 ------------ Loss: 9541.86 ------------ Accuracy: 55.1%\n",
            "Step: 1788 ------------ Loss: 9541.84 ------------ Accuracy: 55.1%\n",
            "Step: 1789 ------------ Loss: 9541.79 ------------ Accuracy: 55.2%\n",
            "Step: 1790 ------------ Loss: 9541.72 ------------ Accuracy: 55.2%\n",
            "Step: 1791 ------------ Loss: 9541.37 ------------ Accuracy: 55.1%\n",
            "Step: 1792 ------------ Loss: 9541.03 ------------ Accuracy: 55.1%\n",
            "Step: 1793 ------------ Loss: 9540.96 ------------ Accuracy: 55.1%\n",
            "Step: 1794 ------------ Loss: 9540.92 ------------ Accuracy: 55.1%\n",
            "Step: 1795 ------------ Loss: 9540.54 ------------ Accuracy: 55.1%\n",
            "Step: 1796 ------------ Loss: 9540.45 ------------ Accuracy: 55.1%\n",
            "Step: 1797 ------------ Loss: 9540.38 ------------ Accuracy: 55.1%\n",
            "Step: 1798 ------------ Loss: 9540.36 ------------ Accuracy: 55.1%\n",
            "Step: 1799 ------------ Loss: 9540.29 ------------ Accuracy: 55.1%\n",
            "Step: 1800 ------------ Loss: 9540.2 ------------ Accuracy: 55.1%\n",
            "Step: 1801 ------------ Loss: 9539.82 ------------ Accuracy: 55.1%\n",
            "Step: 1802 ------------ Loss: 9534.62 ------------ Accuracy: 54.9%\n",
            "Step: 1803 ------------ Loss: 9534.23 ------------ Accuracy: 55.0%\n",
            "Step: 1804 ------------ Loss: 9534.17 ------------ Accuracy: 55.0%\n",
            "Step: 1805 ------------ Loss: 9534.15 ------------ Accuracy: 55.0%\n",
            "Step: 1806 ------------ Loss: 9534.13 ------------ Accuracy: 55.0%\n",
            "Step: 1807 ------------ Loss: 9534.08 ------------ Accuracy: 55.0%\n",
            "Step: 1808 ------------ Loss: 9534.01 ------------ Accuracy: 55.0%\n",
            "Step: 1809 ------------ Loss: 9533.47 ------------ Accuracy: 55.0%\n",
            "Step: 1810 ------------ Loss: 9533.05 ------------ Accuracy: 55.0%\n",
            "Step: 1811 ------------ Loss: 9530.52 ------------ Accuracy: 54.9%\n",
            "Step: 1812 ------------ Loss: 9528.16 ------------ Accuracy: 54.9%\n",
            "Step: 1813 ------------ Loss: 9528.14 ------------ Accuracy: 54.9%\n",
            "Step: 1814 ------------ Loss: 9527.74 ------------ Accuracy: 54.9%\n",
            "Step: 1815 ------------ Loss: 9527.28 ------------ Accuracy: 54.9%\n",
            "Step: 1816 ------------ Loss: 9526.7 ------------ Accuracy: 55.0%\n",
            "Step: 1817 ------------ Loss: 9526.35 ------------ Accuracy: 55.1%\n",
            "Step: 1818 ------------ Loss: 9525.92 ------------ Accuracy: 55.0%\n",
            "Step: 1819 ------------ Loss: 9525.88 ------------ Accuracy: 55.0%\n",
            "Step: 1820 ------------ Loss: 9520.82 ------------ Accuracy: 54.9%\n",
            "Step: 1821 ------------ Loss: 9520.71 ------------ Accuracy: 55.0%\n",
            "Step: 1822 ------------ Loss: 9520.69 ------------ Accuracy: 54.9%\n",
            "Step: 1823 ------------ Loss: 9520.65 ------------ Accuracy: 54.9%\n",
            "Step: 1824 ------------ Loss: 9520.6 ------------ Accuracy: 54.9%\n",
            "Step: 1825 ------------ Loss: 9515.78 ------------ Accuracy: 54.8%\n",
            "Step: 1826 ------------ Loss: 9515.66 ------------ Accuracy: 54.9%\n",
            "Step: 1827 ------------ Loss: 9513.36 ------------ Accuracy: 54.9%\n",
            "Step: 1828 ------------ Loss: 9512.96 ------------ Accuracy: 54.9%\n",
            "Step: 1829 ------------ Loss: 9512.93 ------------ Accuracy: 54.9%\n",
            "Step: 1830 ------------ Loss: 9512.91 ------------ Accuracy: 54.9%\n",
            "Step: 1831 ------------ Loss: 9511.95 ------------ Accuracy: 54.9%\n",
            "Step: 1832 ------------ Loss: 9511.93 ------------ Accuracy: 54.9%\n",
            "Step: 1833 ------------ Loss: 9511.68 ------------ Accuracy: 54.9%\n",
            "Step: 1834 ------------ Loss: 9510.85 ------------ Accuracy: 54.8%\n",
            "Step: 1835 ------------ Loss: 9509.88 ------------ Accuracy: 54.8%\n",
            "Step: 1836 ------------ Loss: 9509.86 ------------ Accuracy: 54.8%\n",
            "Step: 1837 ------------ Loss: 9508.9 ------------ Accuracy: 54.8%\n",
            "Step: 1838 ------------ Loss: 9508.89 ------------ Accuracy: 54.8%\n",
            "Step: 1839 ------------ Loss: 9506.63 ------------ Accuracy: 54.9%\n",
            "Step: 1840 ------------ Loss: 9506.6 ------------ Accuracy: 54.9%\n",
            "Step: 1841 ------------ Loss: 9506.45 ------------ Accuracy: 54.9%\n",
            "Step: 1842 ------------ Loss: 9506.42 ------------ Accuracy: 54.8%\n",
            "Step: 1843 ------------ Loss: 9506.16 ------------ Accuracy: 54.9%\n",
            "Step: 1844 ------------ Loss: 9505.76 ------------ Accuracy: 54.9%\n",
            "Step: 1845 ------------ Loss: 9505.69 ------------ Accuracy: 54.9%\n",
            "Step: 1846 ------------ Loss: 9505.68 ------------ Accuracy: 54.9%\n",
            "Step: 1847 ------------ Loss: 9505.28 ------------ Accuracy: 54.9%\n",
            "Step: 1848 ------------ Loss: 9505.26 ------------ Accuracy: 54.9%\n",
            "Step: 1849 ------------ Loss: 9504.87 ------------ Accuracy: 54.9%\n",
            "Step: 1850 ------------ Loss: 9504.68 ------------ Accuracy: 54.9%\n",
            "Step: 1851 ------------ Loss: 9500.14 ------------ Accuracy: 54.9%\n",
            "Step: 1852 ------------ Loss: 9499.91 ------------ Accuracy: 54.9%\n",
            "Step: 1853 ------------ Loss: 9499.71 ------------ Accuracy: 54.9%\n",
            "Step: 1854 ------------ Loss: 9499.58 ------------ Accuracy: 54.9%\n",
            "Step: 1855 ------------ Loss: 9498.66 ------------ Accuracy: 54.9%\n",
            "Step: 1856 ------------ Loss: 9498.65 ------------ Accuracy: 54.9%\n",
            "Step: 1857 ------------ Loss: 9498.62 ------------ Accuracy: 54.9%\n",
            "Step: 1858 ------------ Loss: 9496.47 ------------ Accuracy: 54.9%\n",
            "Step: 1859 ------------ Loss: 9496.45 ------------ Accuracy: 54.9%\n",
            "Step: 1860 ------------ Loss: 9496.02 ------------ Accuracy: 54.8%\n",
            "Step: 1861 ------------ Loss: 9496.0 ------------ Accuracy: 54.8%\n",
            "Step: 1862 ------------ Loss: 9495.83 ------------ Accuracy: 54.9%\n",
            "Step: 1863 ------------ Loss: 9494.91 ------------ Accuracy: 54.9%\n",
            "Step: 1864 ------------ Loss: 9494.88 ------------ Accuracy: 54.9%\n",
            "Step: 1865 ------------ Loss: 9493.85 ------------ Accuracy: 54.8%\n",
            "Step: 1866 ------------ Loss: 9493.63 ------------ Accuracy: 54.9%\n",
            "Step: 1867 ------------ Loss: 9493.46 ------------ Accuracy: 54.9%\n",
            "Step: 1868 ------------ Loss: 9493.45 ------------ Accuracy: 54.9%\n",
            "Step: 1869 ------------ Loss: 9493.43 ------------ Accuracy: 54.9%\n",
            "Step: 1870 ------------ Loss: 9493.42 ------------ Accuracy: 54.9%\n",
            "Step: 1871 ------------ Loss: 9493.33 ------------ Accuracy: 54.9%\n",
            "Step: 1872 ------------ Loss: 9493.32 ------------ Accuracy: 54.9%\n",
            "Step: 1873 ------------ Loss: 9493.23 ------------ Accuracy: 54.8%\n",
            "Step: 1874 ------------ Loss: 9493.06 ------------ Accuracy: 54.8%\n",
            "Step: 1875 ------------ Loss: 9493.05 ------------ Accuracy: 54.8%\n",
            "Step: 1876 ------------ Loss: 9492.32 ------------ Accuracy: 54.8%\n",
            "Step: 1877 ------------ Loss: 9491.86 ------------ Accuracy: 54.8%\n",
            "Step: 1878 ------------ Loss: 9490.89 ------------ Accuracy: 54.8%\n",
            "Step: 1879 ------------ Loss: 9490.62 ------------ Accuracy: 54.8%\n",
            "Step: 1880 ------------ Loss: 9490.23 ------------ Accuracy: 54.8%\n",
            "Step: 1881 ------------ Loss: 9489.84 ------------ Accuracy: 54.8%\n",
            "Step: 1882 ------------ Loss: 9489.45 ------------ Accuracy: 54.8%\n",
            "Step: 1883 ------------ Loss: 9489.44 ------------ Accuracy: 54.8%\n",
            "Step: 1884 ------------ Loss: 9489.44 ------------ Accuracy: 54.8%\n",
            "Step: 1885 ------------ Loss: 9489.31 ------------ Accuracy: 54.8%\n",
            "Step: 1886 ------------ Loss: 9489.19 ------------ Accuracy: 54.8%\n",
            "Step: 1887 ------------ Loss: 9488.84 ------------ Accuracy: 54.8%\n",
            "Step: 1888 ------------ Loss: 9488.5 ------------ Accuracy: 54.8%\n",
            "Step: 1889 ------------ Loss: 9487.56 ------------ Accuracy: 54.8%\n",
            "Step: 1890 ------------ Loss: 9487.47 ------------ Accuracy: 54.8%\n",
            "Step: 1891 ------------ Loss: 9487.45 ------------ Accuracy: 54.8%\n",
            "Step: 1892 ------------ Loss: 9487.11 ------------ Accuracy: 54.8%\n",
            "Step: 1893 ------------ Loss: 9486.65 ------------ Accuracy: 54.8%\n",
            "Step: 1894 ------------ Loss: 9486.03 ------------ Accuracy: 54.9%\n",
            "Step: 1895 ------------ Loss: 9485.57 ------------ Accuracy: 54.9%\n",
            "Step: 1896 ------------ Loss: 9485.53 ------------ Accuracy: 55.0%\n",
            "Step: 1897 ------------ Loss: 9485.51 ------------ Accuracy: 54.9%\n",
            "Step: 1898 ------------ Loss: 9483.3 ------------ Accuracy: 54.9%\n",
            "Step: 1899 ------------ Loss: 9483.27 ------------ Accuracy: 54.9%\n",
            "Step: 1900 ------------ Loss: 9483.21 ------------ Accuracy: 54.9%\n",
            "Step: 1901 ------------ Loss: 9483.14 ------------ Accuracy: 54.9%\n",
            "Step: 1902 ------------ Loss: 9483.04 ------------ Accuracy: 54.9%\n",
            "Step: 1903 ------------ Loss: 9478.31 ------------ Accuracy: 54.7%\n",
            "Step: 1904 ------------ Loss: 9478.29 ------------ Accuracy: 54.7%\n",
            "Step: 1905 ------------ Loss: 9478.27 ------------ Accuracy: 54.8%\n",
            "Step: 1906 ------------ Loss: 9478.15 ------------ Accuracy: 54.7%\n",
            "Step: 1907 ------------ Loss: 9478.15 ------------ Accuracy: 54.8%\n",
            "Step: 1908 ------------ Loss: 9477.76 ------------ Accuracy: 54.8%\n",
            "Step: 1909 ------------ Loss: 9477.75 ------------ Accuracy: 54.8%\n",
            "Step: 1910 ------------ Loss: 9477.63 ------------ Accuracy: 54.8%\n",
            "Step: 1911 ------------ Loss: 9477.62 ------------ Accuracy: 54.8%\n",
            "Step: 1912 ------------ Loss: 9477.6 ------------ Accuracy: 54.8%\n",
            "Step: 1913 ------------ Loss: 9477.48 ------------ Accuracy: 54.8%\n",
            "Step: 1914 ------------ Loss: 9477.38 ------------ Accuracy: 55.0%\n",
            "Step: 1915 ------------ Loss: 9476.99 ------------ Accuracy: 55.0%\n",
            "Step: 1916 ------------ Loss: 9476.61 ------------ Accuracy: 55.0%\n",
            "Step: 1917 ------------ Loss: 9476.59 ------------ Accuracy: 55.0%\n",
            "Step: 1918 ------------ Loss: 9476.05 ------------ Accuracy: 55.1%\n",
            "Step: 1919 ------------ Loss: 9476.03 ------------ Accuracy: 55.1%\n",
            "Step: 1920 ------------ Loss: 9476.02 ------------ Accuracy: 55.1%\n",
            "Step: 1921 ------------ Loss: 9473.78 ------------ Accuracy: 55.1%\n",
            "Step: 1922 ------------ Loss: 9473.7 ------------ Accuracy: 55.1%\n",
            "Step: 1923 ------------ Loss: 9473.62 ------------ Accuracy: 55.1%\n",
            "Step: 1924 ------------ Loss: 9473.23 ------------ Accuracy: 55.1%\n",
            "Step: 1925 ------------ Loss: 9473.18 ------------ Accuracy: 55.1%\n",
            "Step: 1926 ------------ Loss: 9473.15 ------------ Accuracy: 55.1%\n",
            "Step: 1927 ------------ Loss: 9473.12 ------------ Accuracy: 55.1%\n",
            "Step: 1928 ------------ Loss: 9473.11 ------------ Accuracy: 55.1%\n",
            "Step: 1929 ------------ Loss: 9473.07 ------------ Accuracy: 55.1%\n",
            "Step: 1930 ------------ Loss: 9473.03 ------------ Accuracy: 55.1%\n",
            "Step: 1931 ------------ Loss: 9472.92 ------------ Accuracy: 55.1%\n",
            "Step: 1932 ------------ Loss: 9471.96 ------------ Accuracy: 55.1%\n",
            "Step: 1933 ------------ Loss: 9471.94 ------------ Accuracy: 55.1%\n",
            "Step: 1934 ------------ Loss: 9471.52 ------------ Accuracy: 55.1%\n",
            "Step: 1935 ------------ Loss: 9471.41 ------------ Accuracy: 55.1%\n",
            "Step: 1936 ------------ Loss: 9470.96 ------------ Accuracy: 55.2%\n",
            "Step: 1937 ------------ Loss: 9470.92 ------------ Accuracy: 55.2%\n",
            "Step: 1938 ------------ Loss: 9470.84 ------------ Accuracy: 55.2%\n",
            "Step: 1939 ------------ Loss: 9470.42 ------------ Accuracy: 55.2%\n",
            "Step: 1940 ------------ Loss: 9470.39 ------------ Accuracy: 55.2%\n",
            "Step: 1941 ------------ Loss: 9470.38 ------------ Accuracy: 55.2%\n",
            "Step: 1942 ------------ Loss: 9470.36 ------------ Accuracy: 55.2%\n",
            "Step: 1943 ------------ Loss: 9470.29 ------------ Accuracy: 55.2%\n",
            "Step: 1944 ------------ Loss: 9470.25 ------------ Accuracy: 55.2%\n",
            "Step: 1945 ------------ Loss: 9470.22 ------------ Accuracy: 55.2%\n",
            "Step: 1946 ------------ Loss: 9470.15 ------------ Accuracy: 55.2%\n",
            "Step: 1947 ------------ Loss: 9470.08 ------------ Accuracy: 55.2%\n",
            "Step: 1948 ------------ Loss: 9470.0 ------------ Accuracy: 55.2%\n",
            "Step: 1949 ------------ Loss: 9469.93 ------------ Accuracy: 55.2%\n",
            "Step: 1950 ------------ Loss: 9469.59 ------------ Accuracy: 55.3%\n",
            "Step: 1951 ------------ Loss: 9469.54 ------------ Accuracy: 55.3%\n",
            "Step: 1952 ------------ Loss: 9469.49 ------------ Accuracy: 55.2%\n",
            "Step: 1953 ------------ Loss: 9469.06 ------------ Accuracy: 55.3%\n",
            "Step: 1954 ------------ Loss: 9466.85 ------------ Accuracy: 55.2%\n",
            "Step: 1955 ------------ Loss: 9466.8 ------------ Accuracy: 55.2%\n",
            "Step: 1956 ------------ Loss: 9461.96 ------------ Accuracy: 55.2%\n",
            "Step: 1957 ------------ Loss: 9461.52 ------------ Accuracy: 55.2%\n",
            "Step: 1958 ------------ Loss: 9461.47 ------------ Accuracy: 55.2%\n",
            "Step: 1959 ------------ Loss: 9461.1 ------------ Accuracy: 55.2%\n",
            "Step: 1960 ------------ Loss: 9461.03 ------------ Accuracy: 55.2%\n",
            "Step: 1961 ------------ Loss: 9460.96 ------------ Accuracy: 55.2%\n",
            "Step: 1962 ------------ Loss: 9460.9 ------------ Accuracy: 55.2%\n",
            "Step: 1963 ------------ Loss: 9460.8 ------------ Accuracy: 55.2%\n",
            "Step: 1964 ------------ Loss: 9460.77 ------------ Accuracy: 55.2%\n",
            "Step: 1965 ------------ Loss: 9460.72 ------------ Accuracy: 55.2%\n",
            "Step: 1966 ------------ Loss: 9458.58 ------------ Accuracy: 55.2%\n",
            "Step: 1967 ------------ Loss: 9458.55 ------------ Accuracy: 55.2%\n",
            "Step: 1968 ------------ Loss: 9458.16 ------------ Accuracy: 55.2%\n",
            "Step: 1969 ------------ Loss: 9458.1 ------------ Accuracy: 55.2%\n",
            "Step: 1970 ------------ Loss: 9458.08 ------------ Accuracy: 55.2%\n",
            "Step: 1971 ------------ Loss: 9457.72 ------------ Accuracy: 55.2%\n",
            "Step: 1972 ------------ Loss: 9455.73 ------------ Accuracy: 55.2%\n",
            "Step: 1973 ------------ Loss: 9455.19 ------------ Accuracy: 55.2%\n",
            "Step: 1974 ------------ Loss: 9455.15 ------------ Accuracy: 55.2%\n",
            "Step: 1975 ------------ Loss: 9455.07 ------------ Accuracy: 55.2%\n",
            "Step: 1976 ------------ Loss: 9455.0 ------------ Accuracy: 55.2%\n",
            "Step: 1977 ------------ Loss: 9454.95 ------------ Accuracy: 55.2%\n",
            "Step: 1978 ------------ Loss: 9454.59 ------------ Accuracy: 55.2%\n",
            "Step: 1979 ------------ Loss: 9454.33 ------------ Accuracy: 55.2%\n",
            "Step: 1980 ------------ Loss: 9454.28 ------------ Accuracy: 55.2%\n",
            "Step: 1981 ------------ Loss: 9454.24 ------------ Accuracy: 55.2%\n",
            "Step: 1982 ------------ Loss: 9454.2 ------------ Accuracy: 55.2%\n",
            "Step: 1983 ------------ Loss: 9454.16 ------------ Accuracy: 55.2%\n",
            "Step: 1984 ------------ Loss: 9454.09 ------------ Accuracy: 55.2%\n",
            "Step: 1985 ------------ Loss: 9454.06 ------------ Accuracy: 55.2%\n",
            "Step: 1986 ------------ Loss: 9453.97 ------------ Accuracy: 55.2%\n",
            "Step: 1987 ------------ Loss: 9453.95 ------------ Accuracy: 55.2%\n",
            "Step: 1988 ------------ Loss: 9453.64 ------------ Accuracy: 55.2%\n",
            "Step: 1989 ------------ Loss: 9453.22 ------------ Accuracy: 55.2%\n",
            "Step: 1990 ------------ Loss: 9453.01 ------------ Accuracy: 55.2%\n",
            "Step: 1991 ------------ Loss: 9452.36 ------------ Accuracy: 55.2%\n",
            "Step: 1992 ------------ Loss: 9452.29 ------------ Accuracy: 55.2%\n",
            "Step: 1993 ------------ Loss: 9450.13 ------------ Accuracy: 55.2%\n",
            "Step: 1994 ------------ Loss: 9445.35 ------------ Accuracy: 55.2%\n",
            "Step: 1995 ------------ Loss: 9444.98 ------------ Accuracy: 55.2%\n",
            "Step: 1996 ------------ Loss: 9444.94 ------------ Accuracy: 55.2%\n",
            "Step: 1997 ------------ Loss: 9444.87 ------------ Accuracy: 55.2%\n",
            "Step: 1998 ------------ Loss: 9444.85 ------------ Accuracy: 55.2%\n",
            "Step: 1999 ------------ Loss: 9444.48 ------------ Accuracy: 55.2%\n",
            "Step: 2000 ------------ Loss: 9444.13 ------------ Accuracy: 55.2%\n",
            "Step: 2001 ------------ Loss: 9443.8 ------------ Accuracy: 55.2%\n",
            "Step: 2002 ------------ Loss: 9441.9 ------------ Accuracy: 55.2%\n",
            "Step: 2003 ------------ Loss: 9441.87 ------------ Accuracy: 55.2%\n",
            "Step: 2004 ------------ Loss: 9440.92 ------------ Accuracy: 55.2%\n",
            "Step: 2005 ------------ Loss: 9439.98 ------------ Accuracy: 55.2%\n",
            "Step: 2006 ------------ Loss: 9439.95 ------------ Accuracy: 55.2%\n",
            "Step: 2007 ------------ Loss: 9439.58 ------------ Accuracy: 55.2%\n",
            "Step: 2008 ------------ Loss: 9439.25 ------------ Accuracy: 55.2%\n",
            "Step: 2009 ------------ Loss: 9439.24 ------------ Accuracy: 55.2%\n",
            "Step: 2010 ------------ Loss: 9439.21 ------------ Accuracy: 55.2%\n",
            "Step: 2011 ------------ Loss: 9439.12 ------------ Accuracy: 55.2%\n",
            "Step: 2012 ------------ Loss: 9439.02 ------------ Accuracy: 55.2%\n",
            "Step: 2013 ------------ Loss: 9438.72 ------------ Accuracy: 55.2%\n",
            "Step: 2014 ------------ Loss: 9436.93 ------------ Accuracy: 55.0%\n",
            "Step: 2015 ------------ Loss: 9436.9 ------------ Accuracy: 55.0%\n",
            "Step: 2016 ------------ Loss: 9436.15 ------------ Accuracy: 55.2%\n",
            "Step: 2017 ------------ Loss: 9436.08 ------------ Accuracy: 55.2%\n",
            "Step: 2018 ------------ Loss: 9436.06 ------------ Accuracy: 55.2%\n",
            "Step: 2019 ------------ Loss: 9435.98 ------------ Accuracy: 55.2%\n",
            "Step: 2020 ------------ Loss: 9435.93 ------------ Accuracy: 55.2%\n",
            "Step: 2021 ------------ Loss: 9435.86 ------------ Accuracy: 55.2%\n",
            "Step: 2022 ------------ Loss: 9435.41 ------------ Accuracy: 55.2%\n",
            "Step: 2023 ------------ Loss: 9435.37 ------------ Accuracy: 55.2%\n",
            "Step: 2024 ------------ Loss: 9435.32 ------------ Accuracy: 55.2%\n",
            "Step: 2025 ------------ Loss: 9435.27 ------------ Accuracy: 55.2%\n",
            "Step: 2026 ------------ Loss: 9434.96 ------------ Accuracy: 55.2%\n",
            "Step: 2027 ------------ Loss: 9434.91 ------------ Accuracy: 55.2%\n",
            "Step: 2028 ------------ Loss: 9434.89 ------------ Accuracy: 55.2%\n",
            "Step: 2029 ------------ Loss: 9434.85 ------------ Accuracy: 55.2%\n",
            "Step: 2030 ------------ Loss: 9434.38 ------------ Accuracy: 55.2%\n",
            "Step: 2031 ------------ Loss: 9433.99 ------------ Accuracy: 55.2%\n",
            "Step: 2032 ------------ Loss: 9433.95 ------------ Accuracy: 55.2%\n",
            "Step: 2033 ------------ Loss: 9433.89 ------------ Accuracy: 55.2%\n",
            "Step: 2034 ------------ Loss: 9433.86 ------------ Accuracy: 55.2%\n",
            "Step: 2035 ------------ Loss: 9433.82 ------------ Accuracy: 55.2%\n",
            "Step: 2036 ------------ Loss: 9433.79 ------------ Accuracy: 55.2%\n",
            "Step: 2037 ------------ Loss: 9433.7 ------------ Accuracy: 55.2%\n",
            "Step: 2038 ------------ Loss: 9433.68 ------------ Accuracy: 55.2%\n",
            "Step: 2039 ------------ Loss: 9433.65 ------------ Accuracy: 55.2%\n",
            "Step: 2040 ------------ Loss: 9433.64 ------------ Accuracy: 55.2%\n",
            "Step: 2041 ------------ Loss: 9432.7 ------------ Accuracy: 55.2%\n",
            "Step: 2042 ------------ Loss: 9432.35 ------------ Accuracy: 55.2%\n",
            "Step: 2043 ------------ Loss: 9427.79 ------------ Accuracy: 55.2%\n",
            "Step: 2044 ------------ Loss: 9427.79 ------------ Accuracy: 55.2%\n",
            "Step: 2045 ------------ Loss: 9427.78 ------------ Accuracy: 55.2%\n",
            "Step: 2046 ------------ Loss: 9427.71 ------------ Accuracy: 55.2%\n",
            "Step: 2047 ------------ Loss: 9427.4 ------------ Accuracy: 55.2%\n",
            "Step: 2048 ------------ Loss: 9427.4 ------------ Accuracy: 55.2%\n",
            "Step: 2049 ------------ Loss: 9427.31 ------------ Accuracy: 55.2%\n",
            "Step: 2050 ------------ Loss: 9427.29 ------------ Accuracy: 55.2%\n",
            "Step: 2051 ------------ Loss: 9427.27 ------------ Accuracy: 55.2%\n",
            "Step: 2052 ------------ Loss: 9422.93 ------------ Accuracy: 55.0%\n",
            "Step: 2053 ------------ Loss: 9422.57 ------------ Accuracy: 55.2%\n",
            "Step: 2054 ------------ Loss: 9422.21 ------------ Accuracy: 55.2%\n",
            "Step: 2055 ------------ Loss: 9422.18 ------------ Accuracy: 55.2%\n",
            "Step: 2056 ------------ Loss: 9421.81 ------------ Accuracy: 55.2%\n",
            "Step: 2057 ------------ Loss: 9421.46 ------------ Accuracy: 55.2%\n",
            "Step: 2058 ------------ Loss: 9420.81 ------------ Accuracy: 55.2%\n",
            "Step: 2059 ------------ Loss: 9420.72 ------------ Accuracy: 55.2%\n",
            "Step: 2060 ------------ Loss: 9420.37 ------------ Accuracy: 55.2%\n",
            "Step: 2061 ------------ Loss: 9419.47 ------------ Accuracy: 55.2%\n",
            "Step: 2062 ------------ Loss: 9417.54 ------------ Accuracy: 55.2%\n",
            "Step: 2063 ------------ Loss: 9417.47 ------------ Accuracy: 55.2%\n",
            "Step: 2064 ------------ Loss: 9417.36 ------------ Accuracy: 55.2%\n",
            "Step: 2065 ------------ Loss: 9416.81 ------------ Accuracy: 55.2%\n",
            "Step: 2066 ------------ Loss: 9416.76 ------------ Accuracy: 55.2%\n",
            "Step: 2067 ------------ Loss: 9416.73 ------------ Accuracy: 55.2%\n",
            "Step: 2068 ------------ Loss: 9416.64 ------------ Accuracy: 55.2%\n",
            "Step: 2069 ------------ Loss: 9414.72 ------------ Accuracy: 55.2%\n",
            "Step: 2070 ------------ Loss: 9414.62 ------------ Accuracy: 55.2%\n",
            "Step: 2071 ------------ Loss: 9410.25 ------------ Accuracy: 55.2%\n",
            "Step: 2072 ------------ Loss: 9408.46 ------------ Accuracy: 55.2%\n",
            "Step: 2073 ------------ Loss: 9408.36 ------------ Accuracy: 55.2%\n",
            "Step: 2074 ------------ Loss: 9408.28 ------------ Accuracy: 55.2%\n",
            "Step: 2075 ------------ Loss: 9408.26 ------------ Accuracy: 55.2%\n",
            "Step: 2076 ------------ Loss: 9408.23 ------------ Accuracy: 55.2%\n",
            "Step: 2077 ------------ Loss: 9408.21 ------------ Accuracy: 55.2%\n",
            "Step: 2078 ------------ Loss: 9408.19 ------------ Accuracy: 55.2%\n",
            "Step: 2079 ------------ Loss: 9408.17 ------------ Accuracy: 55.2%\n",
            "Step: 2080 ------------ Loss: 9408.1 ------------ Accuracy: 55.2%\n",
            "Step: 2081 ------------ Loss: 9408.09 ------------ Accuracy: 55.2%\n",
            "Step: 2082 ------------ Loss: 9407.78 ------------ Accuracy: 55.2%\n",
            "Step: 2083 ------------ Loss: 9407.71 ------------ Accuracy: 55.2%\n",
            "Step: 2084 ------------ Loss: 9406.82 ------------ Accuracy: 55.2%\n",
            "Step: 2085 ------------ Loss: 9406.73 ------------ Accuracy: 55.2%\n",
            "Step: 2086 ------------ Loss: 9406.63 ------------ Accuracy: 55.2%\n",
            "Step: 2087 ------------ Loss: 9406.53 ------------ Accuracy: 55.2%\n",
            "Step: 2088 ------------ Loss: 9406.47 ------------ Accuracy: 55.3%\n",
            "Step: 2089 ------------ Loss: 9406.45 ------------ Accuracy: 55.3%\n",
            "Step: 2090 ------------ Loss: 9406.43 ------------ Accuracy: 55.3%\n",
            "Step: 2091 ------------ Loss: 9406.42 ------------ Accuracy: 55.3%\n",
            "Step: 2092 ------------ Loss: 9405.88 ------------ Accuracy: 55.2%\n",
            "Step: 2093 ------------ Loss: 9405.47 ------------ Accuracy: 55.2%\n",
            "Step: 2094 ------------ Loss: 9405.4 ------------ Accuracy: 55.2%\n",
            "Step: 2095 ------------ Loss: 9405.39 ------------ Accuracy: 55.3%\n",
            "Step: 2096 ------------ Loss: 9405.38 ------------ Accuracy: 55.3%\n",
            "Step: 2097 ------------ Loss: 9405.37 ------------ Accuracy: 55.3%\n",
            "Step: 2098 ------------ Loss: 9405.36 ------------ Accuracy: 55.3%\n",
            "Step: 2099 ------------ Loss: 9405.34 ------------ Accuracy: 55.3%\n",
            "Step: 2100 ------------ Loss: 9404.98 ------------ Accuracy: 55.3%\n",
            "Step: 2101 ------------ Loss: 9404.94 ------------ Accuracy: 55.3%\n",
            "Step: 2102 ------------ Loss: 9404.59 ------------ Accuracy: 55.3%\n",
            "Step: 2103 ------------ Loss: 9404.59 ------------ Accuracy: 55.3%\n",
            "Step: 2104 ------------ Loss: 9404.13 ------------ Accuracy: 55.3%\n",
            "Step: 2105 ------------ Loss: 9404.1 ------------ Accuracy: 55.3%\n",
            "Step: 2106 ------------ Loss: 9404.07 ------------ Accuracy: 55.3%\n",
            "Step: 2107 ------------ Loss: 9403.79 ------------ Accuracy: 55.3%\n",
            "Step: 2108 ------------ Loss: 9403.77 ------------ Accuracy: 55.3%\n",
            "Step: 2109 ------------ Loss: 9403.72 ------------ Accuracy: 55.3%\n",
            "Step: 2110 ------------ Loss: 9403.71 ------------ Accuracy: 55.3%\n",
            "Step: 2111 ------------ Loss: 9403.7 ------------ Accuracy: 55.3%\n",
            "Step: 2112 ------------ Loss: 9403.69 ------------ Accuracy: 55.3%\n",
            "Step: 2113 ------------ Loss: 9403.61 ------------ Accuracy: 55.3%\n",
            "Step: 2114 ------------ Loss: 9403.54 ------------ Accuracy: 55.3%\n",
            "Step: 2115 ------------ Loss: 9403.46 ------------ Accuracy: 55.3%\n",
            "Step: 2116 ------------ Loss: 9403.14 ------------ Accuracy: 55.3%\n",
            "Step: 2117 ------------ Loss: 9403.11 ------------ Accuracy: 55.3%\n",
            "Step: 2118 ------------ Loss: 9403.07 ------------ Accuracy: 55.3%\n",
            "Step: 2119 ------------ Loss: 9402.57 ------------ Accuracy: 55.4%\n",
            "Step: 2120 ------------ Loss: 9402.55 ------------ Accuracy: 55.4%\n",
            "Step: 2121 ------------ Loss: 9402.54 ------------ Accuracy: 55.4%\n",
            "Step: 2122 ------------ Loss: 9402.46 ------------ Accuracy: 55.4%\n",
            "Step: 2123 ------------ Loss: 9402.46 ------------ Accuracy: 55.4%\n",
            "Step: 2124 ------------ Loss: 9402.08 ------------ Accuracy: 55.4%\n",
            "Step: 2125 ------------ Loss: 9401.7 ------------ Accuracy: 55.4%\n",
            "Step: 2126 ------------ Loss: 9400.81 ------------ Accuracy: 55.4%\n",
            "Step: 2127 ------------ Loss: 9400.49 ------------ Accuracy: 55.2%\n",
            "Step: 2128 ------------ Loss: 9400.48 ------------ Accuracy: 55.2%\n",
            "Step: 2129 ------------ Loss: 9400.41 ------------ Accuracy: 55.2%\n",
            "Step: 2130 ------------ Loss: 9400.39 ------------ Accuracy: 55.2%\n",
            "Step: 2131 ------------ Loss: 9400.1 ------------ Accuracy: 55.2%\n",
            "Step: 2132 ------------ Loss: 9400.08 ------------ Accuracy: 55.2%\n",
            "Step: 2133 ------------ Loss: 9400.06 ------------ Accuracy: 55.2%\n",
            "Step: 2134 ------------ Loss: 9400.04 ------------ Accuracy: 55.2%\n",
            "Step: 2135 ------------ Loss: 9399.75 ------------ Accuracy: 55.2%\n",
            "Step: 2136 ------------ Loss: 9399.67 ------------ Accuracy: 55.2%\n",
            "Step: 2137 ------------ Loss: 9399.64 ------------ Accuracy: 55.2%\n",
            "Step: 2138 ------------ Loss: 9399.55 ------------ Accuracy: 55.2%\n",
            "Step: 2139 ------------ Loss: 9399.47 ------------ Accuracy: 55.2%\n",
            "Step: 2140 ------------ Loss: 9399.21 ------------ Accuracy: 55.2%\n",
            "Step: 2141 ------------ Loss: 9398.35 ------------ Accuracy: 55.2%\n",
            "Step: 2142 ------------ Loss: 9398.26 ------------ Accuracy: 55.2%\n",
            "Step: 2143 ------------ Loss: 9398.05 ------------ Accuracy: 55.2%\n",
            "Step: 2144 ------------ Loss: 9398.05 ------------ Accuracy: 55.2%\n",
            "Step: 2145 ------------ Loss: 9397.93 ------------ Accuracy: 55.2%\n",
            "Step: 2146 ------------ Loss: 9397.63 ------------ Accuracy: 55.2%\n",
            "Step: 2147 ------------ Loss: 9397.54 ------------ Accuracy: 55.2%\n",
            "Step: 2148 ------------ Loss: 9397.54 ------------ Accuracy: 55.2%\n",
            "Step: 2149 ------------ Loss: 9397.46 ------------ Accuracy: 55.2%\n",
            "Step: 2150 ------------ Loss: 9397.43 ------------ Accuracy: 55.2%\n",
            "Step: 2151 ------------ Loss: 9397.43 ------------ Accuracy: 55.2%\n",
            "Step: 2152 ------------ Loss: 9395.52 ------------ Accuracy: 55.2%\n",
            "Step: 2153 ------------ Loss: 9395.42 ------------ Accuracy: 55.2%\n",
            "Step: 2154 ------------ Loss: 9395.07 ------------ Accuracy: 55.2%\n",
            "Step: 2155 ------------ Loss: 9395.05 ------------ Accuracy: 55.2%\n",
            "Step: 2156 ------------ Loss: 9394.76 ------------ Accuracy: 55.2%\n",
            "Step: 2157 ------------ Loss: 9394.67 ------------ Accuracy: 55.2%\n",
            "Step: 2158 ------------ Loss: 9394.66 ------------ Accuracy: 55.2%\n",
            "Step: 2159 ------------ Loss: 9394.59 ------------ Accuracy: 55.2%\n",
            "Step: 2160 ------------ Loss: 9390.39 ------------ Accuracy: 55.2%\n",
            "Step: 2161 ------------ Loss: 9390.31 ------------ Accuracy: 55.2%\n",
            "Step: 2162 ------------ Loss: 9390.31 ------------ Accuracy: 55.2%\n",
            "Step: 2163 ------------ Loss: 9389.47 ------------ Accuracy: 55.2%\n",
            "Step: 2164 ------------ Loss: 9389.47 ------------ Accuracy: 55.2%\n",
            "Step: 2165 ------------ Loss: 9389.43 ------------ Accuracy: 55.2%\n",
            "Step: 2166 ------------ Loss: 9389.34 ------------ Accuracy: 55.2%\n",
            "Step: 2167 ------------ Loss: 9389.26 ------------ Accuracy: 55.2%\n",
            "Step: 2168 ------------ Loss: 9389.23 ------------ Accuracy: 55.2%\n",
            "Step: 2169 ------------ Loss: 9389.14 ------------ Accuracy: 55.2%\n",
            "Step: 2170 ------------ Loss: 9389.13 ------------ Accuracy: 55.2%\n",
            "Step: 2171 ------------ Loss: 9389.13 ------------ Accuracy: 55.2%\n",
            "Step: 2172 ------------ Loss: 9389.03 ------------ Accuracy: 55.3%\n",
            "Step: 2173 ------------ Loss: 9389.03 ------------ Accuracy: 55.3%\n",
            "Step: 2174 ------------ Loss: 9388.69 ------------ Accuracy: 55.2%\n",
            "Step: 2175 ------------ Loss: 9388.61 ------------ Accuracy: 55.2%\n",
            "Step: 2176 ------------ Loss: 9388.27 ------------ Accuracy: 55.2%\n",
            "Step: 2177 ------------ Loss: 9386.42 ------------ Accuracy: 55.2%\n",
            "Step: 2178 ------------ Loss: 9386.12 ------------ Accuracy: 55.2%\n",
            "Step: 2179 ------------ Loss: 9386.02 ------------ Accuracy: 55.2%\n",
            "Step: 2180 ------------ Loss: 9385.66 ------------ Accuracy: 55.2%\n",
            "Step: 2181 ------------ Loss: 9383.95 ------------ Accuracy: 55.2%\n",
            "Step: 2182 ------------ Loss: 9383.83 ------------ Accuracy: 55.2%\n",
            "Step: 2183 ------------ Loss: 9383.77 ------------ Accuracy: 55.3%\n",
            "Step: 2184 ------------ Loss: 9383.67 ------------ Accuracy: 55.3%\n",
            "Step: 2185 ------------ Loss: 9383.64 ------------ Accuracy: 55.3%\n",
            "Step: 2186 ------------ Loss: 9383.55 ------------ Accuracy: 55.3%\n",
            "Step: 2187 ------------ Loss: 9383.5 ------------ Accuracy: 55.3%\n",
            "Step: 2188 ------------ Loss: 9383.49 ------------ Accuracy: 55.3%\n",
            "Step: 2189 ------------ Loss: 9383.46 ------------ Accuracy: 55.3%\n",
            "Step: 2190 ------------ Loss: 9383.11 ------------ Accuracy: 55.3%\n",
            "Step: 2191 ------------ Loss: 9383.02 ------------ Accuracy: 55.3%\n",
            "Step: 2192 ------------ Loss: 9382.97 ------------ Accuracy: 55.3%\n",
            "Step: 2193 ------------ Loss: 9382.37 ------------ Accuracy: 55.3%\n",
            "Step: 2194 ------------ Loss: 9382.36 ------------ Accuracy: 55.3%\n",
            "Step: 2195 ------------ Loss: 9382.29 ------------ Accuracy: 55.3%\n",
            "Step: 2196 ------------ Loss: 9382.21 ------------ Accuracy: 55.3%\n",
            "Step: 2197 ------------ Loss: 9381.8 ------------ Accuracy: 55.4%\n",
            "Step: 2198 ------------ Loss: 9381.72 ------------ Accuracy: 55.4%\n",
            "Step: 2199 ------------ Loss: 9381.69 ------------ Accuracy: 55.4%\n",
            "Step: 2200 ------------ Loss: 9381.66 ------------ Accuracy: 55.4%\n",
            "Step: 2201 ------------ Loss: 9381.32 ------------ Accuracy: 55.4%\n",
            "Step: 2202 ------------ Loss: 9380.9 ------------ Accuracy: 55.3%\n",
            "Step: 2203 ------------ Loss: 9380.89 ------------ Accuracy: 55.3%\n",
            "Step: 2204 ------------ Loss: 9380.62 ------------ Accuracy: 55.3%\n",
            "Step: 2205 ------------ Loss: 9380.34 ------------ Accuracy: 55.3%\n",
            "Step: 2206 ------------ Loss: 9380.34 ------------ Accuracy: 55.3%\n",
            "Step: 2207 ------------ Loss: 9380.33 ------------ Accuracy: 55.3%\n",
            "Step: 2208 ------------ Loss: 9380.31 ------------ Accuracy: 55.3%\n",
            "Step: 2209 ------------ Loss: 9380.0 ------------ Accuracy: 55.3%\n",
            "Step: 2210 ------------ Loss: 9379.95 ------------ Accuracy: 55.3%\n",
            "Step: 2211 ------------ Loss: 9379.94 ------------ Accuracy: 55.3%\n",
            "Step: 2212 ------------ Loss: 9379.93 ------------ Accuracy: 55.3%\n",
            "Step: 2213 ------------ Loss: 9379.87 ------------ Accuracy: 55.3%\n",
            "Step: 2214 ------------ Loss: 9379.85 ------------ Accuracy: 55.3%\n",
            "Step: 2215 ------------ Loss: 9379.48 ------------ Accuracy: 55.4%\n",
            "Step: 2216 ------------ Loss: 9379.4 ------------ Accuracy: 55.4%\n",
            "Step: 2217 ------------ Loss: 9379.33 ------------ Accuracy: 55.4%\n",
            "Step: 2218 ------------ Loss: 9378.96 ------------ Accuracy: 55.4%\n",
            "Step: 2219 ------------ Loss: 9378.88 ------------ Accuracy: 55.4%\n",
            "Step: 2220 ------------ Loss: 9378.87 ------------ Accuracy: 55.4%\n",
            "Step: 2221 ------------ Loss: 9378.82 ------------ Accuracy: 55.4%\n",
            "Step: 2222 ------------ Loss: 9378.79 ------------ Accuracy: 55.4%\n",
            "Step: 2223 ------------ Loss: 9378.71 ------------ Accuracy: 55.4%\n",
            "Step: 2224 ------------ Loss: 9378.63 ------------ Accuracy: 55.4%\n",
            "Step: 2225 ------------ Loss: 9377.73 ------------ Accuracy: 55.4%\n",
            "Step: 2226 ------------ Loss: 9377.72 ------------ Accuracy: 55.4%\n",
            "Step: 2227 ------------ Loss: 9377.7 ------------ Accuracy: 55.4%\n",
            "Step: 2228 ------------ Loss: 9377.38 ------------ Accuracy: 55.4%\n",
            "Step: 2229 ------------ Loss: 9377.36 ------------ Accuracy: 55.4%\n",
            "Step: 2230 ------------ Loss: 9377.33 ------------ Accuracy: 55.4%\n",
            "Step: 2231 ------------ Loss: 9376.99 ------------ Accuracy: 55.4%\n",
            "Step: 2232 ------------ Loss: 9376.98 ------------ Accuracy: 55.4%\n",
            "Step: 2233 ------------ Loss: 9376.96 ------------ Accuracy: 55.4%\n",
            "Step: 2234 ------------ Loss: 9376.89 ------------ Accuracy: 55.4%\n",
            "Step: 2235 ------------ Loss: 9376.0 ------------ Accuracy: 55.3%\n",
            "Step: 2236 ------------ Loss: 9375.67 ------------ Accuracy: 55.3%\n",
            "Step: 2237 ------------ Loss: 9375.33 ------------ Accuracy: 55.3%\n",
            "Step: 2238 ------------ Loss: 9375.32 ------------ Accuracy: 55.3%\n",
            "Step: 2239 ------------ Loss: 9375.29 ------------ Accuracy: 55.3%\n",
            "Step: 2240 ------------ Loss: 9374.95 ------------ Accuracy: 55.3%\n",
            "Step: 2241 ------------ Loss: 9374.92 ------------ Accuracy: 55.4%\n",
            "Step: 2242 ------------ Loss: 9374.89 ------------ Accuracy: 55.4%\n",
            "Step: 2243 ------------ Loss: 9374.82 ------------ Accuracy: 55.4%\n",
            "Step: 2244 ------------ Loss: 9374.8 ------------ Accuracy: 55.4%\n",
            "Step: 2245 ------------ Loss: 9374.75 ------------ Accuracy: 55.3%\n",
            "Step: 2246 ------------ Loss: 9374.73 ------------ Accuracy: 55.3%\n",
            "Step: 2247 ------------ Loss: 9374.42 ------------ Accuracy: 55.3%\n",
            "Step: 2248 ------------ Loss: 9374.4 ------------ Accuracy: 55.3%\n",
            "Step: 2249 ------------ Loss: 9374.39 ------------ Accuracy: 55.3%\n",
            "Step: 2250 ------------ Loss: 9374.38 ------------ Accuracy: 55.3%\n",
            "Step: 2251 ------------ Loss: 9374.07 ------------ Accuracy: 55.3%\n",
            "Step: 2252 ------------ Loss: 9374.0 ------------ Accuracy: 55.3%\n",
            "Step: 2253 ------------ Loss: 9373.98 ------------ Accuracy: 55.3%\n",
            "Step: 2254 ------------ Loss: 9373.64 ------------ Accuracy: 55.3%\n",
            "Step: 2255 ------------ Loss: 9373.62 ------------ Accuracy: 55.3%\n",
            "Step: 2256 ------------ Loss: 9373.61 ------------ Accuracy: 55.3%\n",
            "Step: 2257 ------------ Loss: 9373.54 ------------ Accuracy: 55.3%\n",
            "Step: 2258 ------------ Loss: 9373.53 ------------ Accuracy: 55.3%\n",
            "Step: 2259 ------------ Loss: 9373.51 ------------ Accuracy: 55.3%\n",
            "Step: 2260 ------------ Loss: 9373.21 ------------ Accuracy: 55.3%\n",
            "Step: 2261 ------------ Loss: 9373.18 ------------ Accuracy: 55.3%\n",
            "Step: 2262 ------------ Loss: 9373.16 ------------ Accuracy: 55.3%\n",
            "Step: 2263 ------------ Loss: 9372.79 ------------ Accuracy: 55.3%\n",
            "Step: 2264 ------------ Loss: 9372.72 ------------ Accuracy: 55.3%\n",
            "Step: 2265 ------------ Loss: 9368.47 ------------ Accuracy: 55.3%\n",
            "Step: 2266 ------------ Loss: 9368.18 ------------ Accuracy: 55.3%\n",
            "Step: 2267 ------------ Loss: 9368.1 ------------ Accuracy: 55.3%\n",
            "Step: 2268 ------------ Loss: 9366.32 ------------ Accuracy: 55.3%\n",
            "Step: 2269 ------------ Loss: 9366.26 ------------ Accuracy: 55.3%\n",
            "Step: 2270 ------------ Loss: 9366.18 ------------ Accuracy: 55.3%\n",
            "Step: 2271 ------------ Loss: 9366.15 ------------ Accuracy: 55.3%\n",
            "Step: 2272 ------------ Loss: 9366.14 ------------ Accuracy: 55.3%\n",
            "Step: 2273 ------------ Loss: 9366.08 ------------ Accuracy: 55.3%\n",
            "Step: 2274 ------------ Loss: 9365.23 ------------ Accuracy: 55.3%\n",
            "Step: 2275 ------------ Loss: 9365.22 ------------ Accuracy: 55.3%\n",
            "Step: 2276 ------------ Loss: 9365.15 ------------ Accuracy: 55.3%\n",
            "Step: 2277 ------------ Loss: 9365.11 ------------ Accuracy: 55.3%\n",
            "Step: 2278 ------------ Loss: 9365.04 ------------ Accuracy: 55.3%\n",
            "Step: 2279 ------------ Loss: 9365.03 ------------ Accuracy: 55.3%\n",
            "Step: 2280 ------------ Loss: 9365.01 ------------ Accuracy: 55.3%\n",
            "Step: 2281 ------------ Loss: 9364.95 ------------ Accuracy: 55.3%\n",
            "Step: 2282 ------------ Loss: 9364.94 ------------ Accuracy: 55.3%\n",
            "Step: 2283 ------------ Loss: 9364.87 ------------ Accuracy: 55.3%\n",
            "Step: 2284 ------------ Loss: 9364.85 ------------ Accuracy: 55.3%\n",
            "Step: 2285 ------------ Loss: 9364.55 ------------ Accuracy: 55.3%\n",
            "Step: 2286 ------------ Loss: 9360.55 ------------ Accuracy: 55.3%\n",
            "Step: 2287 ------------ Loss: 9358.87 ------------ Accuracy: 55.3%\n",
            "Step: 2288 ------------ Loss: 9358.69 ------------ Accuracy: 55.3%\n",
            "Step: 2289 ------------ Loss: 9358.68 ------------ Accuracy: 55.3%\n",
            "Step: 2290 ------------ Loss: 9358.4 ------------ Accuracy: 55.3%\n",
            "Step: 2291 ------------ Loss: 9357.56 ------------ Accuracy: 55.4%\n",
            "Step: 2292 ------------ Loss: 9357.49 ------------ Accuracy: 55.4%\n",
            "Step: 2293 ------------ Loss: 9357.15 ------------ Accuracy: 55.4%\n",
            "Step: 2294 ------------ Loss: 9357.07 ------------ Accuracy: 55.4%\n",
            "Step: 2295 ------------ Loss: 9356.99 ------------ Accuracy: 55.4%\n",
            "Step: 2296 ------------ Loss: 9356.74 ------------ Accuracy: 55.3%\n",
            "Step: 2297 ------------ Loss: 9356.65 ------------ Accuracy: 55.4%\n",
            "Step: 2298 ------------ Loss: 9356.62 ------------ Accuracy: 55.4%\n",
            "Step: 2299 ------------ Loss: 9356.35 ------------ Accuracy: 55.4%\n",
            "Step: 2300 ------------ Loss: 9354.68 ------------ Accuracy: 55.3%\n",
            "Step: 2301 ------------ Loss: 9354.67 ------------ Accuracy: 55.3%\n",
            "Step: 2302 ------------ Loss: 9353.84 ------------ Accuracy: 55.3%\n",
            "Step: 2303 ------------ Loss: 9353.83 ------------ Accuracy: 55.3%\n",
            "Step: 2304 ------------ Loss: 9353.01 ------------ Accuracy: 55.3%\n",
            "Step: 2305 ------------ Loss: 9352.2 ------------ Accuracy: 55.3%\n",
            "Step: 2306 ------------ Loss: 9352.03 ------------ Accuracy: 55.3%\n",
            "Step: 2307 ------------ Loss: 9351.78 ------------ Accuracy: 55.3%\n",
            "Step: 2308 ------------ Loss: 9351.72 ------------ Accuracy: 55.3%\n",
            "Step: 2309 ------------ Loss: 9350.95 ------------ Accuracy: 55.3%\n",
            "Step: 2310 ------------ Loss: 9350.94 ------------ Accuracy: 55.3%\n",
            "Step: 2311 ------------ Loss: 9350.6 ------------ Accuracy: 55.3%\n",
            "Step: 2312 ------------ Loss: 9350.6 ------------ Accuracy: 55.3%\n",
            "Step: 2313 ------------ Loss: 9350.35 ------------ Accuracy: 55.3%\n",
            "Step: 2314 ------------ Loss: 9348.71 ------------ Accuracy: 55.3%\n",
            "Step: 2315 ------------ Loss: 9348.64 ------------ Accuracy: 55.3%\n",
            "Step: 2316 ------------ Loss: 9348.3 ------------ Accuracy: 55.3%\n",
            "Step: 2317 ------------ Loss: 9348.08 ------------ Accuracy: 55.3%\n",
            "Step: 2318 ------------ Loss: 9348.01 ------------ Accuracy: 55.3%\n",
            "Step: 2319 ------------ Loss: 9347.95 ------------ Accuracy: 55.3%\n",
            "Step: 2320 ------------ Loss: 9347.93 ------------ Accuracy: 55.3%\n",
            "Step: 2321 ------------ Loss: 9347.73 ------------ Accuracy: 55.3%\n",
            "Step: 2322 ------------ Loss: 9347.71 ------------ Accuracy: 55.3%\n",
            "Step: 2323 ------------ Loss: 9347.63 ------------ Accuracy: 55.4%\n",
            "Step: 2324 ------------ Loss: 9347.62 ------------ Accuracy: 55.4%\n",
            "Step: 2325 ------------ Loss: 9347.6 ------------ Accuracy: 55.4%\n",
            "Step: 2326 ------------ Loss: 9347.59 ------------ Accuracy: 55.4%\n",
            "Step: 2327 ------------ Loss: 9347.58 ------------ Accuracy: 55.4%\n",
            "Step: 2328 ------------ Loss: 9347.52 ------------ Accuracy: 55.4%\n",
            "Step: 2329 ------------ Loss: 9347.51 ------------ Accuracy: 55.4%\n",
            "Step: 2330 ------------ Loss: 9347.26 ------------ Accuracy: 55.4%\n",
            "Step: 2331 ------------ Loss: 9347.26 ------------ Accuracy: 55.4%\n",
            "Step: 2332 ------------ Loss: 9346.91 ------------ Accuracy: 55.3%\n",
            "Step: 2333 ------------ Loss: 9346.88 ------------ Accuracy: 55.3%\n",
            "Step: 2334 ------------ Loss: 9346.86 ------------ Accuracy: 55.3%\n",
            "Step: 2335 ------------ Loss: 9346.85 ------------ Accuracy: 55.3%\n",
            "Step: 2336 ------------ Loss: 9346.51 ------------ Accuracy: 55.3%\n",
            "Step: 2337 ------------ Loss: 9346.5 ------------ Accuracy: 55.3%\n",
            "Step: 2338 ------------ Loss: 9346.24 ------------ Accuracy: 55.4%\n",
            "Step: 2339 ------------ Loss: 9346.15 ------------ Accuracy: 55.4%\n",
            "Step: 2340 ------------ Loss: 9346.07 ------------ Accuracy: 55.4%\n",
            "Step: 2341 ------------ Loss: 9345.24 ------------ Accuracy: 55.4%\n",
            "Step: 2342 ------------ Loss: 9344.65 ------------ Accuracy: 55.4%\n",
            "Step: 2343 ------------ Loss: 9344.6 ------------ Accuracy: 55.4%\n",
            "Step: 2344 ------------ Loss: 9344.28 ------------ Accuracy: 55.4%\n",
            "Step: 2345 ------------ Loss: 9344.2 ------------ Accuracy: 55.4%\n",
            "Step: 2346 ------------ Loss: 9344.19 ------------ Accuracy: 55.4%\n",
            "Step: 2347 ------------ Loss: 9340.18 ------------ Accuracy: 55.4%\n",
            "Step: 2348 ------------ Loss: 9339.93 ------------ Accuracy: 55.4%\n",
            "Step: 2349 ------------ Loss: 9339.91 ------------ Accuracy: 55.4%\n",
            "Step: 2350 ------------ Loss: 9339.88 ------------ Accuracy: 55.4%\n",
            "Step: 2351 ------------ Loss: 9339.88 ------------ Accuracy: 55.4%\n",
            "Step: 2352 ------------ Loss: 9339.8 ------------ Accuracy: 55.4%\n",
            "Step: 2353 ------------ Loss: 9335.97 ------------ Accuracy: 55.4%\n",
            "Step: 2354 ------------ Loss: 9335.87 ------------ Accuracy: 55.4%\n",
            "Step: 2355 ------------ Loss: 9335.87 ------------ Accuracy: 55.4%\n",
            "Step: 2356 ------------ Loss: 9335.77 ------------ Accuracy: 55.4%\n",
            "Step: 2357 ------------ Loss: 9335.69 ------------ Accuracy: 55.4%\n",
            "Step: 2358 ------------ Loss: 9335.44 ------------ Accuracy: 55.4%\n",
            "Step: 2359 ------------ Loss: 9335.37 ------------ Accuracy: 55.4%\n",
            "Step: 2360 ------------ Loss: 9335.29 ------------ Accuracy: 55.4%\n",
            "Step: 2361 ------------ Loss: 9335.29 ------------ Accuracy: 55.4%\n",
            "Step: 2362 ------------ Loss: 9333.62 ------------ Accuracy: 55.4%\n",
            "Step: 2363 ------------ Loss: 9333.62 ------------ Accuracy: 55.4%\n",
            "Step: 2364 ------------ Loss: 9333.53 ------------ Accuracy: 55.4%\n",
            "Step: 2365 ------------ Loss: 9333.5 ------------ Accuracy: 55.4%\n",
            "Step: 2366 ------------ Loss: 9332.88 ------------ Accuracy: 55.4%\n",
            "Step: 2367 ------------ Loss: 9332.57 ------------ Accuracy: 55.5%\n",
            "Step: 2368 ------------ Loss: 9332.55 ------------ Accuracy: 55.5%\n",
            "Step: 2369 ------------ Loss: 9332.54 ------------ Accuracy: 55.5%\n",
            "Step: 2370 ------------ Loss: 9332.54 ------------ Accuracy: 55.5%\n",
            "Step: 2371 ------------ Loss: 9332.47 ------------ Accuracy: 55.5%\n",
            "Step: 2372 ------------ Loss: 9332.13 ------------ Accuracy: 55.5%\n",
            "Step: 2373 ------------ Loss: 9328.3 ------------ Accuracy: 55.4%\n",
            "Step: 2374 ------------ Loss: 9327.97 ------------ Accuracy: 55.5%\n",
            "Step: 2375 ------------ Loss: 9327.89 ------------ Accuracy: 55.5%\n",
            "Step: 2376 ------------ Loss: 9327.66 ------------ Accuracy: 55.4%\n",
            "Step: 2377 ------------ Loss: 9327.34 ------------ Accuracy: 55.4%\n",
            "Step: 2378 ------------ Loss: 9326.57 ------------ Accuracy: 55.4%\n",
            "Step: 2379 ------------ Loss: 9326.56 ------------ Accuracy: 55.4%\n",
            "Step: 2380 ------------ Loss: 9326.56 ------------ Accuracy: 55.4%\n",
            "Step: 2381 ------------ Loss: 9326.48 ------------ Accuracy: 55.4%\n",
            "Step: 2382 ------------ Loss: 9326.31 ------------ Accuracy: 55.5%\n",
            "Step: 2383 ------------ Loss: 9325.97 ------------ Accuracy: 55.5%\n",
            "Step: 2384 ------------ Loss: 9325.97 ------------ Accuracy: 55.5%\n",
            "Step: 2385 ------------ Loss: 9325.87 ------------ Accuracy: 55.5%\n",
            "Step: 2386 ------------ Loss: 9324.28 ------------ Accuracy: 55.5%\n",
            "Step: 2387 ------------ Loss: 9324.19 ------------ Accuracy: 55.5%\n",
            "Step: 2388 ------------ Loss: 9324.18 ------------ Accuracy: 55.5%\n",
            "Step: 2389 ------------ Loss: 9323.38 ------------ Accuracy: 55.4%\n",
            "Step: 2390 ------------ Loss: 9323.16 ------------ Accuracy: 55.4%\n",
            "Step: 2391 ------------ Loss: 9322.93 ------------ Accuracy: 55.4%\n",
            "Step: 2392 ------------ Loss: 9322.3 ------------ Accuracy: 55.5%\n",
            "Step: 2393 ------------ Loss: 9322.03 ------------ Accuracy: 55.4%\n",
            "Step: 2394 ------------ Loss: 9320.44 ------------ Accuracy: 55.4%\n",
            "Step: 2395 ------------ Loss: 9320.43 ------------ Accuracy: 55.4%\n",
            "Step: 2396 ------------ Loss: 9320.41 ------------ Accuracy: 55.4%\n",
            "Step: 2397 ------------ Loss: 9320.07 ------------ Accuracy: 55.4%\n",
            "Step: 2398 ------------ Loss: 9319.99 ------------ Accuracy: 55.4%\n",
            "Step: 2399 ------------ Loss: 9316.18 ------------ Accuracy: 55.4%\n",
            "Step: 2400 ------------ Loss: 9315.93 ------------ Accuracy: 55.4%\n",
            "Step: 2401 ------------ Loss: 9315.84 ------------ Accuracy: 55.4%\n",
            "Step: 2402 ------------ Loss: 9315.66 ------------ Accuracy: 55.4%\n",
            "Step: 2403 ------------ Loss: 9315.58 ------------ Accuracy: 55.4%\n",
            "Step: 2404 ------------ Loss: 9315.49 ------------ Accuracy: 55.4%\n",
            "Step: 2405 ------------ Loss: 9315.49 ------------ Accuracy: 55.4%\n",
            "Step: 2406 ------------ Loss: 9315.43 ------------ Accuracy: 55.4%\n",
            "Step: 2407 ------------ Loss: 9315.35 ------------ Accuracy: 55.4%\n",
            "Step: 2408 ------------ Loss: 9315.31 ------------ Accuracy: 55.4%\n",
            "Step: 2409 ------------ Loss: 9314.99 ------------ Accuracy: 55.4%\n",
            "Step: 2410 ------------ Loss: 9314.98 ------------ Accuracy: 55.4%\n",
            "Step: 2411 ------------ Loss: 9314.9 ------------ Accuracy: 55.4%\n",
            "Step: 2412 ------------ Loss: 9314.85 ------------ Accuracy: 55.4%\n",
            "Step: 2413 ------------ Loss: 9314.84 ------------ Accuracy: 55.4%\n",
            "Step: 2414 ------------ Loss: 9314.79 ------------ Accuracy: 55.4%\n",
            "Step: 2415 ------------ Loss: 9314.79 ------------ Accuracy: 55.4%\n",
            "Step: 2416 ------------ Loss: 9314.54 ------------ Accuracy: 55.4%\n",
            "Step: 2417 ------------ Loss: 9314.53 ------------ Accuracy: 55.4%\n",
            "Step: 2418 ------------ Loss: 9314.31 ------------ Accuracy: 55.4%\n",
            "Step: 2419 ------------ Loss: 9313.51 ------------ Accuracy: 55.4%\n",
            "Step: 2420 ------------ Loss: 9313.29 ------------ Accuracy: 55.4%\n",
            "Step: 2421 ------------ Loss: 9313.26 ------------ Accuracy: 55.4%\n",
            "Step: 2422 ------------ Loss: 9309.56 ------------ Accuracy: 55.4%\n",
            "Step: 2423 ------------ Loss: 9308.04 ------------ Accuracy: 55.4%\n",
            "Step: 2424 ------------ Loss: 9308.01 ------------ Accuracy: 55.4%\n",
            "Step: 2425 ------------ Loss: 9307.92 ------------ Accuracy: 55.4%\n",
            "Step: 2426 ------------ Loss: 9304.38 ------------ Accuracy: 55.4%\n",
            "Step: 2427 ------------ Loss: 9304.34 ------------ Accuracy: 55.4%\n",
            "Step: 2428 ------------ Loss: 9304.09 ------------ Accuracy: 55.4%\n",
            "Step: 2429 ------------ Loss: 9304.08 ------------ Accuracy: 55.4%\n",
            "Step: 2430 ------------ Loss: 9303.83 ------------ Accuracy: 55.4%\n",
            "Step: 2431 ------------ Loss: 9302.37 ------------ Accuracy: 55.4%\n",
            "Step: 2432 ------------ Loss: 9301.63 ------------ Accuracy: 55.4%\n",
            "Step: 2433 ------------ Loss: 9301.55 ------------ Accuracy: 55.4%\n",
            "Step: 2434 ------------ Loss: 9301.53 ------------ Accuracy: 55.4%\n",
            "Step: 2435 ------------ Loss: 9301.46 ------------ Accuracy: 55.4%\n",
            "Step: 2436 ------------ Loss: 9301.39 ------------ Accuracy: 55.4%\n",
            "Step: 2437 ------------ Loss: 9300.64 ------------ Accuracy: 55.4%\n",
            "Step: 2438 ------------ Loss: 9297.29 ------------ Accuracy: 55.3%\n",
            "Step: 2439 ------------ Loss: 9297.27 ------------ Accuracy: 55.3%\n",
            "Step: 2440 ------------ Loss: 9297.14 ------------ Accuracy: 55.3%\n",
            "Step: 2441 ------------ Loss: 9297.0 ------------ Accuracy: 55.3%\n",
            "Step: 2442 ------------ Loss: 9296.98 ------------ Accuracy: 55.2%\n",
            "Step: 2443 ------------ Loss: 9296.91 ------------ Accuracy: 55.2%\n",
            "Step: 2444 ------------ Loss: 9296.78 ------------ Accuracy: 55.2%\n",
            "Step: 2445 ------------ Loss: 9296.67 ------------ Accuracy: 55.2%\n",
            "Step: 2446 ------------ Loss: 9296.59 ------------ Accuracy: 55.2%\n",
            "Step: 2447 ------------ Loss: 9296.57 ------------ Accuracy: 55.2%\n",
            "Step: 2448 ------------ Loss: 9296.53 ------------ Accuracy: 55.2%\n",
            "Step: 2449 ------------ Loss: 9296.37 ------------ Accuracy: 55.2%\n",
            "Step: 2450 ------------ Loss: 9294.92 ------------ Accuracy: 55.2%\n",
            "Step: 2451 ------------ Loss: 9294.81 ------------ Accuracy: 55.2%\n",
            "Step: 2452 ------------ Loss: 9294.62 ------------ Accuracy: 55.2%\n",
            "Step: 2453 ------------ Loss: 9294.61 ------------ Accuracy: 55.2%\n",
            "Step: 2454 ------------ Loss: 9294.52 ------------ Accuracy: 55.2%\n",
            "Step: 2455 ------------ Loss: 9293.79 ------------ Accuracy: 55.2%\n",
            "Step: 2456 ------------ Loss: 9293.68 ------------ Accuracy: 55.3%\n",
            "Step: 2457 ------------ Loss: 9293.54 ------------ Accuracy: 55.4%\n",
            "Step: 2458 ------------ Loss: 9293.46 ------------ Accuracy: 55.4%\n",
            "Step: 2459 ------------ Loss: 9293.45 ------------ Accuracy: 55.4%\n",
            "Step: 2460 ------------ Loss: 9292.54 ------------ Accuracy: 55.4%\n",
            "Step: 2461 ------------ Loss: 9292.48 ------------ Accuracy: 55.4%\n",
            "Step: 2462 ------------ Loss: 9292.23 ------------ Accuracy: 55.4%\n",
            "Step: 2463 ------------ Loss: 9291.91 ------------ Accuracy: 55.4%\n",
            "Step: 2464 ------------ Loss: 9291.83 ------------ Accuracy: 55.4%\n",
            "Step: 2465 ------------ Loss: 9291.83 ------------ Accuracy: 55.4%\n",
            "Step: 2466 ------------ Loss: 9291.81 ------------ Accuracy: 55.4%\n",
            "Step: 2467 ------------ Loss: 9291.73 ------------ Accuracy: 55.4%\n",
            "Step: 2468 ------------ Loss: 9291.65 ------------ Accuracy: 55.4%\n",
            "Step: 2469 ------------ Loss: 9291.61 ------------ Accuracy: 55.5%\n",
            "Step: 2470 ------------ Loss: 9291.6 ------------ Accuracy: 55.5%\n",
            "Step: 2471 ------------ Loss: 9291.05 ------------ Accuracy: 55.4%\n",
            "Step: 2472 ------------ Loss: 9290.66 ------------ Accuracy: 56.0%\n",
            "Step: 2473 ------------ Loss: 9290.44 ------------ Accuracy: 56.0%\n",
            "Step: 2474 ------------ Loss: 9289.62 ------------ Accuracy: 56.0%\n",
            "Step: 2475 ------------ Loss: 9289.62 ------------ Accuracy: 56.0%\n",
            "Step: 2476 ------------ Loss: 9289.27 ------------ Accuracy: 56.0%\n",
            "Step: 2477 ------------ Loss: 9288.47 ------------ Accuracy: 56.0%\n",
            "Step: 2478 ------------ Loss: 9288.44 ------------ Accuracy: 56.0%\n",
            "Step: 2479 ------------ Loss: 9288.44 ------------ Accuracy: 56.0%\n",
            "Step: 2480 ------------ Loss: 9288.21 ------------ Accuracy: 56.0%\n",
            "Step: 2481 ------------ Loss: 9288.19 ------------ Accuracy: 56.0%\n",
            "Step: 2482 ------------ Loss: 9287.88 ------------ Accuracy: 56.0%\n",
            "Step: 2483 ------------ Loss: 9287.85 ------------ Accuracy: 56.0%\n",
            "Step: 2484 ------------ Loss: 9287.06 ------------ Accuracy: 56.0%\n",
            "Step: 2485 ------------ Loss: 9287.04 ------------ Accuracy: 56.0%\n",
            "Step: 2486 ------------ Loss: 9283.42 ------------ Accuracy: 56.0%\n",
            "Step: 2487 ------------ Loss: 9283.33 ------------ Accuracy: 56.0%\n",
            "Step: 2488 ------------ Loss: 9283.33 ------------ Accuracy: 56.0%\n",
            "Step: 2489 ------------ Loss: 9283.27 ------------ Accuracy: 56.0%\n",
            "Step: 2490 ------------ Loss: 9283.04 ------------ Accuracy: 56.0%\n",
            "Step: 2491 ------------ Loss: 9283.04 ------------ Accuracy: 56.0%\n",
            "Step: 2492 ------------ Loss: 9282.72 ------------ Accuracy: 56.0%\n",
            "Step: 2493 ------------ Loss: 9282.71 ------------ Accuracy: 56.0%\n",
            "Step: 2494 ------------ Loss: 9282.63 ------------ Accuracy: 56.0%\n",
            "Step: 2495 ------------ Loss: 9281.03 ------------ Accuracy: 56.1%\n",
            "Step: 2496 ------------ Loss: 9280.83 ------------ Accuracy: 56.1%\n",
            "Step: 2497 ------------ Loss: 9280.82 ------------ Accuracy: 56.0%\n",
            "Step: 2498 ------------ Loss: 9280.5 ------------ Accuracy: 56.0%\n",
            "Step: 2499 ------------ Loss: 9280.18 ------------ Accuracy: 56.0%\n",
            "Step: 2500 ------------ Loss: 9280.18 ------------ Accuracy: 56.0%\n",
            "Step: 2501 ------------ Loss: 9280.17 ------------ Accuracy: 56.0%\n",
            "Step: 2502 ------------ Loss: 9279.94 ------------ Accuracy: 56.0%\n",
            "Step: 2503 ------------ Loss: 9279.94 ------------ Accuracy: 56.0%\n",
            "Step: 2504 ------------ Loss: 9279.91 ------------ Accuracy: 56.0%\n",
            "Step: 2505 ------------ Loss: 9279.86 ------------ Accuracy: 56.0%\n",
            "Step: 2506 ------------ Loss: 9279.86 ------------ Accuracy: 56.0%\n",
            "Step: 2507 ------------ Loss: 9279.85 ------------ Accuracy: 56.0%\n",
            "Step: 2508 ------------ Loss: 9279.65 ------------ Accuracy: 56.0%\n",
            "Step: 2509 ------------ Loss: 9279.65 ------------ Accuracy: 56.0%\n",
            "Step: 2510 ------------ Loss: 9279.64 ------------ Accuracy: 56.0%\n",
            "Step: 2511 ------------ Loss: 9279.64 ------------ Accuracy: 56.0%\n",
            "Step: 2512 ------------ Loss: 9279.57 ------------ Accuracy: 56.0%\n",
            "Step: 2513 ------------ Loss: 9279.56 ------------ Accuracy: 56.0%\n",
            "Step: 2514 ------------ Loss: 9278.05 ------------ Accuracy: 56.0%\n",
            "Step: 2515 ------------ Loss: 9277.97 ------------ Accuracy: 56.0%\n",
            "Step: 2516 ------------ Loss: 9277.92 ------------ Accuracy: 56.1%\n",
            "Step: 2517 ------------ Loss: 9277.6 ------------ Accuracy: 56.1%\n",
            "Step: 2518 ------------ Loss: 9277.55 ------------ Accuracy: 56.1%\n",
            "Step: 2519 ------------ Loss: 9277.53 ------------ Accuracy: 56.1%\n",
            "Step: 2520 ------------ Loss: 9274.06 ------------ Accuracy: 56.0%\n",
            "Step: 2521 ------------ Loss: 9274.01 ------------ Accuracy: 56.1%\n",
            "Step: 2522 ------------ Loss: 9274.0 ------------ Accuracy: 56.1%\n",
            "Step: 2523 ------------ Loss: 9273.93 ------------ Accuracy: 56.1%\n",
            "Step: 2524 ------------ Loss: 9273.92 ------------ Accuracy: 56.1%\n",
            "Step: 2525 ------------ Loss: 9273.91 ------------ Accuracy: 56.1%\n",
            "Step: 2526 ------------ Loss: 9273.84 ------------ Accuracy: 56.1%\n",
            "Step: 2527 ------------ Loss: 9273.78 ------------ Accuracy: 56.1%\n",
            "Step: 2528 ------------ Loss: 9273.56 ------------ Accuracy: 56.1%\n",
            "Step: 2529 ------------ Loss: 9273.48 ------------ Accuracy: 56.1%\n",
            "Step: 2530 ------------ Loss: 9273.3 ------------ Accuracy: 56.0%\n",
            "Step: 2531 ------------ Loss: 9273.29 ------------ Accuracy: 56.0%\n",
            "Step: 2532 ------------ Loss: 9273.29 ------------ Accuracy: 56.1%\n",
            "Step: 2533 ------------ Loss: 9273.2 ------------ Accuracy: 56.1%\n",
            "Step: 2534 ------------ Loss: 9273.04 ------------ Accuracy: 56.0%\n",
            "Step: 2535 ------------ Loss: 9272.86 ------------ Accuracy: 56.0%\n",
            "Step: 2536 ------------ Loss: 9272.77 ------------ Accuracy: 56.0%\n",
            "Step: 2537 ------------ Loss: 9271.97 ------------ Accuracy: 56.0%\n",
            "Step: 2538 ------------ Loss: 9271.91 ------------ Accuracy: 56.0%\n",
            "Step: 2539 ------------ Loss: 9271.6 ------------ Accuracy: 56.0%\n",
            "Step: 2540 ------------ Loss: 9271.53 ------------ Accuracy: 56.0%\n",
            "Step: 2541 ------------ Loss: 9271.3 ------------ Accuracy: 56.1%\n",
            "Step: 2542 ------------ Loss: 9271.3 ------------ Accuracy: 56.1%\n",
            "Step: 2543 ------------ Loss: 9271.22 ------------ Accuracy: 56.0%\n",
            "Step: 2544 ------------ Loss: 9271.14 ------------ Accuracy: 56.0%\n",
            "Step: 2545 ------------ Loss: 9269.69 ------------ Accuracy: 56.1%\n",
            "Step: 2546 ------------ Loss: 9269.61 ------------ Accuracy: 56.1%\n",
            "Step: 2547 ------------ Loss: 9269.45 ------------ Accuracy: 56.1%\n",
            "Step: 2548 ------------ Loss: 9269.44 ------------ Accuracy: 56.1%\n",
            "Step: 2549 ------------ Loss: 9268.69 ------------ Accuracy: 56.1%\n",
            "Step: 2550 ------------ Loss: 9268.68 ------------ Accuracy: 56.1%\n",
            "Step: 2551 ------------ Loss: 9268.64 ------------ Accuracy: 56.1%\n",
            "Step: 2552 ------------ Loss: 9268.32 ------------ Accuracy: 56.1%\n",
            "Step: 2553 ------------ Loss: 9268.17 ------------ Accuracy: 56.1%\n",
            "Step: 2554 ------------ Loss: 9267.87 ------------ Accuracy: 56.1%\n",
            "Step: 2555 ------------ Loss: 9267.85 ------------ Accuracy: 56.1%\n",
            "Step: 2556 ------------ Loss: 9267.84 ------------ Accuracy: 56.1%\n",
            "Step: 2557 ------------ Loss: 9267.83 ------------ Accuracy: 56.1%\n",
            "Step: 2558 ------------ Loss: 9267.82 ------------ Accuracy: 56.1%\n",
            "Step: 2559 ------------ Loss: 9267.81 ------------ Accuracy: 56.1%\n",
            "Step: 2560 ------------ Loss: 9267.49 ------------ Accuracy: 56.1%\n",
            "Step: 2561 ------------ Loss: 9267.41 ------------ Accuracy: 56.1%\n",
            "Step: 2562 ------------ Loss: 9267.34 ------------ Accuracy: 56.1%\n",
            "Step: 2563 ------------ Loss: 9267.25 ------------ Accuracy: 56.1%\n",
            "Step: 2564 ------------ Loss: 9267.25 ------------ Accuracy: 56.1%\n",
            "Step: 2565 ------------ Loss: 9267.21 ------------ Accuracy: 56.1%\n",
            "Step: 2566 ------------ Loss: 9266.5 ------------ Accuracy: 56.0%\n",
            "Step: 2567 ------------ Loss: 9266.46 ------------ Accuracy: 56.0%\n",
            "Step: 2568 ------------ Loss: 9266.45 ------------ Accuracy: 56.0%\n",
            "Step: 2569 ------------ Loss: 9266.23 ------------ Accuracy: 56.1%\n",
            "Step: 2570 ------------ Loss: 9265.66 ------------ Accuracy: 56.0%\n",
            "Step: 2571 ------------ Loss: 9264.88 ------------ Accuracy: 56.0%\n",
            "Step: 2572 ------------ Loss: 9264.69 ------------ Accuracy: 56.0%\n",
            "Step: 2573 ------------ Loss: 9264.45 ------------ Accuracy: 56.0%\n",
            "Step: 2574 ------------ Loss: 9264.44 ------------ Accuracy: 56.0%\n",
            "Step: 2575 ------------ Loss: 9264.43 ------------ Accuracy: 56.0%\n",
            "Step: 2576 ------------ Loss: 9264.42 ------------ Accuracy: 56.0%\n",
            "Step: 2577 ------------ Loss: 9264.11 ------------ Accuracy: 56.1%\n",
            "Step: 2578 ------------ Loss: 9263.79 ------------ Accuracy: 56.1%\n",
            "Step: 2579 ------------ Loss: 9263.79 ------------ Accuracy: 56.1%\n",
            "Step: 2580 ------------ Loss: 9263.77 ------------ Accuracy: 56.0%\n",
            "Step: 2581 ------------ Loss: 9263.76 ------------ Accuracy: 56.0%\n",
            "Step: 2582 ------------ Loss: 9263.75 ------------ Accuracy: 56.1%\n",
            "Step: 2583 ------------ Loss: 9263.71 ------------ Accuracy: 56.1%\n",
            "Step: 2584 ------------ Loss: 9263.66 ------------ Accuracy: 56.1%\n",
            "Step: 2585 ------------ Loss: 9263.47 ------------ Accuracy: 56.1%\n",
            "Step: 2586 ------------ Loss: 9263.16 ------------ Accuracy: 56.1%\n",
            "Step: 2587 ------------ Loss: 9263.09 ------------ Accuracy: 56.1%\n",
            "Step: 2588 ------------ Loss: 9263.0 ------------ Accuracy: 56.1%\n",
            "Step: 2589 ------------ Loss: 9262.99 ------------ Accuracy: 56.1%\n",
            "Step: 2590 ------------ Loss: 9262.99 ------------ Accuracy: 56.1%\n",
            "Step: 2591 ------------ Loss: 9262.97 ------------ Accuracy: 56.1%\n",
            "Step: 2592 ------------ Loss: 9262.89 ------------ Accuracy: 56.1%\n",
            "Step: 2593 ------------ Loss: 9262.88 ------------ Accuracy: 56.1%\n",
            "Step: 2594 ------------ Loss: 9262.79 ------------ Accuracy: 56.1%\n",
            "Step: 2595 ------------ Loss: 9262.79 ------------ Accuracy: 56.1%\n",
            "Step: 2596 ------------ Loss: 9262.73 ------------ Accuracy: 56.1%\n",
            "Step: 2597 ------------ Loss: 9262.73 ------------ Accuracy: 56.1%\n",
            "Step: 2598 ------------ Loss: 9262.65 ------------ Accuracy: 56.1%\n",
            "Step: 2599 ------------ Loss: 9262.14 ------------ Accuracy: 56.1%\n",
            "Step: 2600 ------------ Loss: 9261.83 ------------ Accuracy: 56.1%\n",
            "Step: 2601 ------------ Loss: 9261.81 ------------ Accuracy: 56.1%\n",
            "Step: 2602 ------------ Loss: 9261.79 ------------ Accuracy: 56.1%\n",
            "Step: 2603 ------------ Loss: 9261.79 ------------ Accuracy: 56.1%\n",
            "Step: 2604 ------------ Loss: 9261.77 ------------ Accuracy: 56.1%\n",
            "Step: 2605 ------------ Loss: 9261.7 ------------ Accuracy: 56.1%\n",
            "Step: 2606 ------------ Loss: 9261.5 ------------ Accuracy: 56.1%\n",
            "Step: 2607 ------------ Loss: 9261.46 ------------ Accuracy: 56.1%\n",
            "Step: 2608 ------------ Loss: 9261.41 ------------ Accuracy: 56.1%\n",
            "Step: 2609 ------------ Loss: 9259.89 ------------ Accuracy: 56.0%\n",
            "Step: 2610 ------------ Loss: 9259.88 ------------ Accuracy: 56.0%\n",
            "Step: 2611 ------------ Loss: 9259.81 ------------ Accuracy: 56.0%\n",
            "Step: 2612 ------------ Loss: 9259.8 ------------ Accuracy: 56.0%\n",
            "Step: 2613 ------------ Loss: 9256.25 ------------ Accuracy: 56.0%\n",
            "Step: 2614 ------------ Loss: 9256.18 ------------ Accuracy: 56.0%\n",
            "Step: 2615 ------------ Loss: 9252.8 ------------ Accuracy: 56.0%\n",
            "Step: 2616 ------------ Loss: 9252.72 ------------ Accuracy: 56.0%\n",
            "Step: 2617 ------------ Loss: 9252.66 ------------ Accuracy: 56.0%\n",
            "Step: 2618 ------------ Loss: 9252.58 ------------ Accuracy: 56.0%\n",
            "Step: 2619 ------------ Loss: 9252.57 ------------ Accuracy: 56.0%\n",
            "Step: 2620 ------------ Loss: 9251.85 ------------ Accuracy: 56.0%\n",
            "Step: 2621 ------------ Loss: 9251.79 ------------ Accuracy: 56.0%\n",
            "Step: 2622 ------------ Loss: 9251.78 ------------ Accuracy: 56.0%\n",
            "Step: 2623 ------------ Loss: 9251.71 ------------ Accuracy: 56.0%\n",
            "Step: 2624 ------------ Loss: 9248.45 ------------ Accuracy: 56.1%\n",
            "Step: 2625 ------------ Loss: 9248.14 ------------ Accuracy: 56.1%\n",
            "Step: 2626 ------------ Loss: 9248.14 ------------ Accuracy: 56.1%\n",
            "Step: 2627 ------------ Loss: 9248.1 ------------ Accuracy: 56.0%\n",
            "Step: 2628 ------------ Loss: 9248.09 ------------ Accuracy: 56.1%\n",
            "Step: 2629 ------------ Loss: 9248.05 ------------ Accuracy: 56.0%\n",
            "Step: 2630 ------------ Loss: 9246.62 ------------ Accuracy: 56.0%\n",
            "Step: 2631 ------------ Loss: 9246.58 ------------ Accuracy: 56.0%\n",
            "Step: 2632 ------------ Loss: 9246.42 ------------ Accuracy: 56.0%\n",
            "Step: 2633 ------------ Loss: 9246.13 ------------ Accuracy: 56.0%\n",
            "Step: 2634 ------------ Loss: 9245.91 ------------ Accuracy: 56.0%\n",
            "Step: 2635 ------------ Loss: 9245.9 ------------ Accuracy: 56.0%\n",
            "Step: 2636 ------------ Loss: 9245.86 ------------ Accuracy: 56.0%\n",
            "Step: 2637 ------------ Loss: 9245.78 ------------ Accuracy: 56.0%\n",
            "Step: 2638 ------------ Loss: 9245.71 ------------ Accuracy: 56.0%\n",
            "Step: 2639 ------------ Loss: 9245.7 ------------ Accuracy: 56.0%\n",
            "Step: 2640 ------------ Loss: 9244.35 ------------ Accuracy: 56.0%\n",
            "Step: 2641 ------------ Loss: 9244.26 ------------ Accuracy: 56.0%\n",
            "Step: 2642 ------------ Loss: 9244.25 ------------ Accuracy: 56.0%\n",
            "Step: 2643 ------------ Loss: 9244.24 ------------ Accuracy: 56.1%\n",
            "Step: 2644 ------------ Loss: 9243.54 ------------ Accuracy: 56.0%\n",
            "Step: 2645 ------------ Loss: 9243.39 ------------ Accuracy: 56.1%\n",
            "Step: 2646 ------------ Loss: 9243.28 ------------ Accuracy: 56.1%\n",
            "Step: 2647 ------------ Loss: 9243.2 ------------ Accuracy: 56.1%\n",
            "Step: 2648 ------------ Loss: 9242.91 ------------ Accuracy: 56.1%\n",
            "Step: 2649 ------------ Loss: 9242.06 ------------ Accuracy: 56.0%\n",
            "Step: 2650 ------------ Loss: 9241.74 ------------ Accuracy: 56.0%\n",
            "Step: 2651 ------------ Loss: 9241.73 ------------ Accuracy: 56.0%\n",
            "Step: 2652 ------------ Loss: 9241.15 ------------ Accuracy: 56.0%\n",
            "Step: 2653 ------------ Loss: 9240.4 ------------ Accuracy: 56.1%\n",
            "Step: 2654 ------------ Loss: 9240.38 ------------ Accuracy: 56.1%\n",
            "Step: 2655 ------------ Loss: 9240.35 ------------ Accuracy: 56.1%\n",
            "Step: 2656 ------------ Loss: 9240.3 ------------ Accuracy: 56.1%\n",
            "Step: 2657 ------------ Loss: 9240.28 ------------ Accuracy: 56.1%\n",
            "Step: 2658 ------------ Loss: 9240.26 ------------ Accuracy: 56.1%\n",
            "Step: 2659 ------------ Loss: 9236.9 ------------ Accuracy: 56.1%\n",
            "Step: 2660 ------------ Loss: 9236.18 ------------ Accuracy: 56.1%\n",
            "Step: 2661 ------------ Loss: 9235.88 ------------ Accuracy: 56.1%\n",
            "Step: 2662 ------------ Loss: 9235.87 ------------ Accuracy: 56.1%\n",
            "Step: 2663 ------------ Loss: 9234.41 ------------ Accuracy: 56.1%\n",
            "Step: 2664 ------------ Loss: 9234.39 ------------ Accuracy: 56.1%\n",
            "Step: 2665 ------------ Loss: 9234.32 ------------ Accuracy: 56.1%\n",
            "Step: 2666 ------------ Loss: 9234.3 ------------ Accuracy: 56.1%\n",
            "Step: 2667 ------------ Loss: 9234.3 ------------ Accuracy: 56.1%\n",
            "Step: 2668 ------------ Loss: 9233.69 ------------ Accuracy: 56.0%\n",
            "Step: 2669 ------------ Loss: 9232.22 ------------ Accuracy: 56.0%\n",
            "Step: 2670 ------------ Loss: 9232.19 ------------ Accuracy: 56.0%\n",
            "Step: 2671 ------------ Loss: 9232.11 ------------ Accuracy: 56.0%\n",
            "Step: 2672 ------------ Loss: 9231.97 ------------ Accuracy: 56.0%\n",
            "Step: 2673 ------------ Loss: 9231.76 ------------ Accuracy: 56.0%\n",
            "Step: 2674 ------------ Loss: 9228.49 ------------ Accuracy: 56.0%\n",
            "Step: 2675 ------------ Loss: 9228.27 ------------ Accuracy: 56.1%\n",
            "Step: 2676 ------------ Loss: 9228.06 ------------ Accuracy: 56.1%\n",
            "Step: 2677 ------------ Loss: 9227.91 ------------ Accuracy: 56.1%\n",
            "Step: 2678 ------------ Loss: 9227.9 ------------ Accuracy: 56.1%\n",
            "Step: 2679 ------------ Loss: 9227.82 ------------ Accuracy: 56.1%\n",
            "Step: 2680 ------------ Loss: 9224.73 ------------ Accuracy: 56.0%\n",
            "Step: 2681 ------------ Loss: 9224.44 ------------ Accuracy: 56.0%\n",
            "Step: 2682 ------------ Loss: 9224.43 ------------ Accuracy: 56.0%\n",
            "Step: 2683 ------------ Loss: 9224.37 ------------ Accuracy: 56.0%\n",
            "Step: 2684 ------------ Loss: 9224.29 ------------ Accuracy: 56.0%\n",
            "Step: 2685 ------------ Loss: 9224.29 ------------ Accuracy: 56.0%\n",
            "Step: 2686 ------------ Loss: 9224.0 ------------ Accuracy: 56.0%\n",
            "Step: 2687 ------------ Loss: 9223.99 ------------ Accuracy: 56.0%\n",
            "Step: 2688 ------------ Loss: 9223.84 ------------ Accuracy: 56.1%\n",
            "Step: 2689 ------------ Loss: 9223.63 ------------ Accuracy: 56.0%\n",
            "Step: 2690 ------------ Loss: 9223.49 ------------ Accuracy: 56.1%\n",
            "Step: 2691 ------------ Loss: 9220.51 ------------ Accuracy: 55.9%\n",
            "Step: 2692 ------------ Loss: 9220.44 ------------ Accuracy: 55.9%\n",
            "Step: 2693 ------------ Loss: 9220.39 ------------ Accuracy: 55.9%\n",
            "Step: 2694 ------------ Loss: 9220.38 ------------ Accuracy: 55.9%\n",
            "Step: 2695 ------------ Loss: 9220.3 ------------ Accuracy: 55.9%\n",
            "Step: 2696 ------------ Loss: 9220.29 ------------ Accuracy: 55.9%\n",
            "Step: 2697 ------------ Loss: 9220.22 ------------ Accuracy: 55.9%\n",
            "Step: 2698 ------------ Loss: 9220.21 ------------ Accuracy: 55.9%\n",
            "Step: 2699 ------------ Loss: 9219.54 ------------ Accuracy: 55.8%\n",
            "Step: 2700 ------------ Loss: 9219.47 ------------ Accuracy: 55.8%\n",
            "Step: 2701 ------------ Loss: 9219.32 ------------ Accuracy: 55.9%\n",
            "Step: 2702 ------------ Loss: 9219.31 ------------ Accuracy: 55.9%\n",
            "Step: 2703 ------------ Loss: 9219.23 ------------ Accuracy: 55.8%\n",
            "Step: 2704 ------------ Loss: 9219.23 ------------ Accuracy: 55.8%\n",
            "Step: 2705 ------------ Loss: 9218.56 ------------ Accuracy: 55.8%\n",
            "Step: 2706 ------------ Loss: 9218.55 ------------ Accuracy: 55.8%\n",
            "Step: 2707 ------------ Loss: 9218.48 ------------ Accuracy: 56.0%\n",
            "Step: 2708 ------------ Loss: 9218.46 ------------ Accuracy: 56.0%\n",
            "Step: 2709 ------------ Loss: 9218.46 ------------ Accuracy: 56.0%\n",
            "Step: 2710 ------------ Loss: 9218.45 ------------ Accuracy: 56.0%\n",
            "Step: 2711 ------------ Loss: 9218.27 ------------ Accuracy: 55.9%\n",
            "Step: 2712 ------------ Loss: 9218.06 ------------ Accuracy: 55.9%\n",
            "Step: 2713 ------------ Loss: 9218.05 ------------ Accuracy: 55.9%\n",
            "Step: 2714 ------------ Loss: 9218.05 ------------ Accuracy: 55.9%\n",
            "Step: 2715 ------------ Loss: 9218.05 ------------ Accuracy: 55.9%\n",
            "Step: 2716 ------------ Loss: 9218.04 ------------ Accuracy: 55.9%\n",
            "Step: 2717 ------------ Loss: 9217.97 ------------ Accuracy: 55.9%\n",
            "Step: 2718 ------------ Loss: 9217.66 ------------ Accuracy: 55.9%\n",
            "Step: 2719 ------------ Loss: 9217.65 ------------ Accuracy: 55.9%\n",
            "Step: 2720 ------------ Loss: 9217.62 ------------ Accuracy: 55.9%\n",
            "Step: 2721 ------------ Loss: 9217.31 ------------ Accuracy: 55.9%\n",
            "Step: 2722 ------------ Loss: 9217.16 ------------ Accuracy: 55.9%\n",
            "Step: 2723 ------------ Loss: 9216.85 ------------ Accuracy: 55.9%\n",
            "Step: 2724 ------------ Loss: 9216.79 ------------ Accuracy: 56.1%\n",
            "Step: 2725 ------------ Loss: 9216.71 ------------ Accuracy: 56.1%\n",
            "Step: 2726 ------------ Loss: 9216.66 ------------ Accuracy: 56.1%\n",
            "Step: 2727 ------------ Loss: 9216.65 ------------ Accuracy: 56.1%\n",
            "Step: 2728 ------------ Loss: 9216.65 ------------ Accuracy: 56.1%\n",
            "Step: 2729 ------------ Loss: 9216.64 ------------ Accuracy: 56.1%\n",
            "Step: 2730 ------------ Loss: 9216.64 ------------ Accuracy: 56.1%\n",
            "Step: 2731 ------------ Loss: 9216.49 ------------ Accuracy: 56.1%\n",
            "Step: 2732 ------------ Loss: 9216.44 ------------ Accuracy: 56.1%\n",
            "Step: 2733 ------------ Loss: 9216.13 ------------ Accuracy: 56.1%\n",
            "Step: 2734 ------------ Loss: 9216.12 ------------ Accuracy: 56.1%\n",
            "Step: 2735 ------------ Loss: 9216.07 ------------ Accuracy: 56.1%\n",
            "Step: 2736 ------------ Loss: 9215.38 ------------ Accuracy: 56.1%\n",
            "Step: 2737 ------------ Loss: 9214.75 ------------ Accuracy: 56.2%\n",
            "Step: 2738 ------------ Loss: 9214.59 ------------ Accuracy: 56.2%\n",
            "Step: 2739 ------------ Loss: 9213.89 ------------ Accuracy: 56.2%\n",
            "Step: 2740 ------------ Loss: 9213.84 ------------ Accuracy: 56.1%\n",
            "Step: 2741 ------------ Loss: 9213.8 ------------ Accuracy: 56.1%\n",
            "Step: 2742 ------------ Loss: 9213.6 ------------ Accuracy: 56.2%\n",
            "Step: 2743 ------------ Loss: 9213.6 ------------ Accuracy: 56.2%\n",
            "Step: 2744 ------------ Loss: 9213.14 ------------ Accuracy: 56.2%\n",
            "Step: 2745 ------------ Loss: 9213.12 ------------ Accuracy: 56.2%\n",
            "Step: 2746 ------------ Loss: 9212.77 ------------ Accuracy: 56.1%\n",
            "Step: 2747 ------------ Loss: 9212.5 ------------ Accuracy: 56.1%\n",
            "Step: 2748 ------------ Loss: 9212.3 ------------ Accuracy: 56.1%\n",
            "Step: 2749 ------------ Loss: 9210.95 ------------ Accuracy: 56.1%\n",
            "Step: 2750 ------------ Loss: 9210.95 ------------ Accuracy: 56.1%\n",
            "Step: 2751 ------------ Loss: 9210.82 ------------ Accuracy: 56.1%\n",
            "Step: 2752 ------------ Loss: 9210.74 ------------ Accuracy: 56.1%\n",
            "Step: 2753 ------------ Loss: 9210.66 ------------ Accuracy: 56.1%\n",
            "Step: 2754 ------------ Loss: 9210.58 ------------ Accuracy: 56.1%\n",
            "Step: 2755 ------------ Loss: 9210.5 ------------ Accuracy: 56.1%\n",
            "Step: 2756 ------------ Loss: 9209.79 ------------ Accuracy: 56.1%\n",
            "Step: 2757 ------------ Loss: 9209.76 ------------ Accuracy: 56.1%\n",
            "Step: 2758 ------------ Loss: 9209.46 ------------ Accuracy: 56.1%\n",
            "Step: 2759 ------------ Loss: 9209.37 ------------ Accuracy: 56.1%\n",
            "Step: 2760 ------------ Loss: 9209.35 ------------ Accuracy: 56.1%\n",
            "Step: 2761 ------------ Loss: 9209.33 ------------ Accuracy: 56.1%\n",
            "Step: 2762 ------------ Loss: 9206.15 ------------ Accuracy: 56.1%\n",
            "Step: 2763 ------------ Loss: 9205.85 ------------ Accuracy: 56.2%\n",
            "Step: 2764 ------------ Loss: 9205.56 ------------ Accuracy: 56.1%\n",
            "Step: 2765 ------------ Loss: 9205.55 ------------ Accuracy: 56.1%\n",
            "Step: 2766 ------------ Loss: 9205.55 ------------ Accuracy: 56.1%\n",
            "Step: 2767 ------------ Loss: 9205.55 ------------ Accuracy: 56.1%\n",
            "Step: 2768 ------------ Loss: 9205.26 ------------ Accuracy: 56.1%\n",
            "Step: 2769 ------------ Loss: 9204.58 ------------ Accuracy: 56.1%\n",
            "Step: 2770 ------------ Loss: 9203.9 ------------ Accuracy: 56.1%\n",
            "Step: 2771 ------------ Loss: 9203.9 ------------ Accuracy: 56.1%\n",
            "Step: 2772 ------------ Loss: 9203.89 ------------ Accuracy: 56.1%\n",
            "Step: 2773 ------------ Loss: 9203.88 ------------ Accuracy: 56.1%\n",
            "Step: 2774 ------------ Loss: 9203.82 ------------ Accuracy: 56.1%\n",
            "Step: 2775 ------------ Loss: 9203.82 ------------ Accuracy: 56.1%\n",
            "Step: 2776 ------------ Loss: 9203.14 ------------ Accuracy: 56.1%\n",
            "Step: 2777 ------------ Loss: 9203.05 ------------ Accuracy: 56.1%\n",
            "Step: 2778 ------------ Loss: 9203.0 ------------ Accuracy: 56.1%\n",
            "Step: 2779 ------------ Loss: 9202.91 ------------ Accuracy: 56.1%\n",
            "Step: 2780 ------------ Loss: 9199.93 ------------ Accuracy: 56.1%\n",
            "Step: 2781 ------------ Loss: 9199.91 ------------ Accuracy: 56.1%\n",
            "Step: 2782 ------------ Loss: 9198.56 ------------ Accuracy: 56.1%\n",
            "Step: 2783 ------------ Loss: 9198.54 ------------ Accuracy: 56.1%\n",
            "Step: 2784 ------------ Loss: 9198.45 ------------ Accuracy: 56.1%\n",
            "Step: 2785 ------------ Loss: 9198.15 ------------ Accuracy: 56.1%\n",
            "Step: 2786 ------------ Loss: 9198.07 ------------ Accuracy: 56.1%\n",
            "Step: 2787 ------------ Loss: 9198.03 ------------ Accuracy: 56.1%\n",
            "Step: 2788 ------------ Loss: 9198.03 ------------ Accuracy: 56.1%\n",
            "Step: 2789 ------------ Loss: 9198.02 ------------ Accuracy: 56.1%\n",
            "Step: 2790 ------------ Loss: 9198.0 ------------ Accuracy: 56.1%\n",
            "Step: 2791 ------------ Loss: 9197.86 ------------ Accuracy: 56.1%\n",
            "Step: 2792 ------------ Loss: 9197.84 ------------ Accuracy: 56.1%\n",
            "Step: 2793 ------------ Loss: 9197.84 ------------ Accuracy: 56.1%\n",
            "Step: 2794 ------------ Loss: 9197.18 ------------ Accuracy: 56.1%\n",
            "Step: 2795 ------------ Loss: 9197.09 ------------ Accuracy: 56.1%\n",
            "Step: 2796 ------------ Loss: 9197.09 ------------ Accuracy: 56.1%\n",
            "Step: 2797 ------------ Loss: 9196.95 ------------ Accuracy: 56.1%\n",
            "Step: 2798 ------------ Loss: 9196.81 ------------ Accuracy: 56.1%\n",
            "Step: 2799 ------------ Loss: 9196.8 ------------ Accuracy: 56.1%\n",
            "Step: 2800 ------------ Loss: 9196.69 ------------ Accuracy: 56.1%\n",
            "Step: 2801 ------------ Loss: 9196.48 ------------ Accuracy: 56.1%\n",
            "Step: 2802 ------------ Loss: 9196.47 ------------ Accuracy: 56.1%\n",
            "Step: 2803 ------------ Loss: 9196.38 ------------ Accuracy: 56.1%\n",
            "Step: 2804 ------------ Loss: 9193.54 ------------ Accuracy: 55.9%\n",
            "Step: 2805 ------------ Loss: 9193.53 ------------ Accuracy: 55.9%\n",
            "Step: 2806 ------------ Loss: 9193.45 ------------ Accuracy: 55.9%\n",
            "Step: 2807 ------------ Loss: 9193.31 ------------ Accuracy: 55.9%\n",
            "Step: 2808 ------------ Loss: 9193.23 ------------ Accuracy: 55.9%\n",
            "Step: 2809 ------------ Loss: 9193.2 ------------ Accuracy: 55.9%\n",
            "Step: 2810 ------------ Loss: 9193.2 ------------ Accuracy: 56.1%\n",
            "Step: 2811 ------------ Loss: 9193.16 ------------ Accuracy: 56.1%\n",
            "Step: 2812 ------------ Loss: 9193.09 ------------ Accuracy: 56.1%\n",
            "Step: 2813 ------------ Loss: 9193.01 ------------ Accuracy: 56.1%\n",
            "Step: 2814 ------------ Loss: 9193.0 ------------ Accuracy: 56.1%\n",
            "Step: 2815 ------------ Loss: 9192.89 ------------ Accuracy: 55.9%\n",
            "Step: 2816 ------------ Loss: 9191.67 ------------ Accuracy: 55.9%\n",
            "Step: 2817 ------------ Loss: 9191.63 ------------ Accuracy: 55.9%\n",
            "Step: 2818 ------------ Loss: 9191.59 ------------ Accuracy: 55.9%\n",
            "Step: 2819 ------------ Loss: 9191.59 ------------ Accuracy: 55.9%\n",
            "Step: 2820 ------------ Loss: 9190.65 ------------ Accuracy: 56.1%\n",
            "Step: 2821 ------------ Loss: 9189.39 ------------ Accuracy: 56.1%\n",
            "Step: 2822 ------------ Loss: 9189.11 ------------ Accuracy: 56.1%\n",
            "Step: 2823 ------------ Loss: 9189.1 ------------ Accuracy: 56.1%\n",
            "Step: 2824 ------------ Loss: 9189.1 ------------ Accuracy: 56.1%\n",
            "Step: 2825 ------------ Loss: 9189.09 ------------ Accuracy: 56.1%\n",
            "Step: 2826 ------------ Loss: 9189.02 ------------ Accuracy: 56.1%\n",
            "Step: 2827 ------------ Loss: 9189.02 ------------ Accuracy: 56.1%\n",
            "Step: 2828 ------------ Loss: 9188.81 ------------ Accuracy: 56.1%\n",
            "Step: 2829 ------------ Loss: 9187.6 ------------ Accuracy: 56.1%\n",
            "Step: 2830 ------------ Loss: 9187.33 ------------ Accuracy: 56.1%\n",
            "Step: 2831 ------------ Loss: 9186.66 ------------ Accuracy: 56.1%\n",
            "Step: 2832 ------------ Loss: 9186.66 ------------ Accuracy: 56.1%\n",
            "Step: 2833 ------------ Loss: 9186.65 ------------ Accuracy: 56.1%\n",
            "Step: 2834 ------------ Loss: 9186.63 ------------ Accuracy: 56.1%\n",
            "Step: 2835 ------------ Loss: 9186.62 ------------ Accuracy: 56.1%\n",
            "Step: 2836 ------------ Loss: 9186.55 ------------ Accuracy: 56.1%\n",
            "Step: 2837 ------------ Loss: 9186.54 ------------ Accuracy: 56.1%\n",
            "Step: 2838 ------------ Loss: 9186.23 ------------ Accuracy: 56.1%\n",
            "Step: 2839 ------------ Loss: 9186.22 ------------ Accuracy: 56.1%\n",
            "Step: 2840 ------------ Loss: 9186.21 ------------ Accuracy: 56.1%\n",
            "Step: 2841 ------------ Loss: 9185.43 ------------ Accuracy: 56.1%\n",
            "Step: 2842 ------------ Loss: 9185.39 ------------ Accuracy: 56.1%\n",
            "Step: 2843 ------------ Loss: 9185.09 ------------ Accuracy: 56.1%\n",
            "Step: 2844 ------------ Loss: 9184.8 ------------ Accuracy: 56.1%\n",
            "Step: 2845 ------------ Loss: 9184.79 ------------ Accuracy: 56.1%\n",
            "Step: 2846 ------------ Loss: 9184.11 ------------ Accuracy: 56.2%\n",
            "Step: 2847 ------------ Loss: 9184.11 ------------ Accuracy: 56.2%\n",
            "Step: 2848 ------------ Loss: 9184.02 ------------ Accuracy: 56.2%\n",
            "Step: 2849 ------------ Loss: 9183.82 ------------ Accuracy: 56.2%\n",
            "Step: 2850 ------------ Loss: 9183.82 ------------ Accuracy: 56.2%\n",
            "Step: 2851 ------------ Loss: 9183.65 ------------ Accuracy: 56.2%\n",
            "Step: 2852 ------------ Loss: 9183.64 ------------ Accuracy: 56.2%\n",
            "Step: 2853 ------------ Loss: 9182.98 ------------ Accuracy: 56.1%\n",
            "Step: 2854 ------------ Loss: 9182.86 ------------ Accuracy: 56.1%\n",
            "Step: 2855 ------------ Loss: 9182.74 ------------ Accuracy: 56.1%\n",
            "Step: 2856 ------------ Loss: 9182.74 ------------ Accuracy: 56.1%\n",
            "Step: 2857 ------------ Loss: 9182.74 ------------ Accuracy: 56.1%\n",
            "Step: 2858 ------------ Loss: 9182.54 ------------ Accuracy: 56.1%\n",
            "Step: 2859 ------------ Loss: 9182.53 ------------ Accuracy: 56.1%\n",
            "Step: 2860 ------------ Loss: 9182.42 ------------ Accuracy: 56.1%\n",
            "Step: 2861 ------------ Loss: 9181.22 ------------ Accuracy: 56.1%\n",
            "Step: 2862 ------------ Loss: 9181.2 ------------ Accuracy: 56.1%\n",
            "Step: 2863 ------------ Loss: 9181.11 ------------ Accuracy: 56.1%\n",
            "Step: 2864 ------------ Loss: 9181.03 ------------ Accuracy: 56.1%\n",
            "Step: 2865 ------------ Loss: 9180.99 ------------ Accuracy: 56.1%\n",
            "Step: 2866 ------------ Loss: 9180.33 ------------ Accuracy: 56.1%\n",
            "Step: 2867 ------------ Loss: 9180.28 ------------ Accuracy: 56.1%\n",
            "Step: 2868 ------------ Loss: 9180.23 ------------ Accuracy: 56.1%\n",
            "Step: 2869 ------------ Loss: 9180.03 ------------ Accuracy: 56.2%\n",
            "Step: 2870 ------------ Loss: 9179.94 ------------ Accuracy: 56.2%\n",
            "Step: 2871 ------------ Loss: 9179.75 ------------ Accuracy: 56.2%\n",
            "Step: 2872 ------------ Loss: 9179.7 ------------ Accuracy: 56.2%\n",
            "Step: 2873 ------------ Loss: 9179.66 ------------ Accuracy: 56.2%\n",
            "Step: 2874 ------------ Loss: 9179.65 ------------ Accuracy: 56.2%\n",
            "Step: 2875 ------------ Loss: 9179.56 ------------ Accuracy: 56.2%\n",
            "Step: 2876 ------------ Loss: 9179.52 ------------ Accuracy: 56.2%\n",
            "Step: 2877 ------------ Loss: 9178.35 ------------ Accuracy: 56.2%\n",
            "Step: 2878 ------------ Loss: 9178.34 ------------ Accuracy: 56.2%\n",
            "Step: 2879 ------------ Loss: 9178.29 ------------ Accuracy: 56.2%\n",
            "Step: 2880 ------------ Loss: 9178.25 ------------ Accuracy: 56.2%\n",
            "Step: 2881 ------------ Loss: 9178.21 ------------ Accuracy: 56.2%\n",
            "Step: 2882 ------------ Loss: 9178.12 ------------ Accuracy: 56.2%\n",
            "Step: 2883 ------------ Loss: 9178.08 ------------ Accuracy: 56.2%\n",
            "Step: 2884 ------------ Loss: 9177.42 ------------ Accuracy: 56.2%\n",
            "Step: 2885 ------------ Loss: 9177.33 ------------ Accuracy: 56.2%\n",
            "Step: 2886 ------------ Loss: 9177.32 ------------ Accuracy: 56.2%\n",
            "Step: 2887 ------------ Loss: 9176.62 ------------ Accuracy: 56.2%\n",
            "Step: 2888 ------------ Loss: 9176.33 ------------ Accuracy: 56.2%\n",
            "Step: 2889 ------------ Loss: 9176.12 ------------ Accuracy: 56.2%\n",
            "Step: 2890 ------------ Loss: 9176.02 ------------ Accuracy: 56.2%\n",
            "Step: 2891 ------------ Loss: 9175.97 ------------ Accuracy: 56.2%\n",
            "Step: 2892 ------------ Loss: 9175.9 ------------ Accuracy: 56.2%\n",
            "Step: 2893 ------------ Loss: 9175.88 ------------ Accuracy: 56.2%\n",
            "Step: 2894 ------------ Loss: 9175.8 ------------ Accuracy: 56.2%\n",
            "Step: 2895 ------------ Loss: 9175.79 ------------ Accuracy: 56.2%\n",
            "Step: 2896 ------------ Loss: 9175.78 ------------ Accuracy: 56.2%\n",
            "Step: 2897 ------------ Loss: 9175.74 ------------ Accuracy: 56.2%\n",
            "Step: 2898 ------------ Loss: 9175.65 ------------ Accuracy: 56.2%\n",
            "Step: 2899 ------------ Loss: 9175.65 ------------ Accuracy: 56.2%\n",
            "Step: 2900 ------------ Loss: 9175.63 ------------ Accuracy: 56.2%\n",
            "Step: 2901 ------------ Loss: 9175.44 ------------ Accuracy: 56.2%\n",
            "Step: 2902 ------------ Loss: 9175.4 ------------ Accuracy: 56.2%\n",
            "Step: 2903 ------------ Loss: 9175.22 ------------ Accuracy: 56.2%\n",
            "Step: 2904 ------------ Loss: 9175.21 ------------ Accuracy: 56.2%\n",
            "Step: 2905 ------------ Loss: 9174.03 ------------ Accuracy: 56.2%\n",
            "Step: 2906 ------------ Loss: 9173.36 ------------ Accuracy: 56.2%\n",
            "Step: 2907 ------------ Loss: 9173.35 ------------ Accuracy: 56.2%\n",
            "Step: 2908 ------------ Loss: 9173.26 ------------ Accuracy: 56.2%\n",
            "Step: 2909 ------------ Loss: 9173.06 ------------ Accuracy: 56.2%\n",
            "Step: 2910 ------------ Loss: 9173.04 ------------ Accuracy: 56.2%\n",
            "Step: 2911 ------------ Loss: 9172.77 ------------ Accuracy: 56.2%\n",
            "Step: 2912 ------------ Loss: 9172.66 ------------ Accuracy: 56.2%\n",
            "Step: 2913 ------------ Loss: 9172.0 ------------ Accuracy: 56.2%\n",
            "Step: 2914 ------------ Loss: 9172.0 ------------ Accuracy: 56.2%\n",
            "Step: 2915 ------------ Loss: 9171.21 ------------ Accuracy: 56.2%\n",
            "Step: 2916 ------------ Loss: 9170.91 ------------ Accuracy: 56.2%\n",
            "Step: 2917 ------------ Loss: 9170.82 ------------ Accuracy: 56.2%\n",
            "Step: 2918 ------------ Loss: 9169.62 ------------ Accuracy: 56.2%\n",
            "Step: 2919 ------------ Loss: 9169.61 ------------ Accuracy: 56.2%\n",
            "Step: 2920 ------------ Loss: 9169.6 ------------ Accuracy: 56.2%\n",
            "Step: 2921 ------------ Loss: 9169.3 ------------ Accuracy: 56.2%\n",
            "Step: 2922 ------------ Loss: 9168.17 ------------ Accuracy: 56.2%\n",
            "Step: 2923 ------------ Loss: 9168.09 ------------ Accuracy: 56.2%\n",
            "Step: 2924 ------------ Loss: 9167.39 ------------ Accuracy: 56.2%\n",
            "Step: 2925 ------------ Loss: 9167.37 ------------ Accuracy: 56.2%\n",
            "Step: 2926 ------------ Loss: 9167.08 ------------ Accuracy: 56.2%\n",
            "Step: 2927 ------------ Loss: 9166.89 ------------ Accuracy: 56.3%\n",
            "Step: 2928 ------------ Loss: 9166.88 ------------ Accuracy: 56.3%\n",
            "Step: 2929 ------------ Loss: 9166.86 ------------ Accuracy: 56.3%\n",
            "Step: 2930 ------------ Loss: 9166.79 ------------ Accuracy: 56.3%\n",
            "Step: 2931 ------------ Loss: 9166.71 ------------ Accuracy: 56.3%\n",
            "Step: 2932 ------------ Loss: 9166.43 ------------ Accuracy: 56.3%\n",
            "Step: 2933 ------------ Loss: 9165.97 ------------ Accuracy: 56.4%\n",
            "Step: 2934 ------------ Loss: 9165.65 ------------ Accuracy: 56.4%\n",
            "Step: 2935 ------------ Loss: 9165.6 ------------ Accuracy: 56.4%\n",
            "Step: 2936 ------------ Loss: 9162.35 ------------ Accuracy: 56.4%\n",
            "Step: 2937 ------------ Loss: 9161.02 ------------ Accuracy: 56.4%\n",
            "Step: 2938 ------------ Loss: 9157.96 ------------ Accuracy: 56.5%\n",
            "Step: 2939 ------------ Loss: 9157.86 ------------ Accuracy: 56.5%\n",
            "Step: 2940 ------------ Loss: 9157.83 ------------ Accuracy: 56.5%\n",
            "Step: 2941 ------------ Loss: 9157.79 ------------ Accuracy: 56.5%\n",
            "Step: 2942 ------------ Loss: 9157.77 ------------ Accuracy: 56.5%\n",
            "Step: 2943 ------------ Loss: 9157.1 ------------ Accuracy: 56.5%\n",
            "Step: 2944 ------------ Loss: 9157.08 ------------ Accuracy: 56.5%\n",
            "Step: 2945 ------------ Loss: 9157.07 ------------ Accuracy: 56.5%\n",
            "Step: 2946 ------------ Loss: 9156.59 ------------ Accuracy: 56.5%\n",
            "Step: 2947 ------------ Loss: 9156.25 ------------ Accuracy: 56.6%\n",
            "Step: 2948 ------------ Loss: 9156.21 ------------ Accuracy: 56.6%\n",
            "Step: 2949 ------------ Loss: 9155.91 ------------ Accuracy: 56.6%\n",
            "Step: 2950 ------------ Loss: 9155.61 ------------ Accuracy: 56.7%\n",
            "Step: 2951 ------------ Loss: 9155.55 ------------ Accuracy: 56.7%\n",
            "Step: 2952 ------------ Loss: 9154.86 ------------ Accuracy: 56.7%\n",
            "Step: 2953 ------------ Loss: 9154.82 ------------ Accuracy: 56.7%\n",
            "Step: 2954 ------------ Loss: 9154.52 ------------ Accuracy: 56.6%\n",
            "Step: 2955 ------------ Loss: 9154.48 ------------ Accuracy: 56.6%\n",
            "Step: 2956 ------------ Loss: 9153.08 ------------ Accuracy: 56.6%\n",
            "Step: 2957 ------------ Loss: 9153.06 ------------ Accuracy: 56.6%\n",
            "Step: 2958 ------------ Loss: 9152.74 ------------ Accuracy: 56.6%\n",
            "Step: 2959 ------------ Loss: 9152.73 ------------ Accuracy: 56.7%\n",
            "Step: 2960 ------------ Loss: 9152.72 ------------ Accuracy: 56.7%\n",
            "Step: 2961 ------------ Loss: 9152.7 ------------ Accuracy: 56.7%\n",
            "Step: 2962 ------------ Loss: 9152.65 ------------ Accuracy: 56.7%\n",
            "Step: 2963 ------------ Loss: 9152.63 ------------ Accuracy: 56.7%\n",
            "Step: 2964 ------------ Loss: 9152.58 ------------ Accuracy: 56.7%\n",
            "Step: 2965 ------------ Loss: 9152.49 ------------ Accuracy: 56.7%\n",
            "Step: 2966 ------------ Loss: 9152.47 ------------ Accuracy: 56.6%\n",
            "Step: 2967 ------------ Loss: 9152.44 ------------ Accuracy: 56.6%\n",
            "Step: 2968 ------------ Loss: 9152.4 ------------ Accuracy: 56.6%\n",
            "Step: 2969 ------------ Loss: 9151.16 ------------ Accuracy: 56.5%\n",
            "Step: 2970 ------------ Loss: 9151.07 ------------ Accuracy: 56.5%\n",
            "Step: 2971 ------------ Loss: 9150.98 ------------ Accuracy: 56.5%\n",
            "Step: 2972 ------------ Loss: 9150.7 ------------ Accuracy: 56.4%\n",
            "Step: 2973 ------------ Loss: 9150.61 ------------ Accuracy: 56.4%\n",
            "Step: 2974 ------------ Loss: 9150.6 ------------ Accuracy: 56.4%\n",
            "Step: 2975 ------------ Loss: 9150.09 ------------ Accuracy: 56.6%\n",
            "Step: 2976 ------------ Loss: 9150.08 ------------ Accuracy: 56.6%\n",
            "Step: 2977 ------------ Loss: 9150.05 ------------ Accuracy: 56.6%\n",
            "Step: 2978 ------------ Loss: 9149.37 ------------ Accuracy: 56.6%\n",
            "Step: 2979 ------------ Loss: 9149.09 ------------ Accuracy: 56.6%\n",
            "Step: 2980 ------------ Loss: 9149.02 ------------ Accuracy: 56.6%\n",
            "Step: 2981 ------------ Loss: 9149.01 ------------ Accuracy: 56.6%\n",
            "Step: 2982 ------------ Loss: 9148.99 ------------ Accuracy: 56.6%\n",
            "Step: 2983 ------------ Loss: 9148.32 ------------ Accuracy: 56.6%\n",
            "Step: 2984 ------------ Loss: 9148.31 ------------ Accuracy: 56.6%\n",
            "Step: 2985 ------------ Loss: 9148.13 ------------ Accuracy: 56.6%\n",
            "Step: 2986 ------------ Loss: 9148.12 ------------ Accuracy: 56.6%\n",
            "Step: 2987 ------------ Loss: 9148.06 ------------ Accuracy: 56.6%\n",
            "Step: 2988 ------------ Loss: 9145.1 ------------ Accuracy: 56.6%\n",
            "Step: 2989 ------------ Loss: 9145.08 ------------ Accuracy: 56.6%\n",
            "Step: 2990 ------------ Loss: 9144.91 ------------ Accuracy: 56.6%\n",
            "Step: 2991 ------------ Loss: 9144.9 ------------ Accuracy: 56.6%\n",
            "Step: 2992 ------------ Loss: 9144.89 ------------ Accuracy: 56.6%\n",
            "Step: 2993 ------------ Loss: 9142.08 ------------ Accuracy: 56.6%\n",
            "Step: 2994 ------------ Loss: 9142.03 ------------ Accuracy: 56.7%\n",
            "Step: 2995 ------------ Loss: 9142.03 ------------ Accuracy: 56.7%\n",
            "Step: 2996 ------------ Loss: 9141.94 ------------ Accuracy: 56.7%\n",
            "Step: 2997 ------------ Loss: 9141.86 ------------ Accuracy: 56.7%\n",
            "Step: 2998 ------------ Loss: 9141.6 ------------ Accuracy: 56.7%\n",
            "Step: 2999 ------------ Loss: 9140.39 ------------ Accuracy: 56.6%\n",
            "Step: 3000 ------------ Loss: 9140.33 ------------ Accuracy: 56.6%\n",
            "Step: 3001 ------------ Loss: 9140.31 ------------ Accuracy: 56.6%\n",
            "Step: 3002 ------------ Loss: 9140.21 ------------ Accuracy: 56.6%\n",
            "Step: 3003 ------------ Loss: 9140.2 ------------ Accuracy: 56.6%\n",
            "Step: 3004 ------------ Loss: 9137.5 ------------ Accuracy: 56.6%\n",
            "Step: 3005 ------------ Loss: 9137.41 ------------ Accuracy: 56.6%\n",
            "Step: 3006 ------------ Loss: 9137.41 ------------ Accuracy: 56.6%\n",
            "Step: 3007 ------------ Loss: 9137.4 ------------ Accuracy: 56.6%\n",
            "Step: 3008 ------------ Loss: 9137.39 ------------ Accuracy: 56.6%\n",
            "Step: 3009 ------------ Loss: 9137.38 ------------ Accuracy: 56.6%\n",
            "Step: 3010 ------------ Loss: 9134.8 ------------ Accuracy: 56.6%\n",
            "Step: 3011 ------------ Loss: 9134.54 ------------ Accuracy: 56.5%\n",
            "Step: 3012 ------------ Loss: 9134.52 ------------ Accuracy: 56.5%\n",
            "Step: 3013 ------------ Loss: 9134.47 ------------ Accuracy: 56.5%\n",
            "Step: 3014 ------------ Loss: 9134.45 ------------ Accuracy: 56.6%\n",
            "Step: 3015 ------------ Loss: 9134.35 ------------ Accuracy: 56.6%\n",
            "Step: 3016 ------------ Loss: 9133.76 ------------ Accuracy: 56.5%\n",
            "Step: 3017 ------------ Loss: 9133.76 ------------ Accuracy: 56.5%\n",
            "Step: 3018 ------------ Loss: 9133.76 ------------ Accuracy: 56.6%\n",
            "Step: 3019 ------------ Loss: 9132.61 ------------ Accuracy: 56.5%\n",
            "Step: 3020 ------------ Loss: 9132.58 ------------ Accuracy: 56.5%\n",
            "Step: 3021 ------------ Loss: 9132.5 ------------ Accuracy: 56.5%\n",
            "Step: 3022 ------------ Loss: 9132.47 ------------ Accuracy: 56.5%\n",
            "Step: 3023 ------------ Loss: 9132.38 ------------ Accuracy: 56.5%\n",
            "Step: 3024 ------------ Loss: 9132.31 ------------ Accuracy: 56.5%\n",
            "Step: 3025 ------------ Loss: 9131.72 ------------ Accuracy: 56.5%\n",
            "Step: 3026 ------------ Loss: 9131.69 ------------ Accuracy: 56.5%\n",
            "Step: 3027 ------------ Loss: 9131.6 ------------ Accuracy: 56.5%\n",
            "Step: 3028 ------------ Loss: 9129.1 ------------ Accuracy: 56.5%\n",
            "Step: 3029 ------------ Loss: 9128.18 ------------ Accuracy: 56.7%\n",
            "Step: 3030 ------------ Loss: 9127.89 ------------ Accuracy: 56.7%\n",
            "Step: 3031 ------------ Loss: 9127.8 ------------ Accuracy: 56.7%\n",
            "Step: 3032 ------------ Loss: 9127.79 ------------ Accuracy: 56.7%\n",
            "Step: 3033 ------------ Loss: 9127.63 ------------ Accuracy: 56.7%\n",
            "Step: 3034 ------------ Loss: 9127.62 ------------ Accuracy: 56.7%\n",
            "Step: 3035 ------------ Loss: 9127.53 ------------ Accuracy: 56.7%\n",
            "Step: 3036 ------------ Loss: 9127.47 ------------ Accuracy: 56.7%\n",
            "Step: 3037 ------------ Loss: 9127.37 ------------ Accuracy: 56.7%\n",
            "Step: 3038 ------------ Loss: 9127.36 ------------ Accuracy: 56.7%\n",
            "Step: 3039 ------------ Loss: 9127.3 ------------ Accuracy: 56.7%\n",
            "Step: 3040 ------------ Loss: 9127.09 ------------ Accuracy: 56.7%\n",
            "Step: 3041 ------------ Loss: 9127.08 ------------ Accuracy: 56.7%\n",
            "Step: 3042 ------------ Loss: 9126.98 ------------ Accuracy: 56.7%\n",
            "Step: 3043 ------------ Loss: 9126.82 ------------ Accuracy: 56.6%\n",
            "Step: 3044 ------------ Loss: 9126.81 ------------ Accuracy: 56.6%\n",
            "Step: 3045 ------------ Loss: 9126.81 ------------ Accuracy: 56.6%\n",
            "Step: 3046 ------------ Loss: 9126.76 ------------ Accuracy: 56.6%\n",
            "Step: 3047 ------------ Loss: 9126.74 ------------ Accuracy: 56.6%\n",
            "Step: 3048 ------------ Loss: 9126.7 ------------ Accuracy: 56.6%\n",
            "Step: 3049 ------------ Loss: 9126.52 ------------ Accuracy: 56.6%\n",
            "Step: 3050 ------------ Loss: 9126.52 ------------ Accuracy: 56.6%\n",
            "Step: 3051 ------------ Loss: 9126.27 ------------ Accuracy: 56.6%\n",
            "Step: 3052 ------------ Loss: 9125.15 ------------ Accuracy: 56.6%\n",
            "Step: 3053 ------------ Loss: 9125.14 ------------ Accuracy: 56.6%\n",
            "Step: 3054 ------------ Loss: 9125.1 ------------ Accuracy: 56.6%\n",
            "Step: 3055 ------------ Loss: 9122.55 ------------ Accuracy: 56.5%\n",
            "Step: 3056 ------------ Loss: 9122.55 ------------ Accuracy: 56.5%\n",
            "Step: 3057 ------------ Loss: 9122.46 ------------ Accuracy: 56.5%\n",
            "Step: 3058 ------------ Loss: 9122.37 ------------ Accuracy: 56.6%\n",
            "Step: 3059 ------------ Loss: 9122.37 ------------ Accuracy: 56.6%\n",
            "Step: 3060 ------------ Loss: 9122.29 ------------ Accuracy: 56.6%\n",
            "Step: 3061 ------------ Loss: 9122.23 ------------ Accuracy: 56.6%\n",
            "Step: 3062 ------------ Loss: 9122.19 ------------ Accuracy: 56.6%\n",
            "Step: 3063 ------------ Loss: 9122.19 ------------ Accuracy: 56.6%\n",
            "Step: 3064 ------------ Loss: 9122.04 ------------ Accuracy: 56.6%\n",
            "Step: 3065 ------------ Loss: 9122.03 ------------ Accuracy: 56.6%\n",
            "Step: 3066 ------------ Loss: 9121.73 ------------ Accuracy: 56.6%\n",
            "Step: 3067 ------------ Loss: 9121.73 ------------ Accuracy: 56.6%\n",
            "Step: 3068 ------------ Loss: 9121.65 ------------ Accuracy: 56.6%\n",
            "Step: 3069 ------------ Loss: 9121.52 ------------ Accuracy: 56.5%\n",
            "Step: 3070 ------------ Loss: 9121.51 ------------ Accuracy: 56.5%\n",
            "Step: 3071 ------------ Loss: 9121.5 ------------ Accuracy: 56.5%\n",
            "Step: 3072 ------------ Loss: 9121.5 ------------ Accuracy: 56.5%\n",
            "Step: 3073 ------------ Loss: 9121.45 ------------ Accuracy: 56.6%\n",
            "Step: 3074 ------------ Loss: 9121.35 ------------ Accuracy: 56.6%\n",
            "Step: 3075 ------------ Loss: 9121.35 ------------ Accuracy: 56.6%\n",
            "Step: 3076 ------------ Loss: 9120.55 ------------ Accuracy: 56.6%\n",
            "Step: 3077 ------------ Loss: 9120.52 ------------ Accuracy: 56.6%\n",
            "Step: 3078 ------------ Loss: 9120.5 ------------ Accuracy: 56.6%\n",
            "Step: 3079 ------------ Loss: 9120.44 ------------ Accuracy: 56.6%\n",
            "Step: 3080 ------------ Loss: 9120.43 ------------ Accuracy: 56.6%\n",
            "Step: 3081 ------------ Loss: 9120.43 ------------ Accuracy: 56.6%\n",
            "Step: 3082 ------------ Loss: 9120.24 ------------ Accuracy: 56.6%\n",
            "Step: 3083 ------------ Loss: 9119.63 ------------ Accuracy: 56.6%\n",
            "Step: 3084 ------------ Loss: 9119.0 ------------ Accuracy: 56.6%\n",
            "Step: 3085 ------------ Loss: 9118.92 ------------ Accuracy: 56.6%\n",
            "Step: 3086 ------------ Loss: 9118.9 ------------ Accuracy: 56.6%\n",
            "Step: 3087 ------------ Loss: 9118.46 ------------ Accuracy: 56.7%\n",
            "Step: 3088 ------------ Loss: 9118.45 ------------ Accuracy: 56.7%\n",
            "Step: 3089 ------------ Loss: 9118.29 ------------ Accuracy: 56.7%\n",
            "Step: 3090 ------------ Loss: 9118.26 ------------ Accuracy: 56.6%\n",
            "Step: 3091 ------------ Loss: 9118.15 ------------ Accuracy: 56.6%\n",
            "Step: 3092 ------------ Loss: 9117.81 ------------ Accuracy: 56.7%\n",
            "Step: 3093 ------------ Loss: 9117.77 ------------ Accuracy: 56.7%\n",
            "Step: 3094 ------------ Loss: 9117.74 ------------ Accuracy: 56.7%\n",
            "Step: 3095 ------------ Loss: 9117.73 ------------ Accuracy: 56.7%\n",
            "Step: 3096 ------------ Loss: 9117.7 ------------ Accuracy: 56.7%\n",
            "Step: 3097 ------------ Loss: 9117.67 ------------ Accuracy: 56.7%\n",
            "Step: 3098 ------------ Loss: 9117.62 ------------ Accuracy: 56.7%\n",
            "Step: 3099 ------------ Loss: 9117.57 ------------ Accuracy: 56.7%\n",
            "Step: 3100 ------------ Loss: 9116.27 ------------ Accuracy: 56.7%\n",
            "Step: 3101 ------------ Loss: 9116.26 ------------ Accuracy: 56.7%\n",
            "Step: 3102 ------------ Loss: 9116.25 ------------ Accuracy: 56.7%\n",
            "Step: 3103 ------------ Loss: 9113.46 ------------ Accuracy: 56.7%\n",
            "Step: 3104 ------------ Loss: 9113.44 ------------ Accuracy: 56.7%\n",
            "Step: 3105 ------------ Loss: 9113.43 ------------ Accuracy: 56.7%\n",
            "Step: 3106 ------------ Loss: 9113.42 ------------ Accuracy: 56.6%\n",
            "Step: 3107 ------------ Loss: 9112.98 ------------ Accuracy: 56.7%\n",
            "Step: 3108 ------------ Loss: 9112.96 ------------ Accuracy: 56.7%\n",
            "Step: 3109 ------------ Loss: 9112.94 ------------ Accuracy: 56.7%\n",
            "Step: 3110 ------------ Loss: 9112.91 ------------ Accuracy: 56.7%\n",
            "Step: 3111 ------------ Loss: 9110.19 ------------ Accuracy: 56.7%\n",
            "Step: 3112 ------------ Loss: 9110.19 ------------ Accuracy: 56.7%\n",
            "Step: 3113 ------------ Loss: 9109.93 ------------ Accuracy: 56.7%\n",
            "Step: 3114 ------------ Loss: 9109.92 ------------ Accuracy: 56.7%\n",
            "Step: 3115 ------------ Loss: 9109.9 ------------ Accuracy: 56.7%\n",
            "Step: 3116 ------------ Loss: 9108.7 ------------ Accuracy: 56.7%\n",
            "Step: 3117 ------------ Loss: 9108.42 ------------ Accuracy: 56.7%\n",
            "Step: 3118 ------------ Loss: 9108.14 ------------ Accuracy: 56.7%\n",
            "Step: 3119 ------------ Loss: 9108.13 ------------ Accuracy: 56.7%\n",
            "Step: 3120 ------------ Loss: 9108.11 ------------ Accuracy: 56.7%\n",
            "Step: 3121 ------------ Loss: 9106.98 ------------ Accuracy: 56.7%\n",
            "Step: 3122 ------------ Loss: 9106.73 ------------ Accuracy: 56.7%\n",
            "Step: 3123 ------------ Loss: 9104.19 ------------ Accuracy: 56.6%\n",
            "Step: 3124 ------------ Loss: 9104.18 ------------ Accuracy: 56.6%\n",
            "Step: 3125 ------------ Loss: 9103.13 ------------ Accuracy: 56.6%\n",
            "Step: 3126 ------------ Loss: 9103.09 ------------ Accuracy: 56.6%\n",
            "Step: 3127 ------------ Loss: 9103.0 ------------ Accuracy: 56.6%\n",
            "Step: 3128 ------------ Loss: 9102.95 ------------ Accuracy: 56.6%\n",
            "Step: 3129 ------------ Loss: 9102.66 ------------ Accuracy: 56.6%\n",
            "Step: 3130 ------------ Loss: 9102.6 ------------ Accuracy: 56.6%\n",
            "Step: 3131 ------------ Loss: 9102.55 ------------ Accuracy: 56.6%\n",
            "Step: 3132 ------------ Loss: 9102.54 ------------ Accuracy: 56.6%\n",
            "Step: 3133 ------------ Loss: 9102.54 ------------ Accuracy: 56.6%\n",
            "Step: 3134 ------------ Loss: 9102.53 ------------ Accuracy: 56.6%\n",
            "Step: 3135 ------------ Loss: 9102.49 ------------ Accuracy: 56.6%\n",
            "Step: 3136 ------------ Loss: 9102.47 ------------ Accuracy: 56.7%\n",
            "Step: 3137 ------------ Loss: 9101.88 ------------ Accuracy: 56.7%\n",
            "Step: 3138 ------------ Loss: 9101.59 ------------ Accuracy: 56.7%\n",
            "Step: 3139 ------------ Loss: 9101.57 ------------ Accuracy: 56.7%\n",
            "Step: 3140 ------------ Loss: 9101.48 ------------ Accuracy: 56.7%\n",
            "Step: 3141 ------------ Loss: 9101.41 ------------ Accuracy: 56.7%\n",
            "Step: 3142 ------------ Loss: 9101.37 ------------ Accuracy: 56.7%\n",
            "Step: 3143 ------------ Loss: 9100.78 ------------ Accuracy: 56.7%\n",
            "Step: 3144 ------------ Loss: 9100.61 ------------ Accuracy: 56.7%\n",
            "Step: 3145 ------------ Loss: 9100.6 ------------ Accuracy: 56.7%\n",
            "Step: 3146 ------------ Loss: 9100.59 ------------ Accuracy: 56.7%\n",
            "Step: 3147 ------------ Loss: 9100.01 ------------ Accuracy: 56.7%\n",
            "Step: 3148 ------------ Loss: 9100.0 ------------ Accuracy: 56.7%\n",
            "Step: 3149 ------------ Loss: 9100.0 ------------ Accuracy: 56.7%\n",
            "Step: 3150 ------------ Loss: 9099.92 ------------ Accuracy: 56.7%\n",
            "Step: 3151 ------------ Loss: 9099.89 ------------ Accuracy: 56.7%\n",
            "Step: 3152 ------------ Loss: 9099.83 ------------ Accuracy: 56.7%\n",
            "Step: 3153 ------------ Loss: 9099.14 ------------ Accuracy: 56.7%\n",
            "Step: 3154 ------------ Loss: 9098.54 ------------ Accuracy: 56.7%\n",
            "Step: 3155 ------------ Loss: 9097.94 ------------ Accuracy: 56.7%\n",
            "Step: 3156 ------------ Loss: 9097.92 ------------ Accuracy: 56.7%\n",
            "Step: 3157 ------------ Loss: 9097.9 ------------ Accuracy: 56.7%\n",
            "Step: 3158 ------------ Loss: 9097.88 ------------ Accuracy: 56.7%\n",
            "Step: 3159 ------------ Loss: 9097.28 ------------ Accuracy: 56.7%\n",
            "Step: 3160 ------------ Loss: 9097.0 ------------ Accuracy: 56.7%\n",
            "Step: 3161 ------------ Loss: 9096.91 ------------ Accuracy: 56.7%\n",
            "Step: 3162 ------------ Loss: 9096.9 ------------ Accuracy: 56.7%\n",
            "Step: 3163 ------------ Loss: 9096.84 ------------ Accuracy: 56.7%\n",
            "Step: 3164 ------------ Loss: 9096.82 ------------ Accuracy: 56.7%\n",
            "Step: 3165 ------------ Loss: 9096.82 ------------ Accuracy: 56.7%\n",
            "Step: 3166 ------------ Loss: 9096.6 ------------ Accuracy: 56.8%\n",
            "Step: 3167 ------------ Loss: 9096.59 ------------ Accuracy: 56.8%\n",
            "Step: 3168 ------------ Loss: 9094.11 ------------ Accuracy: 56.8%\n",
            "Step: 3169 ------------ Loss: 9094.09 ------------ Accuracy: 56.8%\n",
            "Step: 3170 ------------ Loss: 9094.08 ------------ Accuracy: 56.8%\n",
            "Step: 3171 ------------ Loss: 9094.04 ------------ Accuracy: 56.8%\n",
            "Step: 3172 ------------ Loss: 9093.47 ------------ Accuracy: 56.8%\n",
            "Step: 3173 ------------ Loss: 9093.47 ------------ Accuracy: 56.8%\n",
            "Step: 3174 ------------ Loss: 9093.46 ------------ Accuracy: 56.8%\n",
            "Step: 3175 ------------ Loss: 9093.3 ------------ Accuracy: 56.8%\n",
            "Step: 3176 ------------ Loss: 9093.24 ------------ Accuracy: 56.8%\n",
            "Step: 3177 ------------ Loss: 9093.23 ------------ Accuracy: 56.8%\n",
            "Step: 3178 ------------ Loss: 9093.23 ------------ Accuracy: 56.8%\n",
            "Step: 3179 ------------ Loss: 9093.22 ------------ Accuracy: 56.8%\n",
            "Step: 3180 ------------ Loss: 9092.12 ------------ Accuracy: 56.8%\n",
            "Step: 3181 ------------ Loss: 9092.07 ------------ Accuracy: 56.8%\n",
            "Step: 3182 ------------ Loss: 9092.06 ------------ Accuracy: 56.8%\n",
            "Step: 3183 ------------ Loss: 9091.81 ------------ Accuracy: 56.8%\n",
            "Step: 3184 ------------ Loss: 9091.81 ------------ Accuracy: 56.8%\n",
            "Step: 3185 ------------ Loss: 9090.78 ------------ Accuracy: 56.8%\n",
            "Step: 3186 ------------ Loss: 9090.74 ------------ Accuracy: 56.7%\n",
            "Step: 3187 ------------ Loss: 9090.74 ------------ Accuracy: 56.7%\n",
            "Step: 3188 ------------ Loss: 9090.73 ------------ Accuracy: 56.8%\n",
            "Step: 3189 ------------ Loss: 9090.66 ------------ Accuracy: 56.8%\n",
            "Step: 3190 ------------ Loss: 9088.29 ------------ Accuracy: 56.7%\n",
            "Step: 3191 ------------ Loss: 9086.03 ------------ Accuracy: 56.7%\n",
            "Step: 3192 ------------ Loss: 9085.98 ------------ Accuracy: 56.6%\n",
            "Step: 3193 ------------ Loss: 9085.0 ------------ Accuracy: 56.6%\n",
            "Step: 3194 ------------ Loss: 9084.76 ------------ Accuracy: 56.6%\n",
            "Step: 3195 ------------ Loss: 9084.7 ------------ Accuracy: 56.6%\n",
            "Step: 3196 ------------ Loss: 9084.66 ------------ Accuracy: 56.6%\n",
            "Step: 3197 ------------ Loss: 9082.47 ------------ Accuracy: 56.5%\n",
            "Step: 3198 ------------ Loss: 9082.46 ------------ Accuracy: 56.5%\n",
            "Step: 3199 ------------ Loss: 9082.32 ------------ Accuracy: 56.6%\n",
            "Step: 3200 ------------ Loss: 9080.22 ------------ Accuracy: 56.6%\n",
            "Step: 3201 ------------ Loss: 9080.21 ------------ Accuracy: 56.6%\n",
            "Step: 3202 ------------ Loss: 9080.04 ------------ Accuracy: 56.6%\n",
            "Step: 3203 ------------ Loss: 9079.98 ------------ Accuracy: 56.6%\n",
            "Step: 3204 ------------ Loss: 9079.92 ------------ Accuracy: 56.6%\n",
            "Step: 3205 ------------ Loss: 9079.84 ------------ Accuracy: 56.6%\n",
            "Step: 3206 ------------ Loss: 9079.82 ------------ Accuracy: 56.6%\n",
            "Step: 3207 ------------ Loss: 9078.76 ------------ Accuracy: 56.8%\n",
            "Step: 3208 ------------ Loss: 9077.73 ------------ Accuracy: 56.8%\n",
            "Step: 3209 ------------ Loss: 9077.72 ------------ Accuracy: 56.8%\n",
            "Step: 3210 ------------ Loss: 9077.69 ------------ Accuracy: 56.8%\n",
            "Step: 3211 ------------ Loss: 9077.45 ------------ Accuracy: 56.8%\n",
            "Step: 3212 ------------ Loss: 9077.37 ------------ Accuracy: 56.8%\n",
            "Step: 3213 ------------ Loss: 9077.27 ------------ Accuracy: 56.8%\n",
            "Step: 3214 ------------ Loss: 9077.19 ------------ Accuracy: 56.8%\n",
            "Step: 3215 ------------ Loss: 9077.18 ------------ Accuracy: 56.8%\n",
            "Step: 3216 ------------ Loss: 9077.02 ------------ Accuracy: 56.8%\n",
            "Step: 3217 ------------ Loss: 9076.95 ------------ Accuracy: 56.8%\n",
            "Step: 3218 ------------ Loss: 9076.88 ------------ Accuracy: 56.8%\n",
            "Step: 3219 ------------ Loss: 9076.83 ------------ Accuracy: 56.8%\n",
            "Step: 3220 ------------ Loss: 9076.82 ------------ Accuracy: 56.8%\n",
            "Step: 3221 ------------ Loss: 9076.75 ------------ Accuracy: 56.8%\n",
            "Step: 3222 ------------ Loss: 9075.79 ------------ Accuracy: 56.8%\n",
            "Step: 3223 ------------ Loss: 9075.63 ------------ Accuracy: 56.8%\n",
            "Step: 3224 ------------ Loss: 9075.08 ------------ Accuracy: 56.8%\n",
            "Step: 3225 ------------ Loss: 9074.54 ------------ Accuracy: 56.8%\n",
            "Step: 3226 ------------ Loss: 9074.31 ------------ Accuracy: 56.7%\n",
            "Step: 3227 ------------ Loss: 9074.3 ------------ Accuracy: 56.8%\n",
            "Step: 3228 ------------ Loss: 9074.29 ------------ Accuracy: 56.8%\n",
            "Step: 3229 ------------ Loss: 9074.23 ------------ Accuracy: 56.8%\n",
            "Step: 3230 ------------ Loss: 9074.15 ------------ Accuracy: 56.8%\n",
            "Step: 3231 ------------ Loss: 9073.92 ------------ Accuracy: 56.8%\n",
            "Step: 3232 ------------ Loss: 9073.38 ------------ Accuracy: 56.8%\n",
            "Step: 3233 ------------ Loss: 9073.28 ------------ Accuracy: 56.8%\n",
            "Step: 3234 ------------ Loss: 9073.22 ------------ Accuracy: 56.8%\n",
            "Step: 3235 ------------ Loss: 9072.33 ------------ Accuracy: 56.7%\n",
            "Step: 3236 ------------ Loss: 9072.28 ------------ Accuracy: 56.8%\n",
            "Step: 3237 ------------ Loss: 9072.23 ------------ Accuracy: 56.8%\n",
            "Step: 3238 ------------ Loss: 9072.22 ------------ Accuracy: 56.8%\n",
            "Step: 3239 ------------ Loss: 9072.17 ------------ Accuracy: 56.8%\n",
            "Step: 3240 ------------ Loss: 9072.07 ------------ Accuracy: 56.7%\n",
            "Step: 3241 ------------ Loss: 9072.0 ------------ Accuracy: 56.7%\n",
            "Step: 3242 ------------ Loss: 9071.83 ------------ Accuracy: 56.7%\n",
            "Step: 3243 ------------ Loss: 9071.79 ------------ Accuracy: 56.7%\n",
            "Step: 3244 ------------ Loss: 9071.5 ------------ Accuracy: 56.7%\n",
            "Step: 3245 ------------ Loss: 9071.21 ------------ Accuracy: 56.7%\n",
            "Step: 3246 ------------ Loss: 9071.2 ------------ Accuracy: 56.8%\n",
            "Step: 3247 ------------ Loss: 9068.98 ------------ Accuracy: 56.8%\n",
            "Step: 3248 ------------ Loss: 9066.86 ------------ Accuracy: 56.7%\n",
            "Step: 3249 ------------ Loss: 9066.7 ------------ Accuracy: 56.7%\n",
            "Step: 3250 ------------ Loss: 9066.68 ------------ Accuracy: 56.7%\n",
            "Step: 3251 ------------ Loss: 9066.61 ------------ Accuracy: 56.7%\n",
            "Step: 3252 ------------ Loss: 9066.53 ------------ Accuracy: 56.8%\n",
            "Step: 3253 ------------ Loss: 9066.37 ------------ Accuracy: 56.8%\n",
            "Step: 3254 ------------ Loss: 9066.33 ------------ Accuracy: 56.8%\n",
            "Step: 3255 ------------ Loss: 9066.04 ------------ Accuracy: 56.8%\n",
            "Step: 3256 ------------ Loss: 9066.03 ------------ Accuracy: 56.8%\n",
            "Step: 3257 ------------ Loss: 9066.01 ------------ Accuracy: 56.8%\n",
            "Step: 3258 ------------ Loss: 9065.1 ------------ Accuracy: 56.8%\n",
            "Step: 3259 ------------ Loss: 9064.06 ------------ Accuracy: 56.7%\n",
            "Step: 3260 ------------ Loss: 9064.06 ------------ Accuracy: 56.7%\n",
            "Step: 3261 ------------ Loss: 9064.03 ------------ Accuracy: 56.7%\n",
            "Step: 3262 ------------ Loss: 9064.03 ------------ Accuracy: 56.7%\n",
            "Step: 3263 ------------ Loss: 9063.93 ------------ Accuracy: 56.7%\n",
            "Step: 3264 ------------ Loss: 9063.92 ------------ Accuracy: 56.7%\n",
            "Step: 3265 ------------ Loss: 9063.86 ------------ Accuracy: 56.7%\n",
            "Step: 3266 ------------ Loss: 9063.85 ------------ Accuracy: 56.7%\n",
            "Step: 3267 ------------ Loss: 9063.78 ------------ Accuracy: 56.7%\n",
            "Step: 3268 ------------ Loss: 9063.63 ------------ Accuracy: 56.7%\n",
            "Step: 3269 ------------ Loss: 9063.62 ------------ Accuracy: 56.7%\n",
            "Step: 3270 ------------ Loss: 9063.37 ------------ Accuracy: 56.8%\n",
            "Step: 3271 ------------ Loss: 9063.36 ------------ Accuracy: 56.8%\n",
            "Step: 3272 ------------ Loss: 9063.34 ------------ Accuracy: 56.8%\n",
            "Step: 3273 ------------ Loss: 9063.07 ------------ Accuracy: 56.7%\n",
            "Step: 3274 ------------ Loss: 9062.83 ------------ Accuracy: 56.8%\n",
            "Step: 3275 ------------ Loss: 9062.73 ------------ Accuracy: 56.8%\n",
            "Step: 3276 ------------ Loss: 9062.72 ------------ Accuracy: 56.8%\n",
            "Step: 3277 ------------ Loss: 9060.52 ------------ Accuracy: 56.8%\n",
            "Step: 3278 ------------ Loss: 9060.51 ------------ Accuracy: 56.8%\n",
            "Step: 3279 ------------ Loss: 9060.44 ------------ Accuracy: 56.8%\n",
            "Step: 3280 ------------ Loss: 9060.38 ------------ Accuracy: 56.8%\n",
            "Step: 3281 ------------ Loss: 9059.4 ------------ Accuracy: 56.8%\n",
            "Step: 3282 ------------ Loss: 9059.25 ------------ Accuracy: 56.8%\n",
            "Step: 3283 ------------ Loss: 9059.23 ------------ Accuracy: 56.8%\n",
            "Step: 3284 ------------ Loss: 9059.22 ------------ Accuracy: 56.8%\n",
            "Step: 3285 ------------ Loss: 9059.17 ------------ Accuracy: 56.8%\n",
            "Step: 3286 ------------ Loss: 9059.11 ------------ Accuracy: 56.8%\n",
            "Step: 3287 ------------ Loss: 9058.34 ------------ Accuracy: 56.9%\n",
            "Step: 3288 ------------ Loss: 9058.34 ------------ Accuracy: 56.9%\n",
            "Step: 3289 ------------ Loss: 9057.77 ------------ Accuracy: 56.9%\n",
            "Step: 3290 ------------ Loss: 9057.67 ------------ Accuracy: 56.9%\n",
            "Step: 3291 ------------ Loss: 9057.67 ------------ Accuracy: 56.9%\n",
            "Step: 3292 ------------ Loss: 9056.64 ------------ Accuracy: 56.9%\n",
            "Step: 3293 ------------ Loss: 9056.61 ------------ Accuracy: 56.9%\n",
            "Step: 3294 ------------ Loss: 9055.65 ------------ Accuracy: 56.7%\n",
            "Step: 3295 ------------ Loss: 9055.61 ------------ Accuracy: 56.8%\n",
            "Step: 3296 ------------ Loss: 9054.9 ------------ Accuracy: 56.8%\n",
            "Step: 3297 ------------ Loss: 9054.64 ------------ Accuracy: 56.8%\n",
            "Step: 3298 ------------ Loss: 9054.63 ------------ Accuracy: 56.8%\n",
            "Step: 3299 ------------ Loss: 9054.6 ------------ Accuracy: 56.8%\n",
            "Step: 3300 ------------ Loss: 9054.58 ------------ Accuracy: 56.8%\n",
            "Step: 3301 ------------ Loss: 9054.58 ------------ Accuracy: 56.8%\n",
            "Step: 3302 ------------ Loss: 9054.06 ------------ Accuracy: 56.9%\n",
            "Step: 3303 ------------ Loss: 9054.0 ------------ Accuracy: 56.8%\n",
            "Step: 3304 ------------ Loss: 9053.97 ------------ Accuracy: 56.8%\n",
            "Step: 3305 ------------ Loss: 9053.7 ------------ Accuracy: 56.8%\n",
            "Step: 3306 ------------ Loss: 9053.44 ------------ Accuracy: 56.8%\n",
            "Step: 3307 ------------ Loss: 9053.19 ------------ Accuracy: 56.8%\n",
            "Step: 3308 ------------ Loss: 9053.17 ------------ Accuracy: 56.8%\n",
            "Step: 3309 ------------ Loss: 9052.92 ------------ Accuracy: 56.9%\n",
            "Step: 3310 ------------ Loss: 9052.89 ------------ Accuracy: 56.9%\n",
            "Step: 3311 ------------ Loss: 9052.87 ------------ Accuracy: 56.9%\n",
            "Step: 3312 ------------ Loss: 9052.45 ------------ Accuracy: 57.0%\n",
            "Step: 3313 ------------ Loss: 9052.42 ------------ Accuracy: 56.9%\n",
            "Step: 3314 ------------ Loss: 9052.39 ------------ Accuracy: 56.9%\n",
            "Step: 3315 ------------ Loss: 9051.8 ------------ Accuracy: 56.9%\n",
            "Step: 3316 ------------ Loss: 9051.8 ------------ Accuracy: 56.9%\n",
            "Step: 3317 ------------ Loss: 9051.7 ------------ Accuracy: 56.9%\n",
            "Step: 3318 ------------ Loss: 9051.69 ------------ Accuracy: 56.9%\n",
            "Step: 3319 ------------ Loss: 9051.44 ------------ Accuracy: 56.9%\n",
            "Step: 3320 ------------ Loss: 9051.42 ------------ Accuracy: 56.9%\n",
            "Step: 3321 ------------ Loss: 9050.84 ------------ Accuracy: 56.9%\n",
            "Step: 3322 ------------ Loss: 9050.56 ------------ Accuracy: 56.9%\n",
            "Step: 3323 ------------ Loss: 9050.55 ------------ Accuracy: 57.0%\n",
            "Step: 3324 ------------ Loss: 9050.48 ------------ Accuracy: 56.9%\n",
            "Step: 3325 ------------ Loss: 9050.46 ------------ Accuracy: 56.9%\n",
            "Step: 3326 ------------ Loss: 9050.44 ------------ Accuracy: 56.9%\n",
            "Step: 3327 ------------ Loss: 9050.37 ------------ Accuracy: 56.9%\n",
            "Step: 3328 ------------ Loss: 9050.1 ------------ Accuracy: 56.9%\n",
            "Step: 3329 ------------ Loss: 9050.09 ------------ Accuracy: 56.9%\n",
            "Step: 3330 ------------ Loss: 9047.75 ------------ Accuracy: 57.0%\n",
            "Step: 3331 ------------ Loss: 9047.7 ------------ Accuracy: 57.0%\n",
            "Step: 3332 ------------ Loss: 9047.69 ------------ Accuracy: 57.0%\n",
            "Step: 3333 ------------ Loss: 9047.68 ------------ Accuracy: 57.0%\n",
            "Step: 3334 ------------ Loss: 9045.45 ------------ Accuracy: 57.0%\n",
            "Step: 3335 ------------ Loss: 9045.35 ------------ Accuracy: 57.0%\n",
            "Step: 3336 ------------ Loss: 9045.34 ------------ Accuracy: 57.0%\n",
            "Step: 3337 ------------ Loss: 9045.31 ------------ Accuracy: 57.0%\n",
            "Step: 3338 ------------ Loss: 9045.24 ------------ Accuracy: 57.0%\n",
            "Step: 3339 ------------ Loss: 9043.11 ------------ Accuracy: 57.0%\n",
            "Step: 3340 ------------ Loss: 9042.97 ------------ Accuracy: 57.0%\n",
            "Step: 3341 ------------ Loss: 9042.97 ------------ Accuracy: 57.0%\n",
            "Step: 3342 ------------ Loss: 9041.95 ------------ Accuracy: 56.9%\n",
            "Step: 3343 ------------ Loss: 9041.95 ------------ Accuracy: 56.9%\n",
            "Step: 3344 ------------ Loss: 9041.81 ------------ Accuracy: 56.9%\n",
            "Step: 3345 ------------ Loss: 9041.73 ------------ Accuracy: 56.9%\n",
            "Step: 3346 ------------ Loss: 9041.72 ------------ Accuracy: 56.9%\n",
            "Step: 3347 ------------ Loss: 9041.72 ------------ Accuracy: 56.9%\n",
            "Step: 3348 ------------ Loss: 9039.68 ------------ Accuracy: 56.9%\n",
            "Step: 3349 ------------ Loss: 9039.18 ------------ Accuracy: 56.9%\n",
            "Step: 3350 ------------ Loss: 9039.15 ------------ Accuracy: 56.9%\n",
            "Step: 3351 ------------ Loss: 9038.87 ------------ Accuracy: 56.9%\n",
            "Step: 3352 ------------ Loss: 9037.91 ------------ Accuracy: 56.8%\n",
            "Step: 3353 ------------ Loss: 9037.68 ------------ Accuracy: 56.8%\n",
            "Step: 3354 ------------ Loss: 9037.63 ------------ Accuracy: 56.9%\n",
            "Step: 3355 ------------ Loss: 9037.59 ------------ Accuracy: 56.9%\n",
            "Step: 3356 ------------ Loss: 9037.58 ------------ Accuracy: 56.9%\n",
            "Step: 3357 ------------ Loss: 9036.7 ------------ Accuracy: 56.9%\n",
            "Step: 3358 ------------ Loss: 9036.66 ------------ Accuracy: 57.0%\n",
            "Step: 3359 ------------ Loss: 9036.64 ------------ Accuracy: 56.9%\n",
            "Step: 3360 ------------ Loss: 9036.54 ------------ Accuracy: 56.9%\n",
            "Step: 3361 ------------ Loss: 9036.49 ------------ Accuracy: 56.9%\n",
            "Step: 3362 ------------ Loss: 9036.49 ------------ Accuracy: 56.9%\n",
            "Step: 3363 ------------ Loss: 9034.4 ------------ Accuracy: 57.0%\n",
            "Step: 3364 ------------ Loss: 9034.34 ------------ Accuracy: 57.0%\n",
            "Step: 3365 ------------ Loss: 9034.33 ------------ Accuracy: 57.0%\n",
            "Step: 3366 ------------ Loss: 9034.27 ------------ Accuracy: 56.9%\n",
            "Step: 3367 ------------ Loss: 9034.27 ------------ Accuracy: 56.9%\n",
            "Step: 3368 ------------ Loss: 9034.16 ------------ Accuracy: 56.9%\n",
            "Step: 3369 ------------ Loss: 9034.16 ------------ Accuracy: 56.9%\n",
            "Step: 3370 ------------ Loss: 9033.92 ------------ Accuracy: 56.9%\n",
            "Step: 3371 ------------ Loss: 9033.87 ------------ Accuracy: 56.9%\n",
            "Step: 3372 ------------ Loss: 9033.83 ------------ Accuracy: 56.9%\n",
            "Step: 3373 ------------ Loss: 9033.8 ------------ Accuracy: 57.0%\n",
            "Step: 3374 ------------ Loss: 9033.78 ------------ Accuracy: 56.9%\n",
            "Step: 3375 ------------ Loss: 9033.77 ------------ Accuracy: 56.9%\n",
            "Step: 3376 ------------ Loss: 9031.76 ------------ Accuracy: 56.9%\n",
            "Step: 3377 ------------ Loss: 9031.48 ------------ Accuracy: 56.9%\n",
            "Step: 3378 ------------ Loss: 9031.38 ------------ Accuracy: 56.9%\n",
            "Step: 3379 ------------ Loss: 9031.37 ------------ Accuracy: 57.0%\n",
            "Step: 3380 ------------ Loss: 9031.36 ------------ Accuracy: 57.1%\n",
            "Step: 3381 ------------ Loss: 9031.3 ------------ Accuracy: 57.1%\n",
            "Step: 3382 ------------ Loss: 9031.22 ------------ Accuracy: 57.1%\n",
            "Step: 3383 ------------ Loss: 9031.15 ------------ Accuracy: 57.1%\n",
            "Step: 3384 ------------ Loss: 9031.04 ------------ Accuracy: 57.1%\n",
            "Step: 3385 ------------ Loss: 9030.99 ------------ Accuracy: 57.1%\n",
            "Step: 3386 ------------ Loss: 9030.8 ------------ Accuracy: 57.0%\n",
            "Step: 3387 ------------ Loss: 9030.78 ------------ Accuracy: 57.0%\n",
            "Step: 3388 ------------ Loss: 9030.7 ------------ Accuracy: 57.0%\n",
            "Step: 3389 ------------ Loss: 9030.48 ------------ Accuracy: 57.0%\n",
            "Step: 3390 ------------ Loss: 9030.32 ------------ Accuracy: 57.0%\n",
            "Step: 3391 ------------ Loss: 9029.81 ------------ Accuracy: 57.0%\n",
            "Step: 3392 ------------ Loss: 9029.67 ------------ Accuracy: 57.0%\n",
            "Step: 3393 ------------ Loss: 9029.66 ------------ Accuracy: 57.1%\n",
            "Step: 3394 ------------ Loss: 9029.58 ------------ Accuracy: 57.0%\n",
            "Step: 3395 ------------ Loss: 9029.3 ------------ Accuracy: 57.0%\n",
            "Step: 3396 ------------ Loss: 9029.29 ------------ Accuracy: 57.0%\n",
            "Step: 3397 ------------ Loss: 9029.29 ------------ Accuracy: 57.0%\n",
            "Step: 3398 ------------ Loss: 9029.15 ------------ Accuracy: 57.1%\n",
            "Step: 3399 ------------ Loss: 9029.09 ------------ Accuracy: 57.1%\n",
            "Step: 3400 ------------ Loss: 9028.95 ------------ Accuracy: 57.1%\n",
            "Step: 3401 ------------ Loss: 9028.81 ------------ Accuracy: 57.1%\n",
            "Step: 3402 ------------ Loss: 9028.54 ------------ Accuracy: 57.1%\n",
            "Step: 3403 ------------ Loss: 9028.4 ------------ Accuracy: 57.1%\n",
            "Step: 3404 ------------ Loss: 9027.44 ------------ Accuracy: 57.1%\n",
            "Step: 3405 ------------ Loss: 9027.41 ------------ Accuracy: 57.1%\n",
            "Step: 3406 ------------ Loss: 9027.36 ------------ Accuracy: 57.1%\n",
            "Step: 3407 ------------ Loss: 9027.14 ------------ Accuracy: 57.1%\n",
            "Step: 3408 ------------ Loss: 9027.09 ------------ Accuracy: 57.1%\n",
            "Step: 3409 ------------ Loss: 9025.12 ------------ Accuracy: 57.0%\n",
            "Step: 3410 ------------ Loss: 9025.11 ------------ Accuracy: 57.0%\n",
            "Step: 3411 ------------ Loss: 9024.84 ------------ Accuracy: 57.0%\n",
            "Step: 3412 ------------ Loss: 9024.78 ------------ Accuracy: 57.0%\n",
            "Step: 3413 ------------ Loss: 9024.28 ------------ Accuracy: 57.0%\n",
            "Step: 3414 ------------ Loss: 9024.27 ------------ Accuracy: 57.0%\n",
            "Step: 3415 ------------ Loss: 9024.27 ------------ Accuracy: 57.0%\n",
            "Step: 3416 ------------ Loss: 9024.21 ------------ Accuracy: 57.0%\n",
            "Step: 3417 ------------ Loss: 9024.15 ------------ Accuracy: 57.0%\n",
            "Step: 3418 ------------ Loss: 9024.14 ------------ Accuracy: 57.0%\n",
            "Step: 3419 ------------ Loss: 9023.87 ------------ Accuracy: 57.0%\n",
            "Step: 3420 ------------ Loss: 9023.37 ------------ Accuracy: 57.0%\n",
            "Step: 3421 ------------ Loss: 9023.22 ------------ Accuracy: 57.0%\n",
            "Step: 3422 ------------ Loss: 9022.33 ------------ Accuracy: 57.0%\n",
            "Step: 3423 ------------ Loss: 9021.36 ------------ Accuracy: 57.2%\n",
            "Step: 3424 ------------ Loss: 9021.31 ------------ Accuracy: 57.2%\n",
            "Step: 3425 ------------ Loss: 9021.29 ------------ Accuracy: 57.2%\n",
            "Step: 3426 ------------ Loss: 9021.28 ------------ Accuracy: 57.2%\n",
            "Step: 3427 ------------ Loss: 9021.28 ------------ Accuracy: 57.2%\n",
            "Step: 3428 ------------ Loss: 9021.27 ------------ Accuracy: 57.2%\n",
            "Step: 3429 ------------ Loss: 9021.04 ------------ Accuracy: 57.2%\n",
            "Step: 3430 ------------ Loss: 9021.04 ------------ Accuracy: 57.2%\n",
            "Step: 3431 ------------ Loss: 9020.87 ------------ Accuracy: 57.3%\n",
            "Step: 3432 ------------ Loss: 9019.98 ------------ Accuracy: 57.2%\n",
            "Step: 3433 ------------ Loss: 9019.95 ------------ Accuracy: 57.2%\n",
            "Step: 3434 ------------ Loss: 9019.68 ------------ Accuracy: 57.2%\n",
            "Step: 3435 ------------ Loss: 9019.66 ------------ Accuracy: 57.2%\n",
            "Step: 3436 ------------ Loss: 9017.67 ------------ Accuracy: 57.2%\n",
            "Step: 3437 ------------ Loss: 9015.76 ------------ Accuracy: 57.0%\n",
            "Step: 3438 ------------ Loss: 9015.74 ------------ Accuracy: 57.0%\n",
            "Step: 3439 ------------ Loss: 9015.69 ------------ Accuracy: 57.0%\n",
            "Step: 3440 ------------ Loss: 9014.84 ------------ Accuracy: 57.0%\n",
            "Step: 3441 ------------ Loss: 9014.71 ------------ Accuracy: 57.0%\n",
            "Step: 3442 ------------ Loss: 9014.61 ------------ Accuracy: 57.0%\n",
            "Step: 3443 ------------ Loss: 9014.51 ------------ Accuracy: 57.0%\n",
            "Step: 3444 ------------ Loss: 9014.5 ------------ Accuracy: 57.0%\n",
            "Step: 3445 ------------ Loss: 9013.55 ------------ Accuracy: 57.2%\n",
            "Step: 3446 ------------ Loss: 9013.47 ------------ Accuracy: 57.2%\n",
            "Step: 3447 ------------ Loss: 9013.2 ------------ Accuracy: 57.3%\n",
            "Step: 3448 ------------ Loss: 9011.24 ------------ Accuracy: 57.3%\n",
            "Step: 3449 ------------ Loss: 9010.74 ------------ Accuracy: 57.3%\n",
            "Step: 3450 ------------ Loss: 9010.51 ------------ Accuracy: 57.3%\n",
            "Step: 3451 ------------ Loss: 9010.37 ------------ Accuracy: 57.3%\n",
            "Step: 3452 ------------ Loss: 9010.27 ------------ Accuracy: 57.3%\n",
            "Step: 3453 ------------ Loss: 9010.24 ------------ Accuracy: 57.3%\n",
            "Step: 3454 ------------ Loss: 9010.21 ------------ Accuracy: 57.3%\n",
            "Step: 3455 ------------ Loss: 9009.99 ------------ Accuracy: 57.3%\n",
            "Step: 3456 ------------ Loss: 9009.72 ------------ Accuracy: 57.3%\n",
            "Step: 3457 ------------ Loss: 9009.5 ------------ Accuracy: 57.3%\n",
            "Step: 3458 ------------ Loss: 9009.46 ------------ Accuracy: 57.3%\n",
            "Step: 3459 ------------ Loss: 9009.4 ------------ Accuracy: 57.3%\n",
            "Step: 3460 ------------ Loss: 9009.34 ------------ Accuracy: 57.3%\n",
            "Step: 3461 ------------ Loss: 9009.34 ------------ Accuracy: 57.3%\n",
            "Step: 3462 ------------ Loss: 9009.34 ------------ Accuracy: 57.3%\n",
            "Step: 3463 ------------ Loss: 9009.2 ------------ Accuracy: 57.3%\n",
            "Step: 3464 ------------ Loss: 9008.47 ------------ Accuracy: 57.2%\n",
            "Step: 3465 ------------ Loss: 9008.46 ------------ Accuracy: 57.2%\n",
            "Step: 3466 ------------ Loss: 9008.44 ------------ Accuracy: 57.2%\n",
            "Step: 3467 ------------ Loss: 9006.47 ------------ Accuracy: 57.3%\n",
            "Step: 3468 ------------ Loss: 9006.47 ------------ Accuracy: 57.3%\n",
            "Step: 3469 ------------ Loss: 9006.41 ------------ Accuracy: 57.3%\n",
            "Step: 3470 ------------ Loss: 9006.18 ------------ Accuracy: 57.3%\n",
            "Step: 3471 ------------ Loss: 9005.23 ------------ Accuracy: 57.3%\n",
            "Step: 3472 ------------ Loss: 9005.22 ------------ Accuracy: 57.3%\n",
            "Step: 3473 ------------ Loss: 9005.15 ------------ Accuracy: 57.3%\n",
            "Step: 3474 ------------ Loss: 9005.12 ------------ Accuracy: 57.2%\n",
            "Step: 3475 ------------ Loss: 9005.12 ------------ Accuracy: 57.2%\n",
            "Step: 3476 ------------ Loss: 9005.01 ------------ Accuracy: 57.2%\n",
            "Step: 3477 ------------ Loss: 9004.93 ------------ Accuracy: 57.2%\n",
            "Step: 3478 ------------ Loss: 9004.91 ------------ Accuracy: 57.3%\n",
            "Step: 3479 ------------ Loss: 9003.03 ------------ Accuracy: 57.0%\n",
            "Step: 3480 ------------ Loss: 9003.02 ------------ Accuracy: 57.0%\n",
            "Step: 3481 ------------ Loss: 9002.91 ------------ Accuracy: 57.0%\n",
            "Step: 3482 ------------ Loss: 9002.88 ------------ Accuracy: 57.0%\n",
            "Step: 3483 ------------ Loss: 9001.07 ------------ Accuracy: 57.0%\n",
            "Step: 3484 ------------ Loss: 9001.05 ------------ Accuracy: 57.0%\n",
            "Step: 3485 ------------ Loss: 9000.84 ------------ Accuracy: 57.0%\n",
            "Step: 3486 ------------ Loss: 9000.8 ------------ Accuracy: 57.0%\n",
            "Step: 3487 ------------ Loss: 9000.79 ------------ Accuracy: 57.0%\n",
            "Step: 3488 ------------ Loss: 9000.31 ------------ Accuracy: 57.0%\n",
            "Step: 3489 ------------ Loss: 9000.28 ------------ Accuracy: 57.0%\n",
            "Step: 3490 ------------ Loss: 9000.22 ------------ Accuracy: 57.0%\n",
            "Step: 3491 ------------ Loss: 9000.18 ------------ Accuracy: 57.0%\n",
            "Step: 3492 ------------ Loss: 9000.15 ------------ Accuracy: 57.0%\n",
            "Step: 3493 ------------ Loss: 9000.1 ------------ Accuracy: 57.0%\n",
            "Step: 3494 ------------ Loss: 8999.83 ------------ Accuracy: 56.9%\n",
            "Step: 3495 ------------ Loss: 8998.94 ------------ Accuracy: 56.9%\n",
            "Step: 3496 ------------ Loss: 8998.07 ------------ Accuracy: 57.3%\n",
            "Step: 3497 ------------ Loss: 8996.21 ------------ Accuracy: 57.0%\n",
            "Step: 3498 ------------ Loss: 8995.95 ------------ Accuracy: 57.0%\n",
            "Step: 3499 ------------ Loss: 8995.94 ------------ Accuracy: 57.0%\n",
            "Step: 3500 ------------ Loss: 8995.74 ------------ Accuracy: 57.0%\n",
            "Step: 3501 ------------ Loss: 8995.74 ------------ Accuracy: 57.0%\n",
            "Step: 3502 ------------ Loss: 8994.85 ------------ Accuracy: 57.0%\n",
            "Step: 3503 ------------ Loss: 8994.03 ------------ Accuracy: 57.3%\n",
            "Step: 3504 ------------ Loss: 8993.93 ------------ Accuracy: 57.3%\n",
            "Step: 3505 ------------ Loss: 8993.92 ------------ Accuracy: 57.3%\n",
            "Step: 3506 ------------ Loss: 8992.06 ------------ Accuracy: 57.0%\n",
            "Step: 3507 ------------ Loss: 8992.05 ------------ Accuracy: 57.0%\n",
            "Step: 3508 ------------ Loss: 8992.0 ------------ Accuracy: 57.0%\n",
            "Step: 3509 ------------ Loss: 8991.99 ------------ Accuracy: 57.0%\n",
            "Step: 3510 ------------ Loss: 8991.96 ------------ Accuracy: 57.1%\n",
            "Step: 3511 ------------ Loss: 8991.96 ------------ Accuracy: 57.1%\n",
            "Step: 3512 ------------ Loss: 8991.91 ------------ Accuracy: 57.1%\n",
            "Step: 3513 ------------ Loss: 8991.42 ------------ Accuracy: 57.1%\n",
            "Step: 3514 ------------ Loss: 8991.29 ------------ Accuracy: 57.1%\n",
            "Step: 3515 ------------ Loss: 8991.19 ------------ Accuracy: 57.1%\n",
            "Step: 3516 ------------ Loss: 8989.42 ------------ Accuracy: 57.0%\n",
            "Step: 3517 ------------ Loss: 8989.34 ------------ Accuracy: 57.0%\n",
            "Step: 3518 ------------ Loss: 8989.12 ------------ Accuracy: 57.0%\n",
            "Step: 3519 ------------ Loss: 8989.06 ------------ Accuracy: 57.0%\n",
            "Step: 3520 ------------ Loss: 8988.96 ------------ Accuracy: 57.0%\n",
            "Step: 3521 ------------ Loss: 8988.95 ------------ Accuracy: 57.0%\n",
            "Step: 3522 ------------ Loss: 8988.94 ------------ Accuracy: 57.0%\n",
            "Step: 3523 ------------ Loss: 8988.72 ------------ Accuracy: 57.0%\n",
            "Step: 3524 ------------ Loss: 8988.62 ------------ Accuracy: 57.0%\n",
            "Step: 3525 ------------ Loss: 8988.61 ------------ Accuracy: 57.0%\n",
            "Step: 3526 ------------ Loss: 8986.89 ------------ Accuracy: 57.0%\n",
            "Step: 3527 ------------ Loss: 8986.81 ------------ Accuracy: 57.0%\n",
            "Step: 3528 ------------ Loss: 8986.81 ------------ Accuracy: 57.0%\n",
            "Step: 3529 ------------ Loss: 8986.8 ------------ Accuracy: 57.0%\n",
            "Step: 3530 ------------ Loss: 8986.74 ------------ Accuracy: 57.0%\n",
            "Step: 3531 ------------ Loss: 8986.48 ------------ Accuracy: 57.0%\n",
            "Step: 3532 ------------ Loss: 8984.83 ------------ Accuracy: 57.0%\n",
            "Step: 3533 ------------ Loss: 8983.94 ------------ Accuracy: 57.1%\n",
            "Step: 3534 ------------ Loss: 8983.94 ------------ Accuracy: 57.1%\n",
            "Step: 3535 ------------ Loss: 8983.89 ------------ Accuracy: 57.1%\n",
            "Step: 3536 ------------ Loss: 8983.64 ------------ Accuracy: 57.1%\n",
            "Step: 3537 ------------ Loss: 8983.64 ------------ Accuracy: 57.1%\n",
            "Step: 3538 ------------ Loss: 8983.63 ------------ Accuracy: 57.1%\n",
            "Step: 3539 ------------ Loss: 8982.95 ------------ Accuracy: 57.2%\n",
            "Step: 3540 ------------ Loss: 8982.46 ------------ Accuracy: 57.2%\n",
            "Step: 3541 ------------ Loss: 8982.44 ------------ Accuracy: 57.2%\n",
            "Step: 3542 ------------ Loss: 8982.38 ------------ Accuracy: 57.2%\n",
            "Step: 3543 ------------ Loss: 8982.06 ------------ Accuracy: 57.2%\n",
            "Step: 3544 ------------ Loss: 8982.04 ------------ Accuracy: 57.2%\n",
            "Step: 3545 ------------ Loss: 8981.54 ------------ Accuracy: 57.2%\n",
            "Step: 3546 ------------ Loss: 8981.44 ------------ Accuracy: 57.2%\n",
            "Step: 3547 ------------ Loss: 8981.31 ------------ Accuracy: 57.2%\n",
            "Step: 3548 ------------ Loss: 8981.31 ------------ Accuracy: 57.2%\n",
            "Step: 3549 ------------ Loss: 8981.25 ------------ Accuracy: 57.2%\n",
            "Step: 3550 ------------ Loss: 8981.22 ------------ Accuracy: 57.2%\n",
            "Step: 3551 ------------ Loss: 8980.21 ------------ Accuracy: 57.2%\n",
            "Step: 3552 ------------ Loss: 8980.2 ------------ Accuracy: 57.2%\n",
            "Step: 3553 ------------ Loss: 8980.2 ------------ Accuracy: 57.2%\n",
            "Step: 3554 ------------ Loss: 8980.16 ------------ Accuracy: 57.2%\n",
            "Step: 3555 ------------ Loss: 8980.15 ------------ Accuracy: 57.2%\n",
            "Step: 3556 ------------ Loss: 8980.09 ------------ Accuracy: 57.2%\n",
            "Step: 3557 ------------ Loss: 8980.08 ------------ Accuracy: 57.2%\n",
            "Step: 3558 ------------ Loss: 8980.02 ------------ Accuracy: 57.2%\n",
            "Step: 3559 ------------ Loss: 8980.0 ------------ Accuracy: 57.2%\n",
            "Step: 3560 ------------ Loss: 8979.98 ------------ Accuracy: 57.2%\n",
            "Step: 3561 ------------ Loss: 8979.8 ------------ Accuracy: 57.2%\n",
            "Step: 3562 ------------ Loss: 8979.8 ------------ Accuracy: 57.2%\n",
            "Step: 3563 ------------ Loss: 8979.66 ------------ Accuracy: 57.2%\n",
            "Step: 3564 ------------ Loss: 8978.99 ------------ Accuracy: 57.4%\n",
            "Step: 3565 ------------ Loss: 8978.92 ------------ Accuracy: 57.4%\n",
            "Step: 3566 ------------ Loss: 8978.91 ------------ Accuracy: 57.4%\n",
            "Step: 3567 ------------ Loss: 8978.85 ------------ Accuracy: 57.4%\n",
            "Step: 3568 ------------ Loss: 8978.8 ------------ Accuracy: 57.4%\n",
            "Step: 3569 ------------ Loss: 8978.8 ------------ Accuracy: 57.4%\n",
            "Step: 3570 ------------ Loss: 8978.72 ------------ Accuracy: 57.4%\n",
            "Step: 3571 ------------ Loss: 8978.64 ------------ Accuracy: 57.4%\n",
            "Step: 3572 ------------ Loss: 8978.62 ------------ Accuracy: 57.4%\n",
            "Step: 3573 ------------ Loss: 8978.61 ------------ Accuracy: 57.4%\n",
            "Step: 3574 ------------ Loss: 8977.67 ------------ Accuracy: 57.2%\n",
            "Step: 3575 ------------ Loss: 8977.17 ------------ Accuracy: 57.2%\n",
            "Step: 3576 ------------ Loss: 8977.15 ------------ Accuracy: 57.4%\n",
            "Step: 3577 ------------ Loss: 8977.07 ------------ Accuracy: 57.4%\n",
            "Step: 3578 ------------ Loss: 8977.03 ------------ Accuracy: 57.3%\n",
            "Step: 3579 ------------ Loss: 8976.99 ------------ Accuracy: 57.3%\n",
            "Step: 3580 ------------ Loss: 8976.43 ------------ Accuracy: 57.4%\n",
            "Step: 3581 ------------ Loss: 8976.38 ------------ Accuracy: 57.4%\n",
            "Step: 3582 ------------ Loss: 8976.36 ------------ Accuracy: 57.4%\n",
            "Step: 3583 ------------ Loss: 8976.32 ------------ Accuracy: 57.4%\n",
            "Step: 3584 ------------ Loss: 8976.21 ------------ Accuracy: 57.4%\n",
            "Step: 3585 ------------ Loss: 8976.11 ------------ Accuracy: 57.4%\n",
            "Step: 3586 ------------ Loss: 8976.08 ------------ Accuracy: 57.4%\n",
            "Step: 3587 ------------ Loss: 8976.07 ------------ Accuracy: 57.4%\n",
            "Step: 3588 ------------ Loss: 8976.04 ------------ Accuracy: 57.4%\n",
            "Step: 3589 ------------ Loss: 8976.03 ------------ Accuracy: 57.4%\n",
            "Step: 3590 ------------ Loss: 8975.97 ------------ Accuracy: 57.4%\n",
            "Step: 3591 ------------ Loss: 8975.96 ------------ Accuracy: 57.4%\n",
            "Step: 3592 ------------ Loss: 8975.96 ------------ Accuracy: 57.4%\n",
            "Step: 3593 ------------ Loss: 8975.45 ------------ Accuracy: 57.4%\n",
            "Step: 3594 ------------ Loss: 8975.43 ------------ Accuracy: 57.4%\n",
            "Step: 3595 ------------ Loss: 8975.35 ------------ Accuracy: 57.4%\n",
            "Step: 3596 ------------ Loss: 8975.33 ------------ Accuracy: 57.4%\n",
            "Step: 3597 ------------ Loss: 8975.32 ------------ Accuracy: 57.4%\n",
            "Step: 3598 ------------ Loss: 8975.28 ------------ Accuracy: 57.4%\n",
            "Step: 3599 ------------ Loss: 8975.06 ------------ Accuracy: 57.4%\n",
            "Step: 3600 ------------ Loss: 8975.02 ------------ Accuracy: 57.4%\n",
            "Step: 3601 ------------ Loss: 8975.01 ------------ Accuracy: 57.4%\n",
            "Step: 3602 ------------ Loss: 8973.15 ------------ Accuracy: 57.2%\n",
            "Step: 3603 ------------ Loss: 8972.27 ------------ Accuracy: 57.2%\n",
            "Step: 3604 ------------ Loss: 8970.5 ------------ Accuracy: 57.2%\n",
            "Step: 3605 ------------ Loss: 8970.37 ------------ Accuracy: 57.2%\n",
            "Step: 3606 ------------ Loss: 8970.23 ------------ Accuracy: 57.2%\n",
            "Step: 3607 ------------ Loss: 8968.54 ------------ Accuracy: 57.1%\n",
            "Step: 3608 ------------ Loss: 8968.43 ------------ Accuracy: 57.1%\n",
            "Step: 3609 ------------ Loss: 8968.42 ------------ Accuracy: 57.1%\n",
            "Step: 3610 ------------ Loss: 8968.28 ------------ Accuracy: 57.1%\n",
            "Step: 3611 ------------ Loss: 8968.28 ------------ Accuracy: 57.1%\n",
            "Step: 3612 ------------ Loss: 8968.23 ------------ Accuracy: 57.1%\n",
            "Step: 3613 ------------ Loss: 8968.16 ------------ Accuracy: 57.1%\n",
            "Step: 3614 ------------ Loss: 8968.03 ------------ Accuracy: 57.1%\n",
            "Step: 3615 ------------ Loss: 8967.98 ------------ Accuracy: 57.1%\n",
            "Step: 3616 ------------ Loss: 8967.87 ------------ Accuracy: 57.1%\n",
            "Step: 3617 ------------ Loss: 8967.59 ------------ Accuracy: 57.1%\n",
            "Step: 3618 ------------ Loss: 8967.49 ------------ Accuracy: 57.1%\n",
            "Step: 3619 ------------ Loss: 8967.46 ------------ Accuracy: 57.2%\n",
            "Step: 3620 ------------ Loss: 8967.46 ------------ Accuracy: 57.2%\n",
            "Step: 3621 ------------ Loss: 8967.45 ------------ Accuracy: 57.2%\n",
            "Step: 3622 ------------ Loss: 8967.35 ------------ Accuracy: 57.2%\n",
            "Step: 3623 ------------ Loss: 8967.35 ------------ Accuracy: 57.2%\n",
            "Step: 3624 ------------ Loss: 8967.21 ------------ Accuracy: 57.2%\n",
            "Step: 3625 ------------ Loss: 8967.21 ------------ Accuracy: 57.2%\n",
            "Step: 3626 ------------ Loss: 8967.2 ------------ Accuracy: 57.2%\n",
            "Step: 3627 ------------ Loss: 8967.18 ------------ Accuracy: 57.2%\n",
            "Step: 3628 ------------ Loss: 8967.17 ------------ Accuracy: 57.2%\n",
            "Step: 3629 ------------ Loss: 8966.36 ------------ Accuracy: 57.2%\n",
            "Step: 3630 ------------ Loss: 8966.16 ------------ Accuracy: 57.2%\n",
            "Step: 3631 ------------ Loss: 8966.12 ------------ Accuracy: 57.2%\n",
            "Step: 3632 ------------ Loss: 8966.12 ------------ Accuracy: 57.2%\n",
            "Step: 3633 ------------ Loss: 8966.11 ------------ Accuracy: 57.2%\n",
            "Step: 3634 ------------ Loss: 8966.06 ------------ Accuracy: 57.2%\n",
            "Step: 3635 ------------ Loss: 8966.01 ------------ Accuracy: 57.2%\n",
            "Step: 3636 ------------ Loss: 8965.16 ------------ Accuracy: 57.4%\n",
            "Step: 3637 ------------ Loss: 8965.1 ------------ Accuracy: 57.4%\n",
            "Step: 3638 ------------ Loss: 8965.09 ------------ Accuracy: 57.4%\n",
            "Step: 3639 ------------ Loss: 8965.07 ------------ Accuracy: 57.4%\n",
            "Step: 3640 ------------ Loss: 8964.94 ------------ Accuracy: 57.4%\n",
            "Step: 3641 ------------ Loss: 8964.84 ------------ Accuracy: 57.4%\n",
            "Step: 3642 ------------ Loss: 8964.83 ------------ Accuracy: 57.4%\n",
            "Step: 3643 ------------ Loss: 8964.83 ------------ Accuracy: 57.4%\n",
            "Step: 3644 ------------ Loss: 8964.35 ------------ Accuracy: 57.4%\n",
            "Step: 3645 ------------ Loss: 8964.34 ------------ Accuracy: 57.4%\n",
            "Step: 3646 ------------ Loss: 8964.34 ------------ Accuracy: 57.4%\n",
            "Step: 3647 ------------ Loss: 8964.2 ------------ Accuracy: 57.4%\n",
            "Step: 3648 ------------ Loss: 8964.07 ------------ Accuracy: 57.4%\n",
            "Step: 3649 ------------ Loss: 8964.06 ------------ Accuracy: 57.4%\n",
            "Step: 3650 ------------ Loss: 8963.22 ------------ Accuracy: 57.4%\n",
            "Step: 3651 ------------ Loss: 8963.14 ------------ Accuracy: 57.4%\n",
            "Step: 3652 ------------ Loss: 8963.14 ------------ Accuracy: 57.4%\n",
            "Step: 3653 ------------ Loss: 8963.03 ------------ Accuracy: 57.4%\n",
            "Step: 3654 ------------ Loss: 8962.83 ------------ Accuracy: 57.4%\n",
            "Step: 3655 ------------ Loss: 8962.79 ------------ Accuracy: 57.4%\n",
            "Step: 3656 ------------ Loss: 8962.78 ------------ Accuracy: 57.4%\n",
            "Step: 3657 ------------ Loss: 8962.76 ------------ Accuracy: 57.4%\n",
            "Step: 3658 ------------ Loss: 8962.67 ------------ Accuracy: 57.4%\n",
            "Step: 3659 ------------ Loss: 8962.57 ------------ Accuracy: 57.4%\n",
            "Step: 3660 ------------ Loss: 8962.49 ------------ Accuracy: 57.4%\n",
            "Step: 3661 ------------ Loss: 8960.75 ------------ Accuracy: 57.2%\n",
            "Step: 3662 ------------ Loss: 8960.71 ------------ Accuracy: 57.2%\n",
            "Step: 3663 ------------ Loss: 8960.68 ------------ Accuracy: 57.2%\n",
            "Step: 3664 ------------ Loss: 8960.65 ------------ Accuracy: 57.2%\n",
            "Step: 3665 ------------ Loss: 8960.56 ------------ Accuracy: 57.2%\n",
            "Step: 3666 ------------ Loss: 8958.88 ------------ Accuracy: 57.2%\n",
            "Step: 3667 ------------ Loss: 8957.26 ------------ Accuracy: 57.2%\n",
            "Step: 3668 ------------ Loss: 8957.06 ------------ Accuracy: 57.2%\n",
            "Step: 3669 ------------ Loss: 8956.99 ------------ Accuracy: 57.2%\n",
            "Step: 3670 ------------ Loss: 8956.88 ------------ Accuracy: 57.2%\n",
            "Step: 3671 ------------ Loss: 8956.84 ------------ Accuracy: 57.2%\n",
            "Step: 3672 ------------ Loss: 8956.39 ------------ Accuracy: 57.2%\n",
            "Step: 3673 ------------ Loss: 8954.82 ------------ Accuracy: 57.2%\n",
            "Step: 3674 ------------ Loss: 8954.77 ------------ Accuracy: 57.2%\n",
            "Step: 3675 ------------ Loss: 8954.76 ------------ Accuracy: 57.2%\n",
            "Step: 3676 ------------ Loss: 8954.49 ------------ Accuracy: 57.2%\n",
            "Step: 3677 ------------ Loss: 8954.29 ------------ Accuracy: 57.2%\n",
            "Step: 3678 ------------ Loss: 8954.29 ------------ Accuracy: 57.2%\n",
            "Step: 3679 ------------ Loss: 8954.26 ------------ Accuracy: 57.2%\n",
            "Step: 3680 ------------ Loss: 8954.13 ------------ Accuracy: 57.2%\n",
            "Step: 3681 ------------ Loss: 8954.12 ------------ Accuracy: 57.2%\n",
            "Step: 3682 ------------ Loss: 8953.85 ------------ Accuracy: 57.2%\n",
            "Step: 3683 ------------ Loss: 8953.85 ------------ Accuracy: 57.2%\n",
            "Step: 3684 ------------ Loss: 8953.8 ------------ Accuracy: 57.2%\n",
            "Step: 3685 ------------ Loss: 8953.8 ------------ Accuracy: 57.2%\n",
            "Step: 3686 ------------ Loss: 8953.78 ------------ Accuracy: 57.2%\n",
            "Step: 3687 ------------ Loss: 8953.74 ------------ Accuracy: 57.2%\n",
            "Step: 3688 ------------ Loss: 8953.29 ------------ Accuracy: 57.2%\n",
            "Step: 3689 ------------ Loss: 8953.25 ------------ Accuracy: 57.2%\n",
            "Step: 3690 ------------ Loss: 8953.22 ------------ Accuracy: 57.2%\n",
            "Step: 3691 ------------ Loss: 8953.22 ------------ Accuracy: 57.2%\n",
            "Step: 3692 ------------ Loss: 8953.22 ------------ Accuracy: 57.2%\n",
            "Step: 3693 ------------ Loss: 8953.2 ------------ Accuracy: 57.2%\n",
            "Step: 3694 ------------ Loss: 8953.08 ------------ Accuracy: 57.2%\n",
            "Step: 3695 ------------ Loss: 8952.99 ------------ Accuracy: 57.2%\n",
            "Step: 3696 ------------ Loss: 8952.99 ------------ Accuracy: 57.2%\n",
            "Step: 3697 ------------ Loss: 8952.92 ------------ Accuracy: 57.2%\n",
            "Step: 3698 ------------ Loss: 8952.92 ------------ Accuracy: 57.2%\n",
            "Step: 3699 ------------ Loss: 8952.08 ------------ Accuracy: 57.2%\n",
            "Step: 3700 ------------ Loss: 8952.02 ------------ Accuracy: 57.2%\n",
            "Step: 3701 ------------ Loss: 8950.45 ------------ Accuracy: 57.2%\n",
            "Step: 3702 ------------ Loss: 8950.42 ------------ Accuracy: 57.2%\n",
            "Step: 3703 ------------ Loss: 8950.36 ------------ Accuracy: 57.2%\n",
            "Step: 3704 ------------ Loss: 8950.34 ------------ Accuracy: 57.2%\n",
            "Step: 3705 ------------ Loss: 8950.07 ------------ Accuracy: 57.2%\n",
            "Step: 3706 ------------ Loss: 8949.99 ------------ Accuracy: 57.2%\n",
            "Step: 3707 ------------ Loss: 8949.55 ------------ Accuracy: 57.2%\n",
            "Step: 3708 ------------ Loss: 8949.51 ------------ Accuracy: 57.2%\n",
            "Step: 3709 ------------ Loss: 8949.47 ------------ Accuracy: 57.2%\n",
            "Step: 3710 ------------ Loss: 8948.66 ------------ Accuracy: 57.2%\n",
            "Step: 3711 ------------ Loss: 8948.66 ------------ Accuracy: 57.2%\n",
            "Step: 3712 ------------ Loss: 8948.39 ------------ Accuracy: 57.2%\n",
            "Step: 3713 ------------ Loss: 8947.5 ------------ Accuracy: 57.4%\n",
            "Step: 3714 ------------ Loss: 8947.44 ------------ Accuracy: 57.4%\n",
            "Step: 3715 ------------ Loss: 8947.39 ------------ Accuracy: 57.4%\n",
            "Step: 3716 ------------ Loss: 8947.38 ------------ Accuracy: 57.4%\n",
            "Step: 3717 ------------ Loss: 8947.35 ------------ Accuracy: 57.4%\n",
            "Step: 3718 ------------ Loss: 8947.29 ------------ Accuracy: 57.4%\n",
            "Step: 3719 ------------ Loss: 8947.24 ------------ Accuracy: 57.4%\n",
            "Step: 3720 ------------ Loss: 8947.24 ------------ Accuracy: 57.4%\n",
            "Step: 3721 ------------ Loss: 8947.23 ------------ Accuracy: 57.4%\n",
            "Step: 3722 ------------ Loss: 8947.16 ------------ Accuracy: 57.4%\n",
            "Step: 3723 ------------ Loss: 8947.1 ------------ Accuracy: 57.4%\n",
            "Step: 3724 ------------ Loss: 8947.04 ------------ Accuracy: 57.4%\n",
            "Step: 3725 ------------ Loss: 8947.01 ------------ Accuracy: 57.4%\n",
            "Step: 3726 ------------ Loss: 8946.9 ------------ Accuracy: 57.4%\n",
            "Step: 3727 ------------ Loss: 8946.78 ------------ Accuracy: 57.4%\n",
            "Step: 3728 ------------ Loss: 8946.77 ------------ Accuracy: 57.4%\n",
            "Step: 3729 ------------ Loss: 8946.69 ------------ Accuracy: 57.4%\n",
            "Step: 3730 ------------ Loss: 8946.65 ------------ Accuracy: 57.4%\n",
            "Step: 3731 ------------ Loss: 8946.18 ------------ Accuracy: 57.4%\n",
            "Step: 3732 ------------ Loss: 8946.17 ------------ Accuracy: 57.4%\n",
            "Step: 3733 ------------ Loss: 8946.06 ------------ Accuracy: 57.4%\n",
            "Step: 3734 ------------ Loss: 8945.23 ------------ Accuracy: 57.4%\n",
            "Step: 3735 ------------ Loss: 8945.02 ------------ Accuracy: 57.4%\n",
            "Step: 3736 ------------ Loss: 8944.9 ------------ Accuracy: 57.4%\n",
            "Step: 3737 ------------ Loss: 8944.79 ------------ Accuracy: 57.4%\n",
            "Step: 3738 ------------ Loss: 8944.79 ------------ Accuracy: 57.4%\n",
            "Step: 3739 ------------ Loss: 8944.74 ------------ Accuracy: 57.3%\n",
            "Step: 3740 ------------ Loss: 8944.73 ------------ Accuracy: 57.4%\n",
            "Step: 3741 ------------ Loss: 8944.72 ------------ Accuracy: 57.4%\n",
            "Step: 3742 ------------ Loss: 8944.71 ------------ Accuracy: 57.4%\n",
            "Step: 3743 ------------ Loss: 8944.71 ------------ Accuracy: 57.4%\n",
            "Step: 3744 ------------ Loss: 8944.6 ------------ Accuracy: 57.4%\n",
            "Step: 3745 ------------ Loss: 8944.58 ------------ Accuracy: 57.4%\n",
            "Step: 3746 ------------ Loss: 8944.55 ------------ Accuracy: 57.4%\n",
            "Step: 3747 ------------ Loss: 8944.44 ------------ Accuracy: 57.4%\n",
            "Step: 3748 ------------ Loss: 8943.75 ------------ Accuracy: 57.3%\n",
            "Step: 3749 ------------ Loss: 8943.64 ------------ Accuracy: 57.3%\n",
            "Step: 3750 ------------ Loss: 8943.15 ------------ Accuracy: 57.4%\n",
            "Step: 3751 ------------ Loss: 8942.9 ------------ Accuracy: 57.4%\n",
            "Step: 3752 ------------ Loss: 8942.89 ------------ Accuracy: 57.4%\n",
            "Step: 3753 ------------ Loss: 8942.4 ------------ Accuracy: 57.4%\n",
            "Step: 3754 ------------ Loss: 8942.39 ------------ Accuracy: 57.4%\n",
            "Step: 3755 ------------ Loss: 8942.36 ------------ Accuracy: 57.4%\n",
            "Step: 3756 ------------ Loss: 8940.61 ------------ Accuracy: 57.4%\n",
            "Step: 3757 ------------ Loss: 8940.57 ------------ Accuracy: 57.4%\n",
            "Step: 3758 ------------ Loss: 8940.54 ------------ Accuracy: 57.4%\n",
            "Step: 3759 ------------ Loss: 8940.52 ------------ Accuracy: 57.4%\n",
            "Step: 3760 ------------ Loss: 8940.41 ------------ Accuracy: 57.4%\n",
            "Step: 3761 ------------ Loss: 8940.19 ------------ Accuracy: 57.4%\n",
            "Step: 3762 ------------ Loss: 8939.73 ------------ Accuracy: 57.4%\n",
            "Step: 3763 ------------ Loss: 8939.44 ------------ Accuracy: 57.4%\n",
            "Step: 3764 ------------ Loss: 8939.19 ------------ Accuracy: 57.4%\n",
            "Step: 3765 ------------ Loss: 8939.19 ------------ Accuracy: 57.4%\n",
            "Step: 3766 ------------ Loss: 8939.18 ------------ Accuracy: 57.4%\n",
            "Step: 3767 ------------ Loss: 8939.16 ------------ Accuracy: 57.4%\n",
            "Step: 3768 ------------ Loss: 8939.15 ------------ Accuracy: 57.4%\n",
            "Step: 3769 ------------ Loss: 8939.13 ------------ Accuracy: 57.4%\n",
            "Step: 3770 ------------ Loss: 8939.13 ------------ Accuracy: 57.4%\n",
            "Step: 3771 ------------ Loss: 8939.06 ------------ Accuracy: 57.4%\n",
            "Step: 3772 ------------ Loss: 8938.86 ------------ Accuracy: 57.5%\n",
            "Step: 3773 ------------ Loss: 8938.85 ------------ Accuracy: 57.5%\n",
            "Step: 3774 ------------ Loss: 8938.83 ------------ Accuracy: 57.5%\n",
            "Step: 3775 ------------ Loss: 8938.57 ------------ Accuracy: 57.5%\n",
            "Step: 3776 ------------ Loss: 8938.57 ------------ Accuracy: 57.5%\n",
            "Step: 3777 ------------ Loss: 8938.45 ------------ Accuracy: 57.5%\n",
            "Step: 3778 ------------ Loss: 8938.43 ------------ Accuracy: 57.5%\n",
            "Step: 3779 ------------ Loss: 8938.4 ------------ Accuracy: 57.5%\n",
            "Step: 3780 ------------ Loss: 8938.39 ------------ Accuracy: 57.5%\n",
            "Step: 3781 ------------ Loss: 8938.39 ------------ Accuracy: 57.5%\n",
            "Step: 3782 ------------ Loss: 8938.32 ------------ Accuracy: 57.5%\n",
            "Step: 3783 ------------ Loss: 8938.27 ------------ Accuracy: 57.5%\n",
            "Step: 3784 ------------ Loss: 8938.26 ------------ Accuracy: 57.5%\n",
            "Step: 3785 ------------ Loss: 8938.24 ------------ Accuracy: 57.5%\n",
            "Step: 3786 ------------ Loss: 8937.98 ------------ Accuracy: 57.5%\n",
            "Step: 3787 ------------ Loss: 8937.51 ------------ Accuracy: 57.5%\n",
            "Step: 3788 ------------ Loss: 8935.83 ------------ Accuracy: 57.5%\n",
            "Step: 3789 ------------ Loss: 8935.82 ------------ Accuracy: 57.5%\n",
            "Step: 3790 ------------ Loss: 8935.71 ------------ Accuracy: 57.5%\n",
            "Step: 3791 ------------ Loss: 8935.13 ------------ Accuracy: 57.4%\n",
            "Step: 3792 ------------ Loss: 8935.08 ------------ Accuracy: 57.4%\n",
            "Step: 3793 ------------ Loss: 8935.0 ------------ Accuracy: 57.4%\n",
            "Step: 3794 ------------ Loss: 8934.05 ------------ Accuracy: 57.5%\n",
            "Step: 3795 ------------ Loss: 8934.04 ------------ Accuracy: 57.5%\n",
            "Step: 3796 ------------ Loss: 8933.96 ------------ Accuracy: 57.5%\n",
            "Step: 3797 ------------ Loss: 8933.95 ------------ Accuracy: 57.5%\n",
            "Step: 3798 ------------ Loss: 8933.74 ------------ Accuracy: 57.5%\n",
            "Step: 3799 ------------ Loss: 8933.69 ------------ Accuracy: 57.5%\n",
            "Step: 3800 ------------ Loss: 8933.57 ------------ Accuracy: 57.5%\n",
            "Step: 3801 ------------ Loss: 8933.55 ------------ Accuracy: 57.5%\n",
            "Step: 3802 ------------ Loss: 8933.05 ------------ Accuracy: 57.4%\n",
            "Step: 3803 ------------ Loss: 8932.57 ------------ Accuracy: 57.4%\n",
            "Step: 3804 ------------ Loss: 8932.46 ------------ Accuracy: 57.4%\n",
            "Step: 3805 ------------ Loss: 8932.39 ------------ Accuracy: 57.4%\n",
            "Step: 3806 ------------ Loss: 8932.34 ------------ Accuracy: 57.4%\n",
            "Step: 3807 ------------ Loss: 8932.32 ------------ Accuracy: 57.3%\n",
            "Step: 3808 ------------ Loss: 8932.29 ------------ Accuracy: 57.4%\n",
            "Step: 3809 ------------ Loss: 8932.28 ------------ Accuracy: 57.4%\n",
            "Step: 3810 ------------ Loss: 8932.27 ------------ Accuracy: 57.4%\n",
            "Step: 3811 ------------ Loss: 8932.24 ------------ Accuracy: 57.4%\n",
            "Step: 3812 ------------ Loss: 8932.22 ------------ Accuracy: 57.4%\n",
            "Step: 3813 ------------ Loss: 8932.01 ------------ Accuracy: 57.4%\n",
            "Step: 3814 ------------ Loss: 8932.0 ------------ Accuracy: 57.4%\n",
            "Step: 3815 ------------ Loss: 8931.99 ------------ Accuracy: 57.4%\n",
            "Step: 3816 ------------ Loss: 8931.78 ------------ Accuracy: 57.4%\n",
            "Step: 3817 ------------ Loss: 8931.77 ------------ Accuracy: 57.4%\n",
            "Step: 3818 ------------ Loss: 8931.76 ------------ Accuracy: 57.4%\n",
            "Step: 3819 ------------ Loss: 8931.73 ------------ Accuracy: 57.4%\n",
            "Step: 3820 ------------ Loss: 8931.29 ------------ Accuracy: 57.3%\n",
            "Step: 3821 ------------ Loss: 8931.26 ------------ Accuracy: 57.3%\n",
            "Step: 3822 ------------ Loss: 8931.24 ------------ Accuracy: 57.3%\n",
            "Step: 3823 ------------ Loss: 8931.16 ------------ Accuracy: 57.3%\n",
            "Step: 3824 ------------ Loss: 8931.11 ------------ Accuracy: 57.3%\n",
            "Step: 3825 ------------ Loss: 8931.08 ------------ Accuracy: 57.3%\n",
            "Step: 3826 ------------ Loss: 8930.6 ------------ Accuracy: 57.3%\n",
            "Step: 3827 ------------ Loss: 8930.24 ------------ Accuracy: 57.4%\n",
            "Step: 3828 ------------ Loss: 8930.19 ------------ Accuracy: 57.4%\n",
            "Step: 3829 ------------ Loss: 8930.14 ------------ Accuracy: 57.4%\n",
            "Step: 3830 ------------ Loss: 8930.09 ------------ Accuracy: 57.5%\n",
            "Step: 3831 ------------ Loss: 8930.05 ------------ Accuracy: 57.5%\n",
            "Step: 3832 ------------ Loss: 8930.04 ------------ Accuracy: 57.5%\n",
            "Step: 3833 ------------ Loss: 8930.03 ------------ Accuracy: 57.5%\n",
            "Step: 3834 ------------ Loss: 8930.01 ------------ Accuracy: 57.4%\n",
            "Step: 3835 ------------ Loss: 8930.0 ------------ Accuracy: 57.4%\n",
            "Step: 3836 ------------ Loss: 8929.51 ------------ Accuracy: 57.4%\n",
            "Step: 3837 ------------ Loss: 8929.48 ------------ Accuracy: 57.5%\n",
            "Step: 3838 ------------ Loss: 8929.24 ------------ Accuracy: 57.5%\n",
            "Step: 3839 ------------ Loss: 8928.98 ------------ Accuracy: 57.4%\n",
            "Step: 3840 ------------ Loss: 8928.05 ------------ Accuracy: 57.4%\n",
            "Step: 3841 ------------ Loss: 8927.85 ------------ Accuracy: 57.4%\n",
            "Step: 3842 ------------ Loss: 8927.6 ------------ Accuracy: 57.3%\n",
            "Step: 3843 ------------ Loss: 8927.58 ------------ Accuracy: 57.4%\n",
            "Step: 3844 ------------ Loss: 8927.47 ------------ Accuracy: 57.4%\n",
            "Step: 3845 ------------ Loss: 8927.45 ------------ Accuracy: 57.3%\n",
            "Step: 3846 ------------ Loss: 8927.29 ------------ Accuracy: 57.4%\n",
            "Step: 3847 ------------ Loss: 8927.28 ------------ Accuracy: 57.4%\n",
            "Step: 3848 ------------ Loss: 8927.27 ------------ Accuracy: 57.4%\n",
            "Step: 3849 ------------ Loss: 8927.07 ------------ Accuracy: 57.4%\n",
            "Step: 3850 ------------ Loss: 8927.03 ------------ Accuracy: 57.4%\n",
            "Step: 3851 ------------ Loss: 8926.21 ------------ Accuracy: 57.4%\n",
            "Step: 3852 ------------ Loss: 8926.1 ------------ Accuracy: 57.4%\n",
            "Step: 3853 ------------ Loss: 8926.01 ------------ Accuracy: 57.5%\n",
            "Step: 3854 ------------ Loss: 8925.99 ------------ Accuracy: 57.4%\n",
            "Step: 3855 ------------ Loss: 8925.94 ------------ Accuracy: 57.4%\n",
            "Step: 3856 ------------ Loss: 8925.21 ------------ Accuracy: 57.6%\n",
            "Step: 3857 ------------ Loss: 8925.2 ------------ Accuracy: 57.6%\n",
            "Step: 3858 ------------ Loss: 8925.2 ------------ Accuracy: 57.6%\n",
            "Step: 3859 ------------ Loss: 8925.08 ------------ Accuracy: 57.6%\n",
            "Step: 3860 ------------ Loss: 8923.37 ------------ Accuracy: 57.5%\n",
            "Step: 3861 ------------ Loss: 8923.26 ------------ Accuracy: 57.5%\n",
            "Step: 3862 ------------ Loss: 8922.8 ------------ Accuracy: 57.5%\n",
            "Step: 3863 ------------ Loss: 8922.8 ------------ Accuracy: 57.5%\n",
            "Step: 3864 ------------ Loss: 8922.68 ------------ Accuracy: 57.5%\n",
            "Step: 3865 ------------ Loss: 8922.68 ------------ Accuracy: 57.5%\n",
            "Step: 3866 ------------ Loss: 8922.67 ------------ Accuracy: 57.5%\n",
            "Step: 3867 ------------ Loss: 8922.67 ------------ Accuracy: 57.5%\n",
            "Step: 3868 ------------ Loss: 8921.06 ------------ Accuracy: 57.5%\n",
            "Step: 3869 ------------ Loss: 8921.02 ------------ Accuracy: 57.5%\n",
            "Step: 3870 ------------ Loss: 8921.01 ------------ Accuracy: 57.5%\n",
            "Step: 3871 ------------ Loss: 8919.46 ------------ Accuracy: 57.6%\n",
            "Step: 3872 ------------ Loss: 8917.98 ------------ Accuracy: 57.6%\n",
            "Step: 3873 ------------ Loss: 8917.94 ------------ Accuracy: 57.6%\n",
            "Step: 3874 ------------ Loss: 8917.13 ------------ Accuracy: 57.4%\n",
            "Step: 3875 ------------ Loss: 8917.12 ------------ Accuracy: 57.4%\n",
            "Step: 3876 ------------ Loss: 8916.25 ------------ Accuracy: 57.4%\n",
            "Step: 3877 ------------ Loss: 8916.14 ------------ Accuracy: 57.4%\n",
            "Step: 3878 ------------ Loss: 8916.03 ------------ Accuracy: 57.4%\n",
            "Step: 3879 ------------ Loss: 8915.77 ------------ Accuracy: 57.4%\n",
            "Step: 3880 ------------ Loss: 8915.75 ------------ Accuracy: 57.4%\n",
            "Step: 3881 ------------ Loss: 8915.64 ------------ Accuracy: 57.4%\n",
            "Step: 3882 ------------ Loss: 8915.64 ------------ Accuracy: 57.4%\n",
            "Step: 3883 ------------ Loss: 8915.62 ------------ Accuracy: 57.4%\n",
            "Step: 3884 ------------ Loss: 8915.56 ------------ Accuracy: 57.4%\n",
            "Step: 3885 ------------ Loss: 8915.48 ------------ Accuracy: 57.4%\n",
            "Step: 3886 ------------ Loss: 8915.22 ------------ Accuracy: 57.4%\n",
            "Step: 3887 ------------ Loss: 8915.08 ------------ Accuracy: 57.4%\n",
            "Step: 3888 ------------ Loss: 8915.02 ------------ Accuracy: 57.4%\n",
            "Step: 3889 ------------ Loss: 8915.02 ------------ Accuracy: 57.4%\n",
            "Step: 3890 ------------ Loss: 8914.96 ------------ Accuracy: 57.4%\n",
            "Step: 3891 ------------ Loss: 8914.84 ------------ Accuracy: 57.5%\n",
            "Step: 3892 ------------ Loss: 8914.84 ------------ Accuracy: 57.5%\n",
            "Step: 3893 ------------ Loss: 8914.4 ------------ Accuracy: 57.6%\n",
            "Step: 3894 ------------ Loss: 8914.21 ------------ Accuracy: 57.6%\n",
            "Step: 3895 ------------ Loss: 8914.02 ------------ Accuracy: 57.6%\n",
            "Step: 3896 ------------ Loss: 8914.01 ------------ Accuracy: 57.6%\n",
            "Step: 3897 ------------ Loss: 8913.28 ------------ Accuracy: 57.4%\n",
            "Step: 3898 ------------ Loss: 8913.28 ------------ Accuracy: 57.4%\n",
            "Step: 3899 ------------ Loss: 8913.27 ------------ Accuracy: 57.4%\n",
            "Step: 3900 ------------ Loss: 8913.13 ------------ Accuracy: 57.4%\n",
            "Step: 3901 ------------ Loss: 8913.12 ------------ Accuracy: 57.4%\n",
            "Step: 3902 ------------ Loss: 8913.12 ------------ Accuracy: 57.4%\n",
            "Step: 3903 ------------ Loss: 8912.86 ------------ Accuracy: 57.4%\n",
            "Step: 3904 ------------ Loss: 8912.86 ------------ Accuracy: 57.4%\n",
            "Step: 3905 ------------ Loss: 8912.85 ------------ Accuracy: 57.4%\n",
            "Step: 3906 ------------ Loss: 8912.73 ------------ Accuracy: 57.5%\n",
            "Step: 3907 ------------ Loss: 8912.64 ------------ Accuracy: 57.5%\n",
            "Step: 3908 ------------ Loss: 8912.55 ------------ Accuracy: 57.5%\n",
            "Step: 3909 ------------ Loss: 8912.55 ------------ Accuracy: 57.5%\n",
            "Step: 3910 ------------ Loss: 8912.47 ------------ Accuracy: 57.5%\n",
            "Step: 3911 ------------ Loss: 8912.28 ------------ Accuracy: 57.5%\n",
            "Step: 3912 ------------ Loss: 8912.19 ------------ Accuracy: 57.5%\n",
            "Step: 3913 ------------ Loss: 8912.0 ------------ Accuracy: 57.3%\n",
            "Step: 3914 ------------ Loss: 8911.33 ------------ Accuracy: 57.3%\n",
            "Step: 3915 ------------ Loss: 8910.46 ------------ Accuracy: 57.4%\n",
            "Step: 3916 ------------ Loss: 8910.45 ------------ Accuracy: 57.4%\n",
            "Step: 3917 ------------ Loss: 8910.42 ------------ Accuracy: 57.4%\n",
            "Step: 3918 ------------ Loss: 8910.37 ------------ Accuracy: 57.4%\n",
            "Step: 3919 ------------ Loss: 8909.91 ------------ Accuracy: 57.4%\n",
            "Step: 3920 ------------ Loss: 8909.9 ------------ Accuracy: 57.4%\n",
            "Step: 3921 ------------ Loss: 8909.9 ------------ Accuracy: 57.4%\n",
            "Step: 3922 ------------ Loss: 8909.85 ------------ Accuracy: 57.4%\n",
            "Step: 3923 ------------ Loss: 8909.77 ------------ Accuracy: 57.4%\n",
            "Step: 3924 ------------ Loss: 8909.24 ------------ Accuracy: 57.6%\n",
            "Step: 3925 ------------ Loss: 8908.86 ------------ Accuracy: 57.3%\n",
            "Step: 3926 ------------ Loss: 8908.64 ------------ Accuracy: 57.3%\n",
            "Step: 3927 ------------ Loss: 8908.62 ------------ Accuracy: 57.3%\n",
            "Step: 3928 ------------ Loss: 8908.58 ------------ Accuracy: 57.3%\n",
            "Step: 3929 ------------ Loss: 8908.55 ------------ Accuracy: 57.4%\n",
            "Step: 3930 ------------ Loss: 8908.45 ------------ Accuracy: 57.4%\n",
            "Step: 3931 ------------ Loss: 8908.42 ------------ Accuracy: 57.4%\n",
            "Step: 3932 ------------ Loss: 8908.34 ------------ Accuracy: 57.4%\n",
            "Step: 3933 ------------ Loss: 8908.3 ------------ Accuracy: 57.5%\n",
            "Step: 3934 ------------ Loss: 8908.28 ------------ Accuracy: 57.5%\n",
            "Step: 3935 ------------ Loss: 8907.93 ------------ Accuracy: 57.3%\n",
            "Step: 3936 ------------ Loss: 8907.68 ------------ Accuracy: 57.5%\n",
            "Step: 3937 ------------ Loss: 8907.67 ------------ Accuracy: 57.5%\n",
            "Step: 3938 ------------ Loss: 8907.56 ------------ Accuracy: 57.5%\n",
            "Step: 3939 ------------ Loss: 8907.48 ------------ Accuracy: 57.5%\n",
            "Step: 3940 ------------ Loss: 8907.4 ------------ Accuracy: 57.5%\n",
            "Step: 3941 ------------ Loss: 8907.38 ------------ Accuracy: 57.4%\n",
            "Step: 3942 ------------ Loss: 8907.34 ------------ Accuracy: 57.3%\n",
            "Step: 3943 ------------ Loss: 8905.57 ------------ Accuracy: 57.6%\n",
            "Step: 3944 ------------ Loss: 8905.54 ------------ Accuracy: 57.5%\n",
            "Step: 3945 ------------ Loss: 8905.43 ------------ Accuracy: 57.5%\n",
            "Step: 3946 ------------ Loss: 8905.41 ------------ Accuracy: 57.5%\n",
            "Step: 3947 ------------ Loss: 8905.36 ------------ Accuracy: 57.4%\n",
            "Step: 3948 ------------ Loss: 8905.34 ------------ Accuracy: 57.4%\n",
            "Step: 3949 ------------ Loss: 8905.31 ------------ Accuracy: 57.4%\n",
            "Step: 3950 ------------ Loss: 8905.06 ------------ Accuracy: 57.4%\n",
            "Step: 3951 ------------ Loss: 8904.59 ------------ Accuracy: 57.4%\n",
            "Step: 3952 ------------ Loss: 8904.52 ------------ Accuracy: 57.4%\n",
            "Step: 3953 ------------ Loss: 8904.5 ------------ Accuracy: 57.4%\n",
            "Step: 3954 ------------ Loss: 8904.48 ------------ Accuracy: 57.4%\n",
            "Step: 3955 ------------ Loss: 8904.37 ------------ Accuracy: 57.4%\n",
            "Step: 3956 ------------ Loss: 8904.26 ------------ Accuracy: 57.4%\n",
            "Step: 3957 ------------ Loss: 8903.8 ------------ Accuracy: 57.4%\n",
            "Step: 3958 ------------ Loss: 8903.7 ------------ Accuracy: 57.4%\n",
            "Step: 3959 ------------ Loss: 8903.69 ------------ Accuracy: 57.4%\n",
            "Step: 3960 ------------ Loss: 8903.49 ------------ Accuracy: 57.5%\n",
            "Step: 3961 ------------ Loss: 8903.47 ------------ Accuracy: 57.4%\n",
            "Step: 3962 ------------ Loss: 8903.41 ------------ Accuracy: 57.4%\n",
            "Step: 3963 ------------ Loss: 8902.98 ------------ Accuracy: 57.4%\n",
            "Step: 3964 ------------ Loss: 8902.93 ------------ Accuracy: 57.4%\n",
            "Step: 3965 ------------ Loss: 8902.92 ------------ Accuracy: 57.4%\n",
            "Step: 3966 ------------ Loss: 8902.82 ------------ Accuracy: 57.4%\n",
            "Step: 3967 ------------ Loss: 8902.74 ------------ Accuracy: 57.4%\n",
            "Step: 3968 ------------ Loss: 8902.63 ------------ Accuracy: 57.4%\n",
            "Step: 3969 ------------ Loss: 8902.39 ------------ Accuracy: 57.4%\n",
            "Step: 3970 ------------ Loss: 8902.38 ------------ Accuracy: 57.4%\n",
            "Step: 3971 ------------ Loss: 8902.35 ------------ Accuracy: 57.4%\n",
            "Step: 3972 ------------ Loss: 8902.11 ------------ Accuracy: 57.4%\n",
            "Step: 3973 ------------ Loss: 8902.08 ------------ Accuracy: 57.4%\n",
            "Step: 3974 ------------ Loss: 8902.03 ------------ Accuracy: 57.4%\n",
            "Step: 3975 ------------ Loss: 8902.0 ------------ Accuracy: 57.4%\n",
            "Step: 3976 ------------ Loss: 8901.93 ------------ Accuracy: 57.4%\n",
            "Step: 3977 ------------ Loss: 8901.9 ------------ Accuracy: 57.4%\n",
            "Step: 3978 ------------ Loss: 8901.58 ------------ Accuracy: 57.5%\n",
            "Step: 3979 ------------ Loss: 8901.1 ------------ Accuracy: 57.5%\n",
            "Step: 3980 ------------ Loss: 8901.09 ------------ Accuracy: 57.5%\n",
            "Step: 3981 ------------ Loss: 8901.01 ------------ Accuracy: 57.5%\n",
            "Step: 3982 ------------ Loss: 8900.97 ------------ Accuracy: 57.5%\n",
            "Step: 3983 ------------ Loss: 8900.71 ------------ Accuracy: 57.5%\n",
            "Step: 3984 ------------ Loss: 8900.7 ------------ Accuracy: 57.5%\n",
            "Step: 3985 ------------ Loss: 8900.67 ------------ Accuracy: 57.5%\n",
            "Step: 3986 ------------ Loss: 8900.63 ------------ Accuracy: 57.5%\n",
            "Step: 3987 ------------ Loss: 8900.3 ------------ Accuracy: 57.6%\n",
            "Step: 3988 ------------ Loss: 8900.28 ------------ Accuracy: 57.5%\n",
            "Step: 3989 ------------ Loss: 8900.25 ------------ Accuracy: 57.5%\n",
            "Step: 3990 ------------ Loss: 8900.24 ------------ Accuracy: 57.5%\n",
            "Step: 3991 ------------ Loss: 8900.13 ------------ Accuracy: 57.5%\n",
            "Step: 3992 ------------ Loss: 8900.08 ------------ Accuracy: 57.5%\n",
            "Step: 3993 ------------ Loss: 8900.04 ------------ Accuracy: 57.5%\n",
            "Step: 3994 ------------ Loss: 8900.03 ------------ Accuracy: 57.5%\n",
            "Step: 3995 ------------ Loss: 8899.73 ------------ Accuracy: 57.6%\n",
            "Step: 3996 ------------ Loss: 8899.43 ------------ Accuracy: 57.6%\n",
            "Step: 3997 ------------ Loss: 8898.48 ------------ Accuracy: 57.5%\n",
            "Step: 3998 ------------ Loss: 8898.27 ------------ Accuracy: 57.4%\n",
            "Step: 3999 ------------ Loss: 8898.26 ------------ Accuracy: 57.4%\n",
            "Step: 4000 ------------ Loss: 8898.01 ------------ Accuracy: 57.4%\n",
            "Step: 4001 ------------ Loss: 8897.98 ------------ Accuracy: 57.4%\n",
            "Step: 4002 ------------ Loss: 8897.97 ------------ Accuracy: 57.4%\n",
            "Step: 4003 ------------ Loss: 8897.93 ------------ Accuracy: 57.4%\n",
            "Step: 4004 ------------ Loss: 8897.9 ------------ Accuracy: 57.4%\n",
            "Step: 4005 ------------ Loss: 8897.89 ------------ Accuracy: 57.4%\n",
            "Step: 4006 ------------ Loss: 8897.64 ------------ Accuracy: 57.4%\n",
            "Step: 4007 ------------ Loss: 8897.18 ------------ Accuracy: 57.4%\n",
            "Step: 4008 ------------ Loss: 8897.17 ------------ Accuracy: 57.4%\n",
            "Step: 4009 ------------ Loss: 8897.15 ------------ Accuracy: 57.4%\n",
            "Step: 4010 ------------ Loss: 8897.12 ------------ Accuracy: 57.4%\n",
            "Step: 4011 ------------ Loss: 8897.08 ------------ Accuracy: 57.5%\n",
            "Step: 4012 ------------ Loss: 8897.0 ------------ Accuracy: 57.5%\n",
            "Step: 4013 ------------ Loss: 8896.94 ------------ Accuracy: 57.5%\n",
            "Step: 4014 ------------ Loss: 8896.83 ------------ Accuracy: 57.5%\n",
            "Step: 4015 ------------ Loss: 8896.44 ------------ Accuracy: 57.5%\n",
            "Step: 4016 ------------ Loss: 8896.23 ------------ Accuracy: 57.5%\n",
            "Step: 4017 ------------ Loss: 8895.3 ------------ Accuracy: 57.5%\n",
            "Step: 4018 ------------ Loss: 8895.29 ------------ Accuracy: 57.5%\n",
            "Step: 4019 ------------ Loss: 8895.05 ------------ Accuracy: 57.5%\n",
            "Step: 4020 ------------ Loss: 8894.81 ------------ Accuracy: 57.7%\n",
            "Step: 4021 ------------ Loss: 8894.74 ------------ Accuracy: 57.5%\n",
            "Step: 4022 ------------ Loss: 8894.73 ------------ Accuracy: 57.5%\n",
            "Step: 4023 ------------ Loss: 8894.62 ------------ Accuracy: 57.5%\n",
            "Step: 4024 ------------ Loss: 8894.52 ------------ Accuracy: 57.7%\n",
            "Step: 4025 ------------ Loss: 8894.19 ------------ Accuracy: 57.5%\n",
            "Step: 4026 ------------ Loss: 8894.16 ------------ Accuracy: 57.5%\n",
            "Step: 4027 ------------ Loss: 8894.15 ------------ Accuracy: 57.5%\n",
            "Step: 4028 ------------ Loss: 8894.08 ------------ Accuracy: 57.5%\n",
            "Step: 4029 ------------ Loss: 8893.86 ------------ Accuracy: 57.5%\n",
            "Step: 4030 ------------ Loss: 8893.85 ------------ Accuracy: 57.5%\n",
            "Step: 4031 ------------ Loss: 8892.93 ------------ Accuracy: 57.7%\n",
            "Step: 4032 ------------ Loss: 8891.22 ------------ Accuracy: 57.7%\n",
            "Step: 4033 ------------ Loss: 8891.11 ------------ Accuracy: 57.7%\n",
            "Step: 4034 ------------ Loss: 8891.11 ------------ Accuracy: 57.7%\n",
            "Step: 4035 ------------ Loss: 8891.08 ------------ Accuracy: 57.7%\n",
            "Step: 4036 ------------ Loss: 8891.02 ------------ Accuracy: 57.7%\n",
            "Step: 4037 ------------ Loss: 8891.01 ------------ Accuracy: 57.7%\n",
            "Step: 4038 ------------ Loss: 8891.0 ------------ Accuracy: 57.7%\n",
            "Step: 4039 ------------ Loss: 8890.98 ------------ Accuracy: 57.5%\n",
            "Step: 4040 ------------ Loss: 8890.81 ------------ Accuracy: 57.4%\n",
            "Step: 4041 ------------ Loss: 8890.56 ------------ Accuracy: 57.4%\n",
            "Step: 4042 ------------ Loss: 8890.32 ------------ Accuracy: 57.4%\n",
            "Step: 4043 ------------ Loss: 8890.3 ------------ Accuracy: 57.4%\n",
            "Step: 4044 ------------ Loss: 8890.11 ------------ Accuracy: 57.4%\n",
            "Step: 4045 ------------ Loss: 8890.08 ------------ Accuracy: 57.4%\n",
            "Step: 4046 ------------ Loss: 8890.07 ------------ Accuracy: 57.4%\n",
            "Step: 4047 ------------ Loss: 8889.96 ------------ Accuracy: 57.4%\n",
            "Step: 4048 ------------ Loss: 8889.95 ------------ Accuracy: 57.4%\n",
            "Step: 4049 ------------ Loss: 8889.89 ------------ Accuracy: 57.4%\n",
            "Step: 4050 ------------ Loss: 8889.44 ------------ Accuracy: 57.4%\n",
            "Step: 4051 ------------ Loss: 8889.44 ------------ Accuracy: 57.4%\n",
            "Step: 4052 ------------ Loss: 8889.38 ------------ Accuracy: 57.4%\n",
            "Step: 4053 ------------ Loss: 8889.36 ------------ Accuracy: 57.4%\n",
            "Step: 4054 ------------ Loss: 8889.36 ------------ Accuracy: 57.4%\n",
            "Step: 4055 ------------ Loss: 8889.17 ------------ Accuracy: 57.4%\n",
            "Step: 4056 ------------ Loss: 8887.6 ------------ Accuracy: 57.5%\n",
            "Step: 4057 ------------ Loss: 8887.59 ------------ Accuracy: 57.5%\n",
            "Step: 4058 ------------ Loss: 8887.58 ------------ Accuracy: 57.5%\n",
            "Step: 4059 ------------ Loss: 8887.57 ------------ Accuracy: 57.5%\n",
            "Step: 4060 ------------ Loss: 8887.56 ------------ Accuracy: 57.5%\n",
            "Step: 4061 ------------ Loss: 8887.56 ------------ Accuracy: 57.5%\n",
            "Step: 4062 ------------ Loss: 8887.56 ------------ Accuracy: 57.5%\n",
            "Step: 4063 ------------ Loss: 8887.5 ------------ Accuracy: 57.5%\n",
            "Step: 4064 ------------ Loss: 8887.44 ------------ Accuracy: 57.4%\n",
            "Step: 4065 ------------ Loss: 8887.43 ------------ Accuracy: 57.6%\n",
            "Step: 4066 ------------ Loss: 8887.43 ------------ Accuracy: 57.4%\n",
            "Step: 4067 ------------ Loss: 8887.32 ------------ Accuracy: 57.4%\n",
            "Step: 4068 ------------ Loss: 8887.19 ------------ Accuracy: 57.5%\n",
            "Step: 4069 ------------ Loss: 8886.75 ------------ Accuracy: 57.5%\n",
            "Step: 4070 ------------ Loss: 8886.73 ------------ Accuracy: 57.5%\n",
            "Step: 4071 ------------ Loss: 8886.62 ------------ Accuracy: 57.5%\n",
            "Step: 4072 ------------ Loss: 8886.61 ------------ Accuracy: 57.5%\n",
            "Step: 4073 ------------ Loss: 8886.53 ------------ Accuracy: 57.5%\n",
            "Step: 4074 ------------ Loss: 8886.47 ------------ Accuracy: 57.4%\n",
            "Step: 4075 ------------ Loss: 8886.28 ------------ Accuracy: 57.5%\n",
            "Step: 4076 ------------ Loss: 8886.25 ------------ Accuracy: 57.4%\n",
            "Step: 4077 ------------ Loss: 8886.23 ------------ Accuracy: 57.4%\n",
            "Step: 4078 ------------ Loss: 8886.15 ------------ Accuracy: 57.4%\n",
            "Step: 4079 ------------ Loss: 8886.15 ------------ Accuracy: 57.4%\n",
            "Step: 4080 ------------ Loss: 8886.12 ------------ Accuracy: 57.4%\n",
            "Step: 4081 ------------ Loss: 8886.12 ------------ Accuracy: 57.4%\n",
            "Step: 4082 ------------ Loss: 8886.06 ------------ Accuracy: 57.4%\n",
            "Step: 4083 ------------ Loss: 8885.88 ------------ Accuracy: 57.5%\n",
            "Step: 4084 ------------ Loss: 8885.76 ------------ Accuracy: 57.5%\n",
            "Step: 4085 ------------ Loss: 8885.76 ------------ Accuracy: 57.5%\n",
            "Step: 4086 ------------ Loss: 8885.68 ------------ Accuracy: 57.5%\n",
            "Step: 4087 ------------ Loss: 8885.68 ------------ Accuracy: 57.5%\n",
            "Step: 4088 ------------ Loss: 8885.59 ------------ Accuracy: 57.5%\n",
            "Step: 4089 ------------ Loss: 8885.48 ------------ Accuracy: 57.5%\n",
            "Step: 4090 ------------ Loss: 8885.4 ------------ Accuracy: 57.5%\n",
            "Step: 4091 ------------ Loss: 8884.63 ------------ Accuracy: 57.7%\n",
            "Step: 4092 ------------ Loss: 8884.57 ------------ Accuracy: 57.7%\n",
            "Step: 4093 ------------ Loss: 8884.51 ------------ Accuracy: 57.6%\n",
            "Step: 4094 ------------ Loss: 8884.4 ------------ Accuracy: 57.5%\n",
            "Step: 4095 ------------ Loss: 8884.34 ------------ Accuracy: 57.6%\n",
            "Step: 4096 ------------ Loss: 8884.33 ------------ Accuracy: 57.6%\n",
            "Step: 4097 ------------ Loss: 8884.32 ------------ Accuracy: 57.6%\n",
            "Step: 4098 ------------ Loss: 8884.31 ------------ Accuracy: 57.4%\n",
            "Step: 4099 ------------ Loss: 8884.3 ------------ Accuracy: 57.6%\n",
            "Step: 4100 ------------ Loss: 8884.19 ------------ Accuracy: 57.6%\n",
            "Step: 4101 ------------ Loss: 8884.09 ------------ Accuracy: 57.4%\n",
            "Step: 4102 ------------ Loss: 8884.08 ------------ Accuracy: 57.4%\n",
            "Step: 4103 ------------ Loss: 8884.08 ------------ Accuracy: 57.5%\n",
            "Step: 4104 ------------ Loss: 8884.02 ------------ Accuracy: 57.4%\n",
            "Step: 4105 ------------ Loss: 8882.5 ------------ Accuracy: 57.3%\n",
            "Step: 4106 ------------ Loss: 8882.44 ------------ Accuracy: 57.3%\n",
            "Step: 4107 ------------ Loss: 8882.43 ------------ Accuracy: 57.3%\n",
            "Step: 4108 ------------ Loss: 8881.71 ------------ Accuracy: 57.5%\n",
            "Step: 4109 ------------ Loss: 8881.63 ------------ Accuracy: 57.4%\n",
            "Step: 4110 ------------ Loss: 8881.57 ------------ Accuracy: 57.4%\n",
            "Step: 4111 ------------ Loss: 8881.56 ------------ Accuracy: 57.3%\n",
            "Step: 4112 ------------ Loss: 8880.11 ------------ Accuracy: 57.3%\n",
            "Step: 4113 ------------ Loss: 8879.27 ------------ Accuracy: 57.3%\n",
            "Step: 4114 ------------ Loss: 8879.21 ------------ Accuracy: 57.3%\n",
            "Step: 4115 ------------ Loss: 8879.12 ------------ Accuracy: 57.3%\n",
            "Step: 4116 ------------ Loss: 8879.11 ------------ Accuracy: 57.4%\n",
            "Step: 4117 ------------ Loss: 8878.68 ------------ Accuracy: 57.4%\n",
            "Step: 4118 ------------ Loss: 8878.67 ------------ Accuracy: 57.4%\n",
            "Step: 4119 ------------ Loss: 8877.21 ------------ Accuracy: 57.4%\n",
            "Step: 4120 ------------ Loss: 8877.21 ------------ Accuracy: 57.4%\n",
            "Step: 4121 ------------ Loss: 8877.13 ------------ Accuracy: 57.4%\n",
            "Step: 4122 ------------ Loss: 8876.38 ------------ Accuracy: 57.3%\n",
            "Step: 4123 ------------ Loss: 8876.38 ------------ Accuracy: 57.3%\n",
            "Step: 4124 ------------ Loss: 8875.67 ------------ Accuracy: 57.3%\n",
            "Step: 4125 ------------ Loss: 8875.26 ------------ Accuracy: 57.3%\n",
            "Step: 4126 ------------ Loss: 8875.24 ------------ Accuracy: 57.3%\n",
            "Step: 4127 ------------ Loss: 8875.06 ------------ Accuracy: 57.3%\n",
            "Step: 4128 ------------ Loss: 8875.05 ------------ Accuracy: 57.3%\n",
            "Step: 4129 ------------ Loss: 8875.04 ------------ Accuracy: 57.3%\n",
            "Step: 4130 ------------ Loss: 8875.02 ------------ Accuracy: 57.3%\n",
            "Step: 4131 ------------ Loss: 8874.91 ------------ Accuracy: 57.3%\n",
            "Step: 4132 ------------ Loss: 8874.8 ------------ Accuracy: 57.3%\n",
            "Step: 4133 ------------ Loss: 8874.69 ------------ Accuracy: 57.3%\n",
            "Step: 4134 ------------ Loss: 8874.68 ------------ Accuracy: 57.3%\n",
            "Step: 4135 ------------ Loss: 8874.66 ------------ Accuracy: 57.3%\n",
            "Step: 4136 ------------ Loss: 8874.6 ------------ Accuracy: 57.3%\n",
            "Step: 4137 ------------ Loss: 8874.6 ------------ Accuracy: 57.3%\n",
            "Step: 4138 ------------ Loss: 8874.51 ------------ Accuracy: 57.3%\n",
            "Step: 4139 ------------ Loss: 8874.5 ------------ Accuracy: 57.3%\n",
            "Step: 4140 ------------ Loss: 8874.48 ------------ Accuracy: 57.3%\n",
            "Step: 4141 ------------ Loss: 8874.4 ------------ Accuracy: 57.3%\n",
            "Step: 4142 ------------ Loss: 8874.29 ------------ Accuracy: 57.3%\n",
            "Step: 4143 ------------ Loss: 8874.04 ------------ Accuracy: 57.3%\n",
            "Step: 4144 ------------ Loss: 8873.35 ------------ Accuracy: 57.3%\n",
            "Step: 4145 ------------ Loss: 8872.7 ------------ Accuracy: 57.5%\n",
            "Step: 4146 ------------ Loss: 8871.29 ------------ Accuracy: 57.5%\n",
            "Step: 4147 ------------ Loss: 8871.28 ------------ Accuracy: 57.5%\n",
            "Step: 4148 ------------ Loss: 8869.93 ------------ Accuracy: 57.5%\n",
            "Step: 4149 ------------ Loss: 8869.75 ------------ Accuracy: 57.3%\n",
            "Step: 4150 ------------ Loss: 8869.7 ------------ Accuracy: 57.5%\n",
            "Step: 4151 ------------ Loss: 8869.43 ------------ Accuracy: 57.5%\n",
            "Step: 4152 ------------ Loss: 8868.82 ------------ Accuracy: 57.5%\n",
            "Step: 4153 ------------ Loss: 8868.25 ------------ Accuracy: 57.5%\n",
            "Step: 4154 ------------ Loss: 8867.7 ------------ Accuracy: 57.5%\n",
            "Step: 4155 ------------ Loss: 8867.65 ------------ Accuracy: 57.5%\n",
            "Step: 4156 ------------ Loss: 8867.56 ------------ Accuracy: 57.5%\n",
            "Step: 4157 ------------ Loss: 8867.49 ------------ Accuracy: 57.5%\n",
            "Step: 4158 ------------ Loss: 8867.46 ------------ Accuracy: 57.5%\n",
            "Step: 4159 ------------ Loss: 8867.43 ------------ Accuracy: 57.5%\n",
            "Step: 4160 ------------ Loss: 8867.41 ------------ Accuracy: 57.3%\n",
            "Step: 4161 ------------ Loss: 8867.4 ------------ Accuracy: 57.3%\n",
            "Step: 4162 ------------ Loss: 8867.39 ------------ Accuracy: 57.3%\n",
            "Step: 4163 ------------ Loss: 8866.84 ------------ Accuracy: 57.5%\n",
            "Step: 4164 ------------ Loss: 8866.78 ------------ Accuracy: 57.3%\n",
            "Step: 4165 ------------ Loss: 8866.25 ------------ Accuracy: 57.5%\n",
            "Step: 4166 ------------ Loss: 8866.08 ------------ Accuracy: 57.5%\n",
            "Step: 4167 ------------ Loss: 8865.94 ------------ Accuracy: 57.5%\n",
            "Step: 4168 ------------ Loss: 8865.91 ------------ Accuracy: 57.5%\n",
            "Step: 4169 ------------ Loss: 8865.88 ------------ Accuracy: 57.5%\n",
            "Step: 4170 ------------ Loss: 8865.88 ------------ Accuracy: 57.5%\n",
            "Step: 4171 ------------ Loss: 8865.77 ------------ Accuracy: 57.5%\n",
            "Step: 4172 ------------ Loss: 8865.72 ------------ Accuracy: 57.5%\n",
            "Step: 4173 ------------ Loss: 8865.31 ------------ Accuracy: 57.5%\n",
            "Step: 4174 ------------ Loss: 8865.21 ------------ Accuracy: 57.5%\n",
            "Step: 4175 ------------ Loss: 8865.2 ------------ Accuracy: 57.5%\n",
            "Step: 4176 ------------ Loss: 8864.79 ------------ Accuracy: 57.5%\n",
            "Step: 4177 ------------ Loss: 8864.53 ------------ Accuracy: 57.5%\n",
            "Step: 4178 ------------ Loss: 8864.45 ------------ Accuracy: 57.5%\n",
            "Step: 4179 ------------ Loss: 8864.39 ------------ Accuracy: 57.5%\n",
            "Step: 4180 ------------ Loss: 8864.38 ------------ Accuracy: 57.5%\n",
            "Step: 4181 ------------ Loss: 8864.37 ------------ Accuracy: 57.5%\n",
            "Step: 4182 ------------ Loss: 8864.25 ------------ Accuracy: 57.5%\n",
            "Step: 4183 ------------ Loss: 8864.24 ------------ Accuracy: 57.3%\n",
            "Step: 4184 ------------ Loss: 8864.22 ------------ Accuracy: 57.3%\n",
            "Step: 4185 ------------ Loss: 8864.14 ------------ Accuracy: 57.3%\n",
            "Step: 4186 ------------ Loss: 8863.22 ------------ Accuracy: 57.4%\n",
            "Step: 4187 ------------ Loss: 8863.21 ------------ Accuracy: 57.4%\n",
            "Step: 4188 ------------ Loss: 8863.2 ------------ Accuracy: 57.4%\n",
            "Step: 4189 ------------ Loss: 8863.19 ------------ Accuracy: 57.4%\n",
            "Step: 4190 ------------ Loss: 8863.18 ------------ Accuracy: 57.4%\n",
            "Step: 4191 ------------ Loss: 8862.75 ------------ Accuracy: 57.4%\n",
            "Step: 4192 ------------ Loss: 8862.74 ------------ Accuracy: 57.4%\n",
            "Step: 4193 ------------ Loss: 8862.63 ------------ Accuracy: 57.4%\n",
            "Step: 4194 ------------ Loss: 8862.62 ------------ Accuracy: 57.4%\n",
            "Step: 4195 ------------ Loss: 8862.53 ------------ Accuracy: 57.4%\n",
            "Step: 4196 ------------ Loss: 8862.42 ------------ Accuracy: 57.4%\n",
            "Step: 4197 ------------ Loss: 8862.37 ------------ Accuracy: 57.4%\n",
            "Step: 4198 ------------ Loss: 8862.33 ------------ Accuracy: 57.4%\n",
            "Step: 4199 ------------ Loss: 8862.32 ------------ Accuracy: 57.4%\n",
            "Step: 4200 ------------ Loss: 8862.31 ------------ Accuracy: 57.4%\n",
            "Step: 4201 ------------ Loss: 8862.25 ------------ Accuracy: 57.4%\n",
            "Step: 4202 ------------ Loss: 8862.13 ------------ Accuracy: 57.6%\n",
            "Step: 4203 ------------ Loss: 8861.7 ------------ Accuracy: 57.5%\n",
            "Step: 4204 ------------ Loss: 8861.69 ------------ Accuracy: 57.5%\n",
            "Step: 4205 ------------ Loss: 8861.59 ------------ Accuracy: 57.5%\n",
            "Step: 4206 ------------ Loss: 8861.58 ------------ Accuracy: 57.5%\n",
            "Step: 4207 ------------ Loss: 8861.39 ------------ Accuracy: 57.6%\n",
            "Step: 4208 ------------ Loss: 8861.38 ------------ Accuracy: 57.5%\n",
            "Step: 4209 ------------ Loss: 8861.38 ------------ Accuracy: 57.6%\n",
            "Step: 4210 ------------ Loss: 8861.37 ------------ Accuracy: 57.6%\n",
            "Step: 4211 ------------ Loss: 8861.36 ------------ Accuracy: 57.6%\n",
            "Step: 4212 ------------ Loss: 8861.25 ------------ Accuracy: 57.6%\n",
            "Step: 4213 ------------ Loss: 8861.14 ------------ Accuracy: 57.6%\n",
            "Step: 4214 ------------ Loss: 8861.13 ------------ Accuracy: 57.6%\n",
            "Step: 4215 ------------ Loss: 8859.71 ------------ Accuracy: 57.7%\n",
            "Step: 4216 ------------ Loss: 8859.3 ------------ Accuracy: 57.7%\n",
            "Step: 4217 ------------ Loss: 8859.28 ------------ Accuracy: 57.7%\n",
            "Step: 4218 ------------ Loss: 8859.27 ------------ Accuracy: 57.7%\n",
            "Step: 4219 ------------ Loss: 8859.26 ------------ Accuracy: 57.7%\n",
            "Step: 4220 ------------ Loss: 8859.18 ------------ Accuracy: 57.7%\n",
            "Step: 4221 ------------ Loss: 8859.12 ------------ Accuracy: 57.5%\n",
            "Step: 4222 ------------ Loss: 8858.93 ------------ Accuracy: 57.7%\n",
            "Step: 4223 ------------ Loss: 8858.88 ------------ Accuracy: 57.7%\n",
            "Step: 4224 ------------ Loss: 8858.2 ------------ Accuracy: 57.5%\n",
            "Step: 4225 ------------ Loss: 8858.09 ------------ Accuracy: 57.5%\n",
            "Step: 4226 ------------ Loss: 8857.93 ------------ Accuracy: 57.4%\n",
            "Step: 4227 ------------ Loss: 8857.92 ------------ Accuracy: 57.4%\n",
            "Step: 4228 ------------ Loss: 8857.92 ------------ Accuracy: 57.4%\n",
            "Step: 4229 ------------ Loss: 8857.88 ------------ Accuracy: 57.4%\n",
            "Step: 4230 ------------ Loss: 8856.44 ------------ Accuracy: 57.5%\n",
            "Step: 4231 ------------ Loss: 8855.72 ------------ Accuracy: 57.5%\n",
            "Step: 4232 ------------ Loss: 8855.72 ------------ Accuracy: 57.5%\n",
            "Step: 4233 ------------ Loss: 8855.71 ------------ Accuracy: 57.5%\n",
            "Step: 4234 ------------ Loss: 8855.71 ------------ Accuracy: 57.5%\n",
            "Step: 4235 ------------ Loss: 8855.52 ------------ Accuracy: 57.5%\n",
            "Step: 4236 ------------ Loss: 8855.51 ------------ Accuracy: 57.5%\n",
            "Step: 4237 ------------ Loss: 8855.33 ------------ Accuracy: 57.5%\n",
            "Step: 4238 ------------ Loss: 8855.21 ------------ Accuracy: 57.5%\n",
            "Step: 4239 ------------ Loss: 8855.15 ------------ Accuracy: 57.7%\n",
            "Step: 4240 ------------ Loss: 8855.14 ------------ Accuracy: 57.7%\n",
            "Step: 4241 ------------ Loss: 8855.06 ------------ Accuracy: 57.7%\n",
            "Step: 4242 ------------ Loss: 8855.05 ------------ Accuracy: 57.7%\n",
            "Step: 4243 ------------ Loss: 8854.64 ------------ Accuracy: 57.7%\n",
            "Step: 4244 ------------ Loss: 8854.63 ------------ Accuracy: 57.7%\n",
            "Step: 4245 ------------ Loss: 8854.52 ------------ Accuracy: 57.7%\n",
            "Step: 4246 ------------ Loss: 8854.42 ------------ Accuracy: 57.7%\n",
            "Step: 4247 ------------ Loss: 8854.01 ------------ Accuracy: 57.7%\n",
            "Step: 4248 ------------ Loss: 8854.0 ------------ Accuracy: 57.7%\n",
            "Step: 4249 ------------ Loss: 8852.65 ------------ Accuracy: 57.5%\n",
            "Step: 4250 ------------ Loss: 8851.35 ------------ Accuracy: 57.5%\n",
            "Step: 4251 ------------ Loss: 8851.1 ------------ Accuracy: 57.5%\n",
            "Step: 4252 ------------ Loss: 8851.08 ------------ Accuracy: 57.5%\n",
            "Step: 4253 ------------ Loss: 8850.97 ------------ Accuracy: 57.5%\n",
            "Step: 4254 ------------ Loss: 8850.31 ------------ Accuracy: 57.5%\n",
            "Step: 4255 ------------ Loss: 8850.3 ------------ Accuracy: 57.5%\n",
            "Step: 4256 ------------ Loss: 8849.68 ------------ Accuracy: 57.6%\n",
            "Step: 4257 ------------ Loss: 8848.76 ------------ Accuracy: 57.5%\n",
            "Step: 4258 ------------ Loss: 8848.35 ------------ Accuracy: 57.5%\n",
            "Step: 4259 ------------ Loss: 8847.95 ------------ Accuracy: 57.5%\n",
            "Step: 4260 ------------ Loss: 8847.85 ------------ Accuracy: 57.5%\n",
            "Step: 4261 ------------ Loss: 8847.74 ------------ Accuracy: 57.5%\n",
            "Step: 4262 ------------ Loss: 8847.68 ------------ Accuracy: 57.5%\n",
            "Step: 4263 ------------ Loss: 8847.03 ------------ Accuracy: 57.5%\n",
            "Step: 4264 ------------ Loss: 8846.79 ------------ Accuracy: 57.5%\n",
            "Step: 4265 ------------ Loss: 8846.74 ------------ Accuracy: 57.5%\n",
            "Step: 4266 ------------ Loss: 8846.67 ------------ Accuracy: 57.5%\n",
            "Step: 4267 ------------ Loss: 8846.66 ------------ Accuracy: 57.5%\n",
            "Step: 4268 ------------ Loss: 8846.19 ------------ Accuracy: 57.6%\n",
            "Step: 4269 ------------ Loss: 8846.17 ------------ Accuracy: 57.6%\n",
            "Step: 4270 ------------ Loss: 8845.73 ------------ Accuracy: 57.6%\n",
            "Step: 4271 ------------ Loss: 8845.53 ------------ Accuracy: 57.6%\n",
            "Step: 4272 ------------ Loss: 8844.1 ------------ Accuracy: 57.7%\n",
            "Step: 4273 ------------ Loss: 8844.05 ------------ Accuracy: 57.7%\n",
            "Step: 4274 ------------ Loss: 8843.84 ------------ Accuracy: 57.6%\n",
            "Step: 4275 ------------ Loss: 8843.09 ------------ Accuracy: 57.5%\n",
            "Step: 4276 ------------ Loss: 8843.07 ------------ Accuracy: 57.5%\n",
            "Step: 4277 ------------ Loss: 8842.89 ------------ Accuracy: 57.5%\n",
            "Step: 4278 ------------ Loss: 8842.18 ------------ Accuracy: 57.5%\n",
            "Step: 4279 ------------ Loss: 8842.0 ------------ Accuracy: 57.5%\n",
            "Step: 4280 ------------ Loss: 8842.0 ------------ Accuracy: 57.5%\n",
            "Step: 4281 ------------ Loss: 8841.93 ------------ Accuracy: 57.5%\n",
            "Step: 4282 ------------ Loss: 8841.93 ------------ Accuracy: 57.5%\n",
            "Step: 4283 ------------ Loss: 8841.85 ------------ Accuracy: 57.5%\n",
            "Step: 4284 ------------ Loss: 8841.84 ------------ Accuracy: 57.5%\n",
            "Step: 4285 ------------ Loss: 8841.66 ------------ Accuracy: 57.5%\n",
            "Step: 4286 ------------ Loss: 8841.26 ------------ Accuracy: 57.5%\n",
            "Step: 4287 ------------ Loss: 8841.17 ------------ Accuracy: 57.5%\n",
            "Step: 4288 ------------ Loss: 8841.16 ------------ Accuracy: 57.5%\n",
            "Step: 4289 ------------ Loss: 8841.15 ------------ Accuracy: 57.5%\n",
            "Step: 4290 ------------ Loss: 8841.14 ------------ Accuracy: 57.5%\n",
            "Step: 4291 ------------ Loss: 8841.03 ------------ Accuracy: 57.5%\n",
            "Step: 4292 ------------ Loss: 8840.97 ------------ Accuracy: 57.5%\n",
            "Step: 4293 ------------ Loss: 8840.85 ------------ Accuracy: 57.5%\n",
            "Step: 4294 ------------ Loss: 8840.19 ------------ Accuracy: 57.6%\n",
            "Step: 4295 ------------ Loss: 8839.72 ------------ Accuracy: 57.6%\n",
            "Step: 4296 ------------ Loss: 8839.52 ------------ Accuracy: 57.5%\n",
            "Step: 4297 ------------ Loss: 8839.5 ------------ Accuracy: 57.5%\n",
            "Step: 4298 ------------ Loss: 8839.5 ------------ Accuracy: 57.5%\n",
            "Step: 4299 ------------ Loss: 8839.38 ------------ Accuracy: 57.5%\n",
            "Step: 4300 ------------ Loss: 8838.96 ------------ Accuracy: 57.5%\n",
            "Step: 4301 ------------ Loss: 8838.76 ------------ Accuracy: 57.5%\n",
            "Step: 4302 ------------ Loss: 8838.75 ------------ Accuracy: 57.5%\n",
            "Step: 4303 ------------ Loss: 8838.73 ------------ Accuracy: 57.6%\n",
            "Step: 4304 ------------ Loss: 8838.62 ------------ Accuracy: 57.6%\n",
            "Step: 4305 ------------ Loss: 8838.43 ------------ Accuracy: 57.6%\n",
            "Step: 4306 ------------ Loss: 8838.42 ------------ Accuracy: 57.6%\n",
            "Step: 4307 ------------ Loss: 8838.34 ------------ Accuracy: 57.6%\n",
            "Step: 4308 ------------ Loss: 8838.33 ------------ Accuracy: 57.6%\n",
            "Step: 4309 ------------ Loss: 8838.14 ------------ Accuracy: 57.6%\n",
            "Step: 4310 ------------ Loss: 8838.05 ------------ Accuracy: 57.6%\n",
            "Step: 4311 ------------ Loss: 8838.03 ------------ Accuracy: 57.6%\n",
            "Step: 4312 ------------ Loss: 8838.02 ------------ Accuracy: 57.6%\n",
            "Step: 4313 ------------ Loss: 8838.01 ------------ Accuracy: 57.6%\n",
            "Step: 4314 ------------ Loss: 8837.6 ------------ Accuracy: 57.6%\n",
            "Step: 4315 ------------ Loss: 8837.58 ------------ Accuracy: 57.6%\n",
            "Step: 4316 ------------ Loss: 8836.84 ------------ Accuracy: 57.6%\n",
            "Step: 4317 ------------ Loss: 8836.83 ------------ Accuracy: 57.6%\n",
            "Step: 4318 ------------ Loss: 8836.83 ------------ Accuracy: 57.6%\n",
            "Step: 4319 ------------ Loss: 8835.46 ------------ Accuracy: 57.5%\n",
            "Step: 4320 ------------ Loss: 8835.35 ------------ Accuracy: 57.5%\n",
            "Step: 4321 ------------ Loss: 8835.29 ------------ Accuracy: 57.5%\n",
            "Step: 4322 ------------ Loss: 8835.28 ------------ Accuracy: 57.5%\n",
            "Step: 4323 ------------ Loss: 8835.16 ------------ Accuracy: 57.5%\n",
            "Step: 4324 ------------ Loss: 8835.06 ------------ Accuracy: 57.4%\n",
            "Step: 4325 ------------ Loss: 8835.05 ------------ Accuracy: 57.5%\n",
            "Step: 4326 ------------ Loss: 8834.65 ------------ Accuracy: 57.5%\n",
            "Step: 4327 ------------ Loss: 8834.57 ------------ Accuracy: 57.3%\n",
            "Step: 4328 ------------ Loss: 8834.5 ------------ Accuracy: 57.5%\n",
            "Step: 4329 ------------ Loss: 8834.49 ------------ Accuracy: 57.5%\n",
            "Step: 4330 ------------ Loss: 8834.32 ------------ Accuracy: 57.5%\n",
            "Step: 4331 ------------ Loss: 8833.92 ------------ Accuracy: 57.5%\n",
            "Step: 4332 ------------ Loss: 8833.86 ------------ Accuracy: 57.5%\n",
            "Step: 4333 ------------ Loss: 8833.85 ------------ Accuracy: 57.5%\n",
            "Step: 4334 ------------ Loss: 8833.83 ------------ Accuracy: 57.5%\n",
            "Step: 4335 ------------ Loss: 8833.82 ------------ Accuracy: 57.5%\n",
            "Step: 4336 ------------ Loss: 8833.74 ------------ Accuracy: 57.3%\n",
            "Step: 4337 ------------ Loss: 8833.04 ------------ Accuracy: 57.5%\n",
            "Step: 4338 ------------ Loss: 8832.97 ------------ Accuracy: 57.5%\n",
            "Step: 4339 ------------ Loss: 8832.97 ------------ Accuracy: 57.5%\n",
            "Step: 4340 ------------ Loss: 8832.47 ------------ Accuracy: 57.7%\n",
            "Step: 4341 ------------ Loss: 8832.44 ------------ Accuracy: 57.8%\n",
            "Step: 4342 ------------ Loss: 8832.28 ------------ Accuracy: 57.7%\n",
            "Step: 4343 ------------ Loss: 8831.86 ------------ Accuracy: 57.7%\n",
            "Step: 4344 ------------ Loss: 8831.86 ------------ Accuracy: 57.7%\n",
            "Step: 4345 ------------ Loss: 8831.84 ------------ Accuracy: 57.7%\n",
            "Step: 4346 ------------ Loss: 8831.39 ------------ Accuracy: 57.9%\n",
            "Step: 4347 ------------ Loss: 8829.94 ------------ Accuracy: 57.8%\n",
            "Step: 4348 ------------ Loss: 8829.76 ------------ Accuracy: 57.8%\n",
            "Step: 4349 ------------ Loss: 8829.75 ------------ Accuracy: 57.8%\n",
            "Step: 4350 ------------ Loss: 8829.74 ------------ Accuracy: 57.8%\n",
            "Step: 4351 ------------ Loss: 8829.7 ------------ Accuracy: 57.8%\n",
            "Step: 4352 ------------ Loss: 8829.69 ------------ Accuracy: 57.8%\n",
            "Step: 4353 ------------ Loss: 8828.32 ------------ Accuracy: 57.6%\n",
            "Step: 4354 ------------ Loss: 8828.29 ------------ Accuracy: 57.6%\n",
            "Step: 4355 ------------ Loss: 8828.28 ------------ Accuracy: 57.6%\n",
            "Step: 4356 ------------ Loss: 8828.23 ------------ Accuracy: 57.6%\n",
            "Step: 4357 ------------ Loss: 8828.22 ------------ Accuracy: 57.6%\n",
            "Step: 4358 ------------ Loss: 8828.2 ------------ Accuracy: 57.6%\n",
            "Step: 4359 ------------ Loss: 8828.19 ------------ Accuracy: 57.6%\n",
            "Step: 4360 ------------ Loss: 8828.19 ------------ Accuracy: 57.6%\n",
            "Step: 4361 ------------ Loss: 8828.1 ------------ Accuracy: 57.6%\n",
            "Step: 4362 ------------ Loss: 8828.09 ------------ Accuracy: 57.6%\n",
            "Step: 4363 ------------ Loss: 8827.99 ------------ Accuracy: 57.6%\n",
            "Step: 4364 ------------ Loss: 8827.9 ------------ Accuracy: 57.6%\n",
            "Step: 4365 ------------ Loss: 8827.89 ------------ Accuracy: 57.6%\n",
            "Step: 4366 ------------ Loss: 8827.49 ------------ Accuracy: 57.6%\n",
            "Step: 4367 ------------ Loss: 8827.01 ------------ Accuracy: 57.9%\n",
            "Step: 4368 ------------ Loss: 8827.0 ------------ Accuracy: 57.9%\n",
            "Step: 4369 ------------ Loss: 8826.98 ------------ Accuracy: 57.9%\n",
            "Step: 4370 ------------ Loss: 8826.9 ------------ Accuracy: 57.9%\n",
            "Step: 4371 ------------ Loss: 8826.49 ------------ Accuracy: 57.9%\n",
            "Step: 4372 ------------ Loss: 8826.47 ------------ Accuracy: 57.8%\n",
            "Step: 4373 ------------ Loss: 8826.28 ------------ Accuracy: 57.6%\n",
            "Step: 4374 ------------ Loss: 8826.23 ------------ Accuracy: 57.8%\n",
            "Step: 4375 ------------ Loss: 8826.22 ------------ Accuracy: 57.6%\n",
            "Step: 4376 ------------ Loss: 8825.81 ------------ Accuracy: 57.6%\n",
            "Step: 4377 ------------ Loss: 8825.8 ------------ Accuracy: 57.6%\n",
            "Step: 4378 ------------ Loss: 8825.79 ------------ Accuracy: 57.6%\n",
            "Step: 4379 ------------ Loss: 8825.77 ------------ Accuracy: 57.6%\n",
            "Step: 4380 ------------ Loss: 8825.76 ------------ Accuracy: 57.6%\n",
            "Step: 4381 ------------ Loss: 8825.75 ------------ Accuracy: 57.6%\n",
            "Step: 4382 ------------ Loss: 8825.73 ------------ Accuracy: 57.6%\n",
            "Step: 4383 ------------ Loss: 8825.73 ------------ Accuracy: 57.6%\n",
            "Step: 4384 ------------ Loss: 8825.72 ------------ Accuracy: 57.6%\n",
            "Step: 4385 ------------ Loss: 8825.68 ------------ Accuracy: 57.8%\n",
            "Step: 4386 ------------ Loss: 8825.67 ------------ Accuracy: 57.6%\n",
            "Step: 4387 ------------ Loss: 8825.43 ------------ Accuracy: 57.6%\n",
            "Step: 4388 ------------ Loss: 8825.32 ------------ Accuracy: 57.6%\n",
            "Step: 4389 ------------ Loss: 8825.31 ------------ Accuracy: 57.6%\n",
            "Step: 4390 ------------ Loss: 8825.3 ------------ Accuracy: 57.6%\n",
            "Step: 4391 ------------ Loss: 8824.55 ------------ Accuracy: 57.7%\n",
            "Step: 4392 ------------ Loss: 8824.38 ------------ Accuracy: 57.7%\n",
            "Step: 4393 ------------ Loss: 8824.32 ------------ Accuracy: 57.7%\n",
            "Step: 4394 ------------ Loss: 8824.28 ------------ Accuracy: 57.7%\n",
            "Step: 4395 ------------ Loss: 8824.11 ------------ Accuracy: 57.7%\n",
            "Step: 4396 ------------ Loss: 8824.04 ------------ Accuracy: 57.7%\n",
            "Step: 4397 ------------ Loss: 8823.94 ------------ Accuracy: 57.7%\n",
            "Step: 4398 ------------ Loss: 8823.85 ------------ Accuracy: 57.7%\n",
            "Step: 4399 ------------ Loss: 8823.14 ------------ Accuracy: 57.6%\n",
            "Step: 4400 ------------ Loss: 8823.03 ------------ Accuracy: 57.6%\n",
            "Step: 4401 ------------ Loss: 8823.02 ------------ Accuracy: 57.6%\n",
            "Step: 4402 ------------ Loss: 8823.01 ------------ Accuracy: 57.6%\n",
            "Step: 4403 ------------ Loss: 8822.84 ------------ Accuracy: 57.6%\n",
            "Step: 4404 ------------ Loss: 8822.83 ------------ Accuracy: 57.6%\n",
            "Step: 4405 ------------ Loss: 8822.72 ------------ Accuracy: 57.6%\n",
            "Step: 4406 ------------ Loss: 8821.41 ------------ Accuracy: 57.6%\n",
            "Step: 4407 ------------ Loss: 8821.16 ------------ Accuracy: 57.6%\n",
            "Step: 4408 ------------ Loss: 8821.07 ------------ Accuracy: 57.6%\n",
            "Step: 4409 ------------ Loss: 8821.07 ------------ Accuracy: 57.6%\n",
            "Step: 4410 ------------ Loss: 8820.91 ------------ Accuracy: 57.5%\n",
            "Step: 4411 ------------ Loss: 8820.9 ------------ Accuracy: 57.6%\n",
            "Step: 4412 ------------ Loss: 8820.83 ------------ Accuracy: 57.6%\n",
            "Step: 4413 ------------ Loss: 8820.82 ------------ Accuracy: 57.6%\n",
            "Step: 4414 ------------ Loss: 8820.81 ------------ Accuracy: 57.6%\n",
            "Step: 4415 ------------ Loss: 8820.79 ------------ Accuracy: 57.6%\n",
            "Step: 4416 ------------ Loss: 8820.79 ------------ Accuracy: 57.6%\n",
            "Step: 4417 ------------ Loss: 8820.16 ------------ Accuracy: 57.6%\n",
            "Step: 4418 ------------ Loss: 8820.1 ------------ Accuracy: 57.5%\n",
            "Step: 4419 ------------ Loss: 8820.09 ------------ Accuracy: 57.5%\n",
            "Step: 4420 ------------ Loss: 8820.07 ------------ Accuracy: 57.6%\n",
            "Step: 4421 ------------ Loss: 8820.06 ------------ Accuracy: 57.6%\n",
            "Step: 4422 ------------ Loss: 8820.05 ------------ Accuracy: 57.6%\n",
            "Step: 4423 ------------ Loss: 8820.03 ------------ Accuracy: 57.6%\n",
            "Step: 4424 ------------ Loss: 8820.02 ------------ Accuracy: 57.6%\n",
            "Step: 4425 ------------ Loss: 8819.86 ------------ Accuracy: 57.6%\n",
            "Step: 4426 ------------ Loss: 8819.85 ------------ Accuracy: 57.6%\n",
            "Step: 4427 ------------ Loss: 8819.85 ------------ Accuracy: 57.6%\n",
            "Step: 4428 ------------ Loss: 8819.77 ------------ Accuracy: 57.6%\n",
            "Step: 4429 ------------ Loss: 8818.5 ------------ Accuracy: 57.6%\n",
            "Step: 4430 ------------ Loss: 8818.49 ------------ Accuracy: 57.6%\n",
            "Step: 4431 ------------ Loss: 8818.33 ------------ Accuracy: 57.6%\n",
            "Step: 4432 ------------ Loss: 8818.25 ------------ Accuracy: 57.6%\n",
            "Step: 4433 ------------ Loss: 8817.65 ------------ Accuracy: 57.6%\n",
            "Step: 4434 ------------ Loss: 8817.64 ------------ Accuracy: 57.6%\n",
            "Step: 4435 ------------ Loss: 8816.8 ------------ Accuracy: 57.6%\n",
            "Step: 4436 ------------ Loss: 8816.79 ------------ Accuracy: 57.5%\n",
            "Step: 4437 ------------ Loss: 8816.7 ------------ Accuracy: 57.5%\n",
            "Step: 4438 ------------ Loss: 8816.06 ------------ Accuracy: 57.9%\n",
            "Step: 4439 ------------ Loss: 8815.89 ------------ Accuracy: 57.9%\n",
            "Step: 4440 ------------ Loss: 8814.56 ------------ Accuracy: 57.7%\n",
            "Step: 4441 ------------ Loss: 8814.5 ------------ Accuracy: 57.7%\n",
            "Step: 4442 ------------ Loss: 8813.81 ------------ Accuracy: 57.5%\n",
            "Step: 4443 ------------ Loss: 8813.81 ------------ Accuracy: 57.7%\n",
            "Step: 4444 ------------ Loss: 8813.42 ------------ Accuracy: 57.5%\n",
            "Step: 4445 ------------ Loss: 8813.41 ------------ Accuracy: 57.5%\n",
            "Step: 4446 ------------ Loss: 8813.31 ------------ Accuracy: 57.5%\n",
            "Step: 4447 ------------ Loss: 8813.31 ------------ Accuracy: 57.5%\n",
            "Step: 4448 ------------ Loss: 8813.24 ------------ Accuracy: 57.5%\n",
            "Step: 4449 ------------ Loss: 8813.23 ------------ Accuracy: 57.5%\n",
            "Step: 4450 ------------ Loss: 8813.23 ------------ Accuracy: 57.5%\n",
            "Step: 4451 ------------ Loss: 8812.59 ------------ Accuracy: 57.5%\n",
            "Step: 4452 ------------ Loss: 8812.57 ------------ Accuracy: 57.5%\n",
            "Step: 4453 ------------ Loss: 8811.31 ------------ Accuracy: 57.5%\n",
            "Step: 4454 ------------ Loss: 8811.24 ------------ Accuracy: 57.5%\n",
            "Step: 4455 ------------ Loss: 8811.24 ------------ Accuracy: 57.5%\n",
            "Step: 4456 ------------ Loss: 8810.98 ------------ Accuracy: 57.5%\n",
            "Step: 4457 ------------ Loss: 8810.92 ------------ Accuracy: 57.5%\n",
            "Step: 4458 ------------ Loss: 8809.71 ------------ Accuracy: 57.5%\n",
            "Step: 4459 ------------ Loss: 8809.64 ------------ Accuracy: 57.5%\n",
            "Step: 4460 ------------ Loss: 8809.64 ------------ Accuracy: 57.5%\n",
            "Step: 4461 ------------ Loss: 8809.55 ------------ Accuracy: 57.5%\n",
            "Step: 4462 ------------ Loss: 8808.95 ------------ Accuracy: 57.5%\n",
            "Step: 4463 ------------ Loss: 8808.94 ------------ Accuracy: 57.5%\n",
            "Step: 4464 ------------ Loss: 8808.93 ------------ Accuracy: 57.5%\n",
            "Step: 4465 ------------ Loss: 8808.88 ------------ Accuracy: 57.5%\n",
            "Step: 4466 ------------ Loss: 8808.62 ------------ Accuracy: 57.5%\n",
            "Step: 4467 ------------ Loss: 8808.5 ------------ Accuracy: 57.5%\n",
            "Step: 4468 ------------ Loss: 8808.48 ------------ Accuracy: 57.5%\n",
            "Step: 4469 ------------ Loss: 8808.47 ------------ Accuracy: 57.5%\n",
            "Step: 4470 ------------ Loss: 8808.45 ------------ Accuracy: 57.5%\n",
            "Step: 4471 ------------ Loss: 8807.88 ------------ Accuracy: 57.5%\n",
            "Step: 4472 ------------ Loss: 8807.81 ------------ Accuracy: 57.5%\n",
            "Step: 4473 ------------ Loss: 8807.72 ------------ Accuracy: 57.5%\n",
            "Step: 4474 ------------ Loss: 8807.7 ------------ Accuracy: 57.5%\n",
            "Step: 4475 ------------ Loss: 8807.68 ------------ Accuracy: 57.5%\n",
            "Step: 4476 ------------ Loss: 8807.43 ------------ Accuracy: 57.5%\n",
            "Step: 4477 ------------ Loss: 8807.37 ------------ Accuracy: 57.5%\n",
            "Step: 4478 ------------ Loss: 8807.35 ------------ Accuracy: 57.5%\n",
            "Step: 4479 ------------ Loss: 8807.34 ------------ Accuracy: 57.5%\n",
            "Step: 4480 ------------ Loss: 8807.27 ------------ Accuracy: 57.5%\n",
            "Step: 4481 ------------ Loss: 8807.21 ------------ Accuracy: 57.5%\n",
            "Step: 4482 ------------ Loss: 8807.11 ------------ Accuracy: 57.5%\n",
            "Step: 4483 ------------ Loss: 8805.9 ------------ Accuracy: 57.5%\n",
            "Step: 4484 ------------ Loss: 8805.74 ------------ Accuracy: 57.5%\n",
            "Step: 4485 ------------ Loss: 8804.9 ------------ Accuracy: 57.6%\n",
            "Step: 4486 ------------ Loss: 8804.9 ------------ Accuracy: 57.6%\n",
            "Step: 4487 ------------ Loss: 8803.67 ------------ Accuracy: 57.6%\n",
            "Step: 4488 ------------ Loss: 8803.67 ------------ Accuracy: 57.6%\n",
            "Step: 4489 ------------ Loss: 8803.67 ------------ Accuracy: 57.6%\n",
            "Step: 4490 ------------ Loss: 8803.61 ------------ Accuracy: 57.6%\n",
            "Step: 4491 ------------ Loss: 8803.6 ------------ Accuracy: 57.6%\n",
            "Step: 4492 ------------ Loss: 8803.59 ------------ Accuracy: 57.6%\n",
            "Step: 4493 ------------ Loss: 8803.58 ------------ Accuracy: 57.6%\n",
            "Step: 4494 ------------ Loss: 8803.52 ------------ Accuracy: 57.6%\n",
            "Step: 4495 ------------ Loss: 8803.52 ------------ Accuracy: 57.6%\n",
            "Step: 4496 ------------ Loss: 8803.52 ------------ Accuracy: 57.6%\n",
            "Step: 4497 ------------ Loss: 8803.5 ------------ Accuracy: 57.6%\n",
            "Step: 4498 ------------ Loss: 8803.44 ------------ Accuracy: 57.6%\n",
            "Step: 4499 ------------ Loss: 8803.39 ------------ Accuracy: 57.6%\n",
            "Step: 4500 ------------ Loss: 8803.22 ------------ Accuracy: 57.6%\n",
            "Step: 4501 ------------ Loss: 8803.21 ------------ Accuracy: 57.6%\n",
            "Step: 4502 ------------ Loss: 8803.2 ------------ Accuracy: 57.6%\n",
            "Step: 4503 ------------ Loss: 8803.14 ------------ Accuracy: 57.6%\n",
            "Step: 4504 ------------ Loss: 8803.07 ------------ Accuracy: 57.6%\n",
            "Step: 4505 ------------ Loss: 8802.99 ------------ Accuracy: 57.6%\n",
            "Step: 4506 ------------ Loss: 8802.98 ------------ Accuracy: 57.6%\n",
            "Step: 4507 ------------ Loss: 8802.9 ------------ Accuracy: 57.6%\n",
            "Step: 4508 ------------ Loss: 8802.89 ------------ Accuracy: 57.6%\n",
            "Step: 4509 ------------ Loss: 8802.8 ------------ Accuracy: 57.6%\n",
            "Step: 4510 ------------ Loss: 8802.63 ------------ Accuracy: 57.6%\n",
            "Step: 4511 ------------ Loss: 8802.54 ------------ Accuracy: 57.6%\n",
            "Step: 4512 ------------ Loss: 8802.45 ------------ Accuracy: 57.6%\n",
            "Step: 4513 ------------ Loss: 8802.45 ------------ Accuracy: 57.6%\n",
            "Step: 4514 ------------ Loss: 8802.44 ------------ Accuracy: 57.6%\n",
            "Step: 4515 ------------ Loss: 8802.44 ------------ Accuracy: 57.6%\n",
            "Step: 4516 ------------ Loss: 8802.43 ------------ Accuracy: 57.6%\n",
            "Step: 4517 ------------ Loss: 8802.42 ------------ Accuracy: 57.6%\n",
            "Step: 4518 ------------ Loss: 8802.31 ------------ Accuracy: 57.6%\n",
            "Step: 4519 ------------ Loss: 8802.22 ------------ Accuracy: 57.6%\n",
            "Step: 4520 ------------ Loss: 8802.06 ------------ Accuracy: 57.6%\n",
            "Step: 4521 ------------ Loss: 8801.98 ------------ Accuracy: 57.6%\n",
            "Step: 4522 ------------ Loss: 8801.96 ------------ Accuracy: 57.6%\n",
            "Step: 4523 ------------ Loss: 8801.95 ------------ Accuracy: 57.6%\n",
            "Step: 4524 ------------ Loss: 8801.94 ------------ Accuracy: 57.7%\n",
            "Step: 4525 ------------ Loss: 8801.93 ------------ Accuracy: 57.7%\n",
            "Step: 4526 ------------ Loss: 8801.86 ------------ Accuracy: 57.6%\n",
            "Step: 4527 ------------ Loss: 8801.18 ------------ Accuracy: 57.8%\n",
            "Step: 4528 ------------ Loss: 8801.16 ------------ Accuracy: 57.7%\n",
            "Step: 4529 ------------ Loss: 8801.15 ------------ Accuracy: 57.7%\n",
            "Step: 4530 ------------ Loss: 8801.09 ------------ Accuracy: 57.8%\n",
            "Step: 4531 ------------ Loss: 8801.01 ------------ Accuracy: 57.8%\n",
            "Step: 4532 ------------ Loss: 8801.0 ------------ Accuracy: 57.8%\n",
            "Step: 4533 ------------ Loss: 8800.98 ------------ Accuracy: 57.7%\n",
            "Step: 4534 ------------ Loss: 8800.97 ------------ Accuracy: 57.7%\n",
            "Step: 4535 ------------ Loss: 8800.97 ------------ Accuracy: 57.7%\n",
            "Step: 4536 ------------ Loss: 8800.91 ------------ Accuracy: 57.7%\n",
            "Step: 4537 ------------ Loss: 8800.67 ------------ Accuracy: 57.8%\n",
            "Step: 4538 ------------ Loss: 8800.66 ------------ Accuracy: 57.7%\n",
            "Step: 4539 ------------ Loss: 8800.59 ------------ Accuracy: 57.7%\n",
            "Step: 4540 ------------ Loss: 8800.42 ------------ Accuracy: 57.7%\n",
            "Step: 4541 ------------ Loss: 8799.18 ------------ Accuracy: 57.7%\n",
            "Step: 4542 ------------ Loss: 8799.09 ------------ Accuracy: 57.8%\n",
            "Step: 4543 ------------ Loss: 8799.0 ------------ Accuracy: 57.8%\n",
            "Step: 4544 ------------ Loss: 8798.98 ------------ Accuracy: 57.8%\n",
            "Step: 4545 ------------ Loss: 8798.97 ------------ Accuracy: 57.8%\n",
            "Step: 4546 ------------ Loss: 8798.32 ------------ Accuracy: 57.7%\n",
            "Step: 4547 ------------ Loss: 8798.24 ------------ Accuracy: 57.7%\n",
            "Step: 4548 ------------ Loss: 8798.23 ------------ Accuracy: 57.7%\n",
            "Step: 4549 ------------ Loss: 8798.12 ------------ Accuracy: 57.7%\n",
            "Step: 4550 ------------ Loss: 8798.03 ------------ Accuracy: 57.7%\n",
            "Step: 4551 ------------ Loss: 8797.97 ------------ Accuracy: 57.7%\n",
            "Step: 4552 ------------ Loss: 8797.95 ------------ Accuracy: 57.7%\n",
            "Step: 4553 ------------ Loss: 8797.86 ------------ Accuracy: 57.7%\n",
            "Step: 4554 ------------ Loss: 8797.8 ------------ Accuracy: 57.6%\n",
            "Step: 4555 ------------ Loss: 8796.61 ------------ Accuracy: 57.6%\n",
            "Step: 4556 ------------ Loss: 8796.61 ------------ Accuracy: 57.6%\n",
            "Step: 4557 ------------ Loss: 8796.51 ------------ Accuracy: 57.7%\n",
            "Step: 4558 ------------ Loss: 8795.76 ------------ Accuracy: 57.8%\n",
            "Step: 4559 ------------ Loss: 8795.23 ------------ Accuracy: 58.0%\n",
            "Step: 4560 ------------ Loss: 8795.21 ------------ Accuracy: 57.9%\n",
            "Step: 4561 ------------ Loss: 8794.97 ------------ Accuracy: 58.0%\n",
            "Step: 4562 ------------ Loss: 8794.97 ------------ Accuracy: 58.0%\n",
            "Step: 4563 ------------ Loss: 8794.96 ------------ Accuracy: 57.9%\n",
            "Step: 4564 ------------ Loss: 8794.95 ------------ Accuracy: 57.9%\n",
            "Step: 4565 ------------ Loss: 8794.86 ------------ Accuracy: 57.9%\n",
            "Step: 4566 ------------ Loss: 8794.84 ------------ Accuracy: 57.9%\n",
            "Step: 4567 ------------ Loss: 8794.8 ------------ Accuracy: 57.9%\n",
            "Step: 4568 ------------ Loss: 8794.79 ------------ Accuracy: 57.9%\n",
            "Step: 4569 ------------ Loss: 8794.79 ------------ Accuracy: 57.9%\n",
            "Step: 4570 ------------ Loss: 8794.08 ------------ Accuracy: 57.8%\n",
            "Step: 4571 ------------ Loss: 8793.96 ------------ Accuracy: 57.8%\n",
            "Step: 4572 ------------ Loss: 8793.95 ------------ Accuracy: 57.8%\n",
            "Step: 4573 ------------ Loss: 8793.93 ------------ Accuracy: 57.8%\n",
            "Step: 4574 ------------ Loss: 8793.92 ------------ Accuracy: 57.8%\n",
            "Step: 4575 ------------ Loss: 8793.81 ------------ Accuracy: 57.8%\n",
            "Step: 4576 ------------ Loss: 8793.81 ------------ Accuracy: 57.8%\n",
            "Step: 4577 ------------ Loss: 8793.8 ------------ Accuracy: 57.8%\n",
            "Step: 4578 ------------ Loss: 8793.25 ------------ Accuracy: 57.9%\n",
            "Step: 4579 ------------ Loss: 8793.17 ------------ Accuracy: 57.9%\n",
            "Step: 4580 ------------ Loss: 8793.16 ------------ Accuracy: 57.9%\n",
            "Step: 4581 ------------ Loss: 8792.98 ------------ Accuracy: 57.9%\n",
            "Step: 4582 ------------ Loss: 8792.96 ------------ Accuracy: 57.9%\n",
            "Step: 4583 ------------ Loss: 8792.83 ------------ Accuracy: 57.8%\n",
            "Step: 4584 ------------ Loss: 8792.72 ------------ Accuracy: 57.8%\n",
            "Step: 4585 ------------ Loss: 8792.55 ------------ Accuracy: 57.8%\n",
            "Step: 4586 ------------ Loss: 8792.54 ------------ Accuracy: 57.8%\n",
            "Step: 4587 ------------ Loss: 8792.47 ------------ Accuracy: 57.8%\n",
            "Step: 4588 ------------ Loss: 8792.08 ------------ Accuracy: 57.8%\n",
            "Step: 4589 ------------ Loss: 8792.01 ------------ Accuracy: 57.8%\n",
            "Step: 4590 ------------ Loss: 8791.95 ------------ Accuracy: 57.8%\n",
            "Step: 4591 ------------ Loss: 8791.95 ------------ Accuracy: 57.8%\n",
            "Step: 4592 ------------ Loss: 8790.72 ------------ Accuracy: 57.8%\n",
            "Step: 4593 ------------ Loss: 8790.71 ------------ Accuracy: 57.8%\n",
            "Step: 4594 ------------ Loss: 8790.7 ------------ Accuracy: 57.8%\n",
            "Step: 4595 ------------ Loss: 8790.7 ------------ Accuracy: 57.8%\n",
            "Step: 4596 ------------ Loss: 8790.7 ------------ Accuracy: 57.8%\n",
            "Step: 4597 ------------ Loss: 8790.61 ------------ Accuracy: 57.8%\n",
            "Step: 4598 ------------ Loss: 8790.61 ------------ Accuracy: 57.8%\n",
            "Step: 4599 ------------ Loss: 8789.96 ------------ Accuracy: 57.8%\n",
            "Step: 4600 ------------ Loss: 8789.95 ------------ Accuracy: 57.8%\n",
            "Step: 4601 ------------ Loss: 8788.77 ------------ Accuracy: 57.8%\n",
            "Step: 4602 ------------ Loss: 8788.4 ------------ Accuracy: 57.8%\n",
            "Step: 4603 ------------ Loss: 8788.31 ------------ Accuracy: 57.8%\n",
            "Step: 4604 ------------ Loss: 8788.24 ------------ Accuracy: 57.8%\n",
            "Step: 4605 ------------ Loss: 8787.64 ------------ Accuracy: 57.8%\n",
            "Step: 4606 ------------ Loss: 8787.56 ------------ Accuracy: 57.8%\n",
            "Step: 4607 ------------ Loss: 8786.43 ------------ Accuracy: 57.8%\n",
            "Step: 4608 ------------ Loss: 8786.42 ------------ Accuracy: 57.8%\n",
            "Step: 4609 ------------ Loss: 8786.42 ------------ Accuracy: 57.8%\n",
            "Step: 4610 ------------ Loss: 8786.41 ------------ Accuracy: 57.8%\n",
            "Step: 4611 ------------ Loss: 8786.4 ------------ Accuracy: 57.8%\n",
            "Step: 4612 ------------ Loss: 8786.24 ------------ Accuracy: 57.8%\n",
            "Step: 4613 ------------ Loss: 8786.15 ------------ Accuracy: 57.8%\n",
            "Step: 4614 ------------ Loss: 8786.14 ------------ Accuracy: 57.8%\n",
            "Step: 4615 ------------ Loss: 8785.39 ------------ Accuracy: 57.9%\n",
            "Step: 4616 ------------ Loss: 8785.27 ------------ Accuracy: 57.9%\n",
            "Step: 4617 ------------ Loss: 8785.26 ------------ Accuracy: 57.9%\n",
            "Step: 4618 ------------ Loss: 8785.26 ------------ Accuracy: 57.9%\n",
            "Step: 4619 ------------ Loss: 8785.26 ------------ Accuracy: 57.9%\n",
            "Step: 4620 ------------ Loss: 8785.24 ------------ Accuracy: 57.9%\n",
            "Step: 4621 ------------ Loss: 8785.24 ------------ Accuracy: 57.9%\n",
            "Step: 4622 ------------ Loss: 8785.23 ------------ Accuracy: 57.9%\n",
            "Step: 4623 ------------ Loss: 8785.13 ------------ Accuracy: 57.8%\n",
            "Step: 4624 ------------ Loss: 8785.12 ------------ Accuracy: 57.8%\n",
            "Step: 4625 ------------ Loss: 8785.11 ------------ Accuracy: 57.8%\n",
            "Step: 4626 ------------ Loss: 8785.11 ------------ Accuracy: 57.8%\n",
            "Step: 4627 ------------ Loss: 8785.09 ------------ Accuracy: 57.8%\n",
            "Step: 4628 ------------ Loss: 8785.09 ------------ Accuracy: 57.8%\n",
            "Step: 4629 ------------ Loss: 8784.49 ------------ Accuracy: 58.0%\n",
            "Step: 4630 ------------ Loss: 8784.48 ------------ Accuracy: 58.0%\n",
            "Step: 4631 ------------ Loss: 8784.47 ------------ Accuracy: 58.0%\n",
            "Step: 4632 ------------ Loss: 8784.36 ------------ Accuracy: 58.0%\n",
            "Step: 4633 ------------ Loss: 8783.16 ------------ Accuracy: 58.0%\n",
            "Step: 4634 ------------ Loss: 8783.11 ------------ Accuracy: 58.0%\n",
            "Step: 4635 ------------ Loss: 8783.1 ------------ Accuracy: 58.0%\n",
            "Step: 4636 ------------ Loss: 8782.62 ------------ Accuracy: 58.2%\n",
            "Step: 4637 ------------ Loss: 8782.53 ------------ Accuracy: 58.2%\n",
            "Step: 4638 ------------ Loss: 8782.52 ------------ Accuracy: 58.1%\n",
            "Step: 4639 ------------ Loss: 8781.79 ------------ Accuracy: 58.1%\n",
            "Step: 4640 ------------ Loss: 8781.77 ------------ Accuracy: 58.1%\n",
            "Step: 4641 ------------ Loss: 8781.76 ------------ Accuracy: 58.1%\n",
            "Step: 4642 ------------ Loss: 8781.53 ------------ Accuracy: 58.1%\n",
            "Step: 4643 ------------ Loss: 8781.35 ------------ Accuracy: 58.1%\n",
            "Step: 4644 ------------ Loss: 8781.35 ------------ Accuracy: 58.1%\n",
            "Step: 4645 ------------ Loss: 8780.97 ------------ Accuracy: 58.1%\n",
            "Step: 4646 ------------ Loss: 8780.95 ------------ Accuracy: 58.0%\n",
            "Step: 4647 ------------ Loss: 8780.89 ------------ Accuracy: 58.1%\n",
            "Step: 4648 ------------ Loss: 8779.73 ------------ Accuracy: 58.1%\n",
            "Step: 4649 ------------ Loss: 8779.22 ------------ Accuracy: 58.2%\n",
            "Step: 4650 ------------ Loss: 8779.21 ------------ Accuracy: 58.2%\n",
            "Step: 4651 ------------ Loss: 8779.19 ------------ Accuracy: 58.2%\n",
            "Step: 4652 ------------ Loss: 8779.18 ------------ Accuracy: 58.2%\n",
            "Step: 4653 ------------ Loss: 8779.14 ------------ Accuracy: 58.2%\n",
            "Step: 4654 ------------ Loss: 8778.96 ------------ Accuracy: 58.2%\n",
            "Step: 4655 ------------ Loss: 8778.94 ------------ Accuracy: 58.1%\n",
            "Step: 4656 ------------ Loss: 8778.93 ------------ Accuracy: 58.1%\n",
            "Step: 4657 ------------ Loss: 8778.81 ------------ Accuracy: 58.1%\n",
            "Step: 4658 ------------ Loss: 8778.12 ------------ Accuracy: 58.1%\n",
            "Step: 4659 ------------ Loss: 8778.11 ------------ Accuracy: 58.1%\n",
            "Step: 4660 ------------ Loss: 8778.1 ------------ Accuracy: 58.1%\n",
            "Step: 4661 ------------ Loss: 8777.72 ------------ Accuracy: 58.1%\n",
            "Step: 4662 ------------ Loss: 8777.64 ------------ Accuracy: 58.1%\n",
            "Step: 4663 ------------ Loss: 8777.64 ------------ Accuracy: 58.1%\n",
            "Step: 4664 ------------ Loss: 8776.5 ------------ Accuracy: 58.1%\n",
            "Step: 4665 ------------ Loss: 8775.4 ------------ Accuracy: 58.1%\n",
            "Step: 4666 ------------ Loss: 8775.4 ------------ Accuracy: 58.1%\n",
            "Step: 4667 ------------ Loss: 8775.4 ------------ Accuracy: 58.1%\n",
            "Step: 4668 ------------ Loss: 8775.31 ------------ Accuracy: 58.1%\n",
            "Step: 4669 ------------ Loss: 8774.96 ------------ Accuracy: 58.1%\n",
            "Step: 4670 ------------ Loss: 8774.32 ------------ Accuracy: 58.1%\n",
            "Step: 4671 ------------ Loss: 8774.08 ------------ Accuracy: 58.1%\n",
            "Step: 4672 ------------ Loss: 8774.07 ------------ Accuracy: 58.1%\n",
            "Step: 4673 ------------ Loss: 8773.98 ------------ Accuracy: 58.1%\n",
            "Step: 4674 ------------ Loss: 8773.97 ------------ Accuracy: 58.1%\n",
            "Step: 4675 ------------ Loss: 8773.81 ------------ Accuracy: 58.1%\n",
            "Step: 4676 ------------ Loss: 8773.46 ------------ Accuracy: 58.1%\n",
            "Step: 4677 ------------ Loss: 8773.45 ------------ Accuracy: 58.1%\n",
            "Step: 4678 ------------ Loss: 8773.45 ------------ Accuracy: 58.1%\n",
            "Step: 4679 ------------ Loss: 8773.44 ------------ Accuracy: 58.1%\n",
            "Step: 4680 ------------ Loss: 8773.44 ------------ Accuracy: 58.1%\n",
            "Step: 4681 ------------ Loss: 8773.44 ------------ Accuracy: 58.1%\n",
            "Step: 4682 ------------ Loss: 8772.4 ------------ Accuracy: 58.1%\n",
            "Step: 4683 ------------ Loss: 8772.39 ------------ Accuracy: 58.1%\n",
            "Step: 4684 ------------ Loss: 8772.39 ------------ Accuracy: 58.1%\n",
            "Step: 4685 ------------ Loss: 8772.32 ------------ Accuracy: 58.1%\n",
            "Step: 4686 ------------ Loss: 8772.24 ------------ Accuracy: 58.1%\n",
            "Step: 4687 ------------ Loss: 8772.22 ------------ Accuracy: 58.1%\n",
            "Step: 4688 ------------ Loss: 8772.14 ------------ Accuracy: 58.1%\n",
            "Step: 4689 ------------ Loss: 8771.46 ------------ Accuracy: 58.1%\n",
            "Step: 4690 ------------ Loss: 8771.38 ------------ Accuracy: 58.1%\n",
            "Step: 4691 ------------ Loss: 8771.14 ------------ Accuracy: 58.1%\n",
            "Step: 4692 ------------ Loss: 8771.14 ------------ Accuracy: 58.1%\n",
            "Step: 4693 ------------ Loss: 8771.06 ------------ Accuracy: 58.1%\n",
            "Step: 4694 ------------ Loss: 8770.98 ------------ Accuracy: 58.1%\n",
            "Step: 4695 ------------ Loss: 8770.89 ------------ Accuracy: 58.1%\n",
            "Step: 4696 ------------ Loss: 8770.81 ------------ Accuracy: 58.1%\n",
            "Step: 4697 ------------ Loss: 8769.73 ------------ Accuracy: 58.1%\n",
            "Step: 4698 ------------ Loss: 8769.66 ------------ Accuracy: 58.1%\n",
            "Step: 4699 ------------ Loss: 8769.66 ------------ Accuracy: 58.1%\n",
            "Step: 4700 ------------ Loss: 8769.49 ------------ Accuracy: 58.1%\n",
            "Step: 4701 ------------ Loss: 8769.49 ------------ Accuracy: 58.1%\n",
            "Step: 4702 ------------ Loss: 8768.45 ------------ Accuracy: 58.1%\n",
            "Step: 4703 ------------ Loss: 8768.45 ------------ Accuracy: 58.1%\n",
            "Step: 4704 ------------ Loss: 8768.45 ------------ Accuracy: 58.1%\n",
            "Step: 4705 ------------ Loss: 8768.39 ------------ Accuracy: 58.1%\n",
            "Step: 4706 ------------ Loss: 8768.37 ------------ Accuracy: 58.1%\n",
            "Step: 4707 ------------ Loss: 8768.37 ------------ Accuracy: 58.1%\n",
            "Step: 4708 ------------ Loss: 8768.24 ------------ Accuracy: 58.0%\n",
            "Step: 4709 ------------ Loss: 8768.24 ------------ Accuracy: 58.0%\n",
            "Step: 4710 ------------ Loss: 8767.61 ------------ Accuracy: 58.1%\n",
            "Step: 4711 ------------ Loss: 8767.61 ------------ Accuracy: 58.1%\n",
            "Step: 4712 ------------ Loss: 8766.62 ------------ Accuracy: 58.0%\n",
            "Step: 4713 ------------ Loss: 8766.6 ------------ Accuracy: 58.0%\n",
            "Step: 4714 ------------ Loss: 8766.51 ------------ Accuracy: 58.0%\n",
            "Step: 4715 ------------ Loss: 8766.49 ------------ Accuracy: 58.0%\n",
            "Step: 4716 ------------ Loss: 8766.34 ------------ Accuracy: 58.0%\n",
            "Step: 4717 ------------ Loss: 8766.23 ------------ Accuracy: 57.9%\n",
            "Step: 4718 ------------ Loss: 8766.23 ------------ Accuracy: 57.9%\n",
            "Step: 4719 ------------ Loss: 8766.21 ------------ Accuracy: 58.1%\n",
            "Step: 4720 ------------ Loss: 8765.24 ------------ Accuracy: 58.0%\n",
            "Step: 4721 ------------ Loss: 8765.21 ------------ Accuracy: 58.0%\n",
            "Step: 4722 ------------ Loss: 8764.88 ------------ Accuracy: 58.0%\n",
            "Step: 4723 ------------ Loss: 8764.88 ------------ Accuracy: 58.0%\n",
            "Step: 4724 ------------ Loss: 8764.86 ------------ Accuracy: 58.0%\n",
            "Step: 4725 ------------ Loss: 8764.79 ------------ Accuracy: 58.0%\n",
            "Step: 4726 ------------ Loss: 8763.85 ------------ Accuracy: 58.0%\n",
            "Step: 4727 ------------ Loss: 8763.76 ------------ Accuracy: 58.0%\n",
            "Step: 4728 ------------ Loss: 8763.74 ------------ Accuracy: 58.0%\n",
            "Step: 4729 ------------ Loss: 8762.94 ------------ Accuracy: 58.2%\n",
            "Step: 4730 ------------ Loss: 8762.94 ------------ Accuracy: 58.2%\n",
            "Step: 4731 ------------ Loss: 8762.86 ------------ Accuracy: 58.2%\n",
            "Step: 4732 ------------ Loss: 8762.21 ------------ Accuracy: 58.2%\n",
            "Step: 4733 ------------ Loss: 8762.19 ------------ Accuracy: 58.1%\n",
            "Step: 4734 ------------ Loss: 8762.18 ------------ Accuracy: 58.1%\n",
            "Step: 4735 ------------ Loss: 8762.1 ------------ Accuracy: 58.1%\n",
            "Step: 4736 ------------ Loss: 8762.02 ------------ Accuracy: 58.1%\n",
            "Step: 4737 ------------ Loss: 8762.0 ------------ Accuracy: 58.1%\n",
            "Step: 4738 ------------ Loss: 8761.89 ------------ Accuracy: 58.0%\n",
            "Step: 4739 ------------ Loss: 8761.77 ------------ Accuracy: 58.0%\n",
            "Step: 4740 ------------ Loss: 8761.42 ------------ Accuracy: 58.0%\n",
            "Step: 4741 ------------ Loss: 8761.34 ------------ Accuracy: 58.0%\n",
            "Step: 4742 ------------ Loss: 8761.24 ------------ Accuracy: 57.9%\n",
            "Step: 4743 ------------ Loss: 8761.18 ------------ Accuracy: 57.9%\n",
            "Step: 4744 ------------ Loss: 8761.18 ------------ Accuracy: 57.9%\n",
            "Step: 4745 ------------ Loss: 8761.16 ------------ Accuracy: 57.9%\n",
            "Step: 4746 ------------ Loss: 8761.15 ------------ Accuracy: 57.9%\n",
            "Step: 4747 ------------ Loss: 8761.15 ------------ Accuracy: 57.9%\n",
            "Step: 4748 ------------ Loss: 8761.06 ------------ Accuracy: 57.8%\n",
            "Step: 4749 ------------ Loss: 8760.91 ------------ Accuracy: 57.8%\n",
            "Step: 4750 ------------ Loss: 8760.21 ------------ Accuracy: 58.1%\n",
            "Step: 4751 ------------ Loss: 8759.71 ------------ Accuracy: 58.0%\n",
            "Step: 4752 ------------ Loss: 8758.61 ------------ Accuracy: 58.0%\n",
            "Step: 4753 ------------ Loss: 8758.59 ------------ Accuracy: 58.0%\n",
            "Step: 4754 ------------ Loss: 8758.56 ------------ Accuracy: 58.0%\n",
            "Step: 4755 ------------ Loss: 8757.88 ------------ Accuracy: 58.1%\n",
            "Step: 4756 ------------ Loss: 8757.82 ------------ Accuracy: 58.1%\n",
            "Step: 4757 ------------ Loss: 8757.82 ------------ Accuracy: 58.1%\n",
            "Step: 4758 ------------ Loss: 8757.65 ------------ Accuracy: 58.1%\n",
            "Step: 4759 ------------ Loss: 8757.65 ------------ Accuracy: 58.1%\n",
            "Step: 4760 ------------ Loss: 8757.53 ------------ Accuracy: 58.0%\n",
            "Step: 4761 ------------ Loss: 8757.52 ------------ Accuracy: 58.0%\n",
            "Step: 4762 ------------ Loss: 8757.52 ------------ Accuracy: 58.0%\n",
            "Step: 4763 ------------ Loss: 8757.52 ------------ Accuracy: 58.0%\n",
            "Step: 4764 ------------ Loss: 8757.52 ------------ Accuracy: 58.0%\n",
            "Step: 4765 ------------ Loss: 8757.51 ------------ Accuracy: 58.0%\n",
            "Step: 4766 ------------ Loss: 8757.16 ------------ Accuracy: 58.0%\n",
            "Step: 4767 ------------ Loss: 8757.1 ------------ Accuracy: 58.0%\n",
            "Step: 4768 ------------ Loss: 8757.1 ------------ Accuracy: 58.0%\n",
            "Step: 4769 ------------ Loss: 8756.07 ------------ Accuracy: 58.0%\n",
            "Step: 4770 ------------ Loss: 8755.08 ------------ Accuracy: 58.1%\n",
            "Step: 4771 ------------ Loss: 8755.07 ------------ Accuracy: 58.1%\n",
            "Step: 4772 ------------ Loss: 8755.01 ------------ Accuracy: 58.1%\n",
            "Step: 4773 ------------ Loss: 8755.01 ------------ Accuracy: 58.1%\n",
            "Step: 4774 ------------ Loss: 8754.93 ------------ Accuracy: 58.1%\n",
            "Step: 4775 ------------ Loss: 8754.93 ------------ Accuracy: 58.1%\n",
            "Step: 4776 ------------ Loss: 8754.87 ------------ Accuracy: 58.1%\n",
            "Step: 4777 ------------ Loss: 8754.86 ------------ Accuracy: 58.1%\n",
            "Step: 4778 ------------ Loss: 8754.86 ------------ Accuracy: 58.1%\n",
            "Step: 4779 ------------ Loss: 8754.76 ------------ Accuracy: 58.0%\n",
            "Step: 4780 ------------ Loss: 8754.11 ------------ Accuracy: 58.0%\n",
            "Step: 4781 ------------ Loss: 8753.1 ------------ Accuracy: 58.0%\n",
            "Step: 4782 ------------ Loss: 8752.13 ------------ Accuracy: 58.0%\n",
            "Step: 4783 ------------ Loss: 8752.11 ------------ Accuracy: 58.0%\n",
            "Step: 4784 ------------ Loss: 8752.1 ------------ Accuracy: 58.0%\n",
            "Step: 4785 ------------ Loss: 8752.1 ------------ Accuracy: 58.0%\n",
            "Step: 4786 ------------ Loss: 8752.08 ------------ Accuracy: 58.0%\n",
            "Step: 4787 ------------ Loss: 8752.08 ------------ Accuracy: 58.0%\n",
            "Step: 4788 ------------ Loss: 8752.0 ------------ Accuracy: 58.0%\n",
            "Step: 4789 ------------ Loss: 8752.0 ------------ Accuracy: 58.0%\n",
            "Step: 4790 ------------ Loss: 8751.93 ------------ Accuracy: 58.0%\n",
            "Step: 4791 ------------ Loss: 8751.92 ------------ Accuracy: 58.0%\n",
            "Step: 4792 ------------ Loss: 8751.9 ------------ Accuracy: 58.0%\n",
            "Step: 4793 ------------ Loss: 8751.9 ------------ Accuracy: 58.0%\n",
            "Step: 4794 ------------ Loss: 8751.26 ------------ Accuracy: 58.1%\n",
            "Step: 4795 ------------ Loss: 8751.25 ------------ Accuracy: 58.1%\n",
            "Step: 4796 ------------ Loss: 8751.19 ------------ Accuracy: 58.0%\n",
            "Step: 4797 ------------ Loss: 8751.11 ------------ Accuracy: 58.0%\n",
            "Step: 4798 ------------ Loss: 8751.1 ------------ Accuracy: 58.1%\n",
            "Step: 4799 ------------ Loss: 8750.86 ------------ Accuracy: 58.0%\n",
            "Step: 4800 ------------ Loss: 8750.86 ------------ Accuracy: 58.0%\n",
            "Step: 4801 ------------ Loss: 8750.78 ------------ Accuracy: 58.1%\n",
            "Step: 4802 ------------ Loss: 8750.71 ------------ Accuracy: 58.0%\n",
            "Step: 4803 ------------ Loss: 8750.12 ------------ Accuracy: 58.0%\n",
            "Step: 4804 ------------ Loss: 8749.97 ------------ Accuracy: 58.0%\n",
            "Step: 4805 ------------ Loss: 8749.96 ------------ Accuracy: 58.0%\n",
            "Step: 4806 ------------ Loss: 8749.95 ------------ Accuracy: 58.0%\n",
            "Step: 4807 ------------ Loss: 8749.82 ------------ Accuracy: 58.0%\n",
            "Step: 4808 ------------ Loss: 8749.59 ------------ Accuracy: 58.0%\n",
            "Step: 4809 ------------ Loss: 8749.42 ------------ Accuracy: 58.0%\n",
            "Step: 4810 ------------ Loss: 8749.42 ------------ Accuracy: 58.0%\n",
            "Step: 4811 ------------ Loss: 8749.41 ------------ Accuracy: 57.9%\n",
            "Step: 4812 ------------ Loss: 8749.41 ------------ Accuracy: 57.9%\n",
            "Step: 4813 ------------ Loss: 8749.06 ------------ Accuracy: 58.0%\n",
            "Step: 4814 ------------ Loss: 8748.43 ------------ Accuracy: 58.0%\n",
            "Step: 4815 ------------ Loss: 8748.42 ------------ Accuracy: 58.0%\n",
            "Step: 4816 ------------ Loss: 8748.3 ------------ Accuracy: 58.0%\n",
            "Step: 4817 ------------ Loss: 8747.95 ------------ Accuracy: 58.0%\n",
            "Step: 4818 ------------ Loss: 8747.94 ------------ Accuracy: 58.0%\n",
            "Step: 4819 ------------ Loss: 8747.7 ------------ Accuracy: 58.0%\n",
            "Step: 4820 ------------ Loss: 8747.69 ------------ Accuracy: 58.0%\n",
            "Step: 4821 ------------ Loss: 8747.61 ------------ Accuracy: 58.0%\n",
            "Step: 4822 ------------ Loss: 8747.6 ------------ Accuracy: 58.0%\n",
            "Step: 4823 ------------ Loss: 8747.53 ------------ Accuracy: 58.0%\n",
            "Step: 4824 ------------ Loss: 8747.52 ------------ Accuracy: 58.0%\n",
            "Step: 4825 ------------ Loss: 8747.44 ------------ Accuracy: 58.0%\n",
            "Step: 4826 ------------ Loss: 8747.35 ------------ Accuracy: 58.0%\n",
            "Step: 4827 ------------ Loss: 8747.35 ------------ Accuracy: 58.0%\n",
            "Step: 4828 ------------ Loss: 8747.35 ------------ Accuracy: 58.0%\n",
            "Step: 4829 ------------ Loss: 8747.34 ------------ Accuracy: 58.0%\n",
            "Step: 4830 ------------ Loss: 8747.33 ------------ Accuracy: 58.0%\n",
            "Step: 4831 ------------ Loss: 8747.32 ------------ Accuracy: 58.0%\n",
            "Step: 4832 ------------ Loss: 8747.24 ------------ Accuracy: 58.0%\n",
            "Step: 4833 ------------ Loss: 8747.23 ------------ Accuracy: 58.0%\n",
            "Step: 4834 ------------ Loss: 8746.99 ------------ Accuracy: 58.0%\n",
            "Step: 4835 ------------ Loss: 8746.9 ------------ Accuracy: 58.0%\n",
            "Step: 4836 ------------ Loss: 8746.85 ------------ Accuracy: 58.0%\n",
            "Step: 4837 ------------ Loss: 8746.85 ------------ Accuracy: 58.0%\n",
            "Step: 4838 ------------ Loss: 8746.84 ------------ Accuracy: 58.0%\n",
            "Step: 4839 ------------ Loss: 8746.83 ------------ Accuracy: 58.0%\n",
            "Step: 4840 ------------ Loss: 8746.76 ------------ Accuracy: 58.0%\n",
            "Step: 4841 ------------ Loss: 8745.76 ------------ Accuracy: 58.0%\n",
            "Step: 4842 ------------ Loss: 8745.6 ------------ Accuracy: 58.0%\n",
            "Step: 4843 ------------ Loss: 8745.48 ------------ Accuracy: 58.0%\n",
            "Step: 4844 ------------ Loss: 8745.43 ------------ Accuracy: 58.0%\n",
            "Step: 4845 ------------ Loss: 8745.35 ------------ Accuracy: 58.0%\n",
            "Step: 4846 ------------ Loss: 8744.39 ------------ Accuracy: 57.9%\n",
            "Step: 4847 ------------ Loss: 8744.24 ------------ Accuracy: 58.0%\n",
            "Step: 4848 ------------ Loss: 8744.16 ------------ Accuracy: 57.9%\n",
            "Step: 4849 ------------ Loss: 8743.92 ------------ Accuracy: 57.9%\n",
            "Step: 4850 ------------ Loss: 8743.76 ------------ Accuracy: 58.0%\n",
            "Step: 4851 ------------ Loss: 8743.68 ------------ Accuracy: 57.9%\n",
            "Step: 4852 ------------ Loss: 8743.67 ------------ Accuracy: 58.0%\n",
            "Step: 4853 ------------ Loss: 8743.61 ------------ Accuracy: 58.0%\n",
            "Step: 4854 ------------ Loss: 8743.6 ------------ Accuracy: 57.9%\n",
            "Step: 4855 ------------ Loss: 8743.52 ------------ Accuracy: 57.9%\n",
            "Step: 4856 ------------ Loss: 8743.52 ------------ Accuracy: 57.9%\n",
            "Step: 4857 ------------ Loss: 8743.51 ------------ Accuracy: 57.9%\n",
            "Step: 4858 ------------ Loss: 8743.51 ------------ Accuracy: 57.9%\n",
            "Step: 4859 ------------ Loss: 8743.5 ------------ Accuracy: 58.0%\n",
            "Step: 4860 ------------ Loss: 8743.5 ------------ Accuracy: 58.0%\n",
            "Step: 4861 ------------ Loss: 8743.41 ------------ Accuracy: 58.0%\n",
            "Step: 4862 ------------ Loss: 8743.4 ------------ Accuracy: 58.0%\n",
            "Step: 4863 ------------ Loss: 8743.3 ------------ Accuracy: 58.0%\n",
            "Step: 4864 ------------ Loss: 8743.3 ------------ Accuracy: 58.0%\n",
            "Step: 4865 ------------ Loss: 8743.29 ------------ Accuracy: 58.0%\n",
            "Step: 4866 ------------ Loss: 8743.17 ------------ Accuracy: 58.0%\n",
            "Step: 4867 ------------ Loss: 8742.52 ------------ Accuracy: 58.0%\n",
            "Step: 4868 ------------ Loss: 8742.5 ------------ Accuracy: 57.9%\n",
            "Step: 4869 ------------ Loss: 8741.52 ------------ Accuracy: 58.0%\n",
            "Step: 4870 ------------ Loss: 8741.47 ------------ Accuracy: 58.0%\n",
            "Step: 4871 ------------ Loss: 8741.45 ------------ Accuracy: 57.9%\n",
            "Step: 4872 ------------ Loss: 8741.45 ------------ Accuracy: 57.9%\n",
            "Step: 4873 ------------ Loss: 8741.33 ------------ Accuracy: 57.9%\n",
            "Step: 4874 ------------ Loss: 8741.2 ------------ Accuracy: 57.9%\n",
            "Step: 4875 ------------ Loss: 8741.2 ------------ Accuracy: 57.9%\n",
            "Step: 4876 ------------ Loss: 8741.19 ------------ Accuracy: 57.9%\n",
            "Step: 4877 ------------ Loss: 8741.08 ------------ Accuracy: 57.9%\n",
            "Step: 4878 ------------ Loss: 8740.92 ------------ Accuracy: 58.0%\n",
            "Step: 4879 ------------ Loss: 8740.91 ------------ Accuracy: 58.0%\n",
            "Step: 4880 ------------ Loss: 8740.67 ------------ Accuracy: 58.0%\n",
            "Step: 4881 ------------ Loss: 8740.67 ------------ Accuracy: 58.0%\n",
            "Step: 4882 ------------ Loss: 8740.66 ------------ Accuracy: 58.0%\n",
            "Step: 4883 ------------ Loss: 8740.66 ------------ Accuracy: 58.0%\n",
            "Step: 4884 ------------ Loss: 8740.66 ------------ Accuracy: 58.0%\n",
            "Step: 4885 ------------ Loss: 8740.65 ------------ Accuracy: 58.0%\n",
            "Step: 4886 ------------ Loss: 8740.64 ------------ Accuracy: 58.0%\n",
            "Step: 4887 ------------ Loss: 8740.4 ------------ Accuracy: 57.9%\n",
            "Step: 4888 ------------ Loss: 8740.4 ------------ Accuracy: 57.9%\n",
            "Step: 4889 ------------ Loss: 8740.16 ------------ Accuracy: 57.9%\n",
            "Step: 4890 ------------ Loss: 8740.15 ------------ Accuracy: 57.9%\n",
            "Step: 4891 ------------ Loss: 8739.81 ------------ Accuracy: 57.9%\n",
            "Step: 4892 ------------ Loss: 8739.71 ------------ Accuracy: 58.0%\n",
            "Step: 4893 ------------ Loss: 8739.11 ------------ Accuracy: 57.9%\n",
            "Step: 4894 ------------ Loss: 8739.1 ------------ Accuracy: 57.9%\n",
            "Step: 4895 ------------ Loss: 8739.1 ------------ Accuracy: 57.9%\n",
            "Step: 4896 ------------ Loss: 8738.1 ------------ Accuracy: 58.0%\n",
            "Step: 4897 ------------ Loss: 8737.62 ------------ Accuracy: 58.1%\n",
            "Step: 4898 ------------ Loss: 8737.57 ------------ Accuracy: 58.1%\n",
            "Step: 4899 ------------ Loss: 8737.57 ------------ Accuracy: 58.1%\n",
            "Step: 4900 ------------ Loss: 8737.56 ------------ Accuracy: 58.1%\n",
            "Step: 4901 ------------ Loss: 8737.39 ------------ Accuracy: 58.0%\n",
            "Step: 4902 ------------ Loss: 8737.37 ------------ Accuracy: 58.0%\n",
            "Step: 4903 ------------ Loss: 8736.96 ------------ Accuracy: 58.1%\n",
            "Step: 4904 ------------ Loss: 8736.23 ------------ Accuracy: 58.1%\n",
            "Step: 4905 ------------ Loss: 8736.23 ------------ Accuracy: 58.1%\n",
            "Step: 4906 ------------ Loss: 8736.21 ------------ Accuracy: 58.1%\n",
            "Step: 4907 ------------ Loss: 8735.98 ------------ Accuracy: 58.1%\n",
            "Step: 4908 ------------ Loss: 8735.96 ------------ Accuracy: 58.1%\n",
            "Step: 4909 ------------ Loss: 8735.81 ------------ Accuracy: 57.9%\n",
            "Step: 4910 ------------ Loss: 8735.65 ------------ Accuracy: 57.9%\n",
            "Step: 4911 ------------ Loss: 8735.02 ------------ Accuracy: 57.9%\n",
            "Step: 4912 ------------ Loss: 8735.01 ------------ Accuracy: 57.9%\n",
            "Step: 4913 ------------ Loss: 8735.0 ------------ Accuracy: 57.9%\n",
            "Step: 4914 ------------ Loss: 8734.65 ------------ Accuracy: 57.9%\n",
            "Step: 4915 ------------ Loss: 8734.64 ------------ Accuracy: 57.9%\n",
            "Step: 4916 ------------ Loss: 8734.64 ------------ Accuracy: 57.9%\n",
            "Step: 4917 ------------ Loss: 8734.05 ------------ Accuracy: 57.8%\n",
            "Step: 4918 ------------ Loss: 8733.97 ------------ Accuracy: 57.8%\n",
            "Step: 4919 ------------ Loss: 8733.96 ------------ Accuracy: 57.9%\n",
            "Step: 4920 ------------ Loss: 8733.91 ------------ Accuracy: 57.9%\n",
            "Step: 4921 ------------ Loss: 8733.91 ------------ Accuracy: 57.9%\n",
            "Step: 4922 ------------ Loss: 8733.83 ------------ Accuracy: 57.9%\n",
            "Step: 4923 ------------ Loss: 8733.74 ------------ Accuracy: 57.9%\n",
            "Step: 4924 ------------ Loss: 8733.73 ------------ Accuracy: 57.9%\n",
            "Step: 4925 ------------ Loss: 8733.61 ------------ Accuracy: 57.9%\n",
            "Step: 4926 ------------ Loss: 8733.61 ------------ Accuracy: 57.9%\n",
            "Step: 4927 ------------ Loss: 8733.56 ------------ Accuracy: 57.9%\n",
            "Step: 4928 ------------ Loss: 8733.55 ------------ Accuracy: 57.9%\n",
            "Step: 4929 ------------ Loss: 8733.55 ------------ Accuracy: 57.9%\n",
            "Step: 4930 ------------ Loss: 8733.46 ------------ Accuracy: 57.9%\n",
            "Step: 4931 ------------ Loss: 8733.45 ------------ Accuracy: 57.9%\n",
            "Step: 4932 ------------ Loss: 8733.36 ------------ Accuracy: 57.9%\n",
            "Step: 4933 ------------ Loss: 8733.36 ------------ Accuracy: 57.9%\n",
            "Step: 4934 ------------ Loss: 8733.35 ------------ Accuracy: 57.9%\n",
            "Step: 4935 ------------ Loss: 8733.34 ------------ Accuracy: 57.9%\n",
            "Step: 4936 ------------ Loss: 8733.34 ------------ Accuracy: 57.9%\n",
            "Step: 4937 ------------ Loss: 8733.34 ------------ Accuracy: 57.9%\n",
            "Step: 4938 ------------ Loss: 8733.33 ------------ Accuracy: 57.9%\n",
            "Step: 4939 ------------ Loss: 8732.76 ------------ Accuracy: 57.8%\n",
            "Step: 4940 ------------ Loss: 8732.69 ------------ Accuracy: 57.8%\n",
            "Step: 4941 ------------ Loss: 8732.61 ------------ Accuracy: 57.8%\n",
            "Step: 4942 ------------ Loss: 8732.38 ------------ Accuracy: 57.8%\n",
            "Step: 4943 ------------ Loss: 8732.25 ------------ Accuracy: 57.8%\n",
            "Step: 4944 ------------ Loss: 8732.21 ------------ Accuracy: 57.8%\n",
            "Step: 4945 ------------ Loss: 8732.2 ------------ Accuracy: 57.8%\n",
            "Step: 4946 ------------ Loss: 8732.2 ------------ Accuracy: 57.8%\n",
            "Step: 4947 ------------ Loss: 8732.19 ------------ Accuracy: 57.8%\n",
            "Step: 4948 ------------ Loss: 8732.18 ------------ Accuracy: 57.8%\n",
            "Step: 4949 ------------ Loss: 8732.18 ------------ Accuracy: 57.8%\n",
            "Step: 4950 ------------ Loss: 8732.17 ------------ Accuracy: 57.8%\n",
            "Step: 4951 ------------ Loss: 8732.16 ------------ Accuracy: 57.8%\n",
            "Step: 4952 ------------ Loss: 8731.82 ------------ Accuracy: 57.8%\n",
            "Step: 4953 ------------ Loss: 8731.81 ------------ Accuracy: 57.8%\n",
            "Step: 4954 ------------ Loss: 8731.24 ------------ Accuracy: 58.5%\n",
            "Step: 4955 ------------ Loss: 8730.83 ------------ Accuracy: 58.7%\n",
            "Step: 4956 ------------ Loss: 8729.76 ------------ Accuracy: 58.7%\n",
            "Step: 4957 ------------ Loss: 8729.64 ------------ Accuracy: 58.7%\n",
            "Step: 4958 ------------ Loss: 8729.64 ------------ Accuracy: 58.7%\n",
            "Step: 4959 ------------ Loss: 8729.52 ------------ Accuracy: 58.7%\n",
            "Step: 4960 ------------ Loss: 8729.43 ------------ Accuracy: 58.7%\n",
            "Step: 4961 ------------ Loss: 8729.41 ------------ Accuracy: 58.7%\n",
            "Step: 4962 ------------ Loss: 8729.38 ------------ Accuracy: 58.7%\n",
            "Step: 4963 ------------ Loss: 8729.36 ------------ Accuracy: 58.7%\n",
            "Step: 4964 ------------ Loss: 8729.35 ------------ Accuracy: 58.7%\n",
            "Step: 4965 ------------ Loss: 8729.29 ------------ Accuracy: 58.7%\n",
            "Step: 4966 ------------ Loss: 8729.28 ------------ Accuracy: 58.7%\n",
            "Step: 4967 ------------ Loss: 8729.27 ------------ Accuracy: 58.2%\n",
            "Step: 4968 ------------ Loss: 8729.25 ------------ Accuracy: 58.2%\n",
            "Step: 4969 ------------ Loss: 8729.24 ------------ Accuracy: 58.2%\n",
            "Step: 4970 ------------ Loss: 8729.19 ------------ Accuracy: 58.2%\n",
            "Step: 4971 ------------ Loss: 8729.13 ------------ Accuracy: 58.2%\n",
            "Step: 4972 ------------ Loss: 8728.78 ------------ Accuracy: 58.2%\n",
            "Step: 4973 ------------ Loss: 8728.42 ------------ Accuracy: 58.2%\n",
            "Step: 4974 ------------ Loss: 8728.41 ------------ Accuracy: 58.1%\n",
            "Step: 4975 ------------ Loss: 8728.39 ------------ Accuracy: 58.1%\n",
            "Step: 4976 ------------ Loss: 8728.27 ------------ Accuracy: 58.1%\n",
            "Step: 4977 ------------ Loss: 8728.04 ------------ Accuracy: 58.1%\n",
            "Step: 4978 ------------ Loss: 8728.03 ------------ Accuracy: 58.1%\n",
            "Step: 4979 ------------ Loss: 8727.8 ------------ Accuracy: 58.1%\n",
            "Step: 4980 ------------ Loss: 8727.8 ------------ Accuracy: 58.1%\n",
            "Step: 4981 ------------ Loss: 8727.79 ------------ Accuracy: 58.0%\n",
            "Step: 4982 ------------ Loss: 8727.29 ------------ Accuracy: 58.7%\n",
            "Step: 4983 ------------ Loss: 8727.27 ------------ Accuracy: 58.7%\n",
            "Step: 4984 ------------ Loss: 8727.2 ------------ Accuracy: 58.7%\n",
            "Step: 4985 ------------ Loss: 8726.55 ------------ Accuracy: 58.7%\n",
            "Step: 4986 ------------ Loss: 8725.55 ------------ Accuracy: 58.1%\n",
            "Step: 4987 ------------ Loss: 8725.54 ------------ Accuracy: 58.1%\n",
            "Step: 4988 ------------ Loss: 8725.53 ------------ Accuracy: 58.1%\n",
            "Step: 4989 ------------ Loss: 8725.46 ------------ Accuracy: 58.6%\n",
            "Step: 4990 ------------ Loss: 8725.46 ------------ Accuracy: 58.6%\n",
            "Step: 4991 ------------ Loss: 8725.44 ------------ Accuracy: 58.1%\n",
            "Step: 4992 ------------ Loss: 8725.1 ------------ Accuracy: 58.1%\n",
            "Step: 4993 ------------ Loss: 8725.03 ------------ Accuracy: 58.7%\n",
            "Step: 4994 ------------ Loss: 8725.02 ------------ Accuracy: 58.7%\n",
            "Step: 4995 ------------ Loss: 8725.01 ------------ Accuracy: 58.1%\n",
            "Step: 4996 ------------ Loss: 8724.07 ------------ Accuracy: 58.1%\n",
            "Step: 4997 ------------ Loss: 8724.07 ------------ Accuracy: 58.1%\n",
            "Step: 4998 ------------ Loss: 8724.06 ------------ Accuracy: 58.1%\n",
            "Step: 4999 ------------ Loss: 8724.05 ------------ Accuracy: 58.1%\n",
            "Step: 5000 ------------ Loss: 8724.04 ------------ Accuracy: 58.1%\n",
            "\n",
            " Time taken: 2518.14 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "# fit model\n",
        "model.fit(X_train, Y_train, type=\"BCGD_R\", alpha=0.0001, max_iter=5000, threshold=100)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"\\n Time taken: {np.round(end_time - start_time,2)} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AVh6zVS5jLYY",
        "outputId": "897f3a1c-48a4-4531-84a5-3d672c973012"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAHHCAYAAACle7JuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABX2klEQVR4nO3dd3xN9/8H8NfNutlTJknEqBVBgkiNKInUKppWpTalWtTo0LRV1RV0oIOWavh9CUpRWqP2qhliNG2MUlQGIlvm/fz+OHKTKzdk3JuTG6/n43Ee995zPvdz3vdQ593P+QyFEEKAiIiIyAAZyR0AERERUVUxkSEiIiKDxUSGiIiIDBYTGSIiIjJYTGSIiIjIYDGRISIiIoPFRIaIiIgMFhMZIiIiMlhMZIiIiMhgMZEheszt27cPCoUC+/btkzsUIqJKYyJDpEPLly+HQqHAyZMn1fu2bt2KDz74QL6g7lu0aBGWL18udxgVtmHDBigUCvzwww/lltm5cycUCgW++uor9b4tW7YgODgYLi4usLS0RKNGjTB48GBs3769wucuKiqCh4cHFAoFtm3bVq3fQUT6xUSGSM+2bt2K2bNnyx1GuYlMt27dcO/ePXTr1q3mg3qIvn37ws7ODjExMeWWiYmJgbGxMYYMGQIA+Pzzz/HMM89AoVAgMjIS8+fPR3h4OC5evIg1a9ZU+Nx79uxBYmIiGjZsiFWrVlX7txCR/pjIHQARVZ4QArm5ubCwsKh2XUZGRjA3N9dBVLqlVCrx3HPPITo6Gjdv3oSHh4fG8dzcXGzcuBGhoaFwcXFBYWEhPvroI4SGhuL3338vU19KSkqFz71y5Ur4+/tj5MiReOedd5CdnQ0rK6tq/yZdKywshEqlgpmZmdyhEMmGLTJEejRq1Ch8++23AACFQqHeiqlUKixYsACtWrWCubk5XF1d8fLLL+Pu3bsa9TRs2BD9+vXDjh070L59e1hYWOD7778HAERHR6NHjx5wcXGBUqlEy5YtsXjx4jLf//PPP7F//351DN27dwdQfh+ZdevWISAgABYWFqhXrx6GDRuG//77r8zvs7a2xn///YeBAwfC2toazs7OeOONN1BUVKRRds2aNQgICICNjQ1sbW3RunVrLFy48KHXb9iwYVCpVFpbU3777Tekp6dj6NChAIDbt28jIyMDnTt31lqXi4vLQ89V7N69e9i4cSOGDBmCwYMH4969e/jll1+0lt22bRuCg4PVv6lDhw5lWpCOHTuGPn36wMHBAVZWVvDz89P43d27d1f/WZQ2atQoNGzYUP356tWrUCgU+Pzzz7FgwQI0btwYSqUS8fHxyM/Px/vvv4+AgADY2dnBysoKXbt2xd69e8vUq1KpsHDhQrRu3Rrm5uZwdnbG008/rX4cGhwcjDZt2mj9vc2aNUNYWNijLiFRjWIiQ6RHL7/8MkJDQwEA//vf/9Rb6eNvvvkmOnfujIULF2L06NFYtWoVwsLCUFBQoFFXQkICIiIiEBoaioULF6Jt27YAgMWLF8Pb2xvvvPMOvvjiC3h6euLVV19VJ1AAsGDBAjRo0ADNmzdXx/Duu++WG/fy5csxePBgGBsbIyoqCuPGjcOGDRvQpUsXpKWlaZQtKipCWFgYnJyc8PnnnyM4OBhffPEFlixZoi6zc+dOREREwMHBAXPnzsWcOXPQvXt3HD58+KHXr1u3bmjQoIHWx0sxMTGwtLTEwIEDAUiJioWFBbZs2YLU1NSH1vswmzdvRlZWFoYMGQI3Nzd0795d6+Ol5cuXo2/fvkhNTUVkZCTmzJmDtm3bavTF2blzJ7p164b4+HhMmTIFX3zxBZ566in8+uuvVY4vOjoaX3/9NcaPH48vvvgCjo6OyMjIwA8//IDu3btj7ty5+OCDD3Dr1i2EhYUhLi5O4/tjx47F1KlT4enpiblz5+Ltt9+Gubk5jh49CgAYPnw4zp49i/Pnz2t878SJE7hw4QKGDRtW5diJ9EIQkc5ER0cLAOLEiRPqfRMnThTa/lM7ePCgACBWrVqlsX/79u1l9nt7ewsAYvv27WXqycnJKbMvLCxMNGrUSGNfq1atRHBwcJmye/fuFQDE3r17hRBC5OfnCxcXF+Hr6yvu3bunLvfrr78KAOL9999X7xs5cqQAID788EONOtu1aycCAgLUn6dMmSJsbW1FYWFhmfM/yptvvikAiISEBPW+9PR0YW5uLiIiIjTKvv/++wKAsLKyEr179xaffPKJiI2NrdT5+vXrJzp37qz+vGTJEmFiYiJSUlLU+9LS0oSNjY0IDAzUuEZCCKFSqYQQQhQWFgofHx/h7e0t7t69q7WMEEIEBwdr/XMZOXKk8Pb2Vn++cuWKACBsbW01Yik+V15ensa+u3fvCldXVzFmzBj1vj179ggA4rXXXitzvuKY0tLShLm5uZgxY4bG8ddee01YWVmJrKysMt8lkhNbZIhksm7dOtjZ2SE0NBS3b99WbwEBAbC2ti7zWMDHx0drs37pfjLp6em4ffs2goOD8c8//yA9Pb3ScZ08eRIpKSl49dVXNfrO9O3bF82bN8dvv/1W5jsTJkzQ+Ny1a1f8888/6s/29vbIzs7Gzp07Kx1PcQtA6VaZn3/+Gbm5uerHSsVmz56NmJgYtGvXDjt27MC7776LgIAA+Pv746+//nrkue7cuYMdO3YgIiJCvS88PBwKhQI//fSTet/OnTuRmZmpbs0orfjR4enTp3HlyhVMnToV9vb2WstURXh4OJydnTX2GRsbq/vJqFQqpKamorCwEO3bt8epU6fU5X7++WcoFArMmjWrTL3FMdnZ2WHAgAFYvXo1hBAApFa3tWvXYuDAgbWyrxA93pjIEMnk4sWLSE9Ph4uLC5ydnTW2rKysMp1TfXx8tNZz+PBhhISEwMrKCvb29nB2dsY777wDAFVKZP79918AUn+IBzVv3lx9vFhxP4vSHBwcNPr5vPrqq3jiiSfQu3dvNGjQAGPGjKnwcGg/Pz/4+vpi9erV6n0xMTGoV6+e1sQuIiICBw8exN27d/H777/jxRdfxOnTp9G/f3/k5uY+9Fxr165FQUEB2rVrh0uXLuHSpUtITU1FYGCgxuOly5cvAwB8fX3LrasiZaqivL8HK1asgJ+fH8zNzeHk5ARnZ2d1P6LSMXl4eMDR0fGh5xgxYgSuXbuGgwcPAgB27dqF5ORkDB8+XHc/hEhHOGqJSCYqlQouLi7lDu99MDnQNkLp8uXL6NmzJ5o3b44vv/wSnp6eMDMzw9atWzF//nyoVCq9xF6asbHxI8u4uLggLi4OO3bswLZt27Bt2zZER0djxIgRWLFixSO/P2zYMLz99ts4efIkGjRogL179+Lll1+GiUn5/4TZ2toiNDQUoaGhMDU1xYoVK3Ds2DEEBweX+53iP4vyOgz/888/aNSo0SPjrQyFQqFu+Sjtwc7SxbT9PVi5ciVGjRqFgQMH4s0334SLi4u6f1NxQlUZYWFhcHV1xcqVK9GtWzesXLkSbm5uCAkJqXRdRPrGRIZIz8p7jNC4cWPs2rULnTt3rvIw6i1btiAvLw+bN2+Gl5eXer+20SoVfZzh7e0NQOpc3KNHD41jCQkJ6uOVZWZmhv79+6N///5QqVR49dVX8f3332PmzJlo0qTJQ78bERGByMhIxMTEwNvbG0VFRWUeKz1M+/btsWLFCiQmJpZb5sqVK/jjjz8wadKkMsmOSqXC8OHDERMTg/feew+NGzcGAJw/f77c2EuXeVgC4ODgoPEYrtiDLV8Ps379ejRq1Eg9iWCxBx8hNW7cGDt27EBqaupDW2WMjY3x4osvYvny5Zg7dy42bdqEcePGVShpJappfLREpGfFfQoeHO0zePBgFBUV4aOPPirzncLCwjLltSm+sZT+P/r09HRER0drjaMidbZv3x4uLi747rvvkJeXp96/bds2/PXXX+jbt+8j63jQnTt3ND4bGRnBz88PADTOUR4vLy907doVa9euxcqVK+Hj44Mnn3xSo0xOTg6OHDmi9fvFs/Nqe1xWrLg15q233sJzzz2nsQ0ePBjBwcHqMr169YKNjQ2ioqLKPK4q/rPw9/eHj48PFixYUOa6l/7zaty4Mf7++2/cunVLve/MmTOPHNFVmra/B8eOHStzPcLDwyGE0DpB44OtQsOHD8fdu3fx8ssvIysri6OVqNZiiwyRngUEBAAAXnvtNYSFhalnog0ODsbLL7+MqKgoxMXFoVevXjA1NcXFixexbt06LFy4EM8999xD6+7Vq5e6paP4hrN06VK4uLiUaX0ICAjA4sWL8fHHH6NJkyZwcXEp0+ICAKamppg7dy5Gjx6N4OBgREREIDk5GQsXLkTDhg0xbdq0Sl+Dl156CampqejRowcaNGiAf//9F19//TXatm2LFi1aVKiOYcOGYfz48bh586bWoeM5OTl48skn0alTJzz99NPw9PREWloaNm3ahIMHD2LgwIFo165dufWvWrUKbdu2haenp9bjzzzzDCZPnoxTp07B398f8+fPx0svvYQOHTrgxRdfhIODA86cOYOcnBysWLECRkZGWLx4Mfr374+2bdti9OjRcHd3x99//40///wTO3bsAACMGTMGX375JcLCwjB27FikpKTgu+++Q6tWrZCRkVGha9OvXz9s2LABgwYNQt++fXHlyhV89913aNmyJbKystTlnnrqKQwfPhxfffUVLl68iKeffhoqlQoHDx7EU089hUmTJqnLtmvXDr6+vli3bh1atGgBf3//CsVCVOPkGzBFVPdoG35dWFgoJk+eLJydnYVCoSgzFHvJkiUiICBAWFhYCBsbG9G6dWvx1ltviZs3b6rLeHt7i759+2o95+bNm4Wfn58wNzcXDRs2FHPnzhU//vijACCuXLmiLpeUlCT69u0rbGxsBAD1kN8Hh18XW7t2rWjXrp1QKpXC0dFRDB06VNy4cUOjzMiRI4WVlVWZmGbNmqXxO9evXy969eolXFxchJmZmfDy8hIvv/yySExMfOj1LC01NVUolUoBQMTHx5c5XlBQIJYuXSoGDhwovL29hVKpFJaWlqJdu3bis88+KzM8ubTY2FgBQMycObPcMlevXhUAxLRp09T7Nm/eLJ588klhYWEhbG1tRceOHcXq1as1vnfo0CERGhoqbGxshJWVlfDz8xNff/21RpmVK1eKRo0aCTMzM9G2bVuxY8eOcodff/bZZ2ViU6lU4tNPP1X/7nbt2olff/21TB1CSH8fP/vsM9G8eXNhZmYmnJ2dRe/evbUOU583b54AID799NNyrwuR3BRCaOllRkREj72FCxdi2rRpuHr1qkYfLKLahIkMERGVIYRAmzZt4OTkpLXzOFFtwT4yRESklp2djc2bN2Pv3r04d+5cuetMEdUWbJEhIiK1q1evwsfHB/b29nj11VfxySefyB0S0UMxkSEiIiKDxXlkiIiIyGAxkSEiIiKDVec7+6pUKty8eRM2NjbVWnGWiIiIao4QApmZmfDw8ICR0UPaXeSawKbYjRs3xNChQ4Wjo6MwNzcXvr6+GpOJqVQqMXPmTOHm5ibMzc1Fz549xYULFypc//Xr1wUAbty4cePGjZsBbtevX3/ofV7WFpm7d++ic+fOeOqpp7Bt2zY4Ozvj4sWLcHBwUJeZN28evvrqK6xYsQI+Pj6YOXMmwsLCEB8fD3Nz80eew8bGBgBw/fp12Nra6u23EBERke5kZGTA09NTfR8vj6yjlt5++20cPnwYBw8e1HpcCAEPDw+8/vrreOONNwBIC+K5urpi+fLlGDJkyCPPkZGRATs7O6SnpzORISIiMhAVvX/L2tl38+bNaN++PZ5//nm4uLigXbt2WLp0qfr4lStXkJSUhJCQEPU+Ozs7BAYGlrvKbV5eHjIyMjQ2IiIiqptkTWT++ecfLF68GE2bNsWOHTvwyiuv4LXXXsOKFSsAAElJSQAAV1dXje+5urqqjz0oKioKdnZ26q28lWyJiIjI8MmayKhUKvj7++PTTz9Fu3btMH78eIwbNw7fffddleuMjIxEenq6ert+/boOIyYiIqLaRNbOvu7u7mjZsqXGvhYtWuDnn38GALi5uQEAkpOT4e7uri6TnJyMtm3baq1TqVRCqVRWOpaioiIUFBRU+nskH1NTUxgbG8sdBhERyUjWRKZz585ISEjQ2HfhwgV4e3sDAHx8fODm5obdu3erE5eMjAwcO3YMr7zyik5iEEIgKSkJaWlpOqmPapa9vT3c3Nw4RxAR0WNK1kRm2rRpePLJJ/Hpp59i8ODBOH78OJYsWYIlS5YAABQKBaZOnYqPP/4YTZs2VQ+/9vDwwMCBA3USQ3ES4+LiAktLS94QDYQQAjk5OUhJSQEAjRY7IiJ6fMiayHTo0AEbN25EZGQkPvzwQ/j4+GDBggUYOnSousxbb72F7OxsjB8/HmlpaejSpQu2b99eoTlkHqWoqEidxDg5OVW7PqpZFhYWAICUlBS4uLjwMRMR0WOozq9+/bBx6Lm5ubhy5QoaNmyovimSYbl37x6uXr0KHx8fnSS3RERUOxjEPDK1BR8nGS7+2RERPd6YyBAREZHBYiJDREREBouJDBERERksJjKkE5xMkIjoMZHzH1CQARRmS68yjxliImOgtm/fji5dusDe3h5OTk7o168fLl++rD5+48YNREREwNHREVZWVmjfvj2OHTumPr5lyxZ06NAB5ubmqFevHgYNGqQ+plAosGnTJo3z2dvbY/ny5QCAq1evQqFQYO3atQgODoa5uTlWrVqFO3fuICIiAvXr14elpSVat26N1atXa9SjUqkwb948NGnSBEqlEl5eXvjkk08AAD169MCkSZM0yt+6dQtmZmbYvXu3Li4bERFVx+kZwKYGwDo74Cdr6XX/M7KGJOs8MrWOEEBRjjznNrYEKjECJzs7G9OnT4efnx+ysrLw/vvvY9CgQYiLi0NOTg6Cg4NRv359bN68GW5ubjh16hRUKhUA4LfffsOgQYPw7rvv4v/+7/+Qn5+PrVu3Vjrkt99+G1988QXatWsHc3Nz5ObmIiAgADNmzICtrS1+++03DB8+HI0bN0bHjh0BSGthLV26FPPnz0eXLl2QmJiIv//+GwDw0ksvYdKkSfjiiy/Uy0ysXLkS9evXR48ePSodHxER6djtI2X33fy15uMohYlMaUU5UoYph8FZgIlVhYuHh4drfP7xxx/h7OyM+Ph4/PHHH7h16xZOnDgBR0dHAECTJk3UZT/55BMMGTIEs2fPVu9r06ZNpUOeOnUqnn32WY19b7zxhvr95MmTsWPHDvz000/o2LEjMjMzsXDhQnzzzTcYOXIkAKBx48bo0qULAODZZ5/FpEmT8Msvv2Dw4MEAgOXLl2PUqFEcZk1EVBuoal83Aj5aMlAXL15EREQEGjVqBFtbWzRs2BAAcO3aNcTFxaFdu3bqJOZBcXFx6NmzZ7VjaN++vcbnoqIifPTRR2jdujUcHR1hbW2NHTt24Nq1awCAv/76C3l5eeWe29zcHMOHD8ePP/4IADh16hTOnz+PUaNGVTtWIiLSAVH7Ehm2yJRmbCm1jMh17kro378/vL29sXTpUnh4eEClUsHX1xf5+fmPnKX4UccVCgUenPBZW2deKyvNFqTPPvsMCxcuxIIFC9C6dWtYWVlh6tSpyM/Pr9B5AenxUtu2bXHjxg1ER0ejR48e6kVEiYjoAflpgKoQMDYDTLXMfluUCxTlAWZ2ujlfLWyRYSJTmkJRqcc7crlz5w4SEhKwdOlSdO3aFQBw6NAh9XE/Pz/88MMPSE1N1doq4+fnh927d2P06NFa63d2dkZiYqL688WLF5GT8+i+Q4cPH8aAAQMwbNgwAFLH3gsXLqBly5YAgKZNm8LCwgK7d+/GSy+9pLWO1q1bo3379li6dCliYmLwzTffPPK8RESPpaRdwJ7Qks8h+wGli/ReFAFm9sDvQUDOdaDvn9L9zdgSgJBe824B1j7l168qBDIvAFbeJfdGVb72svl3ATMHXfyqSmMiY4AcHBzg5OSEJUuWwN3dHdeuXcPbb7+tPh4REYFPP/0UAwcORFRUFNzd3XH69Gl4eHggKCgIs2bNQs+ePdG4cWMMGTIEhYWF2Lp1K2bMmAFAGj30zTffICgoCEVFRZgxYwZMTU0fGVfTpk2xfv16/PHHH3BwcMCXX36J5ORkdSJjbm6OGTNm4K233oKZmRk6d+6MW7du4c8//8TYsWPV9RR3+rWystIYTUVE9FjKSwVMbQCjB/4djp2i+XlXcPl1/NZK+/7m04HG9//HMu82YOUlJTAKBbC5cUm5wTmAiUX5LTJXVgHNJmk/pmfsI2OAjIyMsGbNGsTGxsLX1xfTpk3DZ599pj5uZmaG33//HS4uLujTpw9at26NOXPmqFeH7t69O9atW4fNmzejbdu26NGjB44fP67+/hdffAFPT0907doVL774It544w1YWj760dd7770Hf39/hIWFoXv37nBzc8PAgQM1ysycOROvv/463n//fbRo0QIvvPACUlJSNMpERETAxMQEERERXAiSiAyPEEDeHek1+5r2eVby7wJC9ei6Mi4CG92ArW2A7H9L6sr5D0iP1yxr5iBtlXmy8PeXwG8tpW1XN+CXhsCWJppJDAD8twVI/wtQ5Wmvx9Sm4ufUMa5+feUKV06uZa5evYrGjRvjxIkT8Pf3f2hZ/hkSUa1zcgpw4SvArqWUbDwxCWj3hdSPBZASgt9aAg0GAN02aa8j54bU/+XqKiB+Tsl+9zCg4TDgyHDN8k/HAo6l/r2M0fNIzy7rgPMfAS3fBhpG6OUUFV39mo+WqNYoKCjAnTt38N5776FTp06PTGKIiB6pIAO4lyS9t2laMl+XEFIfEXOXitWTLY2+hLElUJAO2DQGcm9L/VCMSt1KC7KkJAYoaTG58A1w+QdgUJLU6fbid9L+G79oP9edk8CODtqPJe6QttJe1NIeMSQf2D9A6gNzcZH2sv/9CpybDTy5Crh9FDg6Uvs5tbFtAfQ5U/HyesREhmqNw4cP46mnnsITTzyB9evXyx0OEdUWqiLg3n+AwgSwcJMesVh6Agoj6RGO8f0Rkab35wEryJQe3SidpJlni7WJAppNlpKYi4uBuLeAtnOBlm+Vf24hgL+/AE6/qbm/4XDg6v8Az2eBTtHAvWSg6B5QWM7I16JcYL090H07kH6+ZH/ubcC8nhRz1j/SvvKSGAAwUkrJUO79R/JtPi2nnCnw1P2JTn3fA/b1A5qM1yxTv5+0AYDtE0CjEWXrESrgyEjpcVXOf0DqccDeD7BtVn6MNYyPlvhYwqDxz5Cojsi+LnU2FYVSkmLhJnVyzbsNnHq9ZPZYhYlUxrmLdFNPLrV8yTP/AOZuwE/3+/RZNypJDgDA/WkgcXvZc/e/CNg0kW7ad05II3OM7g9n/usz4J9o/f3u1rOlx0W/d3pEuQ+A1rP0F0ctxEdLRESkX/l3Sx6fGFsAlg2kRzVCABl/Sa0QJtbS/+0XEyrpO6p8qRXCyARIPQXEvqZZd8elwPFxZc8pCqXXW4fKHtvcSPNz6SQG0J7EAMCWpsBzqcAfw4Gbv5X/eyvL1FZ6tPUw52ZJWzFzNyD3/qOwgIXSHDD/rikZWURlMJEBykz+RoaDf3ZEOpSbIiUemZekJVuESnqEoMqXHptY+ZT0MSnIAjZ5A4WZJd83UgIDrgCXfwTOvleyP/AHoPH9KRbiIoG/5j06Fm1JjD6t1z4T+iMZmZY/JPn5dM3PZ94F/vwUqPckcPsPaZ+FOwCFtDV9BfB9t2w9Ld8su4/UHutEpnhulJycnArNOku1T/FEfRWZ54aIHiL7X2no7cN0WAw0nSC1dNw+ppnEANLQ3KRdwMVvpc/Fj4FubpP6VQBA8h7tdds2Azz6Sf1RyuMeBqSdl/rLPEz9/tLjqf82A04dpURqXz8g+ypw7+bDv6uNY3sgYAFwchLgNRhoFam93GrTkhYjMy2JUZtPpI106rHuIwMAiYmJSEtLg4uLCywtLbk4oYEQQiAnJwcpKSmwt7eHu7u73CERGRZVkdTptChPamX5/cmSm/DDBP8K7O9Xdr9zl7KPe9zDyo6wKdZhMXBqmvT4qdcxoF5HaX9eKnBggFSXbXMg429p/+BswKTUfFb//Qrs71/yueEw4Mn/PTr+0nJTgA2u5R937gy4hVa8b0rWVWDz/Zlynz4JOAZULh7SUNE+Mo99IiOEQFJSEtLS0mo+OKo2e3t7uLm5MQElKk9BFpCXAuSnS4mKXUsg7RwQNwNIOVD+98xdSkbGlMfCQ2rhaDtXmgb/QqklRZy7SsnK0dHS+UuzbgIEb5FmiiUqBzv7VpBCoYC7uztcXFy0LoxItZepqal6tmIiekBuCnAvEdjWtmrf73Me2NsLuBun/fhTvwPupdb5KciSHvvk3JCG+za6PyfJ08e1f59IRx77RKaYsbExb4pEVLvlpUqjgQoyAYd20pwl9xKlUS4mVoCpvdSSkhoLHH6hcnVbNwJgBBibA/WCAHNnoOnEsp1urRtJfVBKJzGANIdLyN7q/DqiKmEiQ0SkL0JILRqFWVJ/CWNzIO0sYNNMeqyS/jeQf6fkGCD1s0j/UxolZO4C2DwBZF0BVLnA7h66jc+6sTSHSnmPZpu8BLgEA8fGAK3eATx66/b8RDrARIaISF8ufAvETpbeK50A1x7AtXWAiQ3QeAyQsPD+sXpA0EopqfljqO7j6LgEaDIOKLwnrdHjFiKNPqoI26ZA6EHdx0SkI499Z18iIr1QFQFrdPz/irbNgYZDgbMzS/aZOQL5qWXLtngLuHMU8J+vuZggkYFgZ18iIjmdml6979d7UuqnkpEgLdDXZa00+RoA3DkO/LdFeh+8WRomTPSYYiJDRKRrhfdKVkA2tZX6yAiVNOz4mYvAtnYlo4GePiWt5XPha8CpExC4BLBv/fD6u6wDjo2VhjgziaHHHB8tERGVVpQLXN8EuHaXFiy0bVbSElJafpo03Ni+FZB6GoCq5NipN4C0M9L78DvSrLmnpgGt3i072oeItOKjJSKq24RKmvXVuhFwbT0AhTTzq8JYGvGjMJGmzFfWk9YAsmkM3PpDelyTfU1a40ZhIs234ugvLWyYnwasd9A8j3VjoMOi+x8U91dGNgX2hj06RteegNJR2kL26fb3ExEAJjJEZGhUhdKCe+c/AZJ+1129vY4AR8eU3Z91uWJJi7ElYNOk5LO5G9B5te7iIyKtmMgQkWE5/xFw/kPd1/t7UDkHFIBDm7Iz3No8AWReABzaAk6B0nT8XCqDqMYxkSEiw5J5SXo1MgVUBdKjJFFUcrzZFODiYukRkKkdMPAacGQEcOMXzXo8+gI3f9N+jsFZ0ky5pf3aomQBQysfoH+Cbn4PEVULExkiMiyqXOk1YCHQ9BXtZQIWaH7utqn8+v4YAVwttWpyq/fKJjEAEPCVtPYQII0sIqJagYkMERmWojzp1chcN/UFLZf62uQmA/0uSDPZauMeCrxYpwd5EhkkJjJEVHtkXARubATM7AG71oCzln4rOdekV2MdJTIKI+DZJN3URUQ1jokMEVWOqghI2Q+Yu0pzqJQmVEDKQWnIc9YlaYSRKATcQqUhyACQcwO4shJo+jKQd0daqRkKoCgHODpasz7/LwGrhtJ7q4ZSvWnnpM+5TD6ISOZE5oMPPsDs2bM19jVr1gx//y11qOvevTv279+vcfzll1/Gd999V2MxEtVJ+XeBy9HAExMBY2XFvpNyUEoibm4Dbv4qzcEy8Dpg4QYUZgOpp6ROtv+WM+S468/SatCHnpM+n4l89DkfNs1//t2KxU1EdZrsLTKtWrXCrl271J9NTDRDGjduHD78sGSopaWlZY3FRlRrpf8FmFhLU98rnQHzehX/bva/wC8NpfenX5emuy9WkA4U5kiTxQkVkB4P2LWUEpg/P9asRxQCl5dJM98eHS3F8jAHwyseY7F6T0qvt/8oe6zl25Wvj4jqHNkTGRMTE7i5uZV73NLS8qHHiR47yfuA3U9p7uuXILVQ1Ass/3tFuUDiTuDAM5r7Dz1f9VjOvqd9v4U74B0hPQo68w5g6QlYeUvHUmOlmXfNXaV9d44DjcYAHb8HjMr5J+nERODi/dl1rbyBAVerHjMR1SmyJzIXL16Eh4cHzM3NERQUhKioKHh5eamPr1q1CitXroSbmxv69++PmTNnslWGHk/p8UDmReDAwLLHfm0mvXbbBDQYoHmsIEtKHi4v0xxmDAAWHtIU/AAAAdw6JL21bizNaFvMuStw66CURPSNl/rI/PWZ1AcGkCaGy00GGg4DOv2ouTZRqwo8QnqUNp8Cebek5QQaj6t+fURUZ8i6aOS2bduQlZWFZs2aITExEbNnz8Z///2H8+fPw8bGBkuWLIG3tzc8PDxw9uxZzJgxAx07dsSGDRvKrTMvLw95eXnqzxkZGfD09OSikWTYCjKADa5Sq8qjNH0VsPcDknZJfWAuLgKurdMs0/4b6diDYu7PTBuyH9jfXzqvfRugT1y1fwIRUWVUdNHIWrX6dVpaGry9vfHll19i7NixZY7v2bMHPXv2xKVLl9C4cWMtNWjvQAyAiQzVPul/SzPL+ozU3sdFCODSEqkvSmEOEPdW2TLtvwFOTqrceQdcA6w8tR+7+J00e63/fGlK/r8+A9p8Alj7VO4cRETVZJCJDAB06NABISEhiIqKKnMsOzsb1tbW2L59O8LCtC/ixhYZqpVURVILSUEa4NQBSNoDHL//iMSxA/D08bLfubwMOPZS+XVaeQPPXAFOTgYuflvxWCJUXBOIiGq9iiYyRjUY0yNlZWXh8uXLcHd313o8Li4OAMo9DgBKpRK2trYaG5Hs/l0N7HsaODwE2Ny4JIkBgNQTJe8zLwPx84BbfwDxc0v2u/YEHAM06+x/UUpIOnwjzTjr+37JsaavSq9mjoBrD83vMYkhojpE1haZN954A/3794e3tzdu3ryJWbNmIS4uDvHx8cjIyEBMTAz69OkDJycnnD17FtOmTUODBg3KzC3zMBXN6MjA3UsC/vocaPVOycRrD1IVAkk7pZWKyyvzMEIA13+WWlZavSt1vM2/Kz3+6RwDKJ1Kyt7YAqT/KY3MMXcGrvwPuPZT+XWHHABsmwMbXLQfr+7U+AeelWbMfT4TMLWuXl1ERDWgovdvWUct3bhxAxEREbhz5w6cnZ3RpUsXHD16FM7OzsjNzcWuXbuwYMECZGdnw9PTE+Hh4XjvvXKGe9Lj6W6ctObOby2kz39/IY2wsWsFOLWXVkYGpEUA7yUBsa9JnwO+BgozpFlmHdoBRmbSpG7p56WVjfNuATZNpf4pubelPiWJO4F/Y6TvX/peM46f6wGdoqX3KQeAf6IfHbtTIHDnmPR+V7dqXYZH6lZ+B3kiIkNW6/rI6BpbZGqhonzg8lJAVSCtqQMAbiGAZYNHfzc/DbjwLdB0gtTisStYn5HqT8u3pWHJ6+weXdZICQypwGglIqI6xCBaZOgxdXERcGpa2f09dgPZV6Sp701tANsW0qOZM5GAg780WVpx59fyJmJ7kHtvac6Tohzdxf+o8wFA4jbp1a6V1Bpk5iQlbW3nlowYEirtdQRvAer3KxkKXdyqREREZTCRoZpX3lo8e3pWr15TW2neE/Vne+CprcC5D4Fzsx7+3XafSYlF3AygTRSQmQD4jACyr0uJUMAC6TFQ7FRAFAHtPgf29ytbz1NbKx6vopy+9vXv12ukBFR5gFPHitdJRPSYYSJDuqcqkIYOX1sPNIwAfEYBRqVaFfLu6P6c5m5A79NSIlM8y23X+5PANZ8mrZTs9QLg0AaIiwQ8+kj9Ze79BzyXBpjcny26pZa5WhqNkF7dQoC+50v2F3fA/WMYcHUV8OSqyscd9D+pA3Lr2dKcLaVn5X36BHDhG83RSEREpIF9ZEj3zn8MnJ1Z8jnwR6Dx6JLPP9loLjDY4i3gr3nSe+fOwK3DZev0nw9cWSF17i3NZwQQtEJnoRMRUe3APjJ1VfY14O8F0lDfRiMr1kFWn/JSgf+2AM5dgH+WS8OaSycxAHBsjLSYYcYFaW2f4iSmXhDQ4k3Ac5DUEvHPj0DrD6U1fg4MkFpXRJGUrDQZL63jc+ZtoP4zwPmPpBWZOy6t8Z9MRES1B1tkarubOwDbZoB1Q+nzz85A3u2S49WZXyQ/Dbi+AUj8XXrEYtcK8OhddtHBhzn8Yvl9Xh7lubslo5aIiIhKYYuMoRMq4OgY6XEKIK3HY2SimcQAwOUfgaJ7gNJZahlp82n56+g8aF8f4PaRks+3Dknzowy6CViUP3uyWmps1ZOYZlOYxBARUbWxRaa2KcyRZo9N+ApIPVm1OkIPSbPOJv4O2DwB5CYC5u7SYyiv56QEoiATWFfO9aj3JNDxO+kxVv2+QPJeKVGy95WOF2RJHVPPf1h+DIHLgMZjgKwrwOZGZY8PKZASMyIiIi3YImOo4uc+PEGoiJ1dyj92fjbQcx9w4evyy9z+A9jqJ7238pHmdgGArhuBlH3Av2ulUUDleSEXMFZK7619gD5npfWDrq6U9rWMZBJDREQ6wRaZ2iZGhgX9huQDRqbA3qeBxB2V+65LsDTPCiDV0esY4NhO9zESEdFjxSBXv37s5adp329kKnXqDXhIK0r3bdJcJOVpOKz8Y0am98sMfWSIZbSeBQT+AHRYLCVETGKIiKgGsX2/Njn0gvb9LSOlV9snyv+ux9OAe5iUlGT8DTR9VRryXNqd40DmhfLraDAQaDYNKMoGfGcCJtbAycklj4SKeQ+R6vJ+EXDpDrg+9ahfRkREpBdMZGqTpN81Pz99Cri2FmjxuvTZLRRo8jJw6yCQkSDNsQJII5oAQKGQFiIsj71f2USm9+mS96Y2QMCXmsef/B9Qvz9w+H6S1X2blDQRERHVAkxkajPHdpqPahQKaTQRANw+Ji2caFEfCFhYsfrafw1YN5Iml7NpXPE4vJ4D/g6UFj90D6v494iIiPSMnX1rkwc7+lZnsjsiIiIDxs6+hsy5K9DrqNxREBER1Xp8tFRbCAEojKQZfTuvBizryx0RERFRrccWmdqi6J6UxACAaS1/BEZERFRLMJGpLQoyS96bWMkXBxERkQFhIlNbFN5PZEyspUdMRERE9Ei8Y9YWxS0ypjbyxkFERGRAmMjUFrcOSa8mTGSIiIgqiqOW5HY1RpqkLvY16fPDlhAgIiIiDUxk5HTnBPBHFRZqJCIiIgB8tCSvOyfkjoCIiMigMZGR093TZff5f1l2HxEREWnFREZORsqy+1x71nwcREREBoqJjJxUuWX3OfjVfBxEREQGiomMnIoeSGSC/idPHERERAaKiYycHkxkHNrJEwcREZGBYiIjp5T9mp/NXeWJg4iIyEAxkZGLEEDebc195vXkiYWIiMhAMZGRS3q83BEQEREZPCYycsm5IXcEREREBo+JjFz+/EjuCIiIiAweExk5pMYCtw7LHQUREZHBYyIjh7xUuSMgIiKqE5jIyMHUTu4IiIiI6gQmMrIQcgdARERUJ8iayHzwwQdQKBQaW/PmzdXHc3NzMXHiRDg5OcHa2hrh4eFITk6WMWIdEYVyR0BERFQnyN4i06pVKyQmJqq3Q4cOqY9NmzYNW7Zswbp167B//37cvHkTzz77rIzR6oiKiQwREZEumMgegIkJ3NzcyuxPT0/HsmXLEBMTgx49egAAoqOj0aJFCxw9ehSdOnWq6VB1hy0yREREOiF7i8zFixfh4eGBRo0aYejQobh27RoAIDY2FgUFBQgJCVGXbd68Oby8vHDkyJFy68vLy0NGRobGVuuwRYaIiEgnZE1kAgMDsXz5cmzfvh2LFy/GlStX0LVrV2RmZiIpKQlmZmawt7fX+I6rqyuSkpLKrTMqKgp2dnbqzdPTU8+/ogrYIkNERKQTsj5a6t27t/q9n58fAgMD4e3tjZ9++gkWFhZVqjMyMhLTp09Xf87IyKh9yYy2RMbzuZqPg4iIyMDJ3kemNHt7ezzxxBO4dOkSQkNDkZ+fj7S0NI1WmeTkZK19aooplUoolcoaiLYaRFHJ++bTAaeOgEdf+eIhIiIyULL3kSktKysLly9fhru7OwICAmBqaordu3erjyckJODatWsICgqSMUodyLxc8r71B4D3C4CptWzhEBERGSpZW2TeeOMN9O/fH97e3rh58yZmzZoFY2NjREREwM7ODmPHjsX06dPh6OgIW1tbTJ48GUFBQYY9YgkAsq9Ir/ZtAFMbeWMhIiIyYLImMjdu3EBERATu3LkDZ2dndOnSBUePHoWzszMAYP78+TAyMkJ4eDjy8vIQFhaGRYsWyRmybhSPWnLuLG8cREREBk4hhKjT8+VnZGTAzs4O6enpsLW1lTscyeamQNYlIOAroNlkuaMhIiKqdSp6/65VfWQeG8bFnZHrdA5JRESkd0xk5GTXUu4IiIiIDBoTGTmoCqRXo1o+TJyIiKiWYyIjB3UiYypvHERERAaOiYwcBBMZIiIiXWAiI4fiFhkFExkiIqLqYCIjB1W+9GpkJm8cREREBo6JjBzYR4aIiEgnmMjUtCurgMIs6T0TGSIiomphIlPTjgwreW/mIF8cREREdQATGTlxwUgiIqJqYSJDREREBouJDBERERksJjJERERksJjIEBERkcFiIkNEREQGi4kMERERGSwmMkRERGSwmMjUJKGSOwIiIqI6hYlMTRJFckdARERUpzCRqUlMZIiIiHSKiUxNYiJDRESkU0xkalJhttwREBER1SkmcgdQ5wkBHBsrvfcZLm8sREREdQwTGX3Lvgr8Ey29r/ekrKEQERHVNXy0pG9FudrfExERUbUxkdE3VUGp93kl75u/XvOxEBER1TFMZPRNlE5k8qVXUzug7Vx54iEiIqpDmMjoW+kWmTvHpdeie4CRsTzxEBER1SFMZPStdCJzY9P9ffmyhEJERFTXMJHRt9KJDBEREekUExl9YyJDRESkN0xk9C15j9wREBER1VlMZPQtN0nuCIiIiOosJjL6lntL7giIiIjqLCYy+laQVvLeylt6DVgoSyhERER1DRMZfVMVlrwvXqLASClPLERERHUMExl9Kz2zrzqRMZMnFiIiojqGiYy+aW2RYSJDRESkC7UmkZkzZw4UCgWmTp2q3te9e3coFAqNbcKECfIFWRVCy6KRxkxkiIiIdMFE7gAA4MSJE/j+++/h5+dX5ti4cePw4Ycfqj9bWlrWZGjVp21CPIVpzcdBRERUB8neIpOVlYWhQ4di6dKlcHBwKHPc0tISbm5u6s3W1laGKKuh9KOlYny0REREpBOyJzITJ05E3759ERISovX4qlWrUK9ePfj6+iIyMhI5OTkPrS8vLw8ZGRkam6yEthYZrnxNRESkC7I+WlqzZg1OnTqFEydOaD3+4osvwtvbGx4eHjh79ixmzJiBhIQEbNiwodw6o6KiMHv2bH2FXHnaHi2lnQE8wmo+FiIiojpGtkTm+vXrmDJlCnbu3Alzc3OtZcaPH69+37p1a7i7u6Nnz564fPkyGjdurPU7kZGRmD59uvpzRkYGPD09dRt8ZeTd1rJTUeNhEBER1UWyJTKxsbFISUmBv7+/el9RUREOHDiAb775Bnl5eTA21nwEExgYCAC4dOlSuYmMUqmEUllLJpwrLOcxmM/wmo2DiIiojqp0ItOwYUOMGTMGo0aNgpeXV5VP3LNnT5w7d05j3+jRo9G8eXPMmDGjTBIDAHFxcQAAd3f3Kp+3RgktHX1tngAs3Go+FiIiojqo0p19p06dig0bNqBRo0YIDQ3FmjVrkJeXV+kT29jYwNfXV2OzsrKCk5MTfH19cfnyZXz00UeIjY3F1atXsXnzZowYMQLdunXTOky7VtI2Ysmjd83HQUREVEdVKZGJi4vD8ePH0aJFC0yePBnu7u6YNGkSTp06pbPAzMzMsGvXLvTq1QvNmzfH66+/jvDwcGzZskVn59C7B1tkum8D/OfLEwsREVEdpBBCiOpUUFBQgEWLFmHGjBkoKChA69at8dprr2H06NFQKOTv1JqRkQE7Ozukp6fX/Bw0OTeBTfUBhRHwfCZgYmCT+REREcmkovfvKnf2LSgowMaNGxEdHY2dO3eiU6dOGDt2LG7cuIF33nkHu3btQkxMTFWrrxtEkfSqMGUSQ0REpAeVTmROnTqF6OhorF69GkZGRhgxYgTmz5+P5s2bq8sMGjQIHTp00GmgBqn40ZJRrVgJgoiIqM6p9B22Q4cOCA0NxeLFizFw4ECYmpZdN8jHxwdDhgzRSYAGrbizr4KJDBERkT5U+g77zz//wNvb+6FlrKysEB0dXeWg6gy2yBAREelVpUctpaSk4NixY2X2Hzt2DCdPntRJUHWGYIsMERGRPlU6kZk4cSKuX79eZv9///2HiRMn6iSoOkP9aImLRBIREelDpROZ+Ph4jWUFirVr1w7x8fE6CarOiJ8jvbJFhoiISC8qncgolUokJyeX2Z+YmAgTE96wNWRdkV6NtS+KSURERNVT6USmV69eiIyMRHp6unpfWloa3nnnHYSGhuo0OIOmKgRST0jvO34vbyxERER1VKWbUD7//HN069YN3t7eaNeuHQBpMUdXV1f873//03mABuvOiZL3pjU8ozAREdFjotKJTP369XH27FmsWrUKZ86cgYWFBUaPHo2IiAitc8o8thSlGruMOasvERGRPlSpU4uVlRXGjx+v61jqmFLrTBkr5QuDiIioDqty79z4+Hhcu3YN+fn5GvufeeaZagdVJ5ROXqwePoEgERERVU2VZvYdNGgQzp07B4VCgeLFs4tXui4qKtJthIaqeDI8i/qaj5mIiIhIZyp9h50yZQp8fHyQkpICS0tL/Pnnnzhw4ADat2+Pffv26SFEA3X+E+mVHX2JiIj0ptItMkeOHMGePXtQr149GBkZwcjICF26dEFUVBRee+01nD59Wh9xGp68W9KrqY28cRAREdVhlW6RKSoqgo2NdHOuV68ebt68CQDw9vZGQkKCbqMzZKoC6bXVu/LGQUREVIdVukXG19cXZ86cgY+PDwIDAzFv3jyYmZlhyZIlaNSokT5iNEzFiYwRh6QTERHpS6UTmffeew/Z2dkAgA8//BD9+vVD165d4eTkhLVr1+o8QIMlmMgQERHpW6UTmbCwMPX7Jk2a4O+//0ZqaiocHBzUI5cIJS0yCiYyRERE+lKpPjIFBQUwMTHB+fPnNfY7OjoyiXkQHy0RERHpXaUSGVNTU3h5eXGumIpQ3Z8okIkMERGR3lR61NK7776Ld955B6mpqfqIp+4olPoRwchM3jiIiIjqsEr3kfnmm29w6dIleHh4wNvbG1ZWVhrHT506pbPgDFZRHpB/P9FjiwwREZHeVDqRGThwoB7CqGNyrpe8t24iXxxERER1XKUTmVmzZukjjrqlIEN6tagPGPPREhERkb5wNUN9KE5kuM4SERGRXlW6RcbIyOihQ605oglMZIiIiGpIpROZjRs3anwuKCjA6dOnsWLFCsyePVtngRk0JjJEREQ1otKJzIABA8rse+6559CqVSusXbsWY8eO1UlgBo2JDBERUY3QWR+ZTp06Yffu3bqqzrAxkSEiIqoROklk7t27h6+++gr169fXRXWGj4kMERFRjaj0o6UHF4cUQiAzMxOWlpZYuXKlToMzWPl3pVcmMkRERHpV6URm/vz5GomMkZERnJ2dERgYCAcHB50GZ7Au/yC9mtjIGwcREVEdV+lEZtSoUXoIo44xdwHu3QQsPeWOhIiIqE6rdB+Z6OhorFu3rsz+devWYcWKFToJyqAJAeSmSO+dO8sbCxERUR1X6UQmKioK9erVK7PfxcUFn376qU6CMmiiCBCF0ntTa3ljISIiquMqnchcu3YNPj4+ZfZ7e3vj2rVrOgnKoAlVqQ9cAYKIiEifKn2ndXFxwdmzZ8vsP3PmDJycnHQSlGErlcgomMgQERHpU6XvtBEREXjttdewd+9eFBUVoaioCHv27MGUKVMwZMiQKgcyZ84cKBQKTJ06Vb0vNzcXEydOhJOTE6ytrREeHo7k5OQqn6NGCCYyRERENaXSd9qPPvoIgYGB6NmzJywsLGBhYYFevXqhR48eVe4jc+LECXz//ffw8/PT2D9t2jRs2bIF69atw/79+3Hz5k08++yzVTpHjeGjJSIiohpT6eHXZmZmWLt2LT7++GPExcXBwsICrVu3hre3d5UCyMrKwtChQ7F06VJ8/PHH6v3p6elYtmwZYmJi0KNHDwDSiKkWLVrg6NGj6NSpU5XOp3ei1OrfbJEhIiLSq0onMsWaNm2Kpk2bVjuAiRMnom/fvggJCdFIZGJjY1FQUICQkBD1vubNm8PLywtHjhwpN5HJy8tDXl6e+nNGRka1Y6wcPloiIiKqKZW+04aHh2Pu3Lll9s+bNw/PP/98pepas2YNTp06haioqDLHkpKSYGZmBnt7e439rq6uSEpKKrfOqKgo2NnZqTdPzxqelI6PloiIiGpMpe+0Bw4cQJ8+fcrs7927Nw4cOFDheq5fv44pU6Zg1apVMDc3r2wY5YqMjER6erp6u379us7qrhB29iUiIqoxlb7TZmVlwczMrMx+U1PTSj3GiY2NRUpKCvz9/WFiYgITExPs378fX331FUxMTODq6or8/HykpaVpfC85ORlubm7l1qtUKmFra6ux1SiNREZRfjkiIiKqtkonMq1bt8batWvL7F+zZg1atmxZ4Xp69uyJc+fOIS4uTr21b98eQ4cOVb83NTXF7t271d9JSEjAtWvXEBQUVNmwa87tP+SOgIiI6LFR6c6+M2fOxLPPPovLly+rRxPt3r0bMTExWL9+fYXrsbGxga+vr8Y+KysrODk5qfePHTsW06dPh6OjI2xtbTF58mQEBQXV3hFLAHBxkdwREBERPTYqncj0798fmzZtwqeffor169fDwsICbdq0wZ49e+Do6KjT4ObPnw8jIyOEh4cjLy8PYWFhWLSolicKBZlyR0BERPTYUAghRHUqyMjIwOrVq7Fs2TLExsaiqKjo0V+qQRkZGbCzs0N6enrN9JfZ2gZIu7+Ew4vVurRERESPrYrev6s8rObAgQMYOXIkPDw88MUXX6BHjx44evRoVaurO9giQ0REVGMq9WgpKSkJy5cvx7Jly5CRkYHBgwcjLy8PmzZtqlRH3zot+4rcERARET02Ktwi079/fzRr1gxnz57FggULcPPmTXz99df6jI2IiIjooSrcIrNt2za89tpreOWVV3SyNAERERFRdVW4RebQoUPIzMxEQEAAAgMD8c033+D27dv6jI2IiIjooSqcyHTq1AlLly5FYmIiXn75ZaxZswYeHh5QqVTYuXMnMjPZyZWIiIhqVqVHLVlZWWHMmDE4dOgQzp07h9dffx1z5syBi4sLnnnmGX3ESERERKRVtVY1bNasGebNm4cbN25g9erVuoqJiIiIqEJ0sjyzsbExBg4ciM2bN+uiOsPm0l16de0haxhERESPA50kMlTa/dl8m06QNwwiIqLHABMZXROF0qvCWN44iIiIHgNMZHRNdX+tKUWl1+MkIiKiSmIio2tskSEiIqoxbDbQlTsngZtbgbRz0me2yBAREekd77a6sqPDAztUsoRBRET0OOGjJX2xcJc7AiIiojqPiYy+GJnLHQEREVGdx0RGF4Qou0+hqPk4iIiIHjNMZHRCSyLDS0tERKR3vNvqgtDSsVfBS0tERKRvvNvqhLZHS7y0RERE+sa7rS6wRYaIiEgWvNvqhLY+MuzsS0REpG9MZHSBLTJERESy4N1WJzhqiYiISA682+qC1nlkeGmJiIj0jXdbndC2rhL7yBAREekbExldYIsMERGRLHi31Ql29iUiIpID77a6wBYZIiIiWfBuqwvahl/z0hIREekd77Y6wdWviYiI5MBERhfYIkNERCQL3m11gn1kiIiI5MC7rS5wiQIiIiJZ8G5bVUIA/64F0s6Di0YSERHJw0TuAAxW8m7g8BDp/cDrZY+zRYaIiEjveLetqrtnSt6zsy8REZEsZL3bLl68GH5+frC1tYWtrS2CgoKwbds29fHu3btDoVBobBMmTJAx4lIUpRuz2NmXiIhIDrI+WmrQoAHmzJmDpk2bQgiBFStWYMCAATh9+jRatWoFABg3bhw+/PBD9XcsLS3lCrd8Wjv7so8MERGRvsmayPTv31/j8yeffILFixfj6NGj6kTG0tISbm5ucoT3CKWTF22dfYmIiEjfas3zj6KiIqxZswbZ2dkICgpS71+1ahXq1asHX19fREZGIicnR8YoSyndCqMqkl5NbIAOi4HgLfLERERE9JiRfdTSuXPnEBQUhNzcXFhbW2Pjxo1o2bIlAODFF1+Et7c3PDw8cPbsWcyYMQMJCQnYsGFDufXl5eUhLy9P/TkjI0NPkZdqhVHlS68KBdC0lvThISIiegzInsg0a9YMcXFxSE9Px/r16zFy5Ejs378fLVu2xPjx49XlWrduDXd3d/Ts2ROXL19G48aNtdYXFRWF2bNn6z9woSWRqT0NXERERI8F2e+8ZmZmaNKkCQICAhAVFYU2bdpg4cKFWssGBgYCAC5dulRufZGRkUhPT1dv169rmeNFF4xK5YClW2SIiIioxsjeIvMglUql8WiotLi4OACAu7t7ud9XKpVQKpX6CE1T6eHXqvvxcsg1ERFRjZI1kYmMjETv3r3h5eWFzMxMxMTEYN++fdixYwcuX76MmJgY9OnTB05OTjh79iymTZuGbt26wc/PT86w7yvV+nLq9fu7al1eSEREVKfJeudNSUnBiBEjkJiYCDs7O/j5+WHHjh0IDQ3F9evXsWvXLixYsADZ2dnw9PREeHg43nvvPTlDLqVUH5nUk9KrfWt5QiEiInpMyZrILFu2rNxjnp6e2L9/fw1GUw0tZ0itMT7D5Y6EiIjoscJnIdXlNRhoO0fuKIiIiB5L7J1aZcWPljhSiYiISC5MZIiIiMhgMZGpKsH1lYiIiOTGRKa6OAkeERGRbJjIVBlbZIiIiOTGRKba2CJDREQkFyYyVcYWGSIiIrkxkak2tsgQERHJhYlMVXHUEhERkeyYyFQXRy0RERHJholMlbFFhoiISG5MZKqNLTJERERyYSJDREREBouJTJVx0UgiIiK5MZEhIiIig8VEpqqKh19z1BIREZFsmMgQERGRwWIiU2Ucfk1ERCQ3JjLVxkdLREREcmEiU2VskSEiIpIbE5nqYmdfIiIi2TCRqSouGklERCQ7JjLVxhYZIiIiuTCRISIiIoPFRKbKuEQBERGR3JjIEBERkcFiIlNlXKKAiIhIbkxkiIiIyGAxkakqwT4yREREcmMiQ0RERAaLiUyVsUWGiIhIbkxkiIiIyGAxkakqwVFLREREcmMiQ0RERAaLiUyVcdFIIiIiuTGRqTY+WiIiIpILExkiIiIyWExkqozDr4mIiOQmayKzePFi+Pn5wdbWFra2tggKCsK2bdvUx3NzczFx4kQ4OTnB2toa4eHhSE5OljFiIiIiqk1kTWQaNGiAOXPmIDY2FidPnkSPHj0wYMAA/PnnnwCAadOmYcuWLVi3bh3279+Pmzdv4tlnn5Uz5BIcfk1ERCQ7EzlP3r9/f43Pn3zyCRYvXoyjR4+iQYMGWLZsGWJiYtCjRw8AQHR0NFq0aIGjR4+iU6dOcoRMREREtUit6SNTVFSENWvWIDs7G0FBQYiNjUVBQQFCQkLUZZo3bw4vLy8cOXKk3Hry8vKQkZGhsekH+8gQERHJTfZE5ty5c7C2toZSqcSECROwceNGtGzZEklJSTAzM4O9vb1GeVdXVyQlJZVbX1RUFOzs7NSbp6ennn8BERERyUX2RKZZs2aIi4vDsWPH8Morr2DkyJGIj4+vcn2RkZFIT09Xb9evX9dhtKWxRYaIiEhusvaRAQAzMzM0adIEABAQEIATJ05g4cKFeOGFF5Cfn4+0tDSNVpnk5GS4ubmVW59SqYRSqdR32ERERFQLyN4i8yCVSoW8vDwEBATA1NQUu3fvVh9LSEjAtWvXEBQUJGOE93HUEhERkexkbZGJjIxE79694eXlhczMTMTExGDfvn3YsWMH7OzsMHbsWEyfPh2Ojo6wtbXF5MmTERQUxBFLREREBEDmRCYlJQUjRoxAYmIi7Ozs4Ofnhx07diA0NBQAMH/+fBgZGSE8PBx5eXkICwvDokWL5AxZC7bIEBERyUXWRGbZsmUPPW5ubo5vv/0W3377bQ1FVBlc/ZqIiEhuta6PDBEREVFFMZGpMg6/JiIikhsTGSIiIjJYTGSqisOviYiIZMdEhoiIiAwWE5kqYx8ZIiIiuTGRISIiIoPFRKbK2CJDREQkNyYyREREZLCYyFQXRy0RERHJholMVQkuUUBERCQ3JjLVxhYZIiIiuTCRqTK2yBAREcmNiUx1sY8MERGRbJjIVBlbZIiIiOTGRIaIiIgMFhOZqhKcEI+IiEhuTGSIiIjIYDGRqTK2yBAREcmNiQwREREZLCYyVVXcR4bDr4mIiGTDRIaIiIgMFhOZamOLDBERkVyYyFQZJ8QjIiKSGxOZamOLDBERkVyYyFQZW2SIiIjkxkSmujhqiYiISDZMZKpKsEWGiIhIbkxkqo0tMkRERHJhIlNlbJEhIiKSGxMZIiIiMlhMZKqMi0YSERHJjYkMERERGSwmMtXF4ddERESyYSJTVRx+TUREJDsmMtXGFhkiIiK5MJGpMrbIEBERyY2JTLWxRYaIiEguTGSqjC0yREREcpM1kYmKikKHDh1gY2MDFxcXDBw4EAkJCRplunfvDoVCobFNmDBBpoi14KglIiIi2ciayOzfvx8TJ07E0aNHsXPnThQUFKBXr17Izs7WKDdu3DgkJiaqt3nz5skUcSkctURERCQ7EzlPvn37do3Py5cvh4uLC2JjY9GtWzf1fktLS7i5udV0eBXEFhkiIiK51Ko+Munp6QAAR0dHjf2rVq1CvXr14Ovri8jISOTk5JRbR15eHjIyMjQ2/WCLDBERkdxkbZEpTaVSYerUqejcuTN8fX3V+1988UV4e3vDw8MDZ8+exYwZM5CQkIANGzZorScqKgqzZ8+uqbDBFhkiIiL51JpEZuLEiTh//jwOHTqksX/8+PHq961bt4a7uzt69uyJy5cvo3HjxmXqiYyMxPTp09WfMzIy4OnpqfuAjUwBYwvAqNZcQiIiosdOrbgLT5o0Cb/++isOHDiABg0aPLRsYGAgAODSpUtaExmlUgmlUqmXODW0/1raiIiISDayJjJCCEyePBkbN27Evn374OPj88jvxMXFAQDc3d31HB0RERHVdrImMhMnTkRMTAx++eUX2NjYICkpCQBgZ2cHCwsLXL58GTExMejTpw+cnJxw9uxZTJs2Dd26dYOfn5+coRMREVEtoBBCvglRFOVMJhcdHY1Ro0bh+vXrGDZsGM6fP4/s7Gx4enpi0KBBeO+992Bra1uhc2RkZMDOzg7p6ekV/g4RERHJq6L3b9kfLT2Mp6cn9u/fX0PREBERkaGpVfPIEBEREVUGExkiIiIyWExkiIiIyGAxkSEiIiKDxUSGiIiIDBYTGSIiIjJYTGSIiIjIYDGRISIiIoPFRIaIiIgMFhMZIiIiMliyLlFQE4qXQcjIyJA5EiIiIqqo4vv2o5YzqvOJTGZmJgBp3SYiIiIyLJmZmbCzsyv3uKyrX9cElUqFmzdvwsbGptzVtqsiIyMDnp6euH79OlfV1jNe65rB61wzeJ1rBq9zzdDndRZCIDMzEx4eHjAyKr8nTJ1vkTEyMkKDBg30Vr+trS3/I6khvNY1g9e5ZvA61wxe55qhr+v8sJaYYuzsS0RERAaLiQwREREZLCYyVaRUKjFr1iwolUq5Q6nzeK1rBq9zzeB1rhm8zjWjNlznOt/Zl4iIiOoutsgQERGRwWIiQ0RERAaLiQwREREZLCYyREREZLCYyFTRt99+i4YNG8Lc3ByBgYE4fvy43CHVagcOHED//v3h4eEBhUKBTZs2aRwXQuD999+Hu7s7LCwsEBISgosXL2qUSU1NxdChQ2Frawt7e3uMHTsWWVlZGmXOnj2Lrl27wtzcHJ6enpg3b56+f1qtERUVhQ4dOsDGxgYuLi4YOHAgEhISNMrk5uZi4sSJcHJygrW1NcLDw5GcnKxR5tq1a+jbty8sLS3h4uKCN998E4WFhRpl9u3bB39/fyiVSjRp0gTLly/X98+rVRYvXgw/Pz/1JGBBQUHYtm2b+jivs+7NmTMHCoUCU6dOVe/jddaNDz74AAqFQmNr3ry5+nitv86CKm3NmjXCzMxM/Pjjj+LPP/8U48aNE/b29iI5OVnu0GqtrVu3infffVds2LBBABAbN27UOD5nzhxhZ2cnNm3aJM6cOSOeeeYZ4ePjI+7du6cu8/TTT4s2bdqIo0ePioMHD4omTZqIiIgI9fH09HTh6uoqhg4dKs6fPy9Wr14tLCwsxPfff19TP1NWYWFhIjo6Wpw/f17ExcWJPn36CC8vL5GVlaUuM2HCBOHp6Sl2794tTp48KTp16iSefPJJ9fHCwkLh6+srQkJCxOnTp8XWrVtFvXr1RGRkpLrMP//8IywtLcX06dNFfHy8+Prrr4WxsbHYvn17jf5eOW3evFn89ttv4sKFCyIhIUG88847wtTUVJw/f14Iweusa8ePHxcNGzYUfn5+YsqUKer9vM66MWvWLNGqVSuRmJio3m7duqU+XtuvMxOZKujYsaOYOHGi+nNRUZHw8PAQUVFRMkZlOB5MZFQqlXBzcxOfffaZel9aWppQKpVi9erVQggh4uPjBQBx4sQJdZlt27YJhUIh/vvvPyGEEIsWLRIODg4iLy9PXWbGjBmiWbNmev5FtVNKSooAIPbv3y+EkK6pqampWLdunbrMX3/9JQCII0eOCCGkhNPIyEgkJSWpyyxevFjY2tqqr+tbb70lWrVqpXGuF154QYSFhen7J9VqDg4O4ocffuB11rHMzEzRtGlTsXPnThEcHKxOZHiddWfWrFmiTZs2Wo8ZwnXmo6VKys/PR2xsLEJCQtT7jIyMEBISgiNHjsgYmeG6cuUKkpKSNK6pnZ0dAgMD1df0yJEjsLe3R/v27dVlQkJCYGRkhGPHjqnLdOvWDWZmZuoyYWFhSEhIwN27d2vo19Qe6enpAABHR0cAQGxsLAoKCjSuc/PmzeHl5aVxnVu3bg1XV1d1mbCwMGRkZODPP/9UlyldR3GZx/Xvf1FREdasWYPs7GwEBQXxOuvYxIkT0bdv3zLXgtdZty5evAgPDw80atQIQ4cOxbVr1wAYxnVmIlNJt2/fRlFRkcYfGAC4uroiKSlJpqgMW/F1e9g1TUpKgouLi8ZxExMTODo6apTRVkfpczwuVCoVpk6dis6dO8PX1xeAdA3MzMxgb2+vUfbB6/yoa1hemYyMDNy7d08fP6dWOnfuHKytraFUKjFhwgRs3LgRLVu25HXWoTVr1uDUqVOIiooqc4zXWXcCAwOxfPlybN++HYsXL8aVK1fQtWtXZGZmGsR1rvOrXxM9jiZOnIjz58/j0KFDcodSZzVr1gxxcXFIT0/H+vXrMXLkSOzfv1/usOqM69evY8qUKdi5cyfMzc3lDqdO6927t/q9n58fAgMD4e3tjZ9++gkWFhYyRlYxbJGppHr16sHY2LhMj+3k5GS4ubnJFJVhK75uD7umbm5uSElJ0TheWFiI1NRUjTLa6ih9jsfBpEmT8Ouvv2Lv3r1o0KCBer+bmxvy8/ORlpamUf7B6/yoa1heGVtbW4P4R09XzMzM0KRJEwQEBCAqKgpt2rTBwoULeZ11JDY2FikpKfD394eJiQlMTEywf/9+fPXVVzAxMYGrqyuvs57Y29vjiSeewKVLlwzi7zMTmUoyMzNDQEAAdu/erd6nUqmwe/duBAUFyRiZ4fLx8YGbm5vGNc3IyMCxY8fU1zQoKAhpaWmIjY1Vl9mzZw9UKhUCAwPVZQ4cOICCggJ1mZ07d6JZs2ZwcHCooV8jHyEEJk2ahI0bN2LPnj3w8fHROB4QEABTU1ON65yQkIBr165pXOdz585pJI07d+6Era0tWrZsqS5Tuo7iMo/733+VSoW8vDxeZx3p2bMnzp07h7i4OPXWvn17DB06VP2e11k/srKycPnyZbi7uxvG3+dqdxd+DK1Zs0YolUqxfPlyER8fL8aPHy/s7e01emyTpszMTHH69Glx+vRpAUB8+eWX4vTp0+Lff/8VQkjDr+3t7cUvv/wizp49KwYMGKB1+HW7du3EsWPHxKFDh0TTpk01hl+npaUJV1dXMXz4cHH+/HmxZs0aYWlp+dgMv37llVeEnZ2d2Ldvn8YwypycHHWZCRMmCC8vL7Fnzx5x8uRJERQUJIKCgtTHi4dR9urVS8TFxYnt27cLZ2dnrcMo33zzTfHXX3+Jb7/99rEbrvr222+L/fv3iytXroizZ8+Kt99+WygUCvH7778LIXid9aX0qCUheJ115fXXXxf79u0TV65cEYcPHxYhISGiXr16IiUlRQhR+68zE5kq+vrrr4WXl5cwMzMTHTt2FEePHpU7pFpt7969AkCZbeTIkUIIaQj2zJkzhaurq1AqlaJnz54iISFBo447d+6IiIgIYW1tLWxtbcXo0aNFZmamRpkzZ86ILl26CKVSKerXry/mzJlTUz9RdtquLwARHR2tLnPv3j3x6quvCgcHB2FpaSkGDRokEhMTNeq5evWq6N27t7CwsBD16tUTr7/+uigoKNAos3fvXtG2bVthZmYmGjVqpHGOx8GYMWOEt7e3MDMzE87OzqJnz57qJEYIXmd9eTCR4XXWjRdeeEG4u7sLMzMzUb9+ffHCCy+IS5cuqY/X9uusEEKI6rfrEBEREdU89pEhIiIig8VEhoiIiAwWExkiIiIyWExkiIiIyGAxkSEiIiKDxUSGiIiIDBYTGSIiIjJYTGSIiIjIYDGRIaJa4datW3jllVfg5eUFpVIJNzc3hIWF4fDhwwAAhUKBTZs2yRskEdU6JnIHQEQEAOHh4cjPz8eKFSvQqFEjJCcnY/fu3bhz547coRFRLcYlCohIdmlpaXBwcMC+ffsQHBxc5njDhg3x77//qj97e3vj6tWrAIBffvkFs2fPRnx8PDw8PDBy5Ei8++67MDGR/j9NoVBg0aJF2Lx5M/bt2wd3d3fMmzcPzz33XI38NiLSLz5aIiLZWVtbw9raGps2bUJeXl6Z4ydOnAAAREdHIzExUf354MGDGDFiBKZMmYL4+Hh8//33WL58OT755BON78+cORPh4eE4c+YMhg4diiFDhuCvv/7S/w8jIr1jiwwR1Qo///wzxo0bh3v37sHf3x/BwcEYMmQI/Pz8AEgtKxs3bsTAgQPV3wkJCUHPnj0RGRmp3rdy5Uq89dZbuHnzpvp7EyZMwOLFi9VlOnXqBH9/fyxatKhmfhwR6Q1bZIioVggPD8fNmzexefNmPP3009i3bx/8/f2xfPnycr9z5swZfPjhh+oWHWtra4wbNw6JiYnIyclRlwsKCtL4XlBQEFtkiOoIdvYlolrD3NwcoaGhCA0NxcyZM/HSSy9h1qxZGDVqlNbyWVlZmD17Np599lmtdRFR3ccWGSKqtVq2bIns7GwAgKmpKYqKijSO+/v7IyEhAU2aNCmzGRmV/PN29OhRje8dPXoULVq00P8PICK9Y4sMEcnuzp07eP755zFmzBj4+fnBxsYGJ0+exLx58zBgwAAA0sil3bt3o3PnzlAqlXBwcMD777+Pfv36wcvLC8899xyMjIxw5swZnD9/Hh9//LG6/nXr1qF9+/bo0qULVq1ahePHj2PZsmVy/Vwi0iF29iUi2eXl5eGDDz7A77//jsuXL6OgoACenp54/vnn8c4778DCwgJbtmzB9OnTcfXqVdSvX189/HrHjh348MMPcfr0aZiamqJ58+Z46aWXMG7cOABSZ99vv/0WmzZtwoEDB+Du7o65c+di8ODBMv5iItIVJjJEVKdpG+1ERHUH+8gQERGRwWIiQ0RERAaLnX2JqE7j03Oiuo0tMkRERGSwmMgQERGRwWIiQ0RERAaLiQwREREZLCYyREREZLCYyBAREZHBYiJDREREBouJDBERERksJjJERERksP4f8WINjcP2Rg8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Produce plots\n",
        "args = [\"Loss\", \"Accuracy\", \"CPU\"]\n",
        "for a in args: model.plot(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g35xCyU6jLTL",
        "outputId": "90d1192f-952e-4736-ea93-702041979ccb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score on test set: 55.29\n"
          ]
        }
      ],
      "source": [
        "# check accuracy on test set\n",
        "print(f\"Accuracy score on test set: {np.round(np.sum(model.predict(X_test) == Y_test) / X_test.shape[0] * 100,2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EIfjBgzc3FEj"
      },
      "outputs": [],
      "source": [
        "# save the data for later comparison\n",
        "df_random = model.backup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL6QcmoHjAkM"
      },
      "source": [
        "## 4) BCGD GS Rule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deeLZ0RpjDtt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "7d9d1f81-2bd0-4c2d-b80a-3cfc506d7848"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mOutput streaming troncato alle ultime 5000 righe.\u001b[0m\n",
            "Step: 3 ------------ Loss: 12892.02 ------------ Accuracy: 34.5%\n",
            "Step: 4 ------------ Loss: 12804.13 ------------ Accuracy: 34.5%\n",
            "Step: 5 ------------ Loss: 12724.26 ------------ Accuracy: 34.5%\n",
            "Step: 6 ------------ Loss: 12651.73 ------------ Accuracy: 34.5%\n",
            "Step: 7 ------------ Loss: 12588.05 ------------ Accuracy: 34.5%\n",
            "Step: 8 ------------ Loss: 12526.22 ------------ Accuracy: 34.5%\n",
            "Step: 9 ------------ Loss: 12470.18 ------------ Accuracy: 34.5%\n",
            "Step: 10 ------------ Loss: 12418.73 ------------ Accuracy: 34.5%\n",
            "Step: 11 ------------ Loss: 12367.61 ------------ Accuracy: 34.5%\n",
            "Step: 12 ------------ Loss: 12320.11 ------------ Accuracy: 34.5%\n",
            "Step: 13 ------------ Loss: 12273.26 ------------ Accuracy: 34.5%\n",
            "Step: 14 ------------ Loss: 12229.23 ------------ Accuracy: 34.5%\n",
            "Step: 15 ------------ Loss: 12186.09 ------------ Accuracy: 34.5%\n",
            "Step: 16 ------------ Loss: 12145.12 ------------ Accuracy: 34.5%\n",
            "Step: 17 ------------ Loss: 12105.21 ------------ Accuracy: 34.5%\n",
            "Step: 18 ------------ Loss: 12066.95 ------------ Accuracy: 34.7%\n",
            "Step: 19 ------------ Loss: 12029.85 ------------ Accuracy: 34.7%\n",
            "Step: 20 ------------ Loss: 11994.01 ------------ Accuracy: 37.0%\n",
            "Step: 21 ------------ Loss: 11959.36 ------------ Accuracy: 37.0%\n",
            "Step: 22 ------------ Loss: 11925.7 ------------ Accuracy: 40.7%\n",
            "Step: 23 ------------ Loss: 11893.19 ------------ Accuracy: 40.2%\n",
            "Step: 24 ------------ Loss: 11861.51 ------------ Accuracy: 43.4%\n",
            "Step: 25 ------------ Loss: 11830.88 ------------ Accuracy: 43.2%\n",
            "Step: 26 ------------ Loss: 11801.0 ------------ Accuracy: 45.3%\n",
            "Step: 27 ------------ Loss: 11772.01 ------------ Accuracy: 45.1%\n",
            "Step: 28 ------------ Loss: 11743.79 ------------ Accuracy: 46.1%\n",
            "Step: 29 ------------ Loss: 11716.26 ------------ Accuracy: 46.1%\n",
            "Step: 30 ------------ Loss: 11689.57 ------------ Accuracy: 47.7%\n",
            "Step: 31 ------------ Loss: 11663.33 ------------ Accuracy: 47.4%\n",
            "Step: 32 ------------ Loss: 11638.05 ------------ Accuracy: 48.7%\n",
            "Step: 33 ------------ Loss: 11612.97 ------------ Accuracy: 48.5%\n",
            "Step: 34 ------------ Loss: 11589.0 ------------ Accuracy: 49.2%\n",
            "Step: 35 ------------ Loss: 11564.95 ------------ Accuracy: 49.0%\n",
            "Step: 36 ------------ Loss: 11542.21 ------------ Accuracy: 50.6%\n",
            "Step: 37 ------------ Loss: 11519.09 ------------ Accuracy: 50.3%\n",
            "Step: 38 ------------ Loss: 11497.5 ------------ Accuracy: 50.7%\n",
            "Step: 39 ------------ Loss: 11475.23 ------------ Accuracy: 50.7%\n",
            "Step: 40 ------------ Loss: 11454.71 ------------ Accuracy: 51.3%\n",
            "Step: 41 ------------ Loss: 11433.22 ------------ Accuracy: 50.9%\n",
            "Step: 42 ------------ Loss: 11413.34 ------------ Accuracy: 50.9%\n",
            "Step: 43 ------------ Loss: 11392.93 ------------ Accuracy: 51.6%\n",
            "Step: 44 ------------ Loss: 11373.62 ------------ Accuracy: 51.4%\n",
            "Step: 45 ------------ Loss: 11354.25 ------------ Accuracy: 52.1%\n",
            "Step: 46 ------------ Loss: 11335.47 ------------ Accuracy: 51.9%\n",
            "Step: 47 ------------ Loss: 11317.08 ------------ Accuracy: 52.4%\n",
            "Step: 48 ------------ Loss: 11298.79 ------------ Accuracy: 52.2%\n",
            "Step: 49 ------------ Loss: 11281.32 ------------ Accuracy: 52.3%\n",
            "Step: 50 ------------ Loss: 11263.5 ------------ Accuracy: 52.3%\n",
            "Step: 51 ------------ Loss: 11246.89 ------------ Accuracy: 52.6%\n",
            "Step: 52 ------------ Loss: 11229.51 ------------ Accuracy: 52.6%\n",
            "Step: 53 ------------ Loss: 11213.33 ------------ Accuracy: 52.6%\n",
            "Step: 54 ------------ Loss: 11196.76 ------------ Accuracy: 52.6%\n",
            "Step: 55 ------------ Loss: 11180.91 ------------ Accuracy: 52.6%\n",
            "Step: 56 ------------ Loss: 11165.17 ------------ Accuracy: 52.5%\n",
            "Step: 57 ------------ Loss: 11149.64 ------------ Accuracy: 52.6%\n",
            "Step: 58 ------------ Loss: 11134.69 ------------ Accuracy: 52.5%\n",
            "Step: 59 ------------ Loss: 11119.46 ------------ Accuracy: 52.5%\n",
            "Step: 60 ------------ Loss: 11105.26 ------------ Accuracy: 52.5%\n",
            "Step: 61 ------------ Loss: 11090.33 ------------ Accuracy: 52.5%\n",
            "Step: 62 ------------ Loss: 11076.37 ------------ Accuracy: 52.5%\n",
            "Step: 63 ------------ Loss: 11062.55 ------------ Accuracy: 52.4%\n",
            "Step: 64 ------------ Loss: 11047.93 ------------ Accuracy: 52.5%\n",
            "Step: 65 ------------ Loss: 11034.28 ------------ Accuracy: 52.5%\n",
            "Step: 66 ------------ Loss: 11020.41 ------------ Accuracy: 52.4%\n",
            "Step: 67 ------------ Loss: 11007.02 ------------ Accuracy: 52.4%\n",
            "Step: 68 ------------ Loss: 10993.84 ------------ Accuracy: 52.4%\n",
            "Step: 69 ------------ Loss: 10980.71 ------------ Accuracy: 52.4%\n",
            "Step: 70 ------------ Loss: 10968.17 ------------ Accuracy: 52.3%\n",
            "Step: 71 ------------ Loss: 10955.28 ------------ Accuracy: 52.4%\n",
            "Step: 72 ------------ Loss: 10944.09 ------------ Accuracy: 52.2%\n",
            "Step: 73 ------------ Loss: 10930.67 ------------ Accuracy: 52.2%\n",
            "Step: 74 ------------ Loss: 10918.14 ------------ Accuracy: 52.3%\n",
            "Step: 75 ------------ Loss: 10906.26 ------------ Accuracy: 52.2%\n",
            "Step: 76 ------------ Loss: 10893.99 ------------ Accuracy: 52.2%\n",
            "Step: 77 ------------ Loss: 10882.51 ------------ Accuracy: 52.3%\n",
            "Step: 78 ------------ Loss: 10870.66 ------------ Accuracy: 52.2%\n",
            "Step: 79 ------------ Loss: 10859.37 ------------ Accuracy: 52.2%\n",
            "Step: 80 ------------ Loss: 10848.72 ------------ Accuracy: 52.4%\n",
            "Step: 81 ------------ Loss: 10836.9 ------------ Accuracy: 52.4%\n",
            "Step: 82 ------------ Loss: 10825.84 ------------ Accuracy: 52.4%\n",
            "Step: 83 ------------ Loss: 10814.64 ------------ Accuracy: 52.4%\n",
            "Step: 84 ------------ Loss: 10803.8 ------------ Accuracy: 52.4%\n",
            "Step: 85 ------------ Loss: 10793.15 ------------ Accuracy: 52.4%\n",
            "Step: 86 ------------ Loss: 10782.52 ------------ Accuracy: 52.4%\n",
            "Step: 87 ------------ Loss: 10772.37 ------------ Accuracy: 52.4%\n",
            "Step: 88 ------------ Loss: 10761.93 ------------ Accuracy: 52.4%\n",
            "Step: 89 ------------ Loss: 10752.51 ------------ Accuracy: 52.4%\n",
            "Step: 90 ------------ Loss: 10741.66 ------------ Accuracy: 52.4%\n",
            "Step: 91 ------------ Loss: 10731.48 ------------ Accuracy: 52.4%\n",
            "Step: 92 ------------ Loss: 10721.73 ------------ Accuracy: 52.5%\n",
            "Step: 93 ------------ Loss: 10711.76 ------------ Accuracy: 52.4%\n",
            "Step: 94 ------------ Loss: 10702.46 ------------ Accuracy: 52.5%\n",
            "Step: 95 ------------ Loss: 10692.69 ------------ Accuracy: 52.4%\n",
            "Step: 96 ------------ Loss: 10683.51 ------------ Accuracy: 52.4%\n",
            "Step: 97 ------------ Loss: 10674.22 ------------ Accuracy: 52.5%\n",
            "Step: 98 ------------ Loss: 10664.61 ------------ Accuracy: 52.5%\n",
            "Step: 99 ------------ Loss: 10655.59 ------------ Accuracy: 52.4%\n",
            "Step: 100 ------------ Loss: 10646.27 ------------ Accuracy: 52.5%\n",
            "Step: 101 ------------ Loss: 10637.43 ------------ Accuracy: 52.6%\n",
            "Step: 102 ------------ Loss: 10628.56 ------------ Accuracy: 52.5%\n",
            "Step: 103 ------------ Loss: 10619.87 ------------ Accuracy: 52.6%\n",
            "Step: 104 ------------ Loss: 10611.57 ------------ Accuracy: 52.4%\n",
            "Step: 105 ------------ Loss: 10602.52 ------------ Accuracy: 52.4%\n",
            "Step: 106 ------------ Loss: 10594.02 ------------ Accuracy: 52.5%\n",
            "Step: 107 ------------ Loss: 10585.44 ------------ Accuracy: 52.4%\n",
            "Step: 108 ------------ Loss: 10577.11 ------------ Accuracy: 52.5%\n",
            "Step: 109 ------------ Loss: 10568.94 ------------ Accuracy: 52.4%\n",
            "Step: 110 ------------ Loss: 10560.77 ------------ Accuracy: 52.5%\n",
            "Step: 111 ------------ Loss: 10553.13 ------------ Accuracy: 52.6%\n",
            "Step: 112 ------------ Loss: 10544.65 ------------ Accuracy: 52.7%\n",
            "Step: 113 ------------ Loss: 10536.66 ------------ Accuracy: 52.4%\n",
            "Step: 114 ------------ Loss: 10528.7 ------------ Accuracy: 52.7%\n",
            "Step: 115 ------------ Loss: 10520.89 ------------ Accuracy: 52.4%\n",
            "Step: 116 ------------ Loss: 10513.3 ------------ Accuracy: 52.6%\n",
            "Step: 117 ------------ Loss: 10505.64 ------------ Accuracy: 52.7%\n",
            "Step: 118 ------------ Loss: 10498.47 ------------ Accuracy: 52.7%\n",
            "Step: 119 ------------ Loss: 10490.53 ------------ Accuracy: 52.6%\n",
            "Step: 120 ------------ Loss: 10483.05 ------------ Accuracy: 52.7%\n",
            "Step: 121 ------------ Loss: 10475.61 ------------ Accuracy: 52.6%\n",
            "Step: 122 ------------ Loss: 10468.3 ------------ Accuracy: 52.7%\n",
            "Step: 123 ------------ Loss: 10461.2 ------------ Accuracy: 52.6%\n",
            "Step: 124 ------------ Loss: 10454.03 ------------ Accuracy: 52.6%\n",
            "Step: 125 ------------ Loss: 10447.23 ------------ Accuracy: 52.6%\n",
            "Step: 126 ------------ Loss: 10439.8 ------------ Accuracy: 52.7%\n",
            "Step: 127 ------------ Loss: 10432.8 ------------ Accuracy: 52.6%\n",
            "Step: 128 ------------ Loss: 10425.81 ------------ Accuracy: 52.7%\n",
            "Step: 129 ------------ Loss: 10418.96 ------------ Accuracy: 52.6%\n",
            "Step: 130 ------------ Loss: 10412.29 ------------ Accuracy: 52.7%\n",
            "Step: 131 ------------ Loss: 10405.58 ------------ Accuracy: 52.6%\n",
            "Step: 132 ------------ Loss: 10399.07 ------------ Accuracy: 52.6%\n",
            "Step: 133 ------------ Loss: 10392.13 ------------ Accuracy: 52.6%\n",
            "Step: 134 ------------ Loss: 10385.57 ------------ Accuracy: 52.7%\n",
            "Step: 135 ------------ Loss: 10378.98 ------------ Accuracy: 52.6%\n",
            "Step: 136 ------------ Loss: 10372.56 ------------ Accuracy: 52.7%\n",
            "Step: 137 ------------ Loss: 10366.61 ------------ Accuracy: 52.6%\n",
            "Step: 138 ------------ Loss: 10359.97 ------------ Accuracy: 52.6%\n",
            "Step: 139 ------------ Loss: 10353.66 ------------ Accuracy: 52.6%\n",
            "Step: 140 ------------ Loss: 10347.2 ------------ Accuracy: 52.6%\n",
            "Step: 141 ------------ Loss: 10341.08 ------------ Accuracy: 52.7%\n",
            "Step: 142 ------------ Loss: 10334.87 ------------ Accuracy: 52.6%\n",
            "Step: 143 ------------ Loss: 10328.88 ------------ Accuracy: 52.7%\n",
            "Step: 144 ------------ Loss: 10323.01 ------------ Accuracy: 52.6%\n",
            "Step: 145 ------------ Loss: 10316.81 ------------ Accuracy: 52.6%\n",
            "Step: 146 ------------ Loss: 10310.84 ------------ Accuracy: 52.6%\n",
            "Step: 147 ------------ Loss: 10304.8 ------------ Accuracy: 52.6%\n",
            "Step: 148 ------------ Loss: 10299.1 ------------ Accuracy: 52.6%\n",
            "Step: 149 ------------ Loss: 10293.2 ------------ Accuracy: 52.6%\n",
            "Step: 150 ------------ Loss: 10287.86 ------------ Accuracy: 52.6%\n",
            "Step: 151 ------------ Loss: 10281.79 ------------ Accuracy: 52.6%\n",
            "Step: 152 ------------ Loss: 10276.05 ------------ Accuracy: 52.6%\n",
            "Step: 153 ------------ Loss: 10270.34 ------------ Accuracy: 52.6%\n",
            "Step: 154 ------------ Loss: 10264.74 ------------ Accuracy: 52.6%\n",
            "Step: 155 ------------ Loss: 10259.3 ------------ Accuracy: 52.6%\n",
            "Step: 156 ------------ Loss: 10253.81 ------------ Accuracy: 52.6%\n",
            "Step: 157 ------------ Loss: 10248.47 ------------ Accuracy: 52.6%\n",
            "Step: 158 ------------ Loss: 10242.82 ------------ Accuracy: 52.6%\n",
            "Step: 159 ------------ Loss: 10237.46 ------------ Accuracy: 52.6%\n",
            "Step: 160 ------------ Loss: 10232.01 ------------ Accuracy: 52.6%\n",
            "Step: 161 ------------ Loss: 10226.78 ------------ Accuracy: 52.6%\n",
            "Step: 162 ------------ Loss: 10221.81 ------------ Accuracy: 52.5%\n",
            "Step: 163 ------------ Loss: 10216.41 ------------ Accuracy: 52.6%\n",
            "Step: 164 ------------ Loss: 10211.11 ------------ Accuracy: 52.6%\n",
            "Step: 165 ------------ Loss: 10205.86 ------------ Accuracy: 52.6%\n",
            "Step: 166 ------------ Loss: 10200.8 ------------ Accuracy: 52.6%\n",
            "Step: 167 ------------ Loss: 10195.68 ------------ Accuracy: 52.6%\n",
            "Step: 168 ------------ Loss: 10191.0 ------------ Accuracy: 52.6%\n",
            "Step: 169 ------------ Loss: 10185.74 ------------ Accuracy: 52.6%\n",
            "Step: 170 ------------ Loss: 10180.78 ------------ Accuracy: 52.6%\n",
            "Step: 171 ------------ Loss: 10175.66 ------------ Accuracy: 52.6%\n",
            "Step: 172 ------------ Loss: 10170.8 ------------ Accuracy: 52.6%\n",
            "Step: 173 ------------ Loss: 10165.94 ------------ Accuracy: 52.6%\n",
            "Step: 174 ------------ Loss: 10161.25 ------------ Accuracy: 52.6%\n",
            "Step: 175 ------------ Loss: 10156.32 ------------ Accuracy: 52.7%\n",
            "Step: 176 ------------ Loss: 10151.66 ------------ Accuracy: 52.6%\n",
            "Step: 177 ------------ Loss: 10146.86 ------------ Accuracy: 52.7%\n",
            "Step: 178 ------------ Loss: 10142.4 ------------ Accuracy: 52.6%\n",
            "Step: 179 ------------ Loss: 10137.47 ------------ Accuracy: 52.6%\n",
            "Step: 180 ------------ Loss: 10132.8 ------------ Accuracy: 52.7%\n",
            "Step: 181 ------------ Loss: 10128.08 ------------ Accuracy: 52.6%\n",
            "Step: 182 ------------ Loss: 10123.52 ------------ Accuracy: 52.7%\n",
            "Step: 183 ------------ Loss: 10119.02 ------------ Accuracy: 52.7%\n",
            "Step: 184 ------------ Loss: 10114.74 ------------ Accuracy: 52.6%\n",
            "Step: 185 ------------ Loss: 10109.97 ------------ Accuracy: 52.6%\n",
            "Step: 186 ------------ Loss: 10105.43 ------------ Accuracy: 52.7%\n",
            "Step: 187 ------------ Loss: 10100.96 ------------ Accuracy: 52.6%\n",
            "Step: 188 ------------ Loss: 10096.53 ------------ Accuracy: 52.7%\n",
            "Step: 189 ------------ Loss: 10092.25 ------------ Accuracy: 52.6%\n",
            "Step: 190 ------------ Loss: 10087.88 ------------ Accuracy: 52.7%\n",
            "Step: 191 ------------ Loss: 10083.48 ------------ Accuracy: 52.6%\n",
            "Step: 192 ------------ Loss: 10079.22 ------------ Accuracy: 52.7%\n",
            "Step: 193 ------------ Loss: 10075.11 ------------ Accuracy: 52.8%\n",
            "Step: 194 ------------ Loss: 10070.74 ------------ Accuracy: 52.6%\n",
            "Step: 195 ------------ Loss: 10066.39 ------------ Accuracy: 52.6%\n",
            "Step: 196 ------------ Loss: 10062.14 ------------ Accuracy: 52.6%\n",
            "Step: 197 ------------ Loss: 10057.99 ------------ Accuracy: 52.6%\n",
            "Step: 198 ------------ Loss: 10053.85 ------------ Accuracy: 52.7%\n",
            "Step: 199 ------------ Loss: 10049.86 ------------ Accuracy: 52.8%\n",
            "Step: 200 ------------ Loss: 10045.62 ------------ Accuracy: 52.6%\n",
            "Step: 201 ------------ Loss: 10041.49 ------------ Accuracy: 52.6%\n",
            "Step: 202 ------------ Loss: 10037.37 ------------ Accuracy: 52.6%\n",
            "Step: 203 ------------ Loss: 10033.43 ------------ Accuracy: 52.6%\n",
            "Step: 204 ------------ Loss: 10029.41 ------------ Accuracy: 52.6%\n",
            "Step: 205 ------------ Loss: 10025.53 ------------ Accuracy: 52.8%\n",
            "Step: 206 ------------ Loss: 10021.43 ------------ Accuracy: 52.6%\n",
            "Step: 207 ------------ Loss: 10017.48 ------------ Accuracy: 52.6%\n",
            "Step: 208 ------------ Loss: 10013.49 ------------ Accuracy: 52.6%\n",
            "Step: 209 ------------ Loss: 10009.71 ------------ Accuracy: 52.9%\n",
            "Step: 210 ------------ Loss: 10005.78 ------------ Accuracy: 52.8%\n",
            "Step: 211 ------------ Loss: 10001.87 ------------ Accuracy: 52.9%\n",
            "Step: 212 ------------ Loss: 9998.04 ------------ Accuracy: 52.6%\n",
            "Step: 213 ------------ Loss: 9994.51 ------------ Accuracy: 52.9%\n",
            "Step: 214 ------------ Loss: 9990.6 ------------ Accuracy: 52.9%\n",
            "Step: 215 ------------ Loss: 9986.7 ------------ Accuracy: 52.9%\n",
            "Step: 216 ------------ Loss: 9982.91 ------------ Accuracy: 52.8%\n",
            "Step: 217 ------------ Loss: 9979.2 ------------ Accuracy: 52.8%\n",
            "Step: 218 ------------ Loss: 9975.51 ------------ Accuracy: 52.6%\n",
            "Step: 219 ------------ Loss: 9971.82 ------------ Accuracy: 52.9%\n",
            "Step: 220 ------------ Loss: 9968.17 ------------ Accuracy: 52.9%\n",
            "Step: 221 ------------ Loss: 9964.5 ------------ Accuracy: 52.9%\n",
            "Step: 222 ------------ Loss: 9961.13 ------------ Accuracy: 53.0%\n",
            "Step: 223 ------------ Loss: 9957.34 ------------ Accuracy: 52.9%\n",
            "Step: 224 ------------ Loss: 9953.72 ------------ Accuracy: 52.9%\n",
            "Step: 225 ------------ Loss: 9950.05 ------------ Accuracy: 52.9%\n",
            "Step: 226 ------------ Loss: 9946.54 ------------ Accuracy: 52.9%\n",
            "Step: 227 ------------ Loss: 9943.03 ------------ Accuracy: 52.9%\n",
            "Step: 228 ------------ Loss: 9939.65 ------------ Accuracy: 53.0%\n",
            "Step: 229 ------------ Loss: 9936.01 ------------ Accuracy: 52.9%\n",
            "Step: 230 ------------ Loss: 9932.53 ------------ Accuracy: 52.9%\n",
            "Step: 231 ------------ Loss: 9929.0 ------------ Accuracy: 52.9%\n",
            "Step: 232 ------------ Loss: 9925.62 ------------ Accuracy: 52.8%\n",
            "Step: 233 ------------ Loss: 9922.21 ------------ Accuracy: 53.0%\n",
            "Step: 234 ------------ Loss: 9918.75 ------------ Accuracy: 53.0%\n",
            "Step: 235 ------------ Loss: 9915.36 ------------ Accuracy: 52.9%\n",
            "Step: 236 ------------ Loss: 9912.24 ------------ Accuracy: 53.0%\n",
            "Step: 237 ------------ Loss: 9908.78 ------------ Accuracy: 53.0%\n",
            "Step: 238 ------------ Loss: 9905.31 ------------ Accuracy: 53.0%\n",
            "Step: 239 ------------ Loss: 9901.96 ------------ Accuracy: 52.9%\n",
            "Step: 240 ------------ Loss: 9898.67 ------------ Accuracy: 52.9%\n",
            "Step: 241 ------------ Loss: 9895.41 ------------ Accuracy: 52.9%\n",
            "Step: 242 ------------ Loss: 9892.25 ------------ Accuracy: 53.0%\n",
            "Step: 243 ------------ Loss: 9888.93 ------------ Accuracy: 52.9%\n",
            "Step: 244 ------------ Loss: 9885.59 ------------ Accuracy: 52.9%\n",
            "Step: 245 ------------ Loss: 9882.37 ------------ Accuracy: 52.9%\n",
            "Step: 246 ------------ Loss: 9879.2 ------------ Accuracy: 52.9%\n",
            "Step: 247 ------------ Loss: 9876.02 ------------ Accuracy: 53.0%\n",
            "Step: 248 ------------ Loss: 9872.78 ------------ Accuracy: 53.0%\n",
            "Step: 249 ------------ Loss: 9869.69 ------------ Accuracy: 53.0%\n",
            "Step: 250 ------------ Loss: 9866.54 ------------ Accuracy: 53.0%\n",
            "Step: 251 ------------ Loss: 9863.48 ------------ Accuracy: 53.0%\n",
            "Step: 252 ------------ Loss: 9860.28 ------------ Accuracy: 53.0%\n",
            "Step: 253 ------------ Loss: 9857.13 ------------ Accuracy: 53.0%\n",
            "Step: 254 ------------ Loss: 9854.03 ------------ Accuracy: 53.0%\n",
            "Step: 255 ------------ Loss: 9851.04 ------------ Accuracy: 53.0%\n",
            "Step: 256 ------------ Loss: 9848.12 ------------ Accuracy: 53.0%\n",
            "Step: 257 ------------ Loss: 9844.92 ------------ Accuracy: 53.0%\n",
            "Step: 258 ------------ Loss: 9841.87 ------------ Accuracy: 53.0%\n",
            "Step: 259 ------------ Loss: 9838.82 ------------ Accuracy: 53.0%\n",
            "Step: 260 ------------ Loss: 9835.86 ------------ Accuracy: 52.9%\n",
            "Step: 261 ------------ Loss: 9832.87 ------------ Accuracy: 53.0%\n",
            "Step: 262 ------------ Loss: 9829.89 ------------ Accuracy: 53.0%\n",
            "Step: 263 ------------ Loss: 9826.92 ------------ Accuracy: 53.0%\n",
            "Step: 264 ------------ Loss: 9824.18 ------------ Accuracy: 53.0%\n",
            "Step: 265 ------------ Loss: 9821.17 ------------ Accuracy: 53.0%\n",
            "Step: 266 ------------ Loss: 9818.14 ------------ Accuracy: 53.0%\n",
            "Step: 267 ------------ Loss: 9815.22 ------------ Accuracy: 53.0%\n",
            "Step: 268 ------------ Loss: 9812.35 ------------ Accuracy: 53.0%\n",
            "Step: 269 ------------ Loss: 9809.54 ------------ Accuracy: 53.0%\n",
            "Step: 270 ------------ Loss: 9806.61 ------------ Accuracy: 53.0%\n",
            "Step: 271 ------------ Loss: 9803.8 ------------ Accuracy: 53.0%\n",
            "Step: 272 ------------ Loss: 9800.96 ------------ Accuracy: 53.0%\n",
            "Step: 273 ------------ Loss: 9798.21 ------------ Accuracy: 53.0%\n",
            "Step: 274 ------------ Loss: 9795.33 ------------ Accuracy: 53.0%\n",
            "Step: 275 ------------ Loss: 9792.46 ------------ Accuracy: 53.0%\n",
            "Step: 276 ------------ Loss: 9789.67 ------------ Accuracy: 53.0%\n",
            "Step: 277 ------------ Loss: 9786.95 ------------ Accuracy: 53.0%\n",
            "Step: 278 ------------ Loss: 9784.29 ------------ Accuracy: 53.0%\n",
            "Step: 279 ------------ Loss: 9781.42 ------------ Accuracy: 53.0%\n",
            "Step: 280 ------------ Loss: 9778.67 ------------ Accuracy: 53.0%\n",
            "Step: 281 ------------ Loss: 9775.89 ------------ Accuracy: 53.0%\n",
            "Step: 282 ------------ Loss: 9773.24 ------------ Accuracy: 53.0%\n",
            "Step: 283 ------------ Loss: 9770.55 ------------ Accuracy: 53.0%\n",
            "Step: 284 ------------ Loss: 9767.82 ------------ Accuracy: 53.0%\n",
            "Step: 285 ------------ Loss: 9765.16 ------------ Accuracy: 53.0%\n",
            "Step: 286 ------------ Loss: 9762.65 ------------ Accuracy: 53.1%\n",
            "Step: 287 ------------ Loss: 9759.89 ------------ Accuracy: 53.1%\n",
            "Step: 288 ------------ Loss: 9757.16 ------------ Accuracy: 53.0%\n",
            "Step: 289 ------------ Loss: 9754.55 ------------ Accuracy: 53.1%\n",
            "Step: 290 ------------ Loss: 9751.91 ------------ Accuracy: 53.0%\n",
            "Step: 291 ------------ Loss: 9749.45 ------------ Accuracy: 53.2%\n",
            "Step: 292 ------------ Loss: 9746.77 ------------ Accuracy: 53.1%\n",
            "Step: 293 ------------ Loss: 9744.1 ------------ Accuracy: 53.1%\n",
            "Step: 294 ------------ Loss: 9741.51 ------------ Accuracy: 53.0%\n",
            "Step: 295 ------------ Loss: 9738.98 ------------ Accuracy: 53.0%\n",
            "Step: 296 ------------ Loss: 9736.45 ------------ Accuracy: 53.2%\n",
            "Step: 297 ------------ Loss: 9733.86 ------------ Accuracy: 53.1%\n",
            "Step: 298 ------------ Loss: 9731.38 ------------ Accuracy: 53.1%\n",
            "Step: 299 ------------ Loss: 9729.0 ------------ Accuracy: 53.2%\n",
            "Step: 300 ------------ Loss: 9726.35 ------------ Accuracy: 53.2%\n",
            "Step: 301 ------------ Loss: 9723.83 ------------ Accuracy: 53.2%\n",
            "Step: 302 ------------ Loss: 9721.27 ------------ Accuracy: 53.2%\n",
            "Step: 303 ------------ Loss: 9718.81 ------------ Accuracy: 53.1%\n",
            "Step: 304 ------------ Loss: 9716.51 ------------ Accuracy: 53.2%\n",
            "Step: 305 ------------ Loss: 9713.92 ------------ Accuracy: 53.2%\n",
            "Step: 306 ------------ Loss: 9711.41 ------------ Accuracy: 53.2%\n",
            "Step: 307 ------------ Loss: 9708.97 ------------ Accuracy: 53.2%\n",
            "Step: 308 ------------ Loss: 9706.54 ------------ Accuracy: 53.1%\n",
            "Step: 309 ------------ Loss: 9704.15 ------------ Accuracy: 53.2%\n",
            "Step: 310 ------------ Loss: 9701.75 ------------ Accuracy: 53.2%\n",
            "Step: 311 ------------ Loss: 9699.32 ------------ Accuracy: 53.2%\n",
            "Step: 312 ------------ Loss: 9697.07 ------------ Accuracy: 53.2%\n",
            "Step: 313 ------------ Loss: 9694.61 ------------ Accuracy: 53.2%\n",
            "Step: 314 ------------ Loss: 9692.15 ------------ Accuracy: 53.2%\n",
            "Step: 315 ------------ Loss: 9689.77 ------------ Accuracy: 53.2%\n",
            "Step: 316 ------------ Loss: 9687.45 ------------ Accuracy: 53.2%\n",
            "Step: 317 ------------ Loss: 9685.22 ------------ Accuracy: 53.2%\n",
            "Step: 318 ------------ Loss: 9682.79 ------------ Accuracy: 53.2%\n",
            "Step: 319 ------------ Loss: 9680.42 ------------ Accuracy: 53.2%\n",
            "Step: 320 ------------ Loss: 9678.07 ------------ Accuracy: 53.2%\n",
            "Step: 321 ------------ Loss: 9675.83 ------------ Accuracy: 53.2%\n",
            "Step: 322 ------------ Loss: 9673.63 ------------ Accuracy: 53.2%\n",
            "Step: 323 ------------ Loss: 9671.23 ------------ Accuracy: 53.2%\n",
            "Step: 324 ------------ Loss: 9668.94 ------------ Accuracy: 53.2%\n",
            "Step: 325 ------------ Loss: 9666.62 ------------ Accuracy: 53.3%\n",
            "Step: 326 ------------ Loss: 9664.42 ------------ Accuracy: 53.2%\n",
            "Step: 327 ------------ Loss: 9662.13 ------------ Accuracy: 53.2%\n",
            "Step: 328 ------------ Loss: 9659.86 ------------ Accuracy: 53.2%\n",
            "Step: 329 ------------ Loss: 9657.65 ------------ Accuracy: 53.3%\n",
            "Step: 330 ------------ Loss: 9655.53 ------------ Accuracy: 53.2%\n",
            "Step: 331 ------------ Loss: 9653.21 ------------ Accuracy: 53.2%\n",
            "Step: 332 ------------ Loss: 9650.95 ------------ Accuracy: 53.3%\n",
            "Step: 333 ------------ Loss: 9648.76 ------------ Accuracy: 53.2%\n",
            "Step: 334 ------------ Loss: 9646.57 ------------ Accuracy: 53.3%\n",
            "Step: 335 ------------ Loss: 9644.47 ------------ Accuracy: 53.2%\n",
            "Step: 336 ------------ Loss: 9642.24 ------------ Accuracy: 53.2%\n",
            "Step: 337 ------------ Loss: 9640.0 ------------ Accuracy: 53.3%\n",
            "Step: 338 ------------ Loss: 9637.86 ------------ Accuracy: 53.3%\n",
            "Step: 339 ------------ Loss: 9635.72 ------------ Accuracy: 53.3%\n",
            "Step: 340 ------------ Loss: 9633.65 ------------ Accuracy: 53.2%\n",
            "Step: 341 ------------ Loss: 9631.46 ------------ Accuracy: 53.3%\n",
            "Step: 342 ------------ Loss: 9629.28 ------------ Accuracy: 53.3%\n",
            "Step: 343 ------------ Loss: 9627.15 ------------ Accuracy: 53.3%\n",
            "Step: 344 ------------ Loss: 9625.08 ------------ Accuracy: 53.2%\n",
            "Step: 345 ------------ Loss: 9622.94 ------------ Accuracy: 53.2%\n",
            "Step: 346 ------------ Loss: 9620.82 ------------ Accuracy: 53.3%\n",
            "Step: 347 ------------ Loss: 9618.8 ------------ Accuracy: 53.3%\n",
            "Step: 348 ------------ Loss: 9616.75 ------------ Accuracy: 53.2%\n",
            "Step: 349 ------------ Loss: 9614.6 ------------ Accuracy: 53.3%\n",
            "Step: 350 ------------ Loss: 9612.52 ------------ Accuracy: 53.3%\n",
            "Step: 351 ------------ Loss: 9610.44 ------------ Accuracy: 53.3%\n",
            "Step: 352 ------------ Loss: 9608.45 ------------ Accuracy: 53.2%\n",
            "Step: 353 ------------ Loss: 9606.4 ------------ Accuracy: 53.3%\n",
            "Step: 354 ------------ Loss: 9604.33 ------------ Accuracy: 53.3%\n",
            "Step: 355 ------------ Loss: 9602.45 ------------ Accuracy: 53.2%\n",
            "Step: 356 ------------ Loss: 9600.36 ------------ Accuracy: 53.2%\n",
            "Step: 357 ------------ Loss: 9598.26 ------------ Accuracy: 53.3%\n",
            "Step: 358 ------------ Loss: 9596.24 ------------ Accuracy: 53.3%\n",
            "Step: 359 ------------ Loss: 9594.26 ------------ Accuracy: 53.3%\n",
            "Step: 360 ------------ Loss: 9592.36 ------------ Accuracy: 53.2%\n",
            "Step: 361 ------------ Loss: 9590.31 ------------ Accuracy: 53.3%\n",
            "Step: 362 ------------ Loss: 9588.28 ------------ Accuracy: 53.3%\n",
            "Step: 363 ------------ Loss: 9586.29 ------------ Accuracy: 53.3%\n",
            "Step: 364 ------------ Loss: 9584.38 ------------ Accuracy: 53.3%\n",
            "Step: 365 ------------ Loss: 9582.47 ------------ Accuracy: 53.3%\n",
            "Step: 366 ------------ Loss: 9580.46 ------------ Accuracy: 53.3%\n",
            "Step: 367 ------------ Loss: 9578.48 ------------ Accuracy: 53.3%\n",
            "Step: 368 ------------ Loss: 9576.53 ------------ Accuracy: 53.3%\n",
            "Step: 369 ------------ Loss: 9574.65 ------------ Accuracy: 53.3%\n",
            "Step: 370 ------------ Loss: 9572.71 ------------ Accuracy: 53.3%\n",
            "Step: 371 ------------ Loss: 9570.78 ------------ Accuracy: 53.3%\n",
            "Step: 372 ------------ Loss: 9569.02 ------------ Accuracy: 53.3%\n",
            "Step: 373 ------------ Loss: 9567.03 ------------ Accuracy: 53.3%\n",
            "Step: 374 ------------ Loss: 9565.07 ------------ Accuracy: 53.3%\n",
            "Step: 375 ------------ Loss: 9563.18 ------------ Accuracy: 53.3%\n",
            "Step: 376 ------------ Loss: 9561.3 ------------ Accuracy: 53.3%\n",
            "Step: 377 ------------ Loss: 9559.52 ------------ Accuracy: 53.3%\n",
            "Step: 378 ------------ Loss: 9557.59 ------------ Accuracy: 53.3%\n",
            "Step: 379 ------------ Loss: 9555.66 ------------ Accuracy: 53.3%\n",
            "Step: 380 ------------ Loss: 9553.81 ------------ Accuracy: 53.3%\n",
            "Step: 381 ------------ Loss: 9551.99 ------------ Accuracy: 53.3%\n",
            "Step: 382 ------------ Loss: 9550.2 ------------ Accuracy: 53.3%\n",
            "Step: 383 ------------ Loss: 9548.31 ------------ Accuracy: 53.3%\n",
            "Step: 384 ------------ Loss: 9546.44 ------------ Accuracy: 53.3%\n",
            "Step: 385 ------------ Loss: 9544.62 ------------ Accuracy: 53.3%\n",
            "Step: 386 ------------ Loss: 9542.83 ------------ Accuracy: 53.3%\n",
            "Step: 387 ------------ Loss: 9540.99 ------------ Accuracy: 53.3%\n",
            "Step: 388 ------------ Loss: 9539.18 ------------ Accuracy: 53.3%\n",
            "Step: 389 ------------ Loss: 9537.52 ------------ Accuracy: 53.3%\n",
            "Step: 390 ------------ Loss: 9535.63 ------------ Accuracy: 53.3%\n",
            "Step: 391 ------------ Loss: 9533.79 ------------ Accuracy: 53.3%\n",
            "Step: 392 ------------ Loss: 9532.02 ------------ Accuracy: 53.3%\n",
            "Step: 393 ------------ Loss: 9530.24 ------------ Accuracy: 53.3%\n",
            "Step: 394 ------------ Loss: 9528.56 ------------ Accuracy: 53.3%\n",
            "Step: 395 ------------ Loss: 9526.73 ------------ Accuracy: 53.3%\n",
            "Step: 396 ------------ Loss: 9524.92 ------------ Accuracy: 53.3%\n",
            "Step: 397 ------------ Loss: 9523.2 ------------ Accuracy: 53.3%\n",
            "Step: 398 ------------ Loss: 9521.49 ------------ Accuracy: 53.3%\n",
            "Step: 399 ------------ Loss: 9519.7 ------------ Accuracy: 53.3%\n",
            "Step: 400 ------------ Loss: 9517.99 ------------ Accuracy: 53.3%\n",
            "Step: 401 ------------ Loss: 9516.28 ------------ Accuracy: 53.3%\n",
            "Step: 402 ------------ Loss: 9514.57 ------------ Accuracy: 53.3%\n",
            "Step: 403 ------------ Loss: 9512.82 ------------ Accuracy: 53.3%\n",
            "Step: 404 ------------ Loss: 9511.06 ------------ Accuracy: 53.3%\n",
            "Step: 405 ------------ Loss: 9509.38 ------------ Accuracy: 53.3%\n",
            "Step: 406 ------------ Loss: 9507.8 ------------ Accuracy: 53.3%\n",
            "Step: 407 ------------ Loss: 9506.0 ------------ Accuracy: 53.3%\n",
            "Step: 408 ------------ Loss: 9504.28 ------------ Accuracy: 53.3%\n",
            "Step: 409 ------------ Loss: 9502.59 ------------ Accuracy: 53.3%\n",
            "Step: 410 ------------ Loss: 9500.94 ------------ Accuracy: 53.3%\n",
            "Step: 411 ------------ Loss: 9499.33 ------------ Accuracy: 53.3%\n",
            "Step: 412 ------------ Loss: 9497.58 ------------ Accuracy: 53.3%\n",
            "Step: 413 ------------ Loss: 9495.9 ------------ Accuracy: 53.3%\n",
            "Step: 414 ------------ Loss: 9494.26 ------------ Accuracy: 53.3%\n",
            "Step: 415 ------------ Loss: 9492.63 ------------ Accuracy: 53.4%\n",
            "Step: 416 ------------ Loss: 9490.96 ------------ Accuracy: 53.4%\n",
            "Step: 417 ------------ Loss: 9489.35 ------------ Accuracy: 53.3%\n",
            "Step: 418 ------------ Loss: 9487.78 ------------ Accuracy: 53.4%\n",
            "Step: 419 ------------ Loss: 9486.09 ------------ Accuracy: 53.4%\n",
            "Step: 420 ------------ Loss: 9484.43 ------------ Accuracy: 53.4%\n",
            "Step: 421 ------------ Loss: 9482.8 ------------ Accuracy: 53.4%\n",
            "Step: 422 ------------ Loss: 9481.24 ------------ Accuracy: 53.4%\n",
            "Step: 423 ------------ Loss: 9479.65 ------------ Accuracy: 53.4%\n",
            "Step: 424 ------------ Loss: 9477.99 ------------ Accuracy: 53.4%\n",
            "Step: 425 ------------ Loss: 9476.37 ------------ Accuracy: 53.4%\n",
            "Step: 426 ------------ Loss: 9474.78 ------------ Accuracy: 53.4%\n",
            "Step: 427 ------------ Loss: 9473.23 ------------ Accuracy: 53.4%\n",
            "Step: 428 ------------ Loss: 9471.67 ------------ Accuracy: 53.4%\n",
            "Step: 429 ------------ Loss: 9470.1 ------------ Accuracy: 53.4%\n",
            "Step: 430 ------------ Loss: 9468.59 ------------ Accuracy: 53.4%\n",
            "Step: 431 ------------ Loss: 9466.97 ------------ Accuracy: 53.4%\n",
            "Step: 432 ------------ Loss: 9465.34 ------------ Accuracy: 53.4%\n",
            "Step: 433 ------------ Loss: 9463.78 ------------ Accuracy: 53.4%\n",
            "Step: 434 ------------ Loss: 9462.27 ------------ Accuracy: 53.4%\n",
            "Step: 435 ------------ Loss: 9460.67 ------------ Accuracy: 53.4%\n",
            "Step: 436 ------------ Loss: 9459.12 ------------ Accuracy: 53.4%\n",
            "Step: 437 ------------ Loss: 9457.62 ------------ Accuracy: 53.4%\n",
            "Step: 438 ------------ Loss: 9456.09 ------------ Accuracy: 53.3%\n",
            "Step: 439 ------------ Loss: 9454.51 ------------ Accuracy: 53.4%\n",
            "Step: 440 ------------ Loss: 9452.96 ------------ Accuracy: 53.4%\n",
            "Step: 441 ------------ Loss: 9451.44 ------------ Accuracy: 53.4%\n",
            "Step: 442 ------------ Loss: 9450.03 ------------ Accuracy: 53.3%\n",
            "Step: 443 ------------ Loss: 9448.42 ------------ Accuracy: 53.3%\n",
            "Step: 444 ------------ Loss: 9446.88 ------------ Accuracy: 53.4%\n",
            "Step: 445 ------------ Loss: 9445.38 ------------ Accuracy: 53.4%\n",
            "Step: 446 ------------ Loss: 9443.89 ------------ Accuracy: 53.4%\n",
            "Step: 447 ------------ Loss: 9442.45 ------------ Accuracy: 53.3%\n",
            "Step: 448 ------------ Loss: 9440.89 ------------ Accuracy: 53.3%\n",
            "Step: 449 ------------ Loss: 9439.38 ------------ Accuracy: 53.4%\n",
            "Step: 450 ------------ Loss: 9437.92 ------------ Accuracy: 53.3%\n",
            "Step: 451 ------------ Loss: 9436.53 ------------ Accuracy: 53.3%\n",
            "Step: 452 ------------ Loss: 9435.0 ------------ Accuracy: 53.4%\n",
            "Step: 453 ------------ Loss: 9433.48 ------------ Accuracy: 53.4%\n",
            "Step: 454 ------------ Loss: 9432.01 ------------ Accuracy: 53.4%\n",
            "Step: 455 ------------ Loss: 9430.59 ------------ Accuracy: 53.4%\n",
            "Step: 456 ------------ Loss: 9429.17 ------------ Accuracy: 53.3%\n",
            "Step: 457 ------------ Loss: 9427.67 ------------ Accuracy: 53.4%\n",
            "Step: 458 ------------ Loss: 9426.2 ------------ Accuracy: 53.4%\n",
            "Step: 459 ------------ Loss: 9424.75 ------------ Accuracy: 53.4%\n",
            "Step: 460 ------------ Loss: 9423.34 ------------ Accuracy: 53.4%\n",
            "Step: 461 ------------ Loss: 9421.9 ------------ Accuracy: 53.4%\n",
            "Step: 462 ------------ Loss: 9420.47 ------------ Accuracy: 53.4%\n",
            "Step: 463 ------------ Loss: 9419.02 ------------ Accuracy: 53.4%\n",
            "Step: 464 ------------ Loss: 9417.59 ------------ Accuracy: 53.4%\n",
            "Step: 465 ------------ Loss: 9416.19 ------------ Accuracy: 53.4%\n",
            "Step: 466 ------------ Loss: 9414.81 ------------ Accuracy: 53.4%\n",
            "Step: 467 ------------ Loss: 9413.36 ------------ Accuracy: 53.4%\n",
            "Step: 468 ------------ Loss: 9411.91 ------------ Accuracy: 53.5%\n",
            "Step: 469 ------------ Loss: 9410.5 ------------ Accuracy: 53.5%\n",
            "Step: 470 ------------ Loss: 9409.14 ------------ Accuracy: 53.5%\n",
            "Step: 471 ------------ Loss: 9407.75 ------------ Accuracy: 53.4%\n",
            "Step: 472 ------------ Loss: 9406.33 ------------ Accuracy: 53.4%\n",
            "Step: 473 ------------ Loss: 9404.91 ------------ Accuracy: 53.5%\n",
            "Step: 474 ------------ Loss: 9403.53 ------------ Accuracy: 53.5%\n",
            "Step: 475 ------------ Loss: 9402.2 ------------ Accuracy: 53.5%\n",
            "Step: 476 ------------ Loss: 9400.84 ------------ Accuracy: 53.5%\n",
            "Step: 477 ------------ Loss: 9399.47 ------------ Accuracy: 53.5%\n",
            "Step: 478 ------------ Loss: 9398.13 ------------ Accuracy: 53.5%\n",
            "Step: 479 ------------ Loss: 9396.7 ------------ Accuracy: 53.5%\n",
            "Step: 480 ------------ Loss: 9395.31 ------------ Accuracy: 53.5%\n",
            "Step: 481 ------------ Loss: 9393.96 ------------ Accuracy: 53.5%\n",
            "Step: 482 ------------ Loss: 9392.62 ------------ Accuracy: 53.5%\n",
            "Step: 483 ------------ Loss: 9391.28 ------------ Accuracy: 53.5%\n",
            "Step: 484 ------------ Loss: 9389.89 ------------ Accuracy: 53.5%\n",
            "Step: 485 ------------ Loss: 9388.51 ------------ Accuracy: 53.5%\n",
            "Step: 486 ------------ Loss: 9387.19 ------------ Accuracy: 53.5%\n",
            "Step: 487 ------------ Loss: 9385.9 ------------ Accuracy: 53.5%\n",
            "Step: 488 ------------ Loss: 9384.53 ------------ Accuracy: 53.5%\n",
            "Step: 489 ------------ Loss: 9383.22 ------------ Accuracy: 53.5%\n",
            "Step: 490 ------------ Loss: 9381.98 ------------ Accuracy: 53.6%\n",
            "Step: 491 ------------ Loss: 9380.58 ------------ Accuracy: 53.6%\n",
            "Step: 492 ------------ Loss: 9379.27 ------------ Accuracy: 53.6%\n",
            "Step: 493 ------------ Loss: 9377.97 ------------ Accuracy: 53.6%\n",
            "Step: 494 ------------ Loss: 9376.71 ------------ Accuracy: 53.6%\n",
            "Step: 495 ------------ Loss: 9375.34 ------------ Accuracy: 53.6%\n",
            "Step: 496 ------------ Loss: 9373.99 ------------ Accuracy: 53.6%\n",
            "Step: 497 ------------ Loss: 9372.68 ------------ Accuracy: 53.6%\n",
            "Step: 498 ------------ Loss: 9371.41 ------------ Accuracy: 53.6%\n",
            "Step: 499 ------------ Loss: 9370.14 ------------ Accuracy: 53.7%\n",
            "Step: 500 ------------ Loss: 9368.8 ------------ Accuracy: 53.7%\n",
            "Step: 501 ------------ Loss: 9367.48 ------------ Accuracy: 53.7%\n",
            "Step: 502 ------------ Loss: 9366.19 ------------ Accuracy: 53.7%\n",
            "Step: 503 ------------ Loss: 9364.95 ------------ Accuracy: 53.6%\n",
            "Step: 504 ------------ Loss: 9363.66 ------------ Accuracy: 53.6%\n",
            "Step: 505 ------------ Loss: 9362.38 ------------ Accuracy: 53.6%\n",
            "Step: 506 ------------ Loss: 9361.21 ------------ Accuracy: 53.7%\n",
            "Step: 507 ------------ Loss: 9359.92 ------------ Accuracy: 53.6%\n",
            "Step: 508 ------------ Loss: 9358.61 ------------ Accuracy: 53.6%\n",
            "Step: 509 ------------ Loss: 9357.35 ------------ Accuracy: 53.6%\n",
            "Step: 510 ------------ Loss: 9356.11 ------------ Accuracy: 53.7%\n",
            "Step: 511 ------------ Loss: 9354.83 ------------ Accuracy: 53.7%\n",
            "Step: 512 ------------ Loss: 9353.58 ------------ Accuracy: 53.7%\n",
            "Step: 513 ------------ Loss: 9352.41 ------------ Accuracy: 53.7%\n",
            "Step: 514 ------------ Loss: 9351.08 ------------ Accuracy: 53.7%\n",
            "Step: 515 ------------ Loss: 9349.81 ------------ Accuracy: 53.7%\n",
            "Step: 516 ------------ Loss: 9348.57 ------------ Accuracy: 53.7%\n",
            "Step: 517 ------------ Loss: 9347.35 ------------ Accuracy: 53.7%\n",
            "Step: 518 ------------ Loss: 9346.16 ------------ Accuracy: 53.8%\n",
            "Step: 519 ------------ Loss: 9344.87 ------------ Accuracy: 53.7%\n",
            "Step: 520 ------------ Loss: 9343.63 ------------ Accuracy: 53.7%\n",
            "Step: 521 ------------ Loss: 9342.41 ------------ Accuracy: 53.7%\n",
            "Step: 522 ------------ Loss: 9341.27 ------------ Accuracy: 53.8%\n",
            "Step: 523 ------------ Loss: 9340.02 ------------ Accuracy: 53.7%\n",
            "Step: 524 ------------ Loss: 9338.79 ------------ Accuracy: 53.7%\n",
            "Step: 525 ------------ Loss: 9337.57 ------------ Accuracy: 53.7%\n",
            "Step: 526 ------------ Loss: 9336.37 ------------ Accuracy: 53.8%\n",
            "Step: 527 ------------ Loss: 9335.16 ------------ Accuracy: 53.8%\n",
            "Step: 528 ------------ Loss: 9333.95 ------------ Accuracy: 53.8%\n",
            "Step: 529 ------------ Loss: 9332.81 ------------ Accuracy: 53.8%\n",
            "Step: 530 ------------ Loss: 9331.55 ------------ Accuracy: 53.8%\n",
            "Step: 531 ------------ Loss: 9330.33 ------------ Accuracy: 53.7%\n",
            "Step: 532 ------------ Loss: 9329.15 ------------ Accuracy: 53.7%\n",
            "Step: 533 ------------ Loss: 9327.97 ------------ Accuracy: 53.7%\n",
            "Step: 534 ------------ Loss: 9326.82 ------------ Accuracy: 53.7%\n",
            "Step: 535 ------------ Loss: 9325.64 ------------ Accuracy: 53.8%\n",
            "Step: 536 ------------ Loss: 9324.44 ------------ Accuracy: 53.8%\n",
            "Step: 537 ------------ Loss: 9323.29 ------------ Accuracy: 53.7%\n",
            "Step: 538 ------------ Loss: 9322.09 ------------ Accuracy: 53.7%\n",
            "Step: 539 ------------ Loss: 9320.92 ------------ Accuracy: 53.7%\n",
            "Step: 540 ------------ Loss: 9319.83 ------------ Accuracy: 53.8%\n",
            "Step: 541 ------------ Loss: 9318.61 ------------ Accuracy: 53.8%\n",
            "Step: 542 ------------ Loss: 9317.4 ------------ Accuracy: 53.8%\n",
            "Step: 543 ------------ Loss: 9316.23 ------------ Accuracy: 53.8%\n",
            "Step: 544 ------------ Loss: 9315.09 ------------ Accuracy: 53.8%\n",
            "Step: 545 ------------ Loss: 9313.98 ------------ Accuracy: 53.8%\n",
            "Step: 546 ------------ Loss: 9312.84 ------------ Accuracy: 53.8%\n",
            "Step: 547 ------------ Loss: 9311.68 ------------ Accuracy: 53.8%\n",
            "Step: 548 ------------ Loss: 9310.52 ------------ Accuracy: 53.8%\n",
            "Step: 549 ------------ Loss: 9309.42 ------------ Accuracy: 53.8%\n",
            "Step: 550 ------------ Loss: 9308.22 ------------ Accuracy: 53.8%\n",
            "Step: 551 ------------ Loss: 9307.04 ------------ Accuracy: 53.8%\n",
            "Step: 552 ------------ Loss: 9305.91 ------------ Accuracy: 53.8%\n",
            "Step: 553 ------------ Loss: 9304.78 ------------ Accuracy: 53.8%\n",
            "Step: 554 ------------ Loss: 9303.69 ------------ Accuracy: 53.8%\n",
            "Step: 555 ------------ Loss: 9302.51 ------------ Accuracy: 53.8%\n",
            "Step: 556 ------------ Loss: 9301.36 ------------ Accuracy: 53.8%\n",
            "Step: 557 ------------ Loss: 9300.25 ------------ Accuracy: 53.8%\n",
            "Step: 558 ------------ Loss: 9299.21 ------------ Accuracy: 53.8%\n",
            "Step: 559 ------------ Loss: 9298.08 ------------ Accuracy: 53.8%\n",
            "Step: 560 ------------ Loss: 9296.95 ------------ Accuracy: 53.8%\n",
            "Step: 561 ------------ Loss: 9295.83 ------------ Accuracy: 53.8%\n",
            "Step: 562 ------------ Loss: 9294.72 ------------ Accuracy: 53.8%\n",
            "Step: 563 ------------ Loss: 9293.6 ------------ Accuracy: 53.8%\n",
            "Step: 564 ------------ Loss: 9292.5 ------------ Accuracy: 53.8%\n",
            "Step: 565 ------------ Loss: 9291.45 ------------ Accuracy: 53.8%\n",
            "Step: 566 ------------ Loss: 9290.3 ------------ Accuracy: 53.8%\n",
            "Step: 567 ------------ Loss: 9289.17 ------------ Accuracy: 53.8%\n",
            "Step: 568 ------------ Loss: 9288.08 ------------ Accuracy: 53.8%\n",
            "Step: 569 ------------ Loss: 9287.01 ------------ Accuracy: 53.8%\n",
            "Step: 570 ------------ Loss: 9285.95 ------------ Accuracy: 54.0%\n",
            "Step: 571 ------------ Loss: 9284.86 ------------ Accuracy: 53.8%\n",
            "Step: 572 ------------ Loss: 9283.77 ------------ Accuracy: 53.8%\n",
            "Step: 573 ------------ Loss: 9282.7 ------------ Accuracy: 54.0%\n",
            "Step: 574 ------------ Loss: 9281.6 ------------ Accuracy: 54.0%\n",
            "Step: 575 ------------ Loss: 9280.54 ------------ Accuracy: 54.0%\n",
            "Step: 576 ------------ Loss: 9279.52 ------------ Accuracy: 54.0%\n",
            "Step: 577 ------------ Loss: 9278.4 ------------ Accuracy: 54.0%\n",
            "Step: 578 ------------ Loss: 9277.29 ------------ Accuracy: 54.0%\n",
            "Step: 579 ------------ Loss: 9276.22 ------------ Accuracy: 54.0%\n",
            "Step: 580 ------------ Loss: 9275.18 ------------ Accuracy: 54.0%\n",
            "Step: 581 ------------ Loss: 9274.15 ------------ Accuracy: 54.0%\n",
            "Step: 582 ------------ Loss: 9273.08 ------------ Accuracy: 54.0%\n",
            "Step: 583 ------------ Loss: 9272.02 ------------ Accuracy: 54.0%\n",
            "Step: 584 ------------ Loss: 9270.96 ------------ Accuracy: 54.0%\n",
            "Step: 585 ------------ Loss: 9269.93 ------------ Accuracy: 54.0%\n",
            "Step: 586 ------------ Loss: 9268.83 ------------ Accuracy: 53.9%\n",
            "Step: 587 ------------ Loss: 9267.75 ------------ Accuracy: 53.9%\n",
            "Step: 588 ------------ Loss: 9266.71 ------------ Accuracy: 54.0%\n",
            "Step: 589 ------------ Loss: 9265.69 ------------ Accuracy: 53.9%\n",
            "Step: 590 ------------ Loss: 9264.66 ------------ Accuracy: 54.1%\n",
            "Step: 591 ------------ Loss: 9263.59 ------------ Accuracy: 54.1%\n",
            "Step: 592 ------------ Loss: 9262.53 ------------ Accuracy: 54.1%\n",
            "Step: 593 ------------ Loss: 9261.52 ------------ Accuracy: 54.1%\n",
            "Step: 594 ------------ Loss: 9260.51 ------------ Accuracy: 54.0%\n",
            "Step: 595 ------------ Loss: 9259.49 ------------ Accuracy: 54.0%\n",
            "Step: 596 ------------ Loss: 9258.44 ------------ Accuracy: 54.1%\n",
            "Step: 597 ------------ Loss: 9257.42 ------------ Accuracy: 54.1%\n",
            "Step: 598 ------------ Loss: 9256.44 ------------ Accuracy: 54.0%\n",
            "Step: 599 ------------ Loss: 9255.38 ------------ Accuracy: 54.1%\n",
            "Step: 600 ------------ Loss: 9254.32 ------------ Accuracy: 54.0%\n",
            "Step: 601 ------------ Loss: 9253.3 ------------ Accuracy: 54.0%\n",
            "Step: 602 ------------ Loss: 9252.31 ------------ Accuracy: 54.1%\n",
            "Step: 603 ------------ Loss: 9251.33 ------------ Accuracy: 54.0%\n",
            "Step: 604 ------------ Loss: 9250.33 ------------ Accuracy: 54.0%\n",
            "Step: 605 ------------ Loss: 9249.32 ------------ Accuracy: 54.0%\n",
            "Step: 606 ------------ Loss: 9248.31 ------------ Accuracy: 54.1%\n",
            "Step: 607 ------------ Loss: 9247.28 ------------ Accuracy: 54.1%\n",
            "Step: 608 ------------ Loss: 9246.29 ------------ Accuracy: 54.0%\n",
            "Step: 609 ------------ Loss: 9245.35 ------------ Accuracy: 54.1%\n",
            "Step: 610 ------------ Loss: 9244.3 ------------ Accuracy: 54.1%\n",
            "Step: 611 ------------ Loss: 9243.28 ------------ Accuracy: 54.0%\n",
            "Step: 612 ------------ Loss: 9242.28 ------------ Accuracy: 54.0%\n",
            "Step: 613 ------------ Loss: 9241.31 ------------ Accuracy: 54.0%\n",
            "Step: 614 ------------ Loss: 9240.4 ------------ Accuracy: 54.1%\n",
            "Step: 615 ------------ Loss: 9239.4 ------------ Accuracy: 54.1%\n",
            "Step: 616 ------------ Loss: 9238.37 ------------ Accuracy: 54.1%\n",
            "Step: 617 ------------ Loss: 9237.41 ------------ Accuracy: 54.1%\n",
            "Step: 618 ------------ Loss: 9236.41 ------------ Accuracy: 54.1%\n",
            "Step: 619 ------------ Loss: 9235.43 ------------ Accuracy: 54.1%\n",
            "Step: 620 ------------ Loss: 9234.54 ------------ Accuracy: 54.1%\n",
            "Step: 621 ------------ Loss: 9233.5 ------------ Accuracy: 54.1%\n",
            "Step: 622 ------------ Loss: 9232.51 ------------ Accuracy: 54.1%\n",
            "Step: 623 ------------ Loss: 9231.54 ------------ Accuracy: 54.1%\n",
            "Step: 624 ------------ Loss: 9230.59 ------------ Accuracy: 54.1%\n",
            "Step: 625 ------------ Loss: 9229.67 ------------ Accuracy: 54.0%\n",
            "Step: 626 ------------ Loss: 9228.67 ------------ Accuracy: 54.1%\n",
            "Step: 627 ------------ Loss: 9227.7 ------------ Accuracy: 54.1%\n",
            "Step: 628 ------------ Loss: 9226.81 ------------ Accuracy: 54.1%\n",
            "Step: 629 ------------ Loss: 9225.8 ------------ Accuracy: 54.1%\n",
            "Step: 630 ------------ Loss: 9224.81 ------------ Accuracy: 54.1%\n",
            "Step: 631 ------------ Loss: 9223.85 ------------ Accuracy: 54.1%\n",
            "Step: 632 ------------ Loss: 9222.91 ------------ Accuracy: 54.1%\n",
            "Step: 633 ------------ Loss: 9222.01 ------------ Accuracy: 54.0%\n",
            "Step: 634 ------------ Loss: 9221.06 ------------ Accuracy: 54.1%\n",
            "Step: 635 ------------ Loss: 9220.1 ------------ Accuracy: 54.1%\n",
            "Step: 636 ------------ Loss: 9219.17 ------------ Accuracy: 54.0%\n",
            "Step: 637 ------------ Loss: 9218.21 ------------ Accuracy: 54.0%\n",
            "Step: 638 ------------ Loss: 9217.28 ------------ Accuracy: 54.0%\n",
            "Step: 639 ------------ Loss: 9216.39 ------------ Accuracy: 54.1%\n",
            "Step: 640 ------------ Loss: 9215.42 ------------ Accuracy: 54.1%\n",
            "Step: 641 ------------ Loss: 9214.45 ------------ Accuracy: 54.1%\n",
            "Step: 642 ------------ Loss: 9213.52 ------------ Accuracy: 54.1%\n",
            "Step: 643 ------------ Loss: 9212.61 ------------ Accuracy: 54.1%\n",
            "Step: 644 ------------ Loss: 9211.72 ------------ Accuracy: 54.0%\n",
            "Step: 645 ------------ Loss: 9210.76 ------------ Accuracy: 54.0%\n",
            "Step: 646 ------------ Loss: 9209.84 ------------ Accuracy: 54.0%\n",
            "Step: 647 ------------ Loss: 9208.93 ------------ Accuracy: 54.1%\n",
            "Step: 648 ------------ Loss: 9207.99 ------------ Accuracy: 54.1%\n",
            "Step: 649 ------------ Loss: 9207.08 ------------ Accuracy: 54.1%\n",
            "Step: 650 ------------ Loss: 9206.24 ------------ Accuracy: 53.9%\n",
            "Step: 651 ------------ Loss: 9205.26 ------------ Accuracy: 53.9%\n",
            "Step: 652 ------------ Loss: 9204.36 ------------ Accuracy: 54.1%\n",
            "Step: 653 ------------ Loss: 9203.47 ------------ Accuracy: 54.0%\n",
            "Step: 654 ------------ Loss: 9202.54 ------------ Accuracy: 54.1%\n",
            "Step: 655 ------------ Loss: 9201.63 ------------ Accuracy: 54.1%\n",
            "Step: 656 ------------ Loss: 9200.79 ------------ Accuracy: 53.9%\n",
            "Step: 657 ------------ Loss: 9199.83 ------------ Accuracy: 53.9%\n",
            "Step: 658 ------------ Loss: 9198.91 ------------ Accuracy: 54.0%\n",
            "Step: 659 ------------ Loss: 9198.01 ------------ Accuracy: 54.0%\n",
            "Step: 660 ------------ Loss: 9197.12 ------------ Accuracy: 54.0%\n",
            "Step: 661 ------------ Loss: 9196.28 ------------ Accuracy: 53.9%\n",
            "Step: 662 ------------ Loss: 9195.34 ------------ Accuracy: 54.0%\n",
            "Step: 663 ------------ Loss: 9194.44 ------------ Accuracy: 54.0%\n",
            "Step: 664 ------------ Loss: 9193.6 ------------ Accuracy: 54.0%\n",
            "Step: 665 ------------ Loss: 9192.66 ------------ Accuracy: 54.0%\n",
            "Step: 666 ------------ Loss: 9191.74 ------------ Accuracy: 54.0%\n",
            "Step: 667 ------------ Loss: 9190.86 ------------ Accuracy: 54.0%\n",
            "Step: 668 ------------ Loss: 9189.98 ------------ Accuracy: 54.0%\n",
            "Step: 669 ------------ Loss: 9189.15 ------------ Accuracy: 53.9%\n",
            "Step: 670 ------------ Loss: 9188.24 ------------ Accuracy: 54.0%\n",
            "Step: 671 ------------ Loss: 9187.36 ------------ Accuracy: 54.0%\n",
            "Step: 672 ------------ Loss: 9186.48 ------------ Accuracy: 54.0%\n",
            "Step: 673 ------------ Loss: 9185.6 ------------ Accuracy: 54.0%\n",
            "Step: 674 ------------ Loss: 9184.74 ------------ Accuracy: 54.0%\n",
            "Step: 675 ------------ Loss: 9183.9 ------------ Accuracy: 54.0%\n",
            "Step: 676 ------------ Loss: 9183.02 ------------ Accuracy: 54.0%\n",
            "Step: 677 ------------ Loss: 9182.15 ------------ Accuracy: 54.0%\n",
            "Step: 678 ------------ Loss: 9181.29 ------------ Accuracy: 54.0%\n",
            "Step: 679 ------------ Loss: 9180.4 ------------ Accuracy: 54.0%\n",
            "Step: 680 ------------ Loss: 9179.54 ------------ Accuracy: 54.0%\n",
            "Step: 681 ------------ Loss: 9178.74 ------------ Accuracy: 54.1%\n",
            "Step: 682 ------------ Loss: 9177.82 ------------ Accuracy: 54.1%\n",
            "Step: 683 ------------ Loss: 9177.0 ------------ Accuracy: 54.0%\n",
            "Step: 684 ------------ Loss: 9176.15 ------------ Accuracy: 54.0%\n",
            "Step: 685 ------------ Loss: 9175.28 ------------ Accuracy: 54.0%\n",
            "Step: 686 ------------ Loss: 9174.41 ------------ Accuracy: 54.0%\n",
            "Step: 687 ------------ Loss: 9173.62 ------------ Accuracy: 54.2%\n",
            "Step: 688 ------------ Loss: 9172.72 ------------ Accuracy: 54.1%\n",
            "Step: 689 ------------ Loss: 9171.84 ------------ Accuracy: 54.1%\n",
            "Step: 690 ------------ Loss: 9171.0 ------------ Accuracy: 54.1%\n",
            "Step: 691 ------------ Loss: 9170.16 ------------ Accuracy: 54.1%\n",
            "Step: 692 ------------ Loss: 9169.36 ------------ Accuracy: 54.2%\n",
            "Step: 693 ------------ Loss: 9168.47 ------------ Accuracy: 54.1%\n",
            "Step: 694 ------------ Loss: 9167.63 ------------ Accuracy: 54.1%\n",
            "Step: 695 ------------ Loss: 9166.83 ------------ Accuracy: 54.2%\n",
            "Step: 696 ------------ Loss: 9165.96 ------------ Accuracy: 54.2%\n",
            "Step: 697 ------------ Loss: 9165.09 ------------ Accuracy: 54.2%\n",
            "Step: 698 ------------ Loss: 9164.25 ------------ Accuracy: 54.2%\n",
            "Step: 699 ------------ Loss: 9163.43 ------------ Accuracy: 54.2%\n",
            "Step: 700 ------------ Loss: 9162.64 ------------ Accuracy: 54.3%\n",
            "Step: 701 ------------ Loss: 9161.77 ------------ Accuracy: 54.2%\n",
            "Step: 702 ------------ Loss: 9160.95 ------------ Accuracy: 54.1%\n",
            "Step: 703 ------------ Loss: 9160.16 ------------ Accuracy: 54.3%\n",
            "Step: 704 ------------ Loss: 9159.3 ------------ Accuracy: 54.3%\n",
            "Step: 705 ------------ Loss: 9158.44 ------------ Accuracy: 54.2%\n",
            "Step: 706 ------------ Loss: 9157.61 ------------ Accuracy: 54.2%\n",
            "Step: 707 ------------ Loss: 9156.81 ------------ Accuracy: 54.2%\n",
            "Step: 708 ------------ Loss: 9156.03 ------------ Accuracy: 54.2%\n",
            "Step: 709 ------------ Loss: 9155.18 ------------ Accuracy: 54.2%\n",
            "Step: 710 ------------ Loss: 9154.37 ------------ Accuracy: 54.2%\n",
            "Step: 711 ------------ Loss: 9153.55 ------------ Accuracy: 54.3%\n",
            "Step: 712 ------------ Loss: 9152.72 ------------ Accuracy: 54.3%\n",
            "Step: 713 ------------ Loss: 9151.92 ------------ Accuracy: 54.3%\n",
            "Step: 714 ------------ Loss: 9151.12 ------------ Accuracy: 54.2%\n",
            "Step: 715 ------------ Loss: 9150.32 ------------ Accuracy: 54.3%\n",
            "Step: 716 ------------ Loss: 9149.53 ------------ Accuracy: 54.3%\n",
            "Step: 717 ------------ Loss: 9148.76 ------------ Accuracy: 54.3%\n",
            "Step: 718 ------------ Loss: 9147.9 ------------ Accuracy: 54.3%\n",
            "Step: 719 ------------ Loss: 9147.09 ------------ Accuracy: 54.3%\n",
            "Step: 720 ------------ Loss: 9146.33 ------------ Accuracy: 54.3%\n",
            "Step: 721 ------------ Loss: 9145.49 ------------ Accuracy: 54.3%\n",
            "Step: 722 ------------ Loss: 9144.67 ------------ Accuracy: 54.3%\n",
            "Step: 723 ------------ Loss: 9143.88 ------------ Accuracy: 54.3%\n",
            "Step: 724 ------------ Loss: 9143.1 ------------ Accuracy: 54.3%\n",
            "Step: 725 ------------ Loss: 9142.34 ------------ Accuracy: 54.3%\n",
            "Step: 726 ------------ Loss: 9141.5 ------------ Accuracy: 54.3%\n",
            "Step: 727 ------------ Loss: 9140.71 ------------ Accuracy: 54.2%\n",
            "Step: 728 ------------ Loss: 9139.95 ------------ Accuracy: 54.3%\n",
            "Step: 729 ------------ Loss: 9139.14 ------------ Accuracy: 54.3%\n",
            "Step: 730 ------------ Loss: 9138.32 ------------ Accuracy: 54.3%\n",
            "Step: 731 ------------ Loss: 9137.54 ------------ Accuracy: 54.3%\n",
            "Step: 732 ------------ Loss: 9136.76 ------------ Accuracy: 54.3%\n",
            "Step: 733 ------------ Loss: 9136.0 ------------ Accuracy: 54.3%\n",
            "Step: 734 ------------ Loss: 9135.23 ------------ Accuracy: 54.4%\n",
            "Step: 735 ------------ Loss: 9134.43 ------------ Accuracy: 54.3%\n",
            "Step: 736 ------------ Loss: 9133.66 ------------ Accuracy: 54.3%\n",
            "Step: 737 ------------ Loss: 9132.86 ------------ Accuracy: 54.3%\n",
            "Step: 738 ------------ Loss: 9132.08 ------------ Accuracy: 54.3%\n",
            "Step: 739 ------------ Loss: 9131.33 ------------ Accuracy: 54.4%\n",
            "Step: 740 ------------ Loss: 9130.59 ------------ Accuracy: 54.3%\n",
            "Step: 741 ------------ Loss: 9129.83 ------------ Accuracy: 54.4%\n",
            "Step: 742 ------------ Loss: 9129.01 ------------ Accuracy: 54.4%\n",
            "Step: 743 ------------ Loss: 9128.23 ------------ Accuracy: 54.4%\n",
            "Step: 744 ------------ Loss: 9127.46 ------------ Accuracy: 54.4%\n",
            "Step: 745 ------------ Loss: 9126.69 ------------ Accuracy: 54.3%\n",
            "Step: 746 ------------ Loss: 9125.98 ------------ Accuracy: 54.4%\n",
            "Step: 747 ------------ Loss: 9125.2 ------------ Accuracy: 54.5%\n",
            "Step: 748 ------------ Loss: 9124.42 ------------ Accuracy: 54.4%\n",
            "Step: 749 ------------ Loss: 9123.66 ------------ Accuracy: 54.5%\n",
            "Step: 750 ------------ Loss: 9122.88 ------------ Accuracy: 54.5%\n",
            "Step: 751 ------------ Loss: 9122.12 ------------ Accuracy: 54.5%\n",
            "Step: 752 ------------ Loss: 9121.37 ------------ Accuracy: 54.5%\n",
            "Step: 753 ------------ Loss: 9120.64 ------------ Accuracy: 54.5%\n",
            "Step: 754 ------------ Loss: 9119.89 ------------ Accuracy: 54.6%\n",
            "Step: 755 ------------ Loss: 9119.13 ------------ Accuracy: 54.5%\n",
            "Step: 756 ------------ Loss: 9118.4 ------------ Accuracy: 54.6%\n",
            "Step: 757 ------------ Loss: 9117.61 ------------ Accuracy: 54.6%\n",
            "Step: 758 ------------ Loss: 9116.82 ------------ Accuracy: 54.6%\n",
            "Step: 759 ------------ Loss: 9116.06 ------------ Accuracy: 54.6%\n",
            "Step: 760 ------------ Loss: 9115.31 ------------ Accuracy: 54.6%\n",
            "Step: 761 ------------ Loss: 9114.56 ------------ Accuracy: 54.6%\n",
            "Step: 762 ------------ Loss: 9113.83 ------------ Accuracy: 54.5%\n",
            "Step: 763 ------------ Loss: 9113.08 ------------ Accuracy: 54.5%\n",
            "Step: 764 ------------ Loss: 9112.33 ------------ Accuracy: 54.5%\n",
            "Step: 765 ------------ Loss: 9111.59 ------------ Accuracy: 54.5%\n",
            "Step: 766 ------------ Loss: 9110.9 ------------ Accuracy: 54.5%\n",
            "Step: 767 ------------ Loss: 9110.13 ------------ Accuracy: 54.6%\n",
            "Step: 768 ------------ Loss: 9109.37 ------------ Accuracy: 54.6%\n",
            "Step: 769 ------------ Loss: 9108.63 ------------ Accuracy: 54.5%\n",
            "Step: 770 ------------ Loss: 9107.88 ------------ Accuracy: 54.5%\n",
            "Step: 771 ------------ Loss: 9107.15 ------------ Accuracy: 54.5%\n",
            "Step: 772 ------------ Loss: 9106.45 ------------ Accuracy: 54.6%\n",
            "Step: 773 ------------ Loss: 9105.7 ------------ Accuracy: 54.6%\n",
            "Step: 774 ------------ Loss: 9104.96 ------------ Accuracy: 54.6%\n",
            "Step: 775 ------------ Loss: 9104.26 ------------ Accuracy: 54.6%\n",
            "Step: 776 ------------ Loss: 9103.49 ------------ Accuracy: 54.6%\n",
            "Step: 777 ------------ Loss: 9102.73 ------------ Accuracy: 54.6%\n",
            "Step: 778 ------------ Loss: 9101.99 ------------ Accuracy: 54.6%\n",
            "Step: 779 ------------ Loss: 9101.25 ------------ Accuracy: 54.6%\n",
            "Step: 780 ------------ Loss: 9100.52 ------------ Accuracy: 54.6%\n",
            "Step: 781 ------------ Loss: 9099.79 ------------ Accuracy: 54.6%\n",
            "Step: 782 ------------ Loss: 9099.08 ------------ Accuracy: 54.5%\n",
            "Step: 783 ------------ Loss: 9098.35 ------------ Accuracy: 54.6%\n",
            "Step: 784 ------------ Loss: 9097.63 ------------ Accuracy: 54.5%\n",
            "Step: 785 ------------ Loss: 9096.92 ------------ Accuracy: 54.6%\n",
            "Step: 786 ------------ Loss: 9096.19 ------------ Accuracy: 54.6%\n",
            "Step: 787 ------------ Loss: 9095.46 ------------ Accuracy: 54.6%\n",
            "Step: 788 ------------ Loss: 9094.79 ------------ Accuracy: 54.7%\n",
            "Step: 789 ------------ Loss: 9094.06 ------------ Accuracy: 54.7%\n",
            "Step: 790 ------------ Loss: 9093.33 ------------ Accuracy: 54.7%\n",
            "Step: 791 ------------ Loss: 9092.65 ------------ Accuracy: 54.7%\n",
            "Step: 792 ------------ Loss: 9091.89 ------------ Accuracy: 54.7%\n",
            "Step: 793 ------------ Loss: 9091.14 ------------ Accuracy: 54.7%\n",
            "Step: 794 ------------ Loss: 9090.42 ------------ Accuracy: 54.7%\n",
            "Step: 795 ------------ Loss: 9089.7 ------------ Accuracy: 54.7%\n",
            "Step: 796 ------------ Loss: 9088.98 ------------ Accuracy: 54.7%\n",
            "Step: 797 ------------ Loss: 9088.26 ------------ Accuracy: 54.7%\n",
            "Step: 798 ------------ Loss: 9087.59 ------------ Accuracy: 54.6%\n",
            "Step: 799 ------------ Loss: 9086.88 ------------ Accuracy: 54.7%\n",
            "Step: 800 ------------ Loss: 9086.17 ------------ Accuracy: 54.7%\n",
            "Step: 801 ------------ Loss: 9085.45 ------------ Accuracy: 54.7%\n",
            "Step: 802 ------------ Loss: 9084.73 ------------ Accuracy: 54.7%\n",
            "Step: 803 ------------ Loss: 9084.02 ------------ Accuracy: 54.7%\n",
            "Step: 804 ------------ Loss: 9083.31 ------------ Accuracy: 54.7%\n",
            "Step: 805 ------------ Loss: 9082.61 ------------ Accuracy: 54.7%\n",
            "Step: 806 ------------ Loss: 9081.92 ------------ Accuracy: 54.6%\n",
            "Step: 807 ------------ Loss: 9081.19 ------------ Accuracy: 54.6%\n",
            "Step: 808 ------------ Loss: 9080.47 ------------ Accuracy: 54.6%\n",
            "Step: 809 ------------ Loss: 9079.76 ------------ Accuracy: 54.7%\n",
            "Step: 810 ------------ Loss: 9079.05 ------------ Accuracy: 54.7%\n",
            "Step: 811 ------------ Loss: 9078.35 ------------ Accuracy: 54.7%\n",
            "Step: 812 ------------ Loss: 9077.65 ------------ Accuracy: 54.7%\n",
            "Step: 813 ------------ Loss: 9076.96 ------------ Accuracy: 54.7%\n",
            "Step: 814 ------------ Loss: 9076.27 ------------ Accuracy: 54.7%\n",
            "Step: 815 ------------ Loss: 9075.57 ------------ Accuracy: 54.8%\n",
            "Step: 816 ------------ Loss: 9074.88 ------------ Accuracy: 54.8%\n",
            "Step: 817 ------------ Loss: 9074.2 ------------ Accuracy: 54.7%\n",
            "Step: 818 ------------ Loss: 9073.48 ------------ Accuracy: 54.7%\n",
            "Step: 819 ------------ Loss: 9072.76 ------------ Accuracy: 54.7%\n",
            "Step: 820 ------------ Loss: 9072.06 ------------ Accuracy: 54.7%\n",
            "Step: 821 ------------ Loss: 9071.37 ------------ Accuracy: 54.7%\n",
            "Step: 822 ------------ Loss: 9070.68 ------------ Accuracy: 54.8%\n",
            "Step: 823 ------------ Loss: 9069.99 ------------ Accuracy: 54.8%\n",
            "Step: 824 ------------ Loss: 9069.32 ------------ Accuracy: 54.7%\n",
            "Step: 825 ------------ Loss: 9068.62 ------------ Accuracy: 54.7%\n",
            "Step: 826 ------------ Loss: 9067.93 ------------ Accuracy: 54.7%\n",
            "Step: 827 ------------ Loss: 9067.25 ------------ Accuracy: 54.7%\n",
            "Step: 828 ------------ Loss: 9066.57 ------------ Accuracy: 54.7%\n",
            "Step: 829 ------------ Loss: 9065.94 ------------ Accuracy: 54.7%\n",
            "Step: 830 ------------ Loss: 9065.23 ------------ Accuracy: 54.8%\n",
            "Step: 831 ------------ Loss: 9064.53 ------------ Accuracy: 54.8%\n",
            "Step: 832 ------------ Loss: 9063.89 ------------ Accuracy: 54.8%\n",
            "Step: 833 ------------ Loss: 9063.16 ------------ Accuracy: 54.8%\n",
            "Step: 834 ------------ Loss: 9062.46 ------------ Accuracy: 54.8%\n",
            "Step: 835 ------------ Loss: 9061.78 ------------ Accuracy: 54.8%\n",
            "Step: 836 ------------ Loss: 9061.1 ------------ Accuracy: 54.8%\n",
            "Step: 837 ------------ Loss: 9060.42 ------------ Accuracy: 54.8%\n",
            "Step: 838 ------------ Loss: 9059.79 ------------ Accuracy: 54.8%\n",
            "Step: 839 ------------ Loss: 9059.1 ------------ Accuracy: 54.8%\n",
            "Step: 840 ------------ Loss: 9058.42 ------------ Accuracy: 54.8%\n",
            "Step: 841 ------------ Loss: 9057.79 ------------ Accuracy: 54.8%\n",
            "Step: 842 ------------ Loss: 9057.07 ------------ Accuracy: 54.8%\n",
            "Step: 843 ------------ Loss: 9056.38 ------------ Accuracy: 54.7%\n",
            "Step: 844 ------------ Loss: 9055.7 ------------ Accuracy: 54.7%\n",
            "Step: 845 ------------ Loss: 9055.02 ------------ Accuracy: 54.7%\n",
            "Step: 846 ------------ Loss: 9054.35 ------------ Accuracy: 54.8%\n",
            "Step: 847 ------------ Loss: 9053.68 ------------ Accuracy: 54.9%\n",
            "Step: 848 ------------ Loss: 9053.03 ------------ Accuracy: 54.8%\n",
            "Step: 849 ------------ Loss: 9052.36 ------------ Accuracy: 54.8%\n",
            "Step: 850 ------------ Loss: 9051.7 ------------ Accuracy: 54.9%\n",
            "Step: 851 ------------ Loss: 9051.04 ------------ Accuracy: 54.8%\n",
            "Step: 852 ------------ Loss: 9050.37 ------------ Accuracy: 54.8%\n",
            "Step: 853 ------------ Loss: 9049.7 ------------ Accuracy: 54.9%\n",
            "Step: 854 ------------ Loss: 9049.08 ------------ Accuracy: 54.8%\n",
            "Step: 855 ------------ Loss: 9048.4 ------------ Accuracy: 54.9%\n",
            "Step: 856 ------------ Loss: 9047.74 ------------ Accuracy: 54.9%\n",
            "Step: 857 ------------ Loss: 9047.11 ------------ Accuracy: 54.8%\n",
            "Step: 858 ------------ Loss: 9046.42 ------------ Accuracy: 54.8%\n",
            "Step: 859 ------------ Loss: 9045.74 ------------ Accuracy: 54.9%\n",
            "Step: 860 ------------ Loss: 9045.07 ------------ Accuracy: 55.0%\n",
            "Step: 861 ------------ Loss: 9044.41 ------------ Accuracy: 54.9%\n",
            "Step: 862 ------------ Loss: 9043.75 ------------ Accuracy: 54.9%\n",
            "Step: 863 ------------ Loss: 9043.1 ------------ Accuracy: 54.9%\n",
            "Step: 864 ------------ Loss: 9042.48 ------------ Accuracy: 54.9%\n",
            "Step: 865 ------------ Loss: 9041.82 ------------ Accuracy: 55.0%\n",
            "Step: 866 ------------ Loss: 9041.17 ------------ Accuracy: 54.9%\n",
            "Step: 867 ------------ Loss: 9040.52 ------------ Accuracy: 55.0%\n",
            "Step: 868 ------------ Loss: 9039.86 ------------ Accuracy: 54.9%\n",
            "Step: 869 ------------ Loss: 9039.21 ------------ Accuracy: 54.9%\n",
            "Step: 870 ------------ Loss: 9038.57 ------------ Accuracy: 55.1%\n",
            "Step: 871 ------------ Loss: 9037.91 ------------ Accuracy: 55.1%\n",
            "Step: 872 ------------ Loss: 9037.26 ------------ Accuracy: 55.1%\n",
            "Step: 873 ------------ Loss: 9036.62 ------------ Accuracy: 55.0%\n",
            "Step: 874 ------------ Loss: 9035.97 ------------ Accuracy: 55.0%\n",
            "Step: 875 ------------ Loss: 9035.37 ------------ Accuracy: 55.1%\n",
            "Step: 876 ------------ Loss: 9034.69 ------------ Accuracy: 55.1%\n",
            "Step: 877 ------------ Loss: 9034.05 ------------ Accuracy: 55.1%\n",
            "Step: 878 ------------ Loss: 9033.44 ------------ Accuracy: 55.1%\n",
            "Step: 879 ------------ Loss: 9032.76 ------------ Accuracy: 55.1%\n",
            "Step: 880 ------------ Loss: 9032.1 ------------ Accuracy: 55.1%\n",
            "Step: 881 ------------ Loss: 9031.45 ------------ Accuracy: 55.1%\n",
            "Step: 882 ------------ Loss: 9030.8 ------------ Accuracy: 55.1%\n",
            "Step: 883 ------------ Loss: 9030.16 ------------ Accuracy: 55.1%\n",
            "Step: 884 ------------ Loss: 9029.52 ------------ Accuracy: 55.1%\n",
            "Step: 885 ------------ Loss: 9028.9 ------------ Accuracy: 55.1%\n",
            "Step: 886 ------------ Loss: 9028.28 ------------ Accuracy: 55.2%\n",
            "Step: 887 ------------ Loss: 9027.63 ------------ Accuracy: 55.2%\n",
            "Step: 888 ------------ Loss: 9027.0 ------------ Accuracy: 55.2%\n",
            "Step: 889 ------------ Loss: 9026.4 ------------ Accuracy: 55.2%\n",
            "Step: 890 ------------ Loss: 9025.72 ------------ Accuracy: 55.2%\n",
            "Step: 891 ------------ Loss: 9025.08 ------------ Accuracy: 55.2%\n",
            "Step: 892 ------------ Loss: 9024.43 ------------ Accuracy: 55.2%\n",
            "Step: 893 ------------ Loss: 9023.79 ------------ Accuracy: 55.2%\n",
            "Step: 894 ------------ Loss: 9023.16 ------------ Accuracy: 55.2%\n",
            "Step: 895 ------------ Loss: 9022.53 ------------ Accuracy: 55.2%\n",
            "Step: 896 ------------ Loss: 9021.92 ------------ Accuracy: 55.3%\n",
            "Step: 897 ------------ Loss: 9021.29 ------------ Accuracy: 55.2%\n",
            "Step: 898 ------------ Loss: 9020.66 ------------ Accuracy: 55.2%\n",
            "Step: 899 ------------ Loss: 9020.03 ------------ Accuracy: 55.2%\n",
            "Step: 900 ------------ Loss: 9019.4 ------------ Accuracy: 55.2%\n",
            "Step: 901 ------------ Loss: 9018.83 ------------ Accuracy: 55.4%\n",
            "Step: 902 ------------ Loss: 9018.17 ------------ Accuracy: 55.2%\n",
            "Step: 903 ------------ Loss: 9017.55 ------------ Accuracy: 55.2%\n",
            "Step: 904 ------------ Loss: 9016.96 ------------ Accuracy: 55.4%\n",
            "Step: 905 ------------ Loss: 9016.3 ------------ Accuracy: 55.4%\n",
            "Step: 906 ------------ Loss: 9015.66 ------------ Accuracy: 55.4%\n",
            "Step: 907 ------------ Loss: 9015.03 ------------ Accuracy: 55.4%\n",
            "Step: 908 ------------ Loss: 9014.41 ------------ Accuracy: 55.4%\n",
            "Step: 909 ------------ Loss: 9013.79 ------------ Accuracy: 55.4%\n",
            "Step: 910 ------------ Loss: 9013.18 ------------ Accuracy: 55.4%\n",
            "Step: 911 ------------ Loss: 9012.57 ------------ Accuracy: 55.3%\n",
            "Step: 912 ------------ Loss: 9011.95 ------------ Accuracy: 55.3%\n",
            "Step: 913 ------------ Loss: 9011.33 ------------ Accuracy: 55.4%\n",
            "Step: 914 ------------ Loss: 9010.72 ------------ Accuracy: 55.4%\n",
            "Step: 915 ------------ Loss: 9010.1 ------------ Accuracy: 55.3%\n",
            "Step: 916 ------------ Loss: 9009.49 ------------ Accuracy: 55.3%\n",
            "Step: 917 ------------ Loss: 9008.87 ------------ Accuracy: 55.3%\n",
            "Step: 918 ------------ Loss: 9008.3 ------------ Accuracy: 55.3%\n",
            "Step: 919 ------------ Loss: 9007.67 ------------ Accuracy: 55.3%\n",
            "Step: 920 ------------ Loss: 9007.06 ------------ Accuracy: 55.3%\n",
            "Step: 921 ------------ Loss: 9006.47 ------------ Accuracy: 55.3%\n",
            "Step: 922 ------------ Loss: 9005.83 ------------ Accuracy: 55.3%\n",
            "Step: 923 ------------ Loss: 9005.2 ------------ Accuracy: 55.3%\n",
            "Step: 924 ------------ Loss: 9004.58 ------------ Accuracy: 55.3%\n",
            "Step: 925 ------------ Loss: 9003.97 ------------ Accuracy: 55.3%\n",
            "Step: 926 ------------ Loss: 9003.36 ------------ Accuracy: 55.3%\n",
            "Step: 927 ------------ Loss: 9002.76 ------------ Accuracy: 55.3%\n",
            "Step: 928 ------------ Loss: 9002.21 ------------ Accuracy: 55.3%\n",
            "Step: 929 ------------ Loss: 9001.58 ------------ Accuracy: 55.3%\n",
            "Step: 930 ------------ Loss: 9000.96 ------------ Accuracy: 55.3%\n",
            "Step: 931 ------------ Loss: 9000.39 ------------ Accuracy: 55.3%\n",
            "Step: 932 ------------ Loss: 8999.75 ------------ Accuracy: 55.3%\n",
            "Step: 933 ------------ Loss: 8999.13 ------------ Accuracy: 55.3%\n",
            "Step: 934 ------------ Loss: 8998.53 ------------ Accuracy: 55.3%\n",
            "Step: 935 ------------ Loss: 8997.93 ------------ Accuracy: 55.3%\n",
            "Step: 936 ------------ Loss: 8997.32 ------------ Accuracy: 55.3%\n",
            "Step: 937 ------------ Loss: 8996.77 ------------ Accuracy: 55.3%\n",
            "Step: 938 ------------ Loss: 8996.15 ------------ Accuracy: 55.3%\n",
            "Step: 939 ------------ Loss: 8995.56 ------------ Accuracy: 55.3%\n",
            "Step: 940 ------------ Loss: 8994.95 ------------ Accuracy: 55.3%\n",
            "Step: 941 ------------ Loss: 8994.35 ------------ Accuracy: 55.3%\n",
            "Step: 942 ------------ Loss: 8993.76 ------------ Accuracy: 55.3%\n",
            "Step: 943 ------------ Loss: 8993.21 ------------ Accuracy: 55.3%\n",
            "Step: 944 ------------ Loss: 8992.59 ------------ Accuracy: 55.1%\n",
            "Step: 945 ------------ Loss: 8992.0 ------------ Accuracy: 55.3%\n",
            "Step: 946 ------------ Loss: 8991.43 ------------ Accuracy: 55.1%\n",
            "Step: 947 ------------ Loss: 8990.81 ------------ Accuracy: 55.1%\n",
            "Step: 948 ------------ Loss: 8990.2 ------------ Accuracy: 55.3%\n",
            "Step: 949 ------------ Loss: 8989.6 ------------ Accuracy: 55.1%\n",
            "Step: 950 ------------ Loss: 8989.0 ------------ Accuracy: 55.1%\n",
            "Step: 951 ------------ Loss: 8988.41 ------------ Accuracy: 55.1%\n",
            "Step: 952 ------------ Loss: 8987.82 ------------ Accuracy: 55.1%\n",
            "Step: 953 ------------ Loss: 8987.24 ------------ Accuracy: 55.1%\n",
            "Step: 954 ------------ Loss: 8986.67 ------------ Accuracy: 55.0%\n",
            "Step: 955 ------------ Loss: 8986.08 ------------ Accuracy: 55.1%\n",
            "Step: 956 ------------ Loss: 8985.5 ------------ Accuracy: 55.1%\n",
            "Step: 957 ------------ Loss: 8984.91 ------------ Accuracy: 55.1%\n",
            "Step: 958 ------------ Loss: 8984.31 ------------ Accuracy: 55.1%\n",
            "Step: 959 ------------ Loss: 8983.73 ------------ Accuracy: 55.1%\n",
            "Step: 960 ------------ Loss: 8983.14 ------------ Accuracy: 55.1%\n",
            "Step: 961 ------------ Loss: 8982.56 ------------ Accuracy: 55.1%\n",
            "Step: 962 ------------ Loss: 8982.01 ------------ Accuracy: 55.1%\n",
            "Step: 963 ------------ Loss: 8981.39 ------------ Accuracy: 55.1%\n",
            "Step: 964 ------------ Loss: 8980.8 ------------ Accuracy: 55.1%\n",
            "Step: 965 ------------ Loss: 8980.22 ------------ Accuracy: 55.1%\n",
            "Step: 966 ------------ Loss: 8979.64 ------------ Accuracy: 55.1%\n",
            "Step: 967 ------------ Loss: 8979.05 ------------ Accuracy: 55.0%\n",
            "Step: 968 ------------ Loss: 8978.48 ------------ Accuracy: 55.1%\n",
            "Step: 969 ------------ Loss: 8977.95 ------------ Accuracy: 55.1%\n",
            "Step: 970 ------------ Loss: 8977.34 ------------ Accuracy: 55.0%\n",
            "Step: 971 ------------ Loss: 8976.76 ------------ Accuracy: 55.1%\n",
            "Step: 972 ------------ Loss: 8976.22 ------------ Accuracy: 55.1%\n",
            "Step: 973 ------------ Loss: 8975.61 ------------ Accuracy: 55.1%\n",
            "Step: 974 ------------ Loss: 8975.02 ------------ Accuracy: 55.1%\n",
            "Step: 975 ------------ Loss: 8974.44 ------------ Accuracy: 55.1%\n",
            "Step: 976 ------------ Loss: 8973.86 ------------ Accuracy: 55.1%\n",
            "Step: 977 ------------ Loss: 8973.29 ------------ Accuracy: 55.1%\n",
            "Step: 978 ------------ Loss: 8972.72 ------------ Accuracy: 55.1%\n",
            "Step: 979 ------------ Loss: 8972.16 ------------ Accuracy: 55.1%\n",
            "Step: 980 ------------ Loss: 8971.61 ------------ Accuracy: 55.1%\n",
            "Step: 981 ------------ Loss: 8971.03 ------------ Accuracy: 55.1%\n",
            "Step: 982 ------------ Loss: 8970.46 ------------ Accuracy: 55.0%\n",
            "Step: 983 ------------ Loss: 8969.88 ------------ Accuracy: 55.1%\n",
            "Step: 984 ------------ Loss: 8969.32 ------------ Accuracy: 55.1%\n",
            "Step: 985 ------------ Loss: 8968.79 ------------ Accuracy: 55.3%\n",
            "Step: 986 ------------ Loss: 8968.2 ------------ Accuracy: 55.4%\n",
            "Step: 987 ------------ Loss: 8967.63 ------------ Accuracy: 55.3%\n",
            "Step: 988 ------------ Loss: 8967.1 ------------ Accuracy: 55.4%\n",
            "Step: 989 ------------ Loss: 8966.5 ------------ Accuracy: 55.4%\n",
            "Step: 990 ------------ Loss: 8965.93 ------------ Accuracy: 55.4%\n",
            "Step: 991 ------------ Loss: 8965.36 ------------ Accuracy: 55.4%\n",
            "Step: 992 ------------ Loss: 8964.8 ------------ Accuracy: 55.3%\n",
            "Step: 993 ------------ Loss: 8964.23 ------------ Accuracy: 55.3%\n",
            "Step: 994 ------------ Loss: 8963.67 ------------ Accuracy: 55.4%\n",
            "Step: 995 ------------ Loss: 8963.15 ------------ Accuracy: 55.4%\n",
            "Step: 996 ------------ Loss: 8962.56 ------------ Accuracy: 55.4%\n",
            "Step: 997 ------------ Loss: 8962.01 ------------ Accuracy: 55.4%\n",
            "Step: 998 ------------ Loss: 8961.44 ------------ Accuracy: 55.3%\n",
            "Step: 999 ------------ Loss: 8960.88 ------------ Accuracy: 55.3%\n",
            "Step: 1000 ------------ Loss: 8960.32 ------------ Accuracy: 55.3%\n",
            "Step: 1001 ------------ Loss: 8959.78 ------------ Accuracy: 55.3%\n",
            "Step: 1002 ------------ Loss: 8959.25 ------------ Accuracy: 55.3%\n",
            "Step: 1003 ------------ Loss: 8958.7 ------------ Accuracy: 55.3%\n",
            "Step: 1004 ------------ Loss: 8958.12 ------------ Accuracy: 55.3%\n",
            "Step: 1005 ------------ Loss: 8957.55 ------------ Accuracy: 55.4%\n",
            "Step: 1006 ------------ Loss: 8956.99 ------------ Accuracy: 55.4%\n",
            "Step: 1007 ------------ Loss: 8956.44 ------------ Accuracy: 55.3%\n",
            "Step: 1008 ------------ Loss: 8955.89 ------------ Accuracy: 55.4%\n",
            "Step: 1009 ------------ Loss: 8955.37 ------------ Accuracy: 55.3%\n",
            "Step: 1010 ------------ Loss: 8954.8 ------------ Accuracy: 55.3%\n",
            "Step: 1011 ------------ Loss: 8954.25 ------------ Accuracy: 55.3%\n",
            "Step: 1012 ------------ Loss: 8953.71 ------------ Accuracy: 55.3%\n",
            "Step: 1013 ------------ Loss: 8953.15 ------------ Accuracy: 55.3%\n",
            "Step: 1014 ------------ Loss: 8952.61 ------------ Accuracy: 55.3%\n",
            "Step: 1015 ------------ Loss: 8952.09 ------------ Accuracy: 55.2%\n",
            "Step: 1016 ------------ Loss: 8951.52 ------------ Accuracy: 55.3%\n",
            "Step: 1017 ------------ Loss: 8950.97 ------------ Accuracy: 55.3%\n",
            "Step: 1018 ------------ Loss: 8950.44 ------------ Accuracy: 55.3%\n",
            "Step: 1019 ------------ Loss: 8949.88 ------------ Accuracy: 55.3%\n",
            "Step: 1020 ------------ Loss: 8949.33 ------------ Accuracy: 55.3%\n",
            "Step: 1021 ------------ Loss: 8948.78 ------------ Accuracy: 55.3%\n",
            "Step: 1022 ------------ Loss: 8948.24 ------------ Accuracy: 55.3%\n",
            "Step: 1023 ------------ Loss: 8947.74 ------------ Accuracy: 55.3%\n",
            "Step: 1024 ------------ Loss: 8947.19 ------------ Accuracy: 55.4%\n",
            "Step: 1025 ------------ Loss: 8946.64 ------------ Accuracy: 55.4%\n",
            "Step: 1026 ------------ Loss: 8946.12 ------------ Accuracy: 55.4%\n",
            "Step: 1027 ------------ Loss: 8945.55 ------------ Accuracy: 55.4%\n",
            "Step: 1028 ------------ Loss: 8944.99 ------------ Accuracy: 55.3%\n",
            "Step: 1029 ------------ Loss: 8944.44 ------------ Accuracy: 55.4%\n",
            "Step: 1030 ------------ Loss: 8943.89 ------------ Accuracy: 55.4%\n",
            "Step: 1031 ------------ Loss: 8943.35 ------------ Accuracy: 55.4%\n",
            "Step: 1032 ------------ Loss: 8942.82 ------------ Accuracy: 55.3%\n",
            "Step: 1033 ------------ Loss: 8942.31 ------------ Accuracy: 55.3%\n",
            "Step: 1034 ------------ Loss: 8941.77 ------------ Accuracy: 55.4%\n",
            "Step: 1035 ------------ Loss: 8941.23 ------------ Accuracy: 55.4%\n",
            "Step: 1036 ------------ Loss: 8940.69 ------------ Accuracy: 55.4%\n",
            "Step: 1037 ------------ Loss: 8940.15 ------------ Accuracy: 55.4%\n",
            "Step: 1038 ------------ Loss: 8939.62 ------------ Accuracy: 55.4%\n",
            "Step: 1039 ------------ Loss: 8939.12 ------------ Accuracy: 55.2%\n",
            "Step: 1040 ------------ Loss: 8938.57 ------------ Accuracy: 55.4%\n",
            "Step: 1041 ------------ Loss: 8938.04 ------------ Accuracy: 55.4%\n",
            "Step: 1042 ------------ Loss: 8937.54 ------------ Accuracy: 55.2%\n",
            "Step: 1043 ------------ Loss: 8936.97 ------------ Accuracy: 55.2%\n",
            "Step: 1044 ------------ Loss: 8936.43 ------------ Accuracy: 55.2%\n",
            "Step: 1045 ------------ Loss: 8935.89 ------------ Accuracy: 55.2%\n",
            "Step: 1046 ------------ Loss: 8935.36 ------------ Accuracy: 55.3%\n",
            "Step: 1047 ------------ Loss: 8934.82 ------------ Accuracy: 55.3%\n",
            "Step: 1048 ------------ Loss: 8934.29 ------------ Accuracy: 55.3%\n",
            "Step: 1049 ------------ Loss: 8933.8 ------------ Accuracy: 55.3%\n",
            "Step: 1050 ------------ Loss: 8933.25 ------------ Accuracy: 55.3%\n",
            "Step: 1051 ------------ Loss: 8932.73 ------------ Accuracy: 55.3%\n",
            "Step: 1052 ------------ Loss: 8932.22 ------------ Accuracy: 55.3%\n",
            "Step: 1053 ------------ Loss: 8931.68 ------------ Accuracy: 55.2%\n",
            "Step: 1054 ------------ Loss: 8931.13 ------------ Accuracy: 55.2%\n",
            "Step: 1055 ------------ Loss: 8930.6 ------------ Accuracy: 55.2%\n",
            "Step: 1056 ------------ Loss: 8930.07 ------------ Accuracy: 55.2%\n",
            "Step: 1057 ------------ Loss: 8929.54 ------------ Accuracy: 55.2%\n",
            "Step: 1058 ------------ Loss: 8929.01 ------------ Accuracy: 55.2%\n",
            "Step: 1059 ------------ Loss: 8928.49 ------------ Accuracy: 55.2%\n",
            "Step: 1060 ------------ Loss: 8927.97 ------------ Accuracy: 55.3%\n",
            "Step: 1061 ------------ Loss: 8927.49 ------------ Accuracy: 55.4%\n",
            "Step: 1062 ------------ Loss: 8926.95 ------------ Accuracy: 55.4%\n",
            "Step: 1063 ------------ Loss: 8926.42 ------------ Accuracy: 55.4%\n",
            "Step: 1064 ------------ Loss: 8925.92 ------------ Accuracy: 55.3%\n",
            "Step: 1065 ------------ Loss: 8925.37 ------------ Accuracy: 55.3%\n",
            "Step: 1066 ------------ Loss: 8924.84 ------------ Accuracy: 55.3%\n",
            "Step: 1067 ------------ Loss: 8924.32 ------------ Accuracy: 55.3%\n",
            "Step: 1068 ------------ Loss: 8923.8 ------------ Accuracy: 55.3%\n",
            "Step: 1069 ------------ Loss: 8923.28 ------------ Accuracy: 55.3%\n",
            "Step: 1070 ------------ Loss: 8922.8 ------------ Accuracy: 55.4%\n",
            "Step: 1071 ------------ Loss: 8922.27 ------------ Accuracy: 55.4%\n",
            "Step: 1072 ------------ Loss: 8921.76 ------------ Accuracy: 55.3%\n",
            "Step: 1073 ------------ Loss: 8921.24 ------------ Accuracy: 55.3%\n",
            "Step: 1074 ------------ Loss: 8920.72 ------------ Accuracy: 55.3%\n",
            "Step: 1075 ------------ Loss: 8920.21 ------------ Accuracy: 55.3%\n",
            "Step: 1076 ------------ Loss: 8919.73 ------------ Accuracy: 55.4%\n",
            "Step: 1077 ------------ Loss: 8919.2 ------------ Accuracy: 55.4%\n",
            "Step: 1078 ------------ Loss: 8918.68 ------------ Accuracy: 55.4%\n",
            "Step: 1079 ------------ Loss: 8918.18 ------------ Accuracy: 55.4%\n",
            "Step: 1080 ------------ Loss: 8917.66 ------------ Accuracy: 55.4%\n",
            "Step: 1081 ------------ Loss: 8917.14 ------------ Accuracy: 55.5%\n",
            "Step: 1082 ------------ Loss: 8916.63 ------------ Accuracy: 55.5%\n",
            "Step: 1083 ------------ Loss: 8916.12 ------------ Accuracy: 55.4%\n",
            "Step: 1084 ------------ Loss: 8915.61 ------------ Accuracy: 55.4%\n",
            "Step: 1085 ------------ Loss: 8915.13 ------------ Accuracy: 55.5%\n",
            "Step: 1086 ------------ Loss: 8914.62 ------------ Accuracy: 55.5%\n",
            "Step: 1087 ------------ Loss: 8914.11 ------------ Accuracy: 55.5%\n",
            "Step: 1088 ------------ Loss: 8913.62 ------------ Accuracy: 55.5%\n",
            "Step: 1089 ------------ Loss: 8913.09 ------------ Accuracy: 55.5%\n",
            "Step: 1090 ------------ Loss: 8912.56 ------------ Accuracy: 55.5%\n",
            "Step: 1091 ------------ Loss: 8912.05 ------------ Accuracy: 55.5%\n",
            "Step: 1092 ------------ Loss: 8911.54 ------------ Accuracy: 55.4%\n",
            "Step: 1093 ------------ Loss: 8911.03 ------------ Accuracy: 55.4%\n",
            "Step: 1094 ------------ Loss: 8910.54 ------------ Accuracy: 55.3%\n",
            "Step: 1095 ------------ Loss: 8910.06 ------------ Accuracy: 55.5%\n",
            "Step: 1096 ------------ Loss: 8909.55 ------------ Accuracy: 55.4%\n",
            "Step: 1097 ------------ Loss: 8909.05 ------------ Accuracy: 55.4%\n",
            "Step: 1098 ------------ Loss: 8908.54 ------------ Accuracy: 55.4%\n",
            "Step: 1099 ------------ Loss: 8908.04 ------------ Accuracy: 55.4%\n",
            "Step: 1100 ------------ Loss: 8907.54 ------------ Accuracy: 55.4%\n",
            "Step: 1101 ------------ Loss: 8907.04 ------------ Accuracy: 55.3%\n",
            "Step: 1102 ------------ Loss: 8906.56 ------------ Accuracy: 55.5%\n",
            "Step: 1103 ------------ Loss: 8906.05 ------------ Accuracy: 55.4%\n",
            "Step: 1104 ------------ Loss: 8905.56 ------------ Accuracy: 55.4%\n",
            "Step: 1105 ------------ Loss: 8905.08 ------------ Accuracy: 55.5%\n",
            "Step: 1106 ------------ Loss: 8904.55 ------------ Accuracy: 55.5%\n",
            "Step: 1107 ------------ Loss: 8904.04 ------------ Accuracy: 55.5%\n",
            "Step: 1108 ------------ Loss: 8903.54 ------------ Accuracy: 55.5%\n",
            "Step: 1109 ------------ Loss: 8903.04 ------------ Accuracy: 55.5%\n",
            "Step: 1110 ------------ Loss: 8902.54 ------------ Accuracy: 55.5%\n",
            "Step: 1111 ------------ Loss: 8902.04 ------------ Accuracy: 55.5%\n",
            "Step: 1112 ------------ Loss: 8901.55 ------------ Accuracy: 55.5%\n",
            "Step: 1113 ------------ Loss: 8901.09 ------------ Accuracy: 55.6%\n",
            "Step: 1114 ------------ Loss: 8900.58 ------------ Accuracy: 55.6%\n",
            "Step: 1115 ------------ Loss: 8900.09 ------------ Accuracy: 55.4%\n",
            "Step: 1116 ------------ Loss: 8899.61 ------------ Accuracy: 55.6%\n",
            "Step: 1117 ------------ Loss: 8899.1 ------------ Accuracy: 55.6%\n",
            "Step: 1118 ------------ Loss: 8898.59 ------------ Accuracy: 55.6%\n",
            "Step: 1119 ------------ Loss: 8898.09 ------------ Accuracy: 55.6%\n",
            "Step: 1120 ------------ Loss: 8897.6 ------------ Accuracy: 55.6%\n",
            "Step: 1121 ------------ Loss: 8897.11 ------------ Accuracy: 55.6%\n",
            "Step: 1122 ------------ Loss: 8896.62 ------------ Accuracy: 55.7%\n",
            "Step: 1123 ------------ Loss: 8896.14 ------------ Accuracy: 55.7%\n",
            "Step: 1124 ------------ Loss: 8895.66 ------------ Accuracy: 55.6%\n",
            "Step: 1125 ------------ Loss: 8895.17 ------------ Accuracy: 55.7%\n",
            "Step: 1126 ------------ Loss: 8894.69 ------------ Accuracy: 55.6%\n",
            "Step: 1127 ------------ Loss: 8894.2 ------------ Accuracy: 55.6%\n",
            "Step: 1128 ------------ Loss: 8893.71 ------------ Accuracy: 55.6%\n",
            "Step: 1129 ------------ Loss: 8893.22 ------------ Accuracy: 55.6%\n",
            "Step: 1130 ------------ Loss: 8892.73 ------------ Accuracy: 55.6%\n",
            "Step: 1131 ------------ Loss: 8892.29 ------------ Accuracy: 55.6%\n",
            "Step: 1132 ------------ Loss: 8891.79 ------------ Accuracy: 55.6%\n",
            "Step: 1133 ------------ Loss: 8891.3 ------------ Accuracy: 55.6%\n",
            "Step: 1134 ------------ Loss: 8890.81 ------------ Accuracy: 55.6%\n",
            "Step: 1135 ------------ Loss: 8890.33 ------------ Accuracy: 55.6%\n",
            "Step: 1136 ------------ Loss: 8889.85 ------------ Accuracy: 55.6%\n",
            "Step: 1137 ------------ Loss: 8889.4 ------------ Accuracy: 55.6%\n",
            "Step: 1138 ------------ Loss: 8888.9 ------------ Accuracy: 55.6%\n",
            "Step: 1139 ------------ Loss: 8888.42 ------------ Accuracy: 55.6%\n",
            "Step: 1140 ------------ Loss: 8887.97 ------------ Accuracy: 55.6%\n",
            "Step: 1141 ------------ Loss: 8887.45 ------------ Accuracy: 55.6%\n",
            "Step: 1142 ------------ Loss: 8886.97 ------------ Accuracy: 55.6%\n",
            "Step: 1143 ------------ Loss: 8886.48 ------------ Accuracy: 55.6%\n",
            "Step: 1144 ------------ Loss: 8885.99 ------------ Accuracy: 55.6%\n",
            "Step: 1145 ------------ Loss: 8885.51 ------------ Accuracy: 55.6%\n",
            "Step: 1146 ------------ Loss: 8885.03 ------------ Accuracy: 55.6%\n",
            "Step: 1147 ------------ Loss: 8884.56 ------------ Accuracy: 55.6%\n",
            "Step: 1148 ------------ Loss: 8884.08 ------------ Accuracy: 55.6%\n",
            "Step: 1149 ------------ Loss: 8883.64 ------------ Accuracy: 55.6%\n",
            "Step: 1150 ------------ Loss: 8883.15 ------------ Accuracy: 55.6%\n",
            "Step: 1151 ------------ Loss: 8882.67 ------------ Accuracy: 55.6%\n",
            "Step: 1152 ------------ Loss: 8882.21 ------------ Accuracy: 55.6%\n",
            "Step: 1153 ------------ Loss: 8881.72 ------------ Accuracy: 55.6%\n",
            "Step: 1154 ------------ Loss: 8881.23 ------------ Accuracy: 55.6%\n",
            "Step: 1155 ------------ Loss: 8880.75 ------------ Accuracy: 55.6%\n",
            "Step: 1156 ------------ Loss: 8880.27 ------------ Accuracy: 55.6%\n",
            "Step: 1157 ------------ Loss: 8879.8 ------------ Accuracy: 55.6%\n",
            "Step: 1158 ------------ Loss: 8879.33 ------------ Accuracy: 55.6%\n",
            "Step: 1159 ------------ Loss: 8878.88 ------------ Accuracy: 55.6%\n",
            "Step: 1160 ------------ Loss: 8878.4 ------------ Accuracy: 55.6%\n",
            "Step: 1161 ------------ Loss: 8877.93 ------------ Accuracy: 55.6%\n",
            "Step: 1162 ------------ Loss: 8877.48 ------------ Accuracy: 55.6%\n",
            "Step: 1163 ------------ Loss: 8876.99 ------------ Accuracy: 55.6%\n",
            "Step: 1164 ------------ Loss: 8876.51 ------------ Accuracy: 55.6%\n",
            "Step: 1165 ------------ Loss: 8876.04 ------------ Accuracy: 55.6%\n",
            "Step: 1166 ------------ Loss: 8875.57 ------------ Accuracy: 55.6%\n",
            "Step: 1167 ------------ Loss: 8875.1 ------------ Accuracy: 55.6%\n",
            "Step: 1168 ------------ Loss: 8874.67 ------------ Accuracy: 55.7%\n",
            "Step: 1169 ------------ Loss: 8874.18 ------------ Accuracy: 55.6%\n",
            "Step: 1170 ------------ Loss: 8873.72 ------------ Accuracy: 55.6%\n",
            "Step: 1171 ------------ Loss: 8873.25 ------------ Accuracy: 55.6%\n",
            "Step: 1172 ------------ Loss: 8872.78 ------------ Accuracy: 55.6%\n",
            "Step: 1173 ------------ Loss: 8872.32 ------------ Accuracy: 55.6%\n",
            "Step: 1174 ------------ Loss: 8871.85 ------------ Accuracy: 55.6%\n",
            "Step: 1175 ------------ Loss: 8871.4 ------------ Accuracy: 55.6%\n",
            "Step: 1176 ------------ Loss: 8870.94 ------------ Accuracy: 55.7%\n",
            "Step: 1177 ------------ Loss: 8870.47 ------------ Accuracy: 55.7%\n",
            "Step: 1178 ------------ Loss: 8870.04 ------------ Accuracy: 55.7%\n",
            "Step: 1179 ------------ Loss: 8869.55 ------------ Accuracy: 55.7%\n",
            "Step: 1180 ------------ Loss: 8869.08 ------------ Accuracy: 55.7%\n",
            "Step: 1181 ------------ Loss: 8868.61 ------------ Accuracy: 55.7%\n",
            "Step: 1182 ------------ Loss: 8868.14 ------------ Accuracy: 55.7%\n",
            "Step: 1183 ------------ Loss: 8867.68 ------------ Accuracy: 55.7%\n",
            "Step: 1184 ------------ Loss: 8867.22 ------------ Accuracy: 55.7%\n",
            "Step: 1185 ------------ Loss: 8866.8 ------------ Accuracy: 55.8%\n",
            "Step: 1186 ------------ Loss: 8866.31 ------------ Accuracy: 55.8%\n",
            "Step: 1187 ------------ Loss: 8865.86 ------------ Accuracy: 55.8%\n",
            "Step: 1188 ------------ Loss: 8865.41 ------------ Accuracy: 55.8%\n",
            "Step: 1189 ------------ Loss: 8864.95 ------------ Accuracy: 55.7%\n",
            "Step: 1190 ------------ Loss: 8864.49 ------------ Accuracy: 55.7%\n",
            "Step: 1191 ------------ Loss: 8864.04 ------------ Accuracy: 55.7%\n",
            "Step: 1192 ------------ Loss: 8863.61 ------------ Accuracy: 55.8%\n",
            "Step: 1193 ------------ Loss: 8863.13 ------------ Accuracy: 55.8%\n",
            "Step: 1194 ------------ Loss: 8862.68 ------------ Accuracy: 55.8%\n",
            "Step: 1195 ------------ Loss: 8862.25 ------------ Accuracy: 55.8%\n",
            "Step: 1196 ------------ Loss: 8861.76 ------------ Accuracy: 55.8%\n",
            "Step: 1197 ------------ Loss: 8861.31 ------------ Accuracy: 55.8%\n",
            "Step: 1198 ------------ Loss: 8860.84 ------------ Accuracy: 55.8%\n",
            "Step: 1199 ------------ Loss: 8860.39 ------------ Accuracy: 55.8%\n",
            "Step: 1200 ------------ Loss: 8859.93 ------------ Accuracy: 55.8%\n",
            "Step: 1201 ------------ Loss: 8859.48 ------------ Accuracy: 55.8%\n",
            "Step: 1202 ------------ Loss: 8859.04 ------------ Accuracy: 55.9%\n",
            "Step: 1203 ------------ Loss: 8858.61 ------------ Accuracy: 55.8%\n",
            "Step: 1204 ------------ Loss: 8858.16 ------------ Accuracy: 55.9%\n",
            "Step: 1205 ------------ Loss: 8857.69 ------------ Accuracy: 55.8%\n",
            "Step: 1206 ------------ Loss: 8857.23 ------------ Accuracy: 55.9%\n",
            "Step: 1207 ------------ Loss: 8856.78 ------------ Accuracy: 55.8%\n",
            "Step: 1208 ------------ Loss: 8856.33 ------------ Accuracy: 55.8%\n",
            "Step: 1209 ------------ Loss: 8855.88 ------------ Accuracy: 55.8%\n",
            "Step: 1210 ------------ Loss: 8855.44 ------------ Accuracy: 55.8%\n",
            "Step: 1211 ------------ Loss: 8855.0 ------------ Accuracy: 55.8%\n",
            "Step: 1212 ------------ Loss: 8854.55 ------------ Accuracy: 55.8%\n",
            "Step: 1213 ------------ Loss: 8854.11 ------------ Accuracy: 55.8%\n",
            "Step: 1214 ------------ Loss: 8853.66 ------------ Accuracy: 55.9%\n",
            "Step: 1215 ------------ Loss: 8853.22 ------------ Accuracy: 55.8%\n",
            "Step: 1216 ------------ Loss: 8852.77 ------------ Accuracy: 55.8%\n",
            "Step: 1217 ------------ Loss: 8852.37 ------------ Accuracy: 55.8%\n",
            "Step: 1218 ------------ Loss: 8851.89 ------------ Accuracy: 55.8%\n",
            "Step: 1219 ------------ Loss: 8851.45 ------------ Accuracy: 55.8%\n",
            "Step: 1220 ------------ Loss: 8851.02 ------------ Accuracy: 55.8%\n",
            "Step: 1221 ------------ Loss: 8850.56 ------------ Accuracy: 55.8%\n",
            "Step: 1222 ------------ Loss: 8850.1 ------------ Accuracy: 55.8%\n",
            "Step: 1223 ------------ Loss: 8849.66 ------------ Accuracy: 55.8%\n",
            "Step: 1224 ------------ Loss: 8849.21 ------------ Accuracy: 55.8%\n",
            "Step: 1225 ------------ Loss: 8848.77 ------------ Accuracy: 55.8%\n",
            "Step: 1226 ------------ Loss: 8848.33 ------------ Accuracy: 55.8%\n",
            "Step: 1227 ------------ Loss: 8847.89 ------------ Accuracy: 55.8%\n",
            "Step: 1228 ------------ Loss: 8847.47 ------------ Accuracy: 55.8%\n",
            "Step: 1229 ------------ Loss: 8847.01 ------------ Accuracy: 55.8%\n",
            "Step: 1230 ------------ Loss: 8846.57 ------------ Accuracy: 55.8%\n",
            "Step: 1231 ------------ Loss: 8846.16 ------------ Accuracy: 55.8%\n",
            "Step: 1232 ------------ Loss: 8845.7 ------------ Accuracy: 55.8%\n",
            "Step: 1233 ------------ Loss: 8845.25 ------------ Accuracy: 55.8%\n",
            "Step: 1234 ------------ Loss: 8844.81 ------------ Accuracy: 55.8%\n",
            "Step: 1235 ------------ Loss: 8844.37 ------------ Accuracy: 55.8%\n",
            "Step: 1236 ------------ Loss: 8843.93 ------------ Accuracy: 55.8%\n",
            "Step: 1237 ------------ Loss: 8843.49 ------------ Accuracy: 55.8%\n",
            "Step: 1238 ------------ Loss: 8843.09 ------------ Accuracy: 55.9%\n",
            "Step: 1239 ------------ Loss: 8842.63 ------------ Accuracy: 55.8%\n",
            "Step: 1240 ------------ Loss: 8842.19 ------------ Accuracy: 55.8%\n",
            "Step: 1241 ------------ Loss: 8841.77 ------------ Accuracy: 55.8%\n",
            "Step: 1242 ------------ Loss: 8841.33 ------------ Accuracy: 55.8%\n",
            "Step: 1243 ------------ Loss: 8840.89 ------------ Accuracy: 55.8%\n",
            "Step: 1244 ------------ Loss: 8840.46 ------------ Accuracy: 55.8%\n",
            "Step: 1245 ------------ Loss: 8840.02 ------------ Accuracy: 55.8%\n",
            "Step: 1246 ------------ Loss: 8839.59 ------------ Accuracy: 55.8%\n",
            "Step: 1247 ------------ Loss: 8839.19 ------------ Accuracy: 55.9%\n",
            "Step: 1248 ------------ Loss: 8838.75 ------------ Accuracy: 55.8%\n",
            "Step: 1249 ------------ Loss: 8838.32 ------------ Accuracy: 55.8%\n",
            "Step: 1250 ------------ Loss: 8837.9 ------------ Accuracy: 55.9%\n",
            "Step: 1251 ------------ Loss: 8837.44 ------------ Accuracy: 55.9%\n",
            "Step: 1252 ------------ Loss: 8837.0 ------------ Accuracy: 55.9%\n",
            "Step: 1253 ------------ Loss: 8836.57 ------------ Accuracy: 55.9%\n",
            "Step: 1254 ------------ Loss: 8836.13 ------------ Accuracy: 55.8%\n",
            "Step: 1255 ------------ Loss: 8835.71 ------------ Accuracy: 55.8%\n",
            "Step: 1256 ------------ Loss: 8835.28 ------------ Accuracy: 55.8%\n",
            "Step: 1257 ------------ Loss: 8834.87 ------------ Accuracy: 55.9%\n",
            "Step: 1258 ------------ Loss: 8834.44 ------------ Accuracy: 55.8%\n",
            "Step: 1259 ------------ Loss: 8834.01 ------------ Accuracy: 55.8%\n",
            "Step: 1260 ------------ Loss: 8833.58 ------------ Accuracy: 55.8%\n",
            "Step: 1261 ------------ Loss: 8833.15 ------------ Accuracy: 55.8%\n",
            "Step: 1262 ------------ Loss: 8832.72 ------------ Accuracy: 55.8%\n",
            "Step: 1263 ------------ Loss: 8832.3 ------------ Accuracy: 55.8%\n",
            "Step: 1264 ------------ Loss: 8831.91 ------------ Accuracy: 55.8%\n",
            "Step: 1265 ------------ Loss: 8831.46 ------------ Accuracy: 55.8%\n",
            "Step: 1266 ------------ Loss: 8831.04 ------------ Accuracy: 55.8%\n",
            "Step: 1267 ------------ Loss: 8830.63 ------------ Accuracy: 55.8%\n",
            "Step: 1268 ------------ Loss: 8830.18 ------------ Accuracy: 55.9%\n",
            "Step: 1269 ------------ Loss: 8829.75 ------------ Accuracy: 55.8%\n",
            "Step: 1270 ------------ Loss: 8829.32 ------------ Accuracy: 55.8%\n",
            "Step: 1271 ------------ Loss: 8828.9 ------------ Accuracy: 55.8%\n",
            "Step: 1272 ------------ Loss: 8828.47 ------------ Accuracy: 55.9%\n",
            "Step: 1273 ------------ Loss: 8828.06 ------------ Accuracy: 55.8%\n",
            "Step: 1274 ------------ Loss: 8827.66 ------------ Accuracy: 55.8%\n",
            "Step: 1275 ------------ Loss: 8827.22 ------------ Accuracy: 55.8%\n",
            "Step: 1276 ------------ Loss: 8826.8 ------------ Accuracy: 55.8%\n",
            "Step: 1277 ------------ Loss: 8826.4 ------------ Accuracy: 55.8%\n",
            "Step: 1278 ------------ Loss: 8825.98 ------------ Accuracy: 55.8%\n",
            "Step: 1279 ------------ Loss: 8825.55 ------------ Accuracy: 55.8%\n",
            "Step: 1280 ------------ Loss: 8825.13 ------------ Accuracy: 55.8%\n",
            "Step: 1281 ------------ Loss: 8824.71 ------------ Accuracy: 55.8%\n",
            "Step: 1282 ------------ Loss: 8824.3 ------------ Accuracy: 55.8%\n",
            "Step: 1283 ------------ Loss: 8823.89 ------------ Accuracy: 55.8%\n",
            "Step: 1284 ------------ Loss: 8823.47 ------------ Accuracy: 55.8%\n",
            "Step: 1285 ------------ Loss: 8823.06 ------------ Accuracy: 55.8%\n",
            "Step: 1286 ------------ Loss: 8822.65 ------------ Accuracy: 55.8%\n",
            "Step: 1287 ------------ Loss: 8822.23 ------------ Accuracy: 55.8%\n",
            "Step: 1288 ------------ Loss: 8821.81 ------------ Accuracy: 55.8%\n",
            "Step: 1289 ------------ Loss: 8821.43 ------------ Accuracy: 55.7%\n",
            "Step: 1290 ------------ Loss: 8821.0 ------------ Accuracy: 55.8%\n",
            "Step: 1291 ------------ Loss: 8820.58 ------------ Accuracy: 55.8%\n",
            "Step: 1292 ------------ Loss: 8820.18 ------------ Accuracy: 55.7%\n",
            "Step: 1293 ------------ Loss: 8819.74 ------------ Accuracy: 55.8%\n",
            "Step: 1294 ------------ Loss: 8819.33 ------------ Accuracy: 55.8%\n",
            "Step: 1295 ------------ Loss: 8818.91 ------------ Accuracy: 55.8%\n",
            "Step: 1296 ------------ Loss: 8818.49 ------------ Accuracy: 55.8%\n",
            "Step: 1297 ------------ Loss: 8818.07 ------------ Accuracy: 55.8%\n",
            "Step: 1298 ------------ Loss: 8817.66 ------------ Accuracy: 55.8%\n",
            "Step: 1299 ------------ Loss: 8817.26 ------------ Accuracy: 55.8%\n",
            "Step: 1300 ------------ Loss: 8816.86 ------------ Accuracy: 55.7%\n",
            "Step: 1301 ------------ Loss: 8816.44 ------------ Accuracy: 55.8%\n",
            "Step: 1302 ------------ Loss: 8816.04 ------------ Accuracy: 55.7%\n",
            "Step: 1303 ------------ Loss: 8815.62 ------------ Accuracy: 55.7%\n",
            "Step: 1304 ------------ Loss: 8815.21 ------------ Accuracy: 55.7%\n",
            "Step: 1305 ------------ Loss: 8814.79 ------------ Accuracy: 55.7%\n",
            "Step: 1306 ------------ Loss: 8814.38 ------------ Accuracy: 55.7%\n",
            "Step: 1307 ------------ Loss: 8814.0 ------------ Accuracy: 55.7%\n",
            "Step: 1308 ------------ Loss: 8813.58 ------------ Accuracy: 55.7%\n",
            "Step: 1309 ------------ Loss: 8813.18 ------------ Accuracy: 55.7%\n",
            "Step: 1310 ------------ Loss: 8812.8 ------------ Accuracy: 55.7%\n",
            "Step: 1311 ------------ Loss: 8812.36 ------------ Accuracy: 55.7%\n",
            "Step: 1312 ------------ Loss: 8811.95 ------------ Accuracy: 55.7%\n",
            "Step: 1313 ------------ Loss: 8811.53 ------------ Accuracy: 55.7%\n",
            "Step: 1314 ------------ Loss: 8811.12 ------------ Accuracy: 55.7%\n",
            "Step: 1315 ------------ Loss: 8810.71 ------------ Accuracy: 55.7%\n",
            "Step: 1316 ------------ Loss: 8810.3 ------------ Accuracy: 55.7%\n",
            "Step: 1317 ------------ Loss: 8809.9 ------------ Accuracy: 55.7%\n",
            "Step: 1318 ------------ Loss: 8809.5 ------------ Accuracy: 55.7%\n",
            "Step: 1319 ------------ Loss: 8809.12 ------------ Accuracy: 55.7%\n",
            "Step: 1320 ------------ Loss: 8808.7 ------------ Accuracy: 55.7%\n",
            "Step: 1321 ------------ Loss: 8808.3 ------------ Accuracy: 55.7%\n",
            "Step: 1322 ------------ Loss: 8807.91 ------------ Accuracy: 55.7%\n",
            "Step: 1323 ------------ Loss: 8807.49 ------------ Accuracy: 55.7%\n",
            "Step: 1324 ------------ Loss: 8807.07 ------------ Accuracy: 55.7%\n",
            "Step: 1325 ------------ Loss: 8806.67 ------------ Accuracy: 55.7%\n",
            "Step: 1326 ------------ Loss: 8806.26 ------------ Accuracy: 55.7%\n",
            "Step: 1327 ------------ Loss: 8805.86 ------------ Accuracy: 55.7%\n",
            "Step: 1328 ------------ Loss: 8805.46 ------------ Accuracy: 55.7%\n",
            "Step: 1329 ------------ Loss: 8805.07 ------------ Accuracy: 55.7%\n",
            "Step: 1330 ------------ Loss: 8804.67 ------------ Accuracy: 55.7%\n",
            "Step: 1331 ------------ Loss: 8804.27 ------------ Accuracy: 55.7%\n",
            "Step: 1332 ------------ Loss: 8803.88 ------------ Accuracy: 55.7%\n",
            "Step: 1333 ------------ Loss: 8803.48 ------------ Accuracy: 55.7%\n",
            "Step: 1334 ------------ Loss: 8803.08 ------------ Accuracy: 55.7%\n",
            "Step: 1335 ------------ Loss: 8802.68 ------------ Accuracy: 55.7%\n",
            "Step: 1336 ------------ Loss: 8802.31 ------------ Accuracy: 55.7%\n",
            "Step: 1337 ------------ Loss: 8801.89 ------------ Accuracy: 55.7%\n",
            "Step: 1338 ------------ Loss: 8801.5 ------------ Accuracy: 55.7%\n",
            "Step: 1339 ------------ Loss: 8801.11 ------------ Accuracy: 55.7%\n",
            "Step: 1340 ------------ Loss: 8800.7 ------------ Accuracy: 55.7%\n",
            "Step: 1341 ------------ Loss: 8800.29 ------------ Accuracy: 55.7%\n",
            "Step: 1342 ------------ Loss: 8799.89 ------------ Accuracy: 55.7%\n",
            "Step: 1343 ------------ Loss: 8799.5 ------------ Accuracy: 55.7%\n",
            "Step: 1344 ------------ Loss: 8799.1 ------------ Accuracy: 55.8%\n",
            "Step: 1345 ------------ Loss: 8798.71 ------------ Accuracy: 55.8%\n",
            "Step: 1346 ------------ Loss: 8798.32 ------------ Accuracy: 55.8%\n",
            "Step: 1347 ------------ Loss: 8797.93 ------------ Accuracy: 55.7%\n",
            "Step: 1348 ------------ Loss: 8797.53 ------------ Accuracy: 55.8%\n",
            "Step: 1349 ------------ Loss: 8797.17 ------------ Accuracy: 55.9%\n",
            "Step: 1350 ------------ Loss: 8796.77 ------------ Accuracy: 55.8%\n",
            "Step: 1351 ------------ Loss: 8796.37 ------------ Accuracy: 55.8%\n",
            "Step: 1352 ------------ Loss: 8795.98 ------------ Accuracy: 55.8%\n",
            "Step: 1353 ------------ Loss: 8795.59 ------------ Accuracy: 55.8%\n",
            "Step: 1354 ------------ Loss: 8795.22 ------------ Accuracy: 55.9%\n",
            "Step: 1355 ------------ Loss: 8794.82 ------------ Accuracy: 55.8%\n",
            "Step: 1356 ------------ Loss: 8794.43 ------------ Accuracy: 55.8%\n",
            "Step: 1357 ------------ Loss: 8794.06 ------------ Accuracy: 55.9%\n",
            "Step: 1358 ------------ Loss: 8793.65 ------------ Accuracy: 55.9%\n",
            "Step: 1359 ------------ Loss: 8793.25 ------------ Accuracy: 55.9%\n",
            "Step: 1360 ------------ Loss: 8792.86 ------------ Accuracy: 55.9%\n",
            "Step: 1361 ------------ Loss: 8792.47 ------------ Accuracy: 55.8%\n",
            "Step: 1362 ------------ Loss: 8792.07 ------------ Accuracy: 55.8%\n",
            "Step: 1363 ------------ Loss: 8791.68 ------------ Accuracy: 55.7%\n",
            "Step: 1364 ------------ Loss: 8791.29 ------------ Accuracy: 55.7%\n",
            "Step: 1365 ------------ Loss: 8790.9 ------------ Accuracy: 55.7%\n",
            "Step: 1366 ------------ Loss: 8790.54 ------------ Accuracy: 55.7%\n",
            "Step: 1367 ------------ Loss: 8790.14 ------------ Accuracy: 55.8%\n",
            "Step: 1368 ------------ Loss: 8789.76 ------------ Accuracy: 55.8%\n",
            "Step: 1369 ------------ Loss: 8789.39 ------------ Accuracy: 55.7%\n",
            "Step: 1370 ------------ Loss: 8788.98 ------------ Accuracy: 55.7%\n",
            "Step: 1371 ------------ Loss: 8788.59 ------------ Accuracy: 55.7%\n",
            "Step: 1372 ------------ Loss: 8788.2 ------------ Accuracy: 55.7%\n",
            "Step: 1373 ------------ Loss: 8787.81 ------------ Accuracy: 55.7%\n",
            "Step: 1374 ------------ Loss: 8787.42 ------------ Accuracy: 55.7%\n",
            "Step: 1375 ------------ Loss: 8787.03 ------------ Accuracy: 55.7%\n",
            "Step: 1376 ------------ Loss: 8786.65 ------------ Accuracy: 55.7%\n",
            "Step: 1377 ------------ Loss: 8786.27 ------------ Accuracy: 55.7%\n",
            "Step: 1378 ------------ Loss: 8785.89 ------------ Accuracy: 55.7%\n",
            "Step: 1379 ------------ Loss: 8785.5 ------------ Accuracy: 55.7%\n",
            "Step: 1380 ------------ Loss: 8785.13 ------------ Accuracy: 55.7%\n",
            "Step: 1381 ------------ Loss: 8784.76 ------------ Accuracy: 55.7%\n",
            "Step: 1382 ------------ Loss: 8784.36 ------------ Accuracy: 55.8%\n",
            "Step: 1383 ------------ Loss: 8783.98 ------------ Accuracy: 55.7%\n",
            "Step: 1384 ------------ Loss: 8783.62 ------------ Accuracy: 55.7%\n",
            "Step: 1385 ------------ Loss: 8783.23 ------------ Accuracy: 55.8%\n",
            "Step: 1386 ------------ Loss: 8782.85 ------------ Accuracy: 55.7%\n",
            "Step: 1387 ------------ Loss: 8782.47 ------------ Accuracy: 55.7%\n",
            "Step: 1388 ------------ Loss: 8782.09 ------------ Accuracy: 55.7%\n",
            "Step: 1389 ------------ Loss: 8781.71 ------------ Accuracy: 55.7%\n",
            "Step: 1390 ------------ Loss: 8781.33 ------------ Accuracy: 55.7%\n",
            "Step: 1391 ------------ Loss: 8780.95 ------------ Accuracy: 55.7%\n",
            "Step: 1392 ------------ Loss: 8780.59 ------------ Accuracy: 55.7%\n",
            "Step: 1393 ------------ Loss: 8780.2 ------------ Accuracy: 55.8%\n",
            "Step: 1394 ------------ Loss: 8779.83 ------------ Accuracy: 55.7%\n",
            "Step: 1395 ------------ Loss: 8779.45 ------------ Accuracy: 55.7%\n",
            "Step: 1396 ------------ Loss: 8779.06 ------------ Accuracy: 55.7%\n",
            "Step: 1397 ------------ Loss: 8778.68 ------------ Accuracy: 55.7%\n",
            "Step: 1398 ------------ Loss: 8778.3 ------------ Accuracy: 55.8%\n",
            "Step: 1399 ------------ Loss: 8777.92 ------------ Accuracy: 55.7%\n",
            "Step: 1400 ------------ Loss: 8777.54 ------------ Accuracy: 55.7%\n",
            "Step: 1401 ------------ Loss: 8777.16 ------------ Accuracy: 55.7%\n",
            "Step: 1402 ------------ Loss: 8776.79 ------------ Accuracy: 55.7%\n",
            "Step: 1403 ------------ Loss: 8776.42 ------------ Accuracy: 55.8%\n",
            "Step: 1404 ------------ Loss: 8776.07 ------------ Accuracy: 55.7%\n",
            "Step: 1405 ------------ Loss: 8775.67 ------------ Accuracy: 55.7%\n",
            "Step: 1406 ------------ Loss: 8775.27 ------------ Accuracy: 55.7%\n",
            "Step: 1407 ------------ Loss: 8774.89 ------------ Accuracy: 55.7%\n",
            "Step: 1408 ------------ Loss: 8774.52 ------------ Accuracy: 55.7%\n",
            "Step: 1409 ------------ Loss: 8774.14 ------------ Accuracy: 55.7%\n",
            "Step: 1410 ------------ Loss: 8773.77 ------------ Accuracy: 55.7%\n",
            "Step: 1411 ------------ Loss: 8773.42 ------------ Accuracy: 55.7%\n",
            "Step: 1412 ------------ Loss: 8773.03 ------------ Accuracy: 55.7%\n",
            "Step: 1413 ------------ Loss: 8772.65 ------------ Accuracy: 55.7%\n",
            "Step: 1414 ------------ Loss: 8772.3 ------------ Accuracy: 55.7%\n",
            "Step: 1415 ------------ Loss: 8771.93 ------------ Accuracy: 55.7%\n",
            "Step: 1416 ------------ Loss: 8771.55 ------------ Accuracy: 55.7%\n",
            "Step: 1417 ------------ Loss: 8771.18 ------------ Accuracy: 55.7%\n",
            "Step: 1418 ------------ Loss: 8770.8 ------------ Accuracy: 55.7%\n",
            "Step: 1419 ------------ Loss: 8770.42 ------------ Accuracy: 55.7%\n",
            "Step: 1420 ------------ Loss: 8770.05 ------------ Accuracy: 55.7%\n",
            "Step: 1421 ------------ Loss: 8769.68 ------------ Accuracy: 55.7%\n",
            "Step: 1422 ------------ Loss: 8769.31 ------------ Accuracy: 55.7%\n",
            "Step: 1423 ------------ Loss: 8768.96 ------------ Accuracy: 55.8%\n",
            "Step: 1424 ------------ Loss: 8768.57 ------------ Accuracy: 55.7%\n",
            "Step: 1425 ------------ Loss: 8768.2 ------------ Accuracy: 55.7%\n",
            "Step: 1426 ------------ Loss: 8767.82 ------------ Accuracy: 55.7%\n",
            "Step: 1427 ------------ Loss: 8767.45 ------------ Accuracy: 55.7%\n",
            "Step: 1428 ------------ Loss: 8767.08 ------------ Accuracy: 55.7%\n",
            "Step: 1429 ------------ Loss: 8766.71 ------------ Accuracy: 55.7%\n",
            "Step: 1430 ------------ Loss: 8766.34 ------------ Accuracy: 55.7%\n",
            "Step: 1431 ------------ Loss: 8765.97 ------------ Accuracy: 55.8%\n",
            "Step: 1432 ------------ Loss: 8765.6 ------------ Accuracy: 55.8%\n",
            "Step: 1433 ------------ Loss: 8765.24 ------------ Accuracy: 55.8%\n",
            "Step: 1434 ------------ Loss: 8764.87 ------------ Accuracy: 55.8%\n",
            "Step: 1435 ------------ Loss: 8764.5 ------------ Accuracy: 55.7%\n",
            "Step: 1436 ------------ Loss: 8764.15 ------------ Accuracy: 55.7%\n",
            "Step: 1437 ------------ Loss: 8763.77 ------------ Accuracy: 55.7%\n",
            "Step: 1438 ------------ Loss: 8763.39 ------------ Accuracy: 55.7%\n",
            "Step: 1439 ------------ Loss: 8763.02 ------------ Accuracy: 55.7%\n",
            "Step: 1440 ------------ Loss: 8762.64 ------------ Accuracy: 55.7%\n",
            "Step: 1441 ------------ Loss: 8762.28 ------------ Accuracy: 55.7%\n",
            "Step: 1442 ------------ Loss: 8761.91 ------------ Accuracy: 55.7%\n",
            "Step: 1443 ------------ Loss: 8761.54 ------------ Accuracy: 55.7%\n",
            "Step: 1444 ------------ Loss: 8761.17 ------------ Accuracy: 55.7%\n",
            "Step: 1445 ------------ Loss: 8760.81 ------------ Accuracy: 55.7%\n",
            "Step: 1446 ------------ Loss: 8760.46 ------------ Accuracy: 55.7%\n",
            "Step: 1447 ------------ Loss: 8760.1 ------------ Accuracy: 55.7%\n",
            "Step: 1448 ------------ Loss: 8759.73 ------------ Accuracy: 55.7%\n",
            "Step: 1449 ------------ Loss: 8759.36 ------------ Accuracy: 55.7%\n",
            "Step: 1450 ------------ Loss: 8758.99 ------------ Accuracy: 55.7%\n",
            "Step: 1451 ------------ Loss: 8758.63 ------------ Accuracy: 55.7%\n",
            "Step: 1452 ------------ Loss: 8758.26 ------------ Accuracy: 55.7%\n",
            "Step: 1453 ------------ Loss: 8757.89 ------------ Accuracy: 55.7%\n",
            "Step: 1454 ------------ Loss: 8757.53 ------------ Accuracy: 55.7%\n",
            "Step: 1455 ------------ Loss: 8757.17 ------------ Accuracy: 55.7%\n",
            "Step: 1456 ------------ Loss: 8756.8 ------------ Accuracy: 55.7%\n",
            "Step: 1457 ------------ Loss: 8756.44 ------------ Accuracy: 55.7%\n",
            "Step: 1458 ------------ Loss: 8756.1 ------------ Accuracy: 55.8%\n",
            "Step: 1459 ------------ Loss: 8755.72 ------------ Accuracy: 55.7%\n",
            "Step: 1460 ------------ Loss: 8755.36 ------------ Accuracy: 55.7%\n",
            "Step: 1461 ------------ Loss: 8754.99 ------------ Accuracy: 55.7%\n",
            "Step: 1462 ------------ Loss: 8754.63 ------------ Accuracy: 55.7%\n",
            "Step: 1463 ------------ Loss: 8754.27 ------------ Accuracy: 55.7%\n",
            "Step: 1464 ------------ Loss: 8753.9 ------------ Accuracy: 55.7%\n",
            "Step: 1465 ------------ Loss: 8753.54 ------------ Accuracy: 55.7%\n",
            "Step: 1466 ------------ Loss: 8753.2 ------------ Accuracy: 55.8%\n",
            "Step: 1467 ------------ Loss: 8752.82 ------------ Accuracy: 55.7%\n",
            "Step: 1468 ------------ Loss: 8752.46 ------------ Accuracy: 55.7%\n",
            "Step: 1469 ------------ Loss: 8752.1 ------------ Accuracy: 55.7%\n",
            "Step: 1470 ------------ Loss: 8751.74 ------------ Accuracy: 55.7%\n",
            "Step: 1471 ------------ Loss: 8751.37 ------------ Accuracy: 55.8%\n",
            "Step: 1472 ------------ Loss: 8751.01 ------------ Accuracy: 55.8%\n",
            "Step: 1473 ------------ Loss: 8750.65 ------------ Accuracy: 55.8%\n",
            "Step: 1474 ------------ Loss: 8750.3 ------------ Accuracy: 55.7%\n",
            "Step: 1475 ------------ Loss: 8749.96 ------------ Accuracy: 55.8%\n",
            "Step: 1476 ------------ Loss: 8749.59 ------------ Accuracy: 55.8%\n",
            "Step: 1477 ------------ Loss: 8749.23 ------------ Accuracy: 55.8%\n",
            "Step: 1478 ------------ Loss: 8748.87 ------------ Accuracy: 55.7%\n",
            "Step: 1479 ------------ Loss: 8748.52 ------------ Accuracy: 55.8%\n",
            "Step: 1480 ------------ Loss: 8748.17 ------------ Accuracy: 55.7%\n",
            "Step: 1481 ------------ Loss: 8747.81 ------------ Accuracy: 55.8%\n",
            "Step: 1482 ------------ Loss: 8747.45 ------------ Accuracy: 55.8%\n",
            "Step: 1483 ------------ Loss: 8747.09 ------------ Accuracy: 55.8%\n",
            "Step: 1484 ------------ Loss: 8746.73 ------------ Accuracy: 55.8%\n",
            "Step: 1485 ------------ Loss: 8746.37 ------------ Accuracy: 55.8%\n",
            "Step: 1486 ------------ Loss: 8746.01 ------------ Accuracy: 55.8%\n",
            "Step: 1487 ------------ Loss: 8745.65 ------------ Accuracy: 55.8%\n",
            "Step: 1488 ------------ Loss: 8745.3 ------------ Accuracy: 55.8%\n",
            "Step: 1489 ------------ Loss: 8744.95 ------------ Accuracy: 55.8%\n",
            "Step: 1490 ------------ Loss: 8744.61 ------------ Accuracy: 55.8%\n",
            "Step: 1491 ------------ Loss: 8744.23 ------------ Accuracy: 55.8%\n",
            "Step: 1492 ------------ Loss: 8743.88 ------------ Accuracy: 55.8%\n",
            "Step: 1493 ------------ Loss: 8743.55 ------------ Accuracy: 55.9%\n",
            "Step: 1494 ------------ Loss: 8743.19 ------------ Accuracy: 55.8%\n",
            "Step: 1495 ------------ Loss: 8742.83 ------------ Accuracy: 55.8%\n",
            "Step: 1496 ------------ Loss: 8742.49 ------------ Accuracy: 55.9%\n",
            "Step: 1497 ------------ Loss: 8742.11 ------------ Accuracy: 55.9%\n",
            "Step: 1498 ------------ Loss: 8741.75 ------------ Accuracy: 55.9%\n",
            "Step: 1499 ------------ Loss: 8741.39 ------------ Accuracy: 55.9%\n",
            "Step: 1500 ------------ Loss: 8741.03 ------------ Accuracy: 55.9%\n",
            "Step: 1501 ------------ Loss: 8740.68 ------------ Accuracy: 55.8%\n",
            "Step: 1502 ------------ Loss: 8740.32 ------------ Accuracy: 55.9%\n",
            "Step: 1503 ------------ Loss: 8739.97 ------------ Accuracy: 55.8%\n",
            "Step: 1504 ------------ Loss: 8739.64 ------------ Accuracy: 55.9%\n",
            "Step: 1505 ------------ Loss: 8739.28 ------------ Accuracy: 55.8%\n",
            "Step: 1506 ------------ Loss: 8738.92 ------------ Accuracy: 55.8%\n",
            "Step: 1507 ------------ Loss: 8738.56 ------------ Accuracy: 55.8%\n",
            "Step: 1508 ------------ Loss: 8738.21 ------------ Accuracy: 55.8%\n",
            "Step: 1509 ------------ Loss: 8737.85 ------------ Accuracy: 55.8%\n",
            "Step: 1510 ------------ Loss: 8737.5 ------------ Accuracy: 55.8%\n",
            "Step: 1511 ------------ Loss: 8737.15 ------------ Accuracy: 55.8%\n",
            "Step: 1512 ------------ Loss: 8736.8 ------------ Accuracy: 55.9%\n",
            "Step: 1513 ------------ Loss: 8736.47 ------------ Accuracy: 55.9%\n",
            "Step: 1514 ------------ Loss: 8736.11 ------------ Accuracy: 55.8%\n",
            "Step: 1515 ------------ Loss: 8735.77 ------------ Accuracy: 55.9%\n",
            "Step: 1516 ------------ Loss: 8735.42 ------------ Accuracy: 55.8%\n",
            "Step: 1517 ------------ Loss: 8735.06 ------------ Accuracy: 55.8%\n",
            "Step: 1518 ------------ Loss: 8734.71 ------------ Accuracy: 55.8%\n",
            "Step: 1519 ------------ Loss: 8734.36 ------------ Accuracy: 55.8%\n",
            "Step: 1520 ------------ Loss: 8734.01 ------------ Accuracy: 55.8%\n",
            "Step: 1521 ------------ Loss: 8733.66 ------------ Accuracy: 55.8%\n",
            "Step: 1522 ------------ Loss: 8733.31 ------------ Accuracy: 55.8%\n",
            "Step: 1523 ------------ Loss: 8732.97 ------------ Accuracy: 55.9%\n",
            "Step: 1524 ------------ Loss: 8732.61 ------------ Accuracy: 55.9%\n",
            "Step: 1525 ------------ Loss: 8732.26 ------------ Accuracy: 55.9%\n",
            "Step: 1526 ------------ Loss: 8731.91 ------------ Accuracy: 55.9%\n",
            "Step: 1527 ------------ Loss: 8731.56 ------------ Accuracy: 55.9%\n",
            "Step: 1528 ------------ Loss: 8731.22 ------------ Accuracy: 55.9%\n",
            "Step: 1529 ------------ Loss: 8730.87 ------------ Accuracy: 55.9%\n",
            "Step: 1530 ------------ Loss: 8730.54 ------------ Accuracy: 55.8%\n",
            "Step: 1531 ------------ Loss: 8730.18 ------------ Accuracy: 55.9%\n",
            "Step: 1532 ------------ Loss: 8729.83 ------------ Accuracy: 55.8%\n",
            "Step: 1533 ------------ Loss: 8729.48 ------------ Accuracy: 55.8%\n",
            "Step: 1534 ------------ Loss: 8729.13 ------------ Accuracy: 55.8%\n",
            "Step: 1535 ------------ Loss: 8728.79 ------------ Accuracy: 55.9%\n",
            "Step: 1536 ------------ Loss: 8728.46 ------------ Accuracy: 55.8%\n",
            "Step: 1537 ------------ Loss: 8728.1 ------------ Accuracy: 55.8%\n",
            "Step: 1538 ------------ Loss: 8727.76 ------------ Accuracy: 55.8%\n",
            "Step: 1539 ------------ Loss: 8727.41 ------------ Accuracy: 55.8%\n",
            "Step: 1540 ------------ Loss: 8727.06 ------------ Accuracy: 55.8%\n",
            "Step: 1541 ------------ Loss: 8726.72 ------------ Accuracy: 55.8%\n",
            "Step: 1542 ------------ Loss: 8726.37 ------------ Accuracy: 55.8%\n",
            "Step: 1543 ------------ Loss: 8726.04 ------------ Accuracy: 55.8%\n",
            "Step: 1544 ------------ Loss: 8725.69 ------------ Accuracy: 55.8%\n",
            "Step: 1545 ------------ Loss: 8725.37 ------------ Accuracy: 55.8%\n",
            "Step: 1546 ------------ Loss: 8725.01 ------------ Accuracy: 55.7%\n",
            "Step: 1547 ------------ Loss: 8724.65 ------------ Accuracy: 55.8%\n",
            "Step: 1548 ------------ Loss: 8724.3 ------------ Accuracy: 55.8%\n",
            "Step: 1549 ------------ Loss: 8723.95 ------------ Accuracy: 55.8%\n",
            "Step: 1550 ------------ Loss: 8723.6 ------------ Accuracy: 55.8%\n",
            "Step: 1551 ------------ Loss: 8723.26 ------------ Accuracy: 55.8%\n",
            "Step: 1552 ------------ Loss: 8722.92 ------------ Accuracy: 55.9%\n",
            "Step: 1553 ------------ Loss: 8722.57 ------------ Accuracy: 55.9%\n",
            "Step: 1554 ------------ Loss: 8722.23 ------------ Accuracy: 55.9%\n",
            "Step: 1555 ------------ Loss: 8721.91 ------------ Accuracy: 55.8%\n",
            "Step: 1556 ------------ Loss: 8721.56 ------------ Accuracy: 55.9%\n",
            "Step: 1557 ------------ Loss: 8721.21 ------------ Accuracy: 55.9%\n",
            "Step: 1558 ------------ Loss: 8720.87 ------------ Accuracy: 55.8%\n",
            "Step: 1559 ------------ Loss: 8720.54 ------------ Accuracy: 55.8%\n",
            "Step: 1560 ------------ Loss: 8720.2 ------------ Accuracy: 55.7%\n",
            "Step: 1561 ------------ Loss: 8719.86 ------------ Accuracy: 55.8%\n",
            "Step: 1562 ------------ Loss: 8719.52 ------------ Accuracy: 55.8%\n",
            "Step: 1563 ------------ Loss: 8719.18 ------------ Accuracy: 55.8%\n",
            "Step: 1564 ------------ Loss: 8718.83 ------------ Accuracy: 55.8%\n",
            "Step: 1565 ------------ Loss: 8718.49 ------------ Accuracy: 55.8%\n",
            "Step: 1566 ------------ Loss: 8718.15 ------------ Accuracy: 55.8%\n",
            "Step: 1567 ------------ Loss: 8717.81 ------------ Accuracy: 55.8%\n",
            "Step: 1568 ------------ Loss: 8717.47 ------------ Accuracy: 55.8%\n",
            "Step: 1569 ------------ Loss: 8717.13 ------------ Accuracy: 55.8%\n",
            "Step: 1570 ------------ Loss: 8716.79 ------------ Accuracy: 55.8%\n",
            "Step: 1571 ------------ Loss: 8716.45 ------------ Accuracy: 55.8%\n",
            "Step: 1572 ------------ Loss: 8716.11 ------------ Accuracy: 55.8%\n",
            "Step: 1573 ------------ Loss: 8715.79 ------------ Accuracy: 55.8%\n",
            "Step: 1574 ------------ Loss: 8715.44 ------------ Accuracy: 55.9%\n",
            "Step: 1575 ------------ Loss: 8715.1 ------------ Accuracy: 55.9%\n",
            "Step: 1576 ------------ Loss: 8714.77 ------------ Accuracy: 55.9%\n",
            "Step: 1577 ------------ Loss: 8714.44 ------------ Accuracy: 55.8%\n",
            "Step: 1578 ------------ Loss: 8714.11 ------------ Accuracy: 55.9%\n",
            "Step: 1579 ------------ Loss: 8713.77 ------------ Accuracy: 55.9%\n",
            "Step: 1580 ------------ Loss: 8713.43 ------------ Accuracy: 55.9%\n",
            "Step: 1581 ------------ Loss: 8713.09 ------------ Accuracy: 55.9%\n",
            "Step: 1582 ------------ Loss: 8712.75 ------------ Accuracy: 55.9%\n",
            "Step: 1583 ------------ Loss: 8712.41 ------------ Accuracy: 55.9%\n",
            "Step: 1584 ------------ Loss: 8712.1 ------------ Accuracy: 55.9%\n",
            "Step: 1585 ------------ Loss: 8711.75 ------------ Accuracy: 55.9%\n",
            "Step: 1586 ------------ Loss: 8711.41 ------------ Accuracy: 55.9%\n",
            "Step: 1587 ------------ Loss: 8711.08 ------------ Accuracy: 55.9%\n",
            "Step: 1588 ------------ Loss: 8710.74 ------------ Accuracy: 55.9%\n",
            "Step: 1589 ------------ Loss: 8710.4 ------------ Accuracy: 55.9%\n",
            "Step: 1590 ------------ Loss: 8710.09 ------------ Accuracy: 55.9%\n",
            "Step: 1591 ------------ Loss: 8709.73 ------------ Accuracy: 55.9%\n",
            "Step: 1592 ------------ Loss: 8709.39 ------------ Accuracy: 55.9%\n",
            "Step: 1593 ------------ Loss: 8709.05 ------------ Accuracy: 55.9%\n",
            "Step: 1594 ------------ Loss: 8708.71 ------------ Accuracy: 55.9%\n",
            "Step: 1595 ------------ Loss: 8708.37 ------------ Accuracy: 55.9%\n",
            "Step: 1596 ------------ Loss: 8708.04 ------------ Accuracy: 55.9%\n",
            "Step: 1597 ------------ Loss: 8707.7 ------------ Accuracy: 55.9%\n",
            "Step: 1598 ------------ Loss: 8707.37 ------------ Accuracy: 55.9%\n",
            "Step: 1599 ------------ Loss: 8707.04 ------------ Accuracy: 55.9%\n",
            "Step: 1600 ------------ Loss: 8706.71 ------------ Accuracy: 55.9%\n",
            "Step: 1601 ------------ Loss: 8706.37 ------------ Accuracy: 55.9%\n",
            "Step: 1602 ------------ Loss: 8706.04 ------------ Accuracy: 55.9%\n",
            "Step: 1603 ------------ Loss: 8705.7 ------------ Accuracy: 55.9%\n",
            "Step: 1604 ------------ Loss: 8705.37 ------------ Accuracy: 55.9%\n",
            "Step: 1605 ------------ Loss: 8705.04 ------------ Accuracy: 55.9%\n",
            "Step: 1606 ------------ Loss: 8704.71 ------------ Accuracy: 55.9%\n",
            "Step: 1607 ------------ Loss: 8704.39 ------------ Accuracy: 55.9%\n",
            "Step: 1608 ------------ Loss: 8704.05 ------------ Accuracy: 55.9%\n",
            "Step: 1609 ------------ Loss: 8703.71 ------------ Accuracy: 55.9%\n",
            "Step: 1610 ------------ Loss: 8703.38 ------------ Accuracy: 55.9%\n",
            "Step: 1611 ------------ Loss: 8703.04 ------------ Accuracy: 55.9%\n",
            "Step: 1612 ------------ Loss: 8702.71 ------------ Accuracy: 55.9%\n",
            "Step: 1613 ------------ Loss: 8702.38 ------------ Accuracy: 55.9%\n",
            "Step: 1614 ------------ Loss: 8702.05 ------------ Accuracy: 55.9%\n",
            "Step: 1615 ------------ Loss: 8701.72 ------------ Accuracy: 55.9%\n",
            "Step: 1616 ------------ Loss: 8701.39 ------------ Accuracy: 55.9%\n",
            "Step: 1617 ------------ Loss: 8701.08 ------------ Accuracy: 56.0%\n",
            "Step: 1618 ------------ Loss: 8700.73 ------------ Accuracy: 55.9%\n",
            "Step: 1619 ------------ Loss: 8700.4 ------------ Accuracy: 55.9%\n",
            "Step: 1620 ------------ Loss: 8700.08 ------------ Accuracy: 55.9%\n",
            "Step: 1621 ------------ Loss: 8699.76 ------------ Accuracy: 56.0%\n",
            "Step: 1622 ------------ Loss: 8699.43 ------------ Accuracy: 55.9%\n",
            "Step: 1623 ------------ Loss: 8699.12 ------------ Accuracy: 55.9%\n",
            "Step: 1624 ------------ Loss: 8698.79 ------------ Accuracy: 55.9%\n",
            "Step: 1625 ------------ Loss: 8698.46 ------------ Accuracy: 55.9%\n",
            "Step: 1626 ------------ Loss: 8698.15 ------------ Accuracy: 55.9%\n",
            "Step: 1627 ------------ Loss: 8697.8 ------------ Accuracy: 55.9%\n",
            "Step: 1628 ------------ Loss: 8697.46 ------------ Accuracy: 55.9%\n",
            "Step: 1629 ------------ Loss: 8697.13 ------------ Accuracy: 55.9%\n",
            "Step: 1630 ------------ Loss: 8696.79 ------------ Accuracy: 55.9%\n",
            "Step: 1631 ------------ Loss: 8696.46 ------------ Accuracy: 55.9%\n",
            "Step: 1632 ------------ Loss: 8696.13 ------------ Accuracy: 55.9%\n",
            "Step: 1633 ------------ Loss: 8695.8 ------------ Accuracy: 55.9%\n",
            "Step: 1634 ------------ Loss: 8695.47 ------------ Accuracy: 55.9%\n",
            "Step: 1635 ------------ Loss: 8695.15 ------------ Accuracy: 55.9%\n",
            "Step: 1636 ------------ Loss: 8694.82 ------------ Accuracy: 55.9%\n",
            "Step: 1637 ------------ Loss: 8694.49 ------------ Accuracy: 55.9%\n",
            "Step: 1638 ------------ Loss: 8694.18 ------------ Accuracy: 55.9%\n",
            "Step: 1639 ------------ Loss: 8693.85 ------------ Accuracy: 55.9%\n",
            "Step: 1640 ------------ Loss: 8693.52 ------------ Accuracy: 55.9%\n",
            "Step: 1641 ------------ Loss: 8693.19 ------------ Accuracy: 55.9%\n",
            "Step: 1642 ------------ Loss: 8692.86 ------------ Accuracy: 55.9%\n",
            "Step: 1643 ------------ Loss: 8692.54 ------------ Accuracy: 55.9%\n",
            "Step: 1644 ------------ Loss: 8692.21 ------------ Accuracy: 55.9%\n",
            "Step: 1645 ------------ Loss: 8691.88 ------------ Accuracy: 55.9%\n",
            "Step: 1646 ------------ Loss: 8691.56 ------------ Accuracy: 55.9%\n",
            "Step: 1647 ------------ Loss: 8691.24 ------------ Accuracy: 55.9%\n",
            "Step: 1648 ------------ Loss: 8690.91 ------------ Accuracy: 55.9%\n",
            "Step: 1649 ------------ Loss: 8690.6 ------------ Accuracy: 56.0%\n",
            "Step: 1650 ------------ Loss: 8690.27 ------------ Accuracy: 55.9%\n",
            "Step: 1651 ------------ Loss: 8689.97 ------------ Accuracy: 56.0%\n",
            "Step: 1652 ------------ Loss: 8689.63 ------------ Accuracy: 55.9%\n",
            "Step: 1653 ------------ Loss: 8689.3 ------------ Accuracy: 55.9%\n",
            "Step: 1654 ------------ Loss: 8688.97 ------------ Accuracy: 55.9%\n",
            "Step: 1655 ------------ Loss: 8688.64 ------------ Accuracy: 55.9%\n",
            "Step: 1656 ------------ Loss: 8688.31 ------------ Accuracy: 55.9%\n",
            "Step: 1657 ------------ Loss: 8687.99 ------------ Accuracy: 56.0%\n",
            "Step: 1658 ------------ Loss: 8687.66 ------------ Accuracy: 56.0%\n",
            "Step: 1659 ------------ Loss: 8687.34 ------------ Accuracy: 56.0%\n",
            "Step: 1660 ------------ Loss: 8687.02 ------------ Accuracy: 55.9%\n",
            "Step: 1661 ------------ Loss: 8686.7 ------------ Accuracy: 56.0%\n",
            "Step: 1662 ------------ Loss: 8686.38 ------------ Accuracy: 56.0%\n",
            "Step: 1663 ------------ Loss: 8686.08 ------------ Accuracy: 56.0%\n",
            "Step: 1664 ------------ Loss: 8685.75 ------------ Accuracy: 56.0%\n",
            "Step: 1665 ------------ Loss: 8685.43 ------------ Accuracy: 56.0%\n",
            "Step: 1666 ------------ Loss: 8685.1 ------------ Accuracy: 55.9%\n",
            "Step: 1667 ------------ Loss: 8684.78 ------------ Accuracy: 55.9%\n",
            "Step: 1668 ------------ Loss: 8684.46 ------------ Accuracy: 56.0%\n",
            "Step: 1669 ------------ Loss: 8684.13 ------------ Accuracy: 56.0%\n",
            "Step: 1670 ------------ Loss: 8683.81 ------------ Accuracy: 56.0%\n",
            "Step: 1671 ------------ Loss: 8683.49 ------------ Accuracy: 56.0%\n",
            "Step: 1672 ------------ Loss: 8683.17 ------------ Accuracy: 56.0%\n",
            "Step: 1673 ------------ Loss: 8682.86 ------------ Accuracy: 56.0%\n",
            "Step: 1674 ------------ Loss: 8682.55 ------------ Accuracy: 56.0%\n",
            "Step: 1675 ------------ Loss: 8682.22 ------------ Accuracy: 56.0%\n",
            "Step: 1676 ------------ Loss: 8681.9 ------------ Accuracy: 56.0%\n",
            "Step: 1677 ------------ Loss: 8681.58 ------------ Accuracy: 56.0%\n",
            "Step: 1678 ------------ Loss: 8681.28 ------------ Accuracy: 56.0%\n",
            "Step: 1679 ------------ Loss: 8680.95 ------------ Accuracy: 56.0%\n",
            "Step: 1680 ------------ Loss: 8680.63 ------------ Accuracy: 56.0%\n",
            "Step: 1681 ------------ Loss: 8680.33 ------------ Accuracy: 56.0%\n",
            "Step: 1682 ------------ Loss: 8680.01 ------------ Accuracy: 56.0%\n",
            "Step: 1683 ------------ Loss: 8679.7 ------------ Accuracy: 56.0%\n",
            "Step: 1684 ------------ Loss: 8679.38 ------------ Accuracy: 56.0%\n",
            "Step: 1685 ------------ Loss: 8679.05 ------------ Accuracy: 56.0%\n",
            "Step: 1686 ------------ Loss: 8678.73 ------------ Accuracy: 56.0%\n",
            "Step: 1687 ------------ Loss: 8678.41 ------------ Accuracy: 56.0%\n",
            "Step: 1688 ------------ Loss: 8678.1 ------------ Accuracy: 56.0%\n",
            "Step: 1689 ------------ Loss: 8677.78 ------------ Accuracy: 56.0%\n",
            "Step: 1690 ------------ Loss: 8677.46 ------------ Accuracy: 56.0%\n",
            "Step: 1691 ------------ Loss: 8677.14 ------------ Accuracy: 56.0%\n",
            "Step: 1692 ------------ Loss: 8676.82 ------------ Accuracy: 56.0%\n",
            "Step: 1693 ------------ Loss: 8676.51 ------------ Accuracy: 56.0%\n",
            "Step: 1694 ------------ Loss: 8676.21 ------------ Accuracy: 56.0%\n",
            "Step: 1695 ------------ Loss: 8675.88 ------------ Accuracy: 56.0%\n",
            "Step: 1696 ------------ Loss: 8675.57 ------------ Accuracy: 56.0%\n",
            "Step: 1697 ------------ Loss: 8675.25 ------------ Accuracy: 56.0%\n",
            "Step: 1698 ------------ Loss: 8674.96 ------------ Accuracy: 56.0%\n",
            "Step: 1699 ------------ Loss: 8674.63 ------------ Accuracy: 56.0%\n",
            "Step: 1700 ------------ Loss: 8674.32 ------------ Accuracy: 56.0%\n",
            "Step: 1701 ------------ Loss: 8674.01 ------------ Accuracy: 56.0%\n",
            "Step: 1702 ------------ Loss: 8673.68 ------------ Accuracy: 56.0%\n",
            "Step: 1703 ------------ Loss: 8673.36 ------------ Accuracy: 56.0%\n",
            "Step: 1704 ------------ Loss: 8673.04 ------------ Accuracy: 56.0%\n",
            "Step: 1705 ------------ Loss: 8672.72 ------------ Accuracy: 56.0%\n",
            "Step: 1706 ------------ Loss: 8672.41 ------------ Accuracy: 56.0%\n",
            "Step: 1707 ------------ Loss: 8672.09 ------------ Accuracy: 56.0%\n",
            "Step: 1708 ------------ Loss: 8671.78 ------------ Accuracy: 56.0%\n",
            "Step: 1709 ------------ Loss: 8671.46 ------------ Accuracy: 56.0%\n",
            "Step: 1710 ------------ Loss: 8671.15 ------------ Accuracy: 56.0%\n",
            "Step: 1711 ------------ Loss: 8670.83 ------------ Accuracy: 56.0%\n",
            "Step: 1712 ------------ Loss: 8670.52 ------------ Accuracy: 56.0%\n",
            "Step: 1713 ------------ Loss: 8670.21 ------------ Accuracy: 56.0%\n",
            "Step: 1714 ------------ Loss: 8669.91 ------------ Accuracy: 56.1%\n",
            "Step: 1715 ------------ Loss: 8669.59 ------------ Accuracy: 56.0%\n",
            "Step: 1716 ------------ Loss: 8669.27 ------------ Accuracy: 56.0%\n",
            "Step: 1717 ------------ Loss: 8668.96 ------------ Accuracy: 56.0%\n",
            "Step: 1718 ------------ Loss: 8668.65 ------------ Accuracy: 56.0%\n",
            "Step: 1719 ------------ Loss: 8668.33 ------------ Accuracy: 56.0%\n",
            "Step: 1720 ------------ Loss: 8668.02 ------------ Accuracy: 56.0%\n",
            "Step: 1721 ------------ Loss: 8667.71 ------------ Accuracy: 56.0%\n",
            "Step: 1722 ------------ Loss: 8667.4 ------------ Accuracy: 56.0%\n",
            "Step: 1723 ------------ Loss: 8667.11 ------------ Accuracy: 56.1%\n",
            "Step: 1724 ------------ Loss: 8666.78 ------------ Accuracy: 56.0%\n",
            "Step: 1725 ------------ Loss: 8666.47 ------------ Accuracy: 56.0%\n",
            "Step: 1726 ------------ Loss: 8666.16 ------------ Accuracy: 56.0%\n",
            "Step: 1727 ------------ Loss: 8665.85 ------------ Accuracy: 56.0%\n",
            "Step: 1728 ------------ Loss: 8665.54 ------------ Accuracy: 56.0%\n",
            "Step: 1729 ------------ Loss: 8665.24 ------------ Accuracy: 56.1%\n",
            "Step: 1730 ------------ Loss: 8664.93 ------------ Accuracy: 56.0%\n",
            "Step: 1731 ------------ Loss: 8664.64 ------------ Accuracy: 56.1%\n",
            "Step: 1732 ------------ Loss: 8664.31 ------------ Accuracy: 56.1%\n",
            "Step: 1733 ------------ Loss: 8664.0 ------------ Accuracy: 56.1%\n",
            "Step: 1734 ------------ Loss: 8663.68 ------------ Accuracy: 56.1%\n",
            "Step: 1735 ------------ Loss: 8663.37 ------------ Accuracy: 56.0%\n",
            "Step: 1736 ------------ Loss: 8663.05 ------------ Accuracy: 56.0%\n",
            "Step: 1737 ------------ Loss: 8662.74 ------------ Accuracy: 56.1%\n",
            "Step: 1738 ------------ Loss: 8662.43 ------------ Accuracy: 56.0%\n",
            "Step: 1739 ------------ Loss: 8662.12 ------------ Accuracy: 56.1%\n",
            "Step: 1740 ------------ Loss: 8661.82 ------------ Accuracy: 56.0%\n",
            "Step: 1741 ------------ Loss: 8661.51 ------------ Accuracy: 56.1%\n",
            "Step: 1742 ------------ Loss: 8661.2 ------------ Accuracy: 56.1%\n",
            "Step: 1743 ------------ Loss: 8660.89 ------------ Accuracy: 56.0%\n",
            "Step: 1744 ------------ Loss: 8660.58 ------------ Accuracy: 56.0%\n",
            "Step: 1745 ------------ Loss: 8660.27 ------------ Accuracy: 56.0%\n",
            "Step: 1746 ------------ Loss: 8659.97 ------------ Accuracy: 56.1%\n",
            "Step: 1747 ------------ Loss: 8659.66 ------------ Accuracy: 56.0%\n",
            "Step: 1748 ------------ Loss: 8659.35 ------------ Accuracy: 56.0%\n",
            "Step: 1749 ------------ Loss: 8659.05 ------------ Accuracy: 56.0%\n",
            "Step: 1750 ------------ Loss: 8658.75 ------------ Accuracy: 56.1%\n",
            "Step: 1751 ------------ Loss: 8658.44 ------------ Accuracy: 56.0%\n",
            "Step: 1752 ------------ Loss: 8658.13 ------------ Accuracy: 56.1%\n",
            "Step: 1753 ------------ Loss: 8657.82 ------------ Accuracy: 56.1%\n",
            "Step: 1754 ------------ Loss: 8657.51 ------------ Accuracy: 56.1%\n",
            "Step: 1755 ------------ Loss: 8657.21 ------------ Accuracy: 56.1%\n",
            "Step: 1756 ------------ Loss: 8656.9 ------------ Accuracy: 56.1%\n",
            "Step: 1757 ------------ Loss: 8656.62 ------------ Accuracy: 56.1%\n",
            "Step: 1758 ------------ Loss: 8656.3 ------------ Accuracy: 56.0%\n",
            "Step: 1759 ------------ Loss: 8656.0 ------------ Accuracy: 56.1%\n",
            "Step: 1760 ------------ Loss: 8655.7 ------------ Accuracy: 56.1%\n",
            "Step: 1761 ------------ Loss: 8655.38 ------------ Accuracy: 56.1%\n",
            "Step: 1762 ------------ Loss: 8655.07 ------------ Accuracy: 56.1%\n",
            "Step: 1763 ------------ Loss: 8654.76 ------------ Accuracy: 56.1%\n",
            "Step: 1764 ------------ Loss: 8654.46 ------------ Accuracy: 56.1%\n",
            "Step: 1765 ------------ Loss: 8654.15 ------------ Accuracy: 56.1%\n",
            "Step: 1766 ------------ Loss: 8653.84 ------------ Accuracy: 56.1%\n",
            "Step: 1767 ------------ Loss: 8653.54 ------------ Accuracy: 56.1%\n",
            "Step: 1768 ------------ Loss: 8653.23 ------------ Accuracy: 56.1%\n",
            "Step: 1769 ------------ Loss: 8652.93 ------------ Accuracy: 56.1%\n",
            "Step: 1770 ------------ Loss: 8652.62 ------------ Accuracy: 56.1%\n",
            "Step: 1771 ------------ Loss: 8652.32 ------------ Accuracy: 56.1%\n",
            "Step: 1772 ------------ Loss: 8652.02 ------------ Accuracy: 56.1%\n",
            "Step: 1773 ------------ Loss: 8651.72 ------------ Accuracy: 56.1%\n",
            "Step: 1774 ------------ Loss: 8651.42 ------------ Accuracy: 56.1%\n",
            "Step: 1775 ------------ Loss: 8651.12 ------------ Accuracy: 56.1%\n",
            "Step: 1776 ------------ Loss: 8650.81 ------------ Accuracy: 56.1%\n",
            "Step: 1777 ------------ Loss: 8650.51 ------------ Accuracy: 56.1%\n",
            "Step: 1778 ------------ Loss: 8650.21 ------------ Accuracy: 56.1%\n",
            "Step: 1779 ------------ Loss: 8649.9 ------------ Accuracy: 56.1%\n",
            "Step: 1780 ------------ Loss: 8649.6 ------------ Accuracy: 56.1%\n",
            "Step: 1781 ------------ Loss: 8649.3 ------------ Accuracy: 56.1%\n",
            "Step: 1782 ------------ Loss: 8648.99 ------------ Accuracy: 56.1%\n",
            "Step: 1783 ------------ Loss: 8648.72 ------------ Accuracy: 56.1%\n",
            "Step: 1784 ------------ Loss: 8648.4 ------------ Accuracy: 56.1%\n",
            "Step: 1785 ------------ Loss: 8648.1 ------------ Accuracy: 56.1%\n",
            "Step: 1786 ------------ Loss: 8647.79 ------------ Accuracy: 56.1%\n",
            "Step: 1787 ------------ Loss: 8647.49 ------------ Accuracy: 56.1%\n",
            "Step: 1788 ------------ Loss: 8647.21 ------------ Accuracy: 56.1%\n",
            "Step: 1789 ------------ Loss: 8646.9 ------------ Accuracy: 56.1%\n",
            "Step: 1790 ------------ Loss: 8646.6 ------------ Accuracy: 56.1%\n",
            "Step: 1791 ------------ Loss: 8646.3 ------------ Accuracy: 56.1%\n",
            "Step: 1792 ------------ Loss: 8646.0 ------------ Accuracy: 56.1%\n",
            "Step: 1793 ------------ Loss: 8645.7 ------------ Accuracy: 56.1%\n",
            "Step: 1794 ------------ Loss: 8645.41 ------------ Accuracy: 56.1%\n",
            "Step: 1795 ------------ Loss: 8645.11 ------------ Accuracy: 56.1%\n",
            "Step: 1796 ------------ Loss: 8644.81 ------------ Accuracy: 56.1%\n",
            "Step: 1797 ------------ Loss: 8644.51 ------------ Accuracy: 56.1%\n",
            "Step: 1798 ------------ Loss: 8644.23 ------------ Accuracy: 56.1%\n",
            "Step: 1799 ------------ Loss: 8643.91 ------------ Accuracy: 56.1%\n",
            "Step: 1800 ------------ Loss: 8643.6 ------------ Accuracy: 56.1%\n",
            "Step: 1801 ------------ Loss: 8643.29 ------------ Accuracy: 56.1%\n",
            "Step: 1802 ------------ Loss: 8642.99 ------------ Accuracy: 56.1%\n",
            "Step: 1803 ------------ Loss: 8642.69 ------------ Accuracy: 56.1%\n",
            "Step: 1804 ------------ Loss: 8642.39 ------------ Accuracy: 56.1%\n",
            "Step: 1805 ------------ Loss: 8642.09 ------------ Accuracy: 56.1%\n",
            "Step: 1806 ------------ Loss: 8641.79 ------------ Accuracy: 56.1%\n",
            "Step: 1807 ------------ Loss: 8641.49 ------------ Accuracy: 56.1%\n",
            "Step: 1808 ------------ Loss: 8641.19 ------------ Accuracy: 56.1%\n",
            "Step: 1809 ------------ Loss: 8640.89 ------------ Accuracy: 56.1%\n",
            "Step: 1810 ------------ Loss: 8640.6 ------------ Accuracy: 56.1%\n",
            "Step: 1811 ------------ Loss: 8640.3 ------------ Accuracy: 56.1%\n",
            "Step: 1812 ------------ Loss: 8640.0 ------------ Accuracy: 56.1%\n",
            "Step: 1813 ------------ Loss: 8639.72 ------------ Accuracy: 56.1%\n",
            "Step: 1814 ------------ Loss: 8639.41 ------------ Accuracy: 56.1%\n",
            "Step: 1815 ------------ Loss: 8639.11 ------------ Accuracy: 56.1%\n",
            "Step: 1816 ------------ Loss: 8638.81 ------------ Accuracy: 56.2%\n",
            "Step: 1817 ------------ Loss: 8638.52 ------------ Accuracy: 56.1%\n",
            "Step: 1818 ------------ Loss: 8638.24 ------------ Accuracy: 56.1%\n",
            "Step: 1819 ------------ Loss: 8637.94 ------------ Accuracy: 56.2%\n",
            "Step: 1820 ------------ Loss: 8637.64 ------------ Accuracy: 56.2%\n",
            "Step: 1821 ------------ Loss: 8637.34 ------------ Accuracy: 56.2%\n",
            "Step: 1822 ------------ Loss: 8637.04 ------------ Accuracy: 56.2%\n",
            "Step: 1823 ------------ Loss: 8636.75 ------------ Accuracy: 56.2%\n",
            "Step: 1824 ------------ Loss: 8636.46 ------------ Accuracy: 56.2%\n",
            "Step: 1825 ------------ Loss: 8636.15 ------------ Accuracy: 56.2%\n",
            "Step: 1826 ------------ Loss: 8635.85 ------------ Accuracy: 56.2%\n",
            "Step: 1827 ------------ Loss: 8635.55 ------------ Accuracy: 56.2%\n",
            "Step: 1828 ------------ Loss: 8635.25 ------------ Accuracy: 56.2%\n",
            "Step: 1829 ------------ Loss: 8634.96 ------------ Accuracy: 56.2%\n",
            "Step: 1830 ------------ Loss: 8634.66 ------------ Accuracy: 56.2%\n",
            "Step: 1831 ------------ Loss: 8634.37 ------------ Accuracy: 56.2%\n",
            "Step: 1832 ------------ Loss: 8634.07 ------------ Accuracy: 56.2%\n",
            "Step: 1833 ------------ Loss: 8633.79 ------------ Accuracy: 56.2%\n",
            "Step: 1834 ------------ Loss: 8633.48 ------------ Accuracy: 56.2%\n",
            "Step: 1835 ------------ Loss: 8633.18 ------------ Accuracy: 56.2%\n",
            "Step: 1836 ------------ Loss: 8632.89 ------------ Accuracy: 56.2%\n",
            "Step: 1837 ------------ Loss: 8632.59 ------------ Accuracy: 56.2%\n",
            "Step: 1838 ------------ Loss: 8632.29 ------------ Accuracy: 56.2%\n",
            "Step: 1839 ------------ Loss: 8632.0 ------------ Accuracy: 56.2%\n",
            "Step: 1840 ------------ Loss: 8631.7 ------------ Accuracy: 56.2%\n",
            "Step: 1841 ------------ Loss: 8631.41 ------------ Accuracy: 56.2%\n",
            "Step: 1842 ------------ Loss: 8631.11 ------------ Accuracy: 56.2%\n",
            "Step: 1843 ------------ Loss: 8630.82 ------------ Accuracy: 56.2%\n",
            "Step: 1844 ------------ Loss: 8630.53 ------------ Accuracy: 56.2%\n",
            "Step: 1845 ------------ Loss: 8630.24 ------------ Accuracy: 56.2%\n",
            "Step: 1846 ------------ Loss: 8629.94 ------------ Accuracy: 56.2%\n",
            "Step: 1847 ------------ Loss: 8629.65 ------------ Accuracy: 56.2%\n",
            "Step: 1848 ------------ Loss: 8629.37 ------------ Accuracy: 56.2%\n",
            "Step: 1849 ------------ Loss: 8629.08 ------------ Accuracy: 56.2%\n",
            "Step: 1850 ------------ Loss: 8628.78 ------------ Accuracy: 56.2%\n",
            "Step: 1851 ------------ Loss: 8628.49 ------------ Accuracy: 56.2%\n",
            "Step: 1852 ------------ Loss: 8628.2 ------------ Accuracy: 56.2%\n",
            "Step: 1853 ------------ Loss: 8627.91 ------------ Accuracy: 56.2%\n",
            "Step: 1854 ------------ Loss: 8627.62 ------------ Accuracy: 56.2%\n",
            "Step: 1855 ------------ Loss: 8627.32 ------------ Accuracy: 56.2%\n",
            "Step: 1856 ------------ Loss: 8627.05 ------------ Accuracy: 56.2%\n",
            "Step: 1857 ------------ Loss: 8626.75 ------------ Accuracy: 56.2%\n",
            "Step: 1858 ------------ Loss: 8626.45 ------------ Accuracy: 56.2%\n",
            "Step: 1859 ------------ Loss: 8626.16 ------------ Accuracy: 56.1%\n",
            "Step: 1860 ------------ Loss: 8625.87 ------------ Accuracy: 56.2%\n",
            "Step: 1861 ------------ Loss: 8625.58 ------------ Accuracy: 56.2%\n",
            "Step: 1862 ------------ Loss: 8625.29 ------------ Accuracy: 56.2%\n",
            "Step: 1863 ------------ Loss: 8625.01 ------------ Accuracy: 56.2%\n",
            "Step: 1864 ------------ Loss: 8624.72 ------------ Accuracy: 56.1%\n",
            "Step: 1865 ------------ Loss: 8624.43 ------------ Accuracy: 56.1%\n",
            "Step: 1866 ------------ Loss: 8624.14 ------------ Accuracy: 56.1%\n",
            "Step: 1867 ------------ Loss: 8623.87 ------------ Accuracy: 56.2%\n",
            "Step: 1868 ------------ Loss: 8623.57 ------------ Accuracy: 56.1%\n",
            "Step: 1869 ------------ Loss: 8623.28 ------------ Accuracy: 56.1%\n",
            "Step: 1870 ------------ Loss: 8623.01 ------------ Accuracy: 56.2%\n",
            "Step: 1871 ------------ Loss: 8622.7 ------------ Accuracy: 56.2%\n",
            "Step: 1872 ------------ Loss: 8622.41 ------------ Accuracy: 56.2%\n",
            "Step: 1873 ------------ Loss: 8622.11 ------------ Accuracy: 56.2%\n",
            "Step: 1874 ------------ Loss: 8621.82 ------------ Accuracy: 56.2%\n",
            "Step: 1875 ------------ Loss: 8621.53 ------------ Accuracy: 56.1%\n",
            "Step: 1876 ------------ Loss: 8621.24 ------------ Accuracy: 56.1%\n",
            "Step: 1877 ------------ Loss: 8620.95 ------------ Accuracy: 56.2%\n",
            "Step: 1878 ------------ Loss: 8620.66 ------------ Accuracy: 56.2%\n",
            "Step: 1879 ------------ Loss: 8620.37 ------------ Accuracy: 56.2%\n",
            "Step: 1880 ------------ Loss: 8620.08 ------------ Accuracy: 56.1%\n",
            "Step: 1881 ------------ Loss: 8619.79 ------------ Accuracy: 56.2%\n",
            "Step: 1882 ------------ Loss: 8619.5 ------------ Accuracy: 56.2%\n",
            "Step: 1883 ------------ Loss: 8619.21 ------------ Accuracy: 56.2%\n",
            "Step: 1884 ------------ Loss: 8618.92 ------------ Accuracy: 56.2%\n",
            "Step: 1885 ------------ Loss: 8618.64 ------------ Accuracy: 56.2%\n",
            "Step: 1886 ------------ Loss: 8618.37 ------------ Accuracy: 56.2%\n",
            "Step: 1887 ------------ Loss: 8618.07 ------------ Accuracy: 56.2%\n",
            "Step: 1888 ------------ Loss: 8617.78 ------------ Accuracy: 56.2%\n",
            "Step: 1889 ------------ Loss: 8617.5 ------------ Accuracy: 56.2%\n",
            "Step: 1890 ------------ Loss: 8617.23 ------------ Accuracy: 56.2%\n",
            "Step: 1891 ------------ Loss: 8616.94 ------------ Accuracy: 56.1%\n",
            "Step: 1892 ------------ Loss: 8616.65 ------------ Accuracy: 56.2%\n",
            "Step: 1893 ------------ Loss: 8616.38 ------------ Accuracy: 56.2%\n",
            "Step: 1894 ------------ Loss: 8616.08 ------------ Accuracy: 56.2%\n",
            "Step: 1895 ------------ Loss: 8615.79 ------------ Accuracy: 56.2%\n",
            "Step: 1896 ------------ Loss: 8615.5 ------------ Accuracy: 56.2%\n",
            "Step: 1897 ------------ Loss: 8615.21 ------------ Accuracy: 56.2%\n",
            "Step: 1898 ------------ Loss: 8614.92 ------------ Accuracy: 56.1%\n",
            "Step: 1899 ------------ Loss: 8614.63 ------------ Accuracy: 56.2%\n",
            "Step: 1900 ------------ Loss: 8614.35 ------------ Accuracy: 56.2%\n",
            "Step: 1901 ------------ Loss: 8614.06 ------------ Accuracy: 56.2%\n",
            "Step: 1902 ------------ Loss: 8613.77 ------------ Accuracy: 56.2%\n",
            "Step: 1903 ------------ Loss: 8613.49 ------------ Accuracy: 56.2%\n",
            "Step: 1904 ------------ Loss: 8613.2 ------------ Accuracy: 56.2%\n",
            "Step: 1905 ------------ Loss: 8612.91 ------------ Accuracy: 56.2%\n",
            "Step: 1906 ------------ Loss: 8612.63 ------------ Accuracy: 56.1%\n",
            "Step: 1907 ------------ Loss: 8612.37 ------------ Accuracy: 56.2%\n",
            "Step: 1908 ------------ Loss: 8612.08 ------------ Accuracy: 56.2%\n",
            "Step: 1909 ------------ Loss: 8611.8 ------------ Accuracy: 56.1%\n",
            "Step: 1910 ------------ Loss: 8611.51 ------------ Accuracy: 56.2%\n",
            "Step: 1911 ------------ Loss: 8611.22 ------------ Accuracy: 56.2%\n",
            "Step: 1912 ------------ Loss: 8610.94 ------------ Accuracy: 56.2%\n",
            "Step: 1913 ------------ Loss: 8610.65 ------------ Accuracy: 56.2%\n",
            "Step: 1914 ------------ Loss: 8610.37 ------------ Accuracy: 56.2%\n",
            "Step: 1915 ------------ Loss: 8610.08 ------------ Accuracy: 56.2%\n",
            "Step: 1916 ------------ Loss: 8609.8 ------------ Accuracy: 56.2%\n",
            "Step: 1917 ------------ Loss: 8609.52 ------------ Accuracy: 56.2%\n",
            "Step: 1918 ------------ Loss: 8609.25 ------------ Accuracy: 56.2%\n",
            "Step: 1919 ------------ Loss: 8608.96 ------------ Accuracy: 56.3%\n",
            "Step: 1920 ------------ Loss: 8608.68 ------------ Accuracy: 56.2%\n",
            "Step: 1921 ------------ Loss: 8608.39 ------------ Accuracy: 56.2%\n",
            "Step: 1922 ------------ Loss: 8608.11 ------------ Accuracy: 56.2%\n",
            "Step: 1923 ------------ Loss: 8607.83 ------------ Accuracy: 56.3%\n",
            "Step: 1924 ------------ Loss: 8607.54 ------------ Accuracy: 56.3%\n",
            "Step: 1925 ------------ Loss: 8607.26 ------------ Accuracy: 56.3%\n",
            "Step: 1926 ------------ Loss: 8606.98 ------------ Accuracy: 56.3%\n",
            "Step: 1927 ------------ Loss: 8606.71 ------------ Accuracy: 56.2%\n",
            "Step: 1928 ------------ Loss: 8606.43 ------------ Accuracy: 56.3%\n",
            "Step: 1929 ------------ Loss: 8606.16 ------------ Accuracy: 56.2%\n",
            "Step: 1930 ------------ Loss: 8605.87 ------------ Accuracy: 56.2%\n",
            "Step: 1931 ------------ Loss: 8605.58 ------------ Accuracy: 56.2%\n",
            "Step: 1932 ------------ Loss: 8605.29 ------------ Accuracy: 56.2%\n",
            "Step: 1933 ------------ Loss: 8605.01 ------------ Accuracy: 56.2%\n",
            "Step: 1934 ------------ Loss: 8604.72 ------------ Accuracy: 56.2%\n",
            "Step: 1935 ------------ Loss: 8604.44 ------------ Accuracy: 56.2%\n",
            "Step: 1936 ------------ Loss: 8604.16 ------------ Accuracy: 56.3%\n",
            "Step: 1937 ------------ Loss: 8603.88 ------------ Accuracy: 56.3%\n",
            "Step: 1938 ------------ Loss: 8603.6 ------------ Accuracy: 56.3%\n",
            "Step: 1939 ------------ Loss: 8603.32 ------------ Accuracy: 56.4%\n",
            "Step: 1940 ------------ Loss: 8603.04 ------------ Accuracy: 56.4%\n",
            "Step: 1941 ------------ Loss: 8602.76 ------------ Accuracy: 56.3%\n",
            "Step: 1942 ------------ Loss: 8602.48 ------------ Accuracy: 56.4%\n",
            "Step: 1943 ------------ Loss: 8602.2 ------------ Accuracy: 56.3%\n",
            "Step: 1944 ------------ Loss: 8601.92 ------------ Accuracy: 56.4%\n",
            "Step: 1945 ------------ Loss: 8601.64 ------------ Accuracy: 56.4%\n",
            "Step: 1946 ------------ Loss: 8601.36 ------------ Accuracy: 56.4%\n",
            "Step: 1947 ------------ Loss: 8601.08 ------------ Accuracy: 56.3%\n",
            "Step: 1948 ------------ Loss: 8600.8 ------------ Accuracy: 56.4%\n",
            "Step: 1949 ------------ Loss: 8600.52 ------------ Accuracy: 56.4%\n",
            "Step: 1950 ------------ Loss: 8600.24 ------------ Accuracy: 56.4%\n",
            "Step: 1951 ------------ Loss: 8599.97 ------------ Accuracy: 56.4%\n",
            "Step: 1952 ------------ Loss: 8599.7 ------------ Accuracy: 56.2%\n",
            "Step: 1953 ------------ Loss: 8599.41 ------------ Accuracy: 56.3%\n",
            "Step: 1954 ------------ Loss: 8599.15 ------------ Accuracy: 56.2%\n",
            "Step: 1955 ------------ Loss: 8598.87 ------------ Accuracy: 56.4%\n",
            "Step: 1956 ------------ Loss: 8598.6 ------------ Accuracy: 56.4%\n",
            "Step: 1957 ------------ Loss: 8598.33 ------------ Accuracy: 56.3%\n",
            "Step: 1958 ------------ Loss: 8598.04 ------------ Accuracy: 56.3%\n",
            "Step: 1959 ------------ Loss: 8597.75 ------------ Accuracy: 56.3%\n",
            "Step: 1960 ------------ Loss: 8597.47 ------------ Accuracy: 56.4%\n",
            "Step: 1961 ------------ Loss: 8597.19 ------------ Accuracy: 56.4%\n",
            "Step: 1962 ------------ Loss: 8596.91 ------------ Accuracy: 56.4%\n",
            "Step: 1963 ------------ Loss: 8596.63 ------------ Accuracy: 56.4%\n",
            "Step: 1964 ------------ Loss: 8596.35 ------------ Accuracy: 56.4%\n",
            "Step: 1965 ------------ Loss: 8596.08 ------------ Accuracy: 56.4%\n",
            "Step: 1966 ------------ Loss: 8595.8 ------------ Accuracy: 56.4%\n",
            "Step: 1967 ------------ Loss: 8595.52 ------------ Accuracy: 56.4%\n",
            "Step: 1968 ------------ Loss: 8595.24 ------------ Accuracy: 56.4%\n",
            "Step: 1969 ------------ Loss: 8594.97 ------------ Accuracy: 56.4%\n",
            "Step: 1970 ------------ Loss: 8594.69 ------------ Accuracy: 56.4%\n",
            "Step: 1971 ------------ Loss: 8594.41 ------------ Accuracy: 56.4%\n",
            "Step: 1972 ------------ Loss: 8594.14 ------------ Accuracy: 56.4%\n",
            "Step: 1973 ------------ Loss: 8593.86 ------------ Accuracy: 56.4%\n",
            "Step: 1974 ------------ Loss: 8593.59 ------------ Accuracy: 56.4%\n",
            "Step: 1975 ------------ Loss: 8593.31 ------------ Accuracy: 56.4%\n",
            "Step: 1976 ------------ Loss: 8593.05 ------------ Accuracy: 56.4%\n",
            "Step: 1977 ------------ Loss: 8592.77 ------------ Accuracy: 56.4%\n",
            "Step: 1978 ------------ Loss: 8592.49 ------------ Accuracy: 56.4%\n",
            "Step: 1979 ------------ Loss: 8592.21 ------------ Accuracy: 56.4%\n",
            "Step: 1980 ------------ Loss: 8591.94 ------------ Accuracy: 56.4%\n",
            "Step: 1981 ------------ Loss: 8591.66 ------------ Accuracy: 56.4%\n",
            "Step: 1982 ------------ Loss: 8591.39 ------------ Accuracy: 56.4%\n",
            "Step: 1983 ------------ Loss: 8591.12 ------------ Accuracy: 56.4%\n",
            "Step: 1984 ------------ Loss: 8590.85 ------------ Accuracy: 56.4%\n",
            "Step: 1985 ------------ Loss: 8590.59 ------------ Accuracy: 56.4%\n",
            "Step: 1986 ------------ Loss: 8590.32 ------------ Accuracy: 56.5%\n",
            "Step: 1987 ------------ Loss: 8590.04 ------------ Accuracy: 56.4%\n",
            "Step: 1988 ------------ Loss: 8589.77 ------------ Accuracy: 56.4%\n",
            "Step: 1989 ------------ Loss: 8589.49 ------------ Accuracy: 56.4%\n",
            "Step: 1990 ------------ Loss: 8589.22 ------------ Accuracy: 56.4%\n",
            "Step: 1991 ------------ Loss: 8588.94 ------------ Accuracy: 56.4%\n",
            "Step: 1992 ------------ Loss: 8588.67 ------------ Accuracy: 56.4%\n",
            "Step: 1993 ------------ Loss: 8588.39 ------------ Accuracy: 56.4%\n",
            "Step: 1994 ------------ Loss: 8588.14 ------------ Accuracy: 56.4%\n",
            "Step: 1995 ------------ Loss: 8587.86 ------------ Accuracy: 56.4%\n",
            "Step: 1996 ------------ Loss: 8587.58 ------------ Accuracy: 56.4%\n",
            "Step: 1997 ------------ Loss: 8587.31 ------------ Accuracy: 56.4%\n",
            "Step: 1998 ------------ Loss: 8587.04 ------------ Accuracy: 56.4%\n",
            "Step: 1999 ------------ Loss: 8586.76 ------------ Accuracy: 56.4%\n",
            "Step: 2000 ------------ Loss: 8586.49 ------------ Accuracy: 56.4%\n",
            "Step: 2001 ------------ Loss: 8586.23 ------------ Accuracy: 56.4%\n",
            "Step: 2002 ------------ Loss: 8585.96 ------------ Accuracy: 56.5%\n",
            "Step: 2003 ------------ Loss: 8585.69 ------------ Accuracy: 56.5%\n",
            "Step: 2004 ------------ Loss: 8585.43 ------------ Accuracy: 57.1%\n",
            "Step: 2005 ------------ Loss: 8585.14 ------------ Accuracy: 56.5%\n",
            "Step: 2006 ------------ Loss: 8584.87 ------------ Accuracy: 56.4%\n",
            "Step: 2007 ------------ Loss: 8584.59 ------------ Accuracy: 56.4%\n",
            "Step: 2008 ------------ Loss: 8584.31 ------------ Accuracy: 56.4%\n",
            "Step: 2009 ------------ Loss: 8584.04 ------------ Accuracy: 57.1%\n",
            "Step: 2010 ------------ Loss: 8583.77 ------------ Accuracy: 57.1%\n",
            "Step: 2011 ------------ Loss: 8583.5 ------------ Accuracy: 57.1%\n",
            "Step: 2012 ------------ Loss: 8583.22 ------------ Accuracy: 57.1%\n",
            "Step: 2013 ------------ Loss: 8582.96 ------------ Accuracy: 57.1%\n",
            "Step: 2014 ------------ Loss: 8582.7 ------------ Accuracy: 57.1%\n",
            "Step: 2015 ------------ Loss: 8582.41 ------------ Accuracy: 57.1%\n",
            "Step: 2016 ------------ Loss: 8582.14 ------------ Accuracy: 57.1%\n",
            "Step: 2017 ------------ Loss: 8581.86 ------------ Accuracy: 57.1%\n",
            "Step: 2018 ------------ Loss: 8581.59 ------------ Accuracy: 57.1%\n",
            "Step: 2019 ------------ Loss: 8581.32 ------------ Accuracy: 57.1%\n",
            "Step: 2020 ------------ Loss: 8581.04 ------------ Accuracy: 57.1%\n",
            "Step: 2021 ------------ Loss: 8580.77 ------------ Accuracy: 57.1%\n",
            "Step: 2022 ------------ Loss: 8580.5 ------------ Accuracy: 57.1%\n",
            "Step: 2023 ------------ Loss: 8580.23 ------------ Accuracy: 57.1%\n",
            "Step: 2024 ------------ Loss: 8579.96 ------------ Accuracy: 57.1%\n",
            "Step: 2025 ------------ Loss: 8579.71 ------------ Accuracy: 57.2%\n",
            "Step: 2026 ------------ Loss: 8579.44 ------------ Accuracy: 57.2%\n",
            "Step: 2027 ------------ Loss: 8579.16 ------------ Accuracy: 57.2%\n",
            "Step: 2028 ------------ Loss: 8578.89 ------------ Accuracy: 57.2%\n",
            "Step: 2029 ------------ Loss: 8578.62 ------------ Accuracy: 57.2%\n",
            "Step: 2030 ------------ Loss: 8578.35 ------------ Accuracy: 57.2%\n",
            "Step: 2031 ------------ Loss: 8578.08 ------------ Accuracy: 57.2%\n",
            "Step: 2032 ------------ Loss: 8577.82 ------------ Accuracy: 57.2%\n",
            "Step: 2033 ------------ Loss: 8577.56 ------------ Accuracy: 57.3%\n",
            "Step: 2034 ------------ Loss: 8577.29 ------------ Accuracy: 57.2%\n",
            "Step: 2035 ------------ Loss: 8577.02 ------------ Accuracy: 57.2%\n",
            "Step: 2036 ------------ Loss: 8576.75 ------------ Accuracy: 57.2%\n",
            "Step: 2037 ------------ Loss: 8576.48 ------------ Accuracy: 57.3%\n",
            "Step: 2038 ------------ Loss: 8576.22 ------------ Accuracy: 57.2%\n",
            "Step: 2039 ------------ Loss: 8575.95 ------------ Accuracy: 57.3%\n",
            "Step: 2040 ------------ Loss: 8575.69 ------------ Accuracy: 57.3%\n",
            "Step: 2041 ------------ Loss: 8575.43 ------------ Accuracy: 57.3%\n",
            "Step: 2042 ------------ Loss: 8575.16 ------------ Accuracy: 57.2%\n",
            "Step: 2043 ------------ Loss: 8574.89 ------------ Accuracy: 57.2%\n",
            "Step: 2044 ------------ Loss: 8574.62 ------------ Accuracy: 57.2%\n",
            "Step: 2045 ------------ Loss: 8574.36 ------------ Accuracy: 57.2%\n",
            "Step: 2046 ------------ Loss: 8574.09 ------------ Accuracy: 57.2%\n",
            "Step: 2047 ------------ Loss: 8573.84 ------------ Accuracy: 57.2%\n",
            "Step: 2048 ------------ Loss: 8573.56 ------------ Accuracy: 57.3%\n",
            "Step: 2049 ------------ Loss: 8573.29 ------------ Accuracy: 57.2%\n",
            "Step: 2050 ------------ Loss: 8573.01 ------------ Accuracy: 57.2%\n",
            "Step: 2051 ------------ Loss: 8572.74 ------------ Accuracy: 57.2%\n",
            "Step: 2052 ------------ Loss: 8572.48 ------------ Accuracy: 57.1%\n",
            "Step: 2053 ------------ Loss: 8572.21 ------------ Accuracy: 57.2%\n",
            "Step: 2054 ------------ Loss: 8571.94 ------------ Accuracy: 57.3%\n",
            "Step: 2055 ------------ Loss: 8571.68 ------------ Accuracy: 57.3%\n",
            "Step: 2056 ------------ Loss: 8571.41 ------------ Accuracy: 57.2%\n",
            "Step: 2057 ------------ Loss: 8571.16 ------------ Accuracy: 57.3%\n",
            "Step: 2058 ------------ Loss: 8570.89 ------------ Accuracy: 57.4%\n",
            "Step: 2059 ------------ Loss: 8570.62 ------------ Accuracy: 57.3%\n",
            "Step: 2060 ------------ Loss: 8570.36 ------------ Accuracy: 57.3%\n",
            "Step: 2061 ------------ Loss: 8570.09 ------------ Accuracy: 57.3%\n",
            "Step: 2062 ------------ Loss: 8569.82 ------------ Accuracy: 57.4%\n",
            "Step: 2063 ------------ Loss: 8569.56 ------------ Accuracy: 57.4%\n",
            "Step: 2064 ------------ Loss: 8569.29 ------------ Accuracy: 57.4%\n",
            "Step: 2065 ------------ Loss: 8569.04 ------------ Accuracy: 57.3%\n",
            "Step: 2066 ------------ Loss: 8568.78 ------------ Accuracy: 57.4%\n",
            "Step: 2067 ------------ Loss: 8568.51 ------------ Accuracy: 57.4%\n",
            "Step: 2068 ------------ Loss: 8568.25 ------------ Accuracy: 57.4%\n",
            "Step: 2069 ------------ Loss: 8567.98 ------------ Accuracy: 57.4%\n",
            "Step: 2070 ------------ Loss: 8567.72 ------------ Accuracy: 57.4%\n",
            "Step: 2071 ------------ Loss: 8567.45 ------------ Accuracy: 57.4%\n",
            "Step: 2072 ------------ Loss: 8567.19 ------------ Accuracy: 57.4%\n",
            "Step: 2073 ------------ Loss: 8566.92 ------------ Accuracy: 57.4%\n",
            "Step: 2074 ------------ Loss: 8566.66 ------------ Accuracy: 57.4%\n",
            "Step: 2075 ------------ Loss: 8566.4 ------------ Accuracy: 57.3%\n",
            "Step: 2076 ------------ Loss: 8566.13 ------------ Accuracy: 57.3%\n",
            "Step: 2077 ------------ Loss: 8565.86 ------------ Accuracy: 57.3%\n",
            "Step: 2078 ------------ Loss: 8565.59 ------------ Accuracy: 57.4%\n",
            "Step: 2079 ------------ Loss: 8565.33 ------------ Accuracy: 57.4%\n",
            "Step: 2080 ------------ Loss: 8565.06 ------------ Accuracy: 57.4%\n",
            "Step: 2081 ------------ Loss: 8564.8 ------------ Accuracy: 57.4%\n",
            "Step: 2082 ------------ Loss: 8564.54 ------------ Accuracy: 57.4%\n",
            "Step: 2083 ------------ Loss: 8564.29 ------------ Accuracy: 57.4%\n",
            "Step: 2084 ------------ Loss: 8564.02 ------------ Accuracy: 57.4%\n",
            "Step: 2085 ------------ Loss: 8563.76 ------------ Accuracy: 57.4%\n",
            "Step: 2086 ------------ Loss: 8563.5 ------------ Accuracy: 57.4%\n",
            "Step: 2087 ------------ Loss: 8563.23 ------------ Accuracy: 57.4%\n",
            "Step: 2088 ------------ Loss: 8562.97 ------------ Accuracy: 57.4%\n",
            "Step: 2089 ------------ Loss: 8562.72 ------------ Accuracy: 57.4%\n",
            "Step: 2090 ------------ Loss: 8562.46 ------------ Accuracy: 57.4%\n",
            "Step: 2091 ------------ Loss: 8562.2 ------------ Accuracy: 57.4%\n",
            "Step: 2092 ------------ Loss: 8561.94 ------------ Accuracy: 57.4%\n",
            "Step: 2093 ------------ Loss: 8561.67 ------------ Accuracy: 57.4%\n",
            "Step: 2094 ------------ Loss: 8561.41 ------------ Accuracy: 57.4%\n",
            "Step: 2095 ------------ Loss: 8561.15 ------------ Accuracy: 57.4%\n",
            "Step: 2096 ------------ Loss: 8560.89 ------------ Accuracy: 57.4%\n",
            "Step: 2097 ------------ Loss: 8560.62 ------------ Accuracy: 57.4%\n",
            "Step: 2098 ------------ Loss: 8560.37 ------------ Accuracy: 57.4%\n",
            "Step: 2099 ------------ Loss: 8560.12 ------------ Accuracy: 57.4%\n",
            "Step: 2100 ------------ Loss: 8559.84 ------------ Accuracy: 57.4%\n",
            "Step: 2101 ------------ Loss: 8559.57 ------------ Accuracy: 57.3%\n",
            "Step: 2102 ------------ Loss: 8559.31 ------------ Accuracy: 57.4%\n",
            "Step: 2103 ------------ Loss: 8559.05 ------------ Accuracy: 57.4%\n",
            "Step: 2104 ------------ Loss: 8558.79 ------------ Accuracy: 57.4%\n",
            "Step: 2105 ------------ Loss: 8558.53 ------------ Accuracy: 57.4%\n",
            "Step: 2106 ------------ Loss: 8558.27 ------------ Accuracy: 57.4%\n",
            "Step: 2107 ------------ Loss: 8558.02 ------------ Accuracy: 57.4%\n",
            "Step: 2108 ------------ Loss: 8557.74 ------------ Accuracy: 57.4%\n",
            "Step: 2109 ------------ Loss: 8557.48 ------------ Accuracy: 57.4%\n",
            "Step: 2110 ------------ Loss: 8557.22 ------------ Accuracy: 57.4%\n",
            "Step: 2111 ------------ Loss: 8556.95 ------------ Accuracy: 57.4%\n",
            "Step: 2112 ------------ Loss: 8556.69 ------------ Accuracy: 57.5%\n",
            "Step: 2113 ------------ Loss: 8556.43 ------------ Accuracy: 57.4%\n",
            "Step: 2114 ------------ Loss: 8556.17 ------------ Accuracy: 57.5%\n",
            "Step: 2115 ------------ Loss: 8555.91 ------------ Accuracy: 57.5%\n",
            "Step: 2116 ------------ Loss: 8555.66 ------------ Accuracy: 57.5%\n",
            "Step: 2117 ------------ Loss: 8555.42 ------------ Accuracy: 57.4%\n",
            "Step: 2118 ------------ Loss: 8555.15 ------------ Accuracy: 57.5%\n",
            "Step: 2119 ------------ Loss: 8554.89 ------------ Accuracy: 57.5%\n",
            "Step: 2120 ------------ Loss: 8554.63 ------------ Accuracy: 57.5%\n",
            "Step: 2121 ------------ Loss: 8554.37 ------------ Accuracy: 57.5%\n",
            "Step: 2122 ------------ Loss: 8554.11 ------------ Accuracy: 57.5%\n",
            "Step: 2123 ------------ Loss: 8553.87 ------------ Accuracy: 57.4%\n",
            "Step: 2124 ------------ Loss: 8553.61 ------------ Accuracy: 57.5%\n",
            "Step: 2125 ------------ Loss: 8553.35 ------------ Accuracy: 57.5%\n",
            "Step: 2126 ------------ Loss: 8553.09 ------------ Accuracy: 57.5%\n",
            "Step: 2127 ------------ Loss: 8552.83 ------------ Accuracy: 57.5%\n",
            "Step: 2128 ------------ Loss: 8552.57 ------------ Accuracy: 57.5%\n",
            "Step: 2129 ------------ Loss: 8552.32 ------------ Accuracy: 57.5%\n",
            "Step: 2130 ------------ Loss: 8552.06 ------------ Accuracy: 57.5%\n",
            "Step: 2131 ------------ Loss: 8551.82 ------------ Accuracy: 57.4%\n",
            "Step: 2132 ------------ Loss: 8551.56 ------------ Accuracy: 57.5%\n",
            "Step: 2133 ------------ Loss: 8551.31 ------------ Accuracy: 57.5%\n",
            "Step: 2134 ------------ Loss: 8551.05 ------------ Accuracy: 57.5%\n",
            "Step: 2135 ------------ Loss: 8550.79 ------------ Accuracy: 57.5%\n",
            "Step: 2136 ------------ Loss: 8550.53 ------------ Accuracy: 57.5%\n",
            "Step: 2137 ------------ Loss: 8550.27 ------------ Accuracy: 57.5%\n",
            "Step: 2138 ------------ Loss: 8550.03 ------------ Accuracy: 57.4%\n",
            "Step: 2139 ------------ Loss: 8549.77 ------------ Accuracy: 57.5%\n",
            "Step: 2140 ------------ Loss: 8549.52 ------------ Accuracy: 57.5%\n",
            "Step: 2141 ------------ Loss: 8549.26 ------------ Accuracy: 57.5%\n",
            "Step: 2142 ------------ Loss: 8549.0 ------------ Accuracy: 57.5%\n",
            "Step: 2143 ------------ Loss: 8548.75 ------------ Accuracy: 57.5%\n",
            "Step: 2144 ------------ Loss: 8548.49 ------------ Accuracy: 57.5%\n",
            "Step: 2145 ------------ Loss: 8548.25 ------------ Accuracy: 57.4%\n",
            "Step: 2146 ------------ Loss: 8547.98 ------------ Accuracy: 57.4%\n",
            "Step: 2147 ------------ Loss: 8547.72 ------------ Accuracy: 57.5%\n",
            "Step: 2148 ------------ Loss: 8547.46 ------------ Accuracy: 57.5%\n",
            "Step: 2149 ------------ Loss: 8547.2 ------------ Accuracy: 57.5%\n",
            "Step: 2150 ------------ Loss: 8546.94 ------------ Accuracy: 57.5%\n",
            "Step: 2151 ------------ Loss: 8546.69 ------------ Accuracy: 57.5%\n",
            "Step: 2152 ------------ Loss: 8546.43 ------------ Accuracy: 57.5%\n",
            "Step: 2153 ------------ Loss: 8546.18 ------------ Accuracy: 57.5%\n",
            "Step: 2154 ------------ Loss: 8545.94 ------------ Accuracy: 57.4%\n",
            "Step: 2155 ------------ Loss: 8545.67 ------------ Accuracy: 57.4%\n",
            "Step: 2156 ------------ Loss: 8545.41 ------------ Accuracy: 57.4%\n",
            "Step: 2157 ------------ Loss: 8545.15 ------------ Accuracy: 57.5%\n",
            "Step: 2158 ------------ Loss: 8544.89 ------------ Accuracy: 57.5%\n",
            "Step: 2159 ------------ Loss: 8544.64 ------------ Accuracy: 57.5%\n",
            "Step: 2160 ------------ Loss: 8544.39 ------------ Accuracy: 57.5%\n",
            "Step: 2161 ------------ Loss: 8544.13 ------------ Accuracy: 57.5%\n",
            "Step: 2162 ------------ Loss: 8543.88 ------------ Accuracy: 57.5%\n",
            "Step: 2163 ------------ Loss: 8543.62 ------------ Accuracy: 57.5%\n",
            "Step: 2164 ------------ Loss: 8543.37 ------------ Accuracy: 57.5%\n",
            "Step: 2165 ------------ Loss: 8543.11 ------------ Accuracy: 57.5%\n",
            "Step: 2166 ------------ Loss: 8542.86 ------------ Accuracy: 57.5%\n",
            "Step: 2167 ------------ Loss: 8542.61 ------------ Accuracy: 57.5%\n",
            "Step: 2168 ------------ Loss: 8542.35 ------------ Accuracy: 57.5%\n",
            "Step: 2169 ------------ Loss: 8542.1 ------------ Accuracy: 57.5%\n",
            "Step: 2170 ------------ Loss: 8541.85 ------------ Accuracy: 57.5%\n",
            "Step: 2171 ------------ Loss: 8541.6 ------------ Accuracy: 57.5%\n",
            "Step: 2172 ------------ Loss: 8541.34 ------------ Accuracy: 57.5%\n",
            "Step: 2173 ------------ Loss: 8541.08 ------------ Accuracy: 57.5%\n",
            "Step: 2174 ------------ Loss: 8540.82 ------------ Accuracy: 57.5%\n",
            "Step: 2175 ------------ Loss: 8540.57 ------------ Accuracy: 57.5%\n",
            "Step: 2176 ------------ Loss: 8540.32 ------------ Accuracy: 57.6%\n",
            "Step: 2177 ------------ Loss: 8540.07 ------------ Accuracy: 57.6%\n",
            "Step: 2178 ------------ Loss: 8539.82 ------------ Accuracy: 57.6%\n",
            "Step: 2179 ------------ Loss: 8539.58 ------------ Accuracy: 57.5%\n",
            "Step: 2180 ------------ Loss: 8539.32 ------------ Accuracy: 57.6%\n",
            "Step: 2181 ------------ Loss: 8539.07 ------------ Accuracy: 57.6%\n",
            "Step: 2182 ------------ Loss: 8538.81 ------------ Accuracy: 57.6%\n",
            "Step: 2183 ------------ Loss: 8538.56 ------------ Accuracy: 57.6%\n",
            "Step: 2184 ------------ Loss: 8538.31 ------------ Accuracy: 57.6%\n",
            "Step: 2185 ------------ Loss: 8538.06 ------------ Accuracy: 57.6%\n",
            "Step: 2186 ------------ Loss: 8537.82 ------------ Accuracy: 57.5%\n",
            "Step: 2187 ------------ Loss: 8537.57 ------------ Accuracy: 57.6%\n",
            "Step: 2188 ------------ Loss: 8537.31 ------------ Accuracy: 57.6%\n",
            "Step: 2189 ------------ Loss: 8537.06 ------------ Accuracy: 57.6%\n",
            "Step: 2190 ------------ Loss: 8536.83 ------------ Accuracy: 57.4%\n",
            "Step: 2191 ------------ Loss: 8536.58 ------------ Accuracy: 57.6%\n",
            "Step: 2192 ------------ Loss: 8536.33 ------------ Accuracy: 57.6%\n",
            "Step: 2193 ------------ Loss: 8536.07 ------------ Accuracy: 57.6%\n",
            "Step: 2194 ------------ Loss: 8535.82 ------------ Accuracy: 57.6%\n",
            "Step: 2195 ------------ Loss: 8535.57 ------------ Accuracy: 57.6%\n",
            "Step: 2196 ------------ Loss: 8535.32 ------------ Accuracy: 57.6%\n",
            "Step: 2197 ------------ Loss: 8535.07 ------------ Accuracy: 57.6%\n",
            "Step: 2198 ------------ Loss: 8534.82 ------------ Accuracy: 57.6%\n",
            "Step: 2199 ------------ Loss: 8534.57 ------------ Accuracy: 57.6%\n",
            "Step: 2200 ------------ Loss: 8534.34 ------------ Accuracy: 57.5%\n",
            "Step: 2201 ------------ Loss: 8534.08 ------------ Accuracy: 57.6%\n",
            "Step: 2202 ------------ Loss: 8533.83 ------------ Accuracy: 57.6%\n",
            "Step: 2203 ------------ Loss: 8533.58 ------------ Accuracy: 57.6%\n",
            "Step: 2204 ------------ Loss: 8533.33 ------------ Accuracy: 57.6%\n",
            "Step: 2205 ------------ Loss: 8533.08 ------------ Accuracy: 57.6%\n",
            "Step: 2206 ------------ Loss: 8532.83 ------------ Accuracy: 57.6%\n",
            "Step: 2207 ------------ Loss: 8532.58 ------------ Accuracy: 57.6%\n",
            "Step: 2208 ------------ Loss: 8532.33 ------------ Accuracy: 57.6%\n",
            "Step: 2209 ------------ Loss: 8532.09 ------------ Accuracy: 57.5%\n",
            "Step: 2210 ------------ Loss: 8531.85 ------------ Accuracy: 57.6%\n",
            "Step: 2211 ------------ Loss: 8531.6 ------------ Accuracy: 57.6%\n",
            "Step: 2212 ------------ Loss: 8531.35 ------------ Accuracy: 57.6%\n",
            "Step: 2213 ------------ Loss: 8531.11 ------------ Accuracy: 57.5%\n",
            "Step: 2214 ------------ Loss: 8530.85 ------------ Accuracy: 57.5%\n",
            "Step: 2215 ------------ Loss: 8530.6 ------------ Accuracy: 57.5%\n",
            "Step: 2216 ------------ Loss: 8530.34 ------------ Accuracy: 57.6%\n",
            "Step: 2217 ------------ Loss: 8530.09 ------------ Accuracy: 57.6%\n",
            "Step: 2218 ------------ Loss: 8529.84 ------------ Accuracy: 57.6%\n",
            "Step: 2219 ------------ Loss: 8529.59 ------------ Accuracy: 57.6%\n",
            "Step: 2220 ------------ Loss: 8529.35 ------------ Accuracy: 57.5%\n",
            "Step: 2221 ------------ Loss: 8529.1 ------------ Accuracy: 57.5%\n",
            "Step: 2222 ------------ Loss: 8528.85 ------------ Accuracy: 57.6%\n",
            "Step: 2223 ------------ Loss: 8528.62 ------------ Accuracy: 57.5%\n",
            "Step: 2224 ------------ Loss: 8528.36 ------------ Accuracy: 57.5%\n",
            "Step: 2225 ------------ Loss: 8528.11 ------------ Accuracy: 57.5%\n",
            "Step: 2226 ------------ Loss: 8527.85 ------------ Accuracy: 57.5%\n",
            "Step: 2227 ------------ Loss: 8527.61 ------------ Accuracy: 57.5%\n",
            "Step: 2228 ------------ Loss: 8527.36 ------------ Accuracy: 57.5%\n",
            "Step: 2229 ------------ Loss: 8527.11 ------------ Accuracy: 57.5%\n",
            "Step: 2230 ------------ Loss: 8526.86 ------------ Accuracy: 57.5%\n",
            "Step: 2231 ------------ Loss: 8526.62 ------------ Accuracy: 57.5%\n",
            "Step: 2232 ------------ Loss: 8526.37 ------------ Accuracy: 57.5%\n",
            "Step: 2233 ------------ Loss: 8526.12 ------------ Accuracy: 57.5%\n",
            "Step: 2234 ------------ Loss: 8525.88 ------------ Accuracy: 57.5%\n",
            "Step: 2235 ------------ Loss: 8525.65 ------------ Accuracy: 57.5%\n",
            "Step: 2236 ------------ Loss: 8525.39 ------------ Accuracy: 57.5%\n",
            "Step: 2237 ------------ Loss: 8525.15 ------------ Accuracy: 57.5%\n",
            "Step: 2238 ------------ Loss: 8524.9 ------------ Accuracy: 57.5%\n",
            "Step: 2239 ------------ Loss: 8524.65 ------------ Accuracy: 57.5%\n",
            "Step: 2240 ------------ Loss: 8524.41 ------------ Accuracy: 57.5%\n",
            "Step: 2241 ------------ Loss: 8524.16 ------------ Accuracy: 57.5%\n",
            "Step: 2242 ------------ Loss: 8523.92 ------------ Accuracy: 57.5%\n",
            "Step: 2243 ------------ Loss: 8523.67 ------------ Accuracy: 57.5%\n",
            "Step: 2244 ------------ Loss: 8523.43 ------------ Accuracy: 57.5%\n",
            "Step: 2245 ------------ Loss: 8523.18 ------------ Accuracy: 57.5%\n",
            "Step: 2246 ------------ Loss: 8522.94 ------------ Accuracy: 57.5%\n",
            "Step: 2247 ------------ Loss: 8522.69 ------------ Accuracy: 57.5%\n",
            "Step: 2248 ------------ Loss: 8522.44 ------------ Accuracy: 57.5%\n",
            "Step: 2249 ------------ Loss: 8522.19 ------------ Accuracy: 57.5%\n",
            "Step: 2250 ------------ Loss: 8521.95 ------------ Accuracy: 57.5%\n",
            "Step: 2251 ------------ Loss: 8521.7 ------------ Accuracy: 57.5%\n",
            "Step: 2252 ------------ Loss: 8521.46 ------------ Accuracy: 57.5%\n",
            "Step: 2253 ------------ Loss: 8521.22 ------------ Accuracy: 57.5%\n",
            "Step: 2254 ------------ Loss: 8520.99 ------------ Accuracy: 57.6%\n",
            "Step: 2255 ------------ Loss: 8520.74 ------------ Accuracy: 57.5%\n",
            "Step: 2256 ------------ Loss: 8520.49 ------------ Accuracy: 57.5%\n",
            "Step: 2257 ------------ Loss: 8520.25 ------------ Accuracy: 57.5%\n",
            "Step: 2258 ------------ Loss: 8520.0 ------------ Accuracy: 57.5%\n",
            "Step: 2259 ------------ Loss: 8519.76 ------------ Accuracy: 57.5%\n",
            "Step: 2260 ------------ Loss: 8519.52 ------------ Accuracy: 57.5%\n",
            "Step: 2261 ------------ Loss: 8519.27 ------------ Accuracy: 57.5%\n",
            "Step: 2262 ------------ Loss: 8519.03 ------------ Accuracy: 57.5%\n",
            "Step: 2263 ------------ Loss: 8518.79 ------------ Accuracy: 57.5%\n",
            "Step: 2264 ------------ Loss: 8518.56 ------------ Accuracy: 57.6%\n",
            "Step: 2265 ------------ Loss: 8518.31 ------------ Accuracy: 57.5%\n",
            "Step: 2266 ------------ Loss: 8518.06 ------------ Accuracy: 57.5%\n",
            "Step: 2267 ------------ Loss: 8517.82 ------------ Accuracy: 57.5%\n",
            "Step: 2268 ------------ Loss: 8517.6 ------------ Accuracy: 57.6%\n",
            "Step: 2269 ------------ Loss: 8517.35 ------------ Accuracy: 57.5%\n",
            "Step: 2270 ------------ Loss: 8517.11 ------------ Accuracy: 57.5%\n",
            "Step: 2271 ------------ Loss: 8516.87 ------------ Accuracy: 57.5%\n",
            "Step: 2272 ------------ Loss: 8516.63 ------------ Accuracy: 57.6%\n",
            "Step: 2273 ------------ Loss: 8516.38 ------------ Accuracy: 57.6%\n",
            "Step: 2274 ------------ Loss: 8516.13 ------------ Accuracy: 57.6%\n",
            "Step: 2275 ------------ Loss: 8515.88 ------------ Accuracy: 57.5%\n",
            "Step: 2276 ------------ Loss: 8515.64 ------------ Accuracy: 57.5%\n",
            "Step: 2277 ------------ Loss: 8515.4 ------------ Accuracy: 57.5%\n",
            "Step: 2278 ------------ Loss: 8515.15 ------------ Accuracy: 57.5%\n",
            "Step: 2279 ------------ Loss: 8514.91 ------------ Accuracy: 57.6%\n",
            "Step: 2280 ------------ Loss: 8514.67 ------------ Accuracy: 57.6%\n",
            "Step: 2281 ------------ Loss: 8514.43 ------------ Accuracy: 57.7%\n",
            "Step: 2282 ------------ Loss: 8514.19 ------------ Accuracy: 57.7%\n",
            "Step: 2283 ------------ Loss: 8513.94 ------------ Accuracy: 57.6%\n",
            "Step: 2284 ------------ Loss: 8513.72 ------------ Accuracy: 57.6%\n",
            "Step: 2285 ------------ Loss: 8513.47 ------------ Accuracy: 57.6%\n",
            "Step: 2286 ------------ Loss: 8513.23 ------------ Accuracy: 57.6%\n",
            "Step: 2287 ------------ Loss: 8512.99 ------------ Accuracy: 57.7%\n",
            "Step: 2288 ------------ Loss: 8512.74 ------------ Accuracy: 57.7%\n",
            "Step: 2289 ------------ Loss: 8512.5 ------------ Accuracy: 57.7%\n",
            "Step: 2290 ------------ Loss: 8512.26 ------------ Accuracy: 57.6%\n",
            "Step: 2291 ------------ Loss: 8512.02 ------------ Accuracy: 57.7%\n",
            "Step: 2292 ------------ Loss: 8511.78 ------------ Accuracy: 57.7%\n",
            "Step: 2293 ------------ Loss: 8511.55 ------------ Accuracy: 57.6%\n",
            "Step: 2294 ------------ Loss: 8511.3 ------------ Accuracy: 57.6%\n",
            "Step: 2295 ------------ Loss: 8511.05 ------------ Accuracy: 57.7%\n",
            "Step: 2296 ------------ Loss: 8510.81 ------------ Accuracy: 57.7%\n",
            "Step: 2297 ------------ Loss: 8510.57 ------------ Accuracy: 57.7%\n",
            "Step: 2298 ------------ Loss: 8510.33 ------------ Accuracy: 57.7%\n",
            "Step: 2299 ------------ Loss: 8510.09 ------------ Accuracy: 57.7%\n",
            "Step: 2300 ------------ Loss: 8509.85 ------------ Accuracy: 57.7%\n",
            "Step: 2301 ------------ Loss: 8509.61 ------------ Accuracy: 57.7%\n",
            "Step: 2302 ------------ Loss: 8509.39 ------------ Accuracy: 57.5%\n",
            "Step: 2303 ------------ Loss: 8509.13 ------------ Accuracy: 57.6%\n",
            "Step: 2304 ------------ Loss: 8508.89 ------------ Accuracy: 57.6%\n",
            "Step: 2305 ------------ Loss: 8508.65 ------------ Accuracy: 57.7%\n",
            "Step: 2306 ------------ Loss: 8508.41 ------------ Accuracy: 57.7%\n",
            "Step: 2307 ------------ Loss: 8508.17 ------------ Accuracy: 57.7%\n",
            "Step: 2308 ------------ Loss: 8507.93 ------------ Accuracy: 57.7%\n",
            "Step: 2309 ------------ Loss: 8507.69 ------------ Accuracy: 57.7%\n",
            "Step: 2310 ------------ Loss: 8507.45 ------------ Accuracy: 57.7%\n",
            "Step: 2311 ------------ Loss: 8507.21 ------------ Accuracy: 57.7%\n",
            "Step: 2312 ------------ Loss: 8506.97 ------------ Accuracy: 57.7%\n",
            "Step: 2313 ------------ Loss: 8506.74 ------------ Accuracy: 57.7%\n",
            "Step: 2314 ------------ Loss: 8506.51 ------------ Accuracy: 57.5%\n",
            "Step: 2315 ------------ Loss: 8506.27 ------------ Accuracy: 57.7%\n",
            "Step: 2316 ------------ Loss: 8506.04 ------------ Accuracy: 57.7%\n",
            "Step: 2317 ------------ Loss: 8505.8 ------------ Accuracy: 57.7%\n",
            "Step: 2318 ------------ Loss: 8505.56 ------------ Accuracy: 57.7%\n",
            "Step: 2319 ------------ Loss: 8505.32 ------------ Accuracy: 57.7%\n",
            "Step: 2320 ------------ Loss: 8505.08 ------------ Accuracy: 57.7%\n",
            "Step: 2321 ------------ Loss: 8504.84 ------------ Accuracy: 57.7%\n",
            "Step: 2322 ------------ Loss: 8504.61 ------------ Accuracy: 57.7%\n",
            "Step: 2323 ------------ Loss: 8504.37 ------------ Accuracy: 57.7%\n",
            "Step: 2324 ------------ Loss: 8504.13 ------------ Accuracy: 57.7%\n",
            "Step: 2325 ------------ Loss: 8503.89 ------------ Accuracy: 57.7%\n",
            "Step: 2326 ------------ Loss: 8503.67 ------------ Accuracy: 57.6%\n",
            "Step: 2327 ------------ Loss: 8503.43 ------------ Accuracy: 57.7%\n",
            "Step: 2328 ------------ Loss: 8503.19 ------------ Accuracy: 57.7%\n",
            "Step: 2329 ------------ Loss: 8502.95 ------------ Accuracy: 57.7%\n",
            "Step: 2330 ------------ Loss: 8502.71 ------------ Accuracy: 57.7%\n",
            "Step: 2331 ------------ Loss: 8502.48 ------------ Accuracy: 57.7%\n",
            "Step: 2332 ------------ Loss: 8502.26 ------------ Accuracy: 57.6%\n",
            "Step: 2333 ------------ Loss: 8502.02 ------------ Accuracy: 57.7%\n",
            "Step: 2334 ------------ Loss: 8501.78 ------------ Accuracy: 57.7%\n",
            "Step: 2335 ------------ Loss: 8501.54 ------------ Accuracy: 57.7%\n",
            "Step: 2336 ------------ Loss: 8501.31 ------------ Accuracy: 57.7%\n",
            "Step: 2337 ------------ Loss: 8501.08 ------------ Accuracy: 57.5%\n",
            "Step: 2338 ------------ Loss: 8500.83 ------------ Accuracy: 57.6%\n",
            "Step: 2339 ------------ Loss: 8500.59 ------------ Accuracy: 57.7%\n",
            "Step: 2340 ------------ Loss: 8500.35 ------------ Accuracy: 57.7%\n",
            "Step: 2341 ------------ Loss: 8500.11 ------------ Accuracy: 57.7%\n",
            "Step: 2342 ------------ Loss: 8499.88 ------------ Accuracy: 57.7%\n",
            "Step: 2343 ------------ Loss: 8499.64 ------------ Accuracy: 57.7%\n",
            "Step: 2344 ------------ Loss: 8499.4 ------------ Accuracy: 57.7%\n",
            "Step: 2345 ------------ Loss: 8499.17 ------------ Accuracy: 57.7%\n",
            "Step: 2346 ------------ Loss: 8498.93 ------------ Accuracy: 57.7%\n",
            "Step: 2347 ------------ Loss: 8498.7 ------------ Accuracy: 57.7%\n",
            "Step: 2348 ------------ Loss: 8498.46 ------------ Accuracy: 57.7%\n",
            "Step: 2349 ------------ Loss: 8498.23 ------------ Accuracy: 57.7%\n",
            "Step: 2350 ------------ Loss: 8498.0 ------------ Accuracy: 57.7%\n",
            "Step: 2351 ------------ Loss: 8497.77 ------------ Accuracy: 57.6%\n",
            "Step: 2352 ------------ Loss: 8497.53 ------------ Accuracy: 57.6%\n",
            "Step: 2353 ------------ Loss: 8497.29 ------------ Accuracy: 57.6%\n",
            "Step: 2354 ------------ Loss: 8497.06 ------------ Accuracy: 57.7%\n",
            "Step: 2355 ------------ Loss: 8496.84 ------------ Accuracy: 57.6%\n",
            "Step: 2356 ------------ Loss: 8496.6 ------------ Accuracy: 57.7%\n",
            "Step: 2357 ------------ Loss: 8496.37 ------------ Accuracy: 57.7%\n",
            "Step: 2358 ------------ Loss: 8496.13 ------------ Accuracy: 57.7%\n",
            "Step: 2359 ------------ Loss: 8495.9 ------------ Accuracy: 57.6%\n",
            "Step: 2360 ------------ Loss: 8495.68 ------------ Accuracy: 57.6%\n",
            "Step: 2361 ------------ Loss: 8495.43 ------------ Accuracy: 57.6%\n",
            "Step: 2362 ------------ Loss: 8495.19 ------------ Accuracy: 57.6%\n",
            "Step: 2363 ------------ Loss: 8494.96 ------------ Accuracy: 57.6%\n",
            "Step: 2364 ------------ Loss: 8494.72 ------------ Accuracy: 57.6%\n",
            "Step: 2365 ------------ Loss: 8494.48 ------------ Accuracy: 57.6%\n",
            "Step: 2366 ------------ Loss: 8494.25 ------------ Accuracy: 57.6%\n",
            "Step: 2367 ------------ Loss: 8494.02 ------------ Accuracy: 57.6%\n",
            "Step: 2368 ------------ Loss: 8493.79 ------------ Accuracy: 57.6%\n",
            "Step: 2369 ------------ Loss: 8493.57 ------------ Accuracy: 57.7%\n",
            "Step: 2370 ------------ Loss: 8493.33 ------------ Accuracy: 57.7%\n",
            "Step: 2371 ------------ Loss: 8493.09 ------------ Accuracy: 57.7%\n",
            "Step: 2372 ------------ Loss: 8492.86 ------------ Accuracy: 57.7%\n",
            "Step: 2373 ------------ Loss: 8492.63 ------------ Accuracy: 57.7%\n",
            "Step: 2374 ------------ Loss: 8492.39 ------------ Accuracy: 57.7%\n",
            "Step: 2375 ------------ Loss: 8492.16 ------------ Accuracy: 57.7%\n",
            "Step: 2376 ------------ Loss: 8491.93 ------------ Accuracy: 57.7%\n",
            "Step: 2377 ------------ Loss: 8491.69 ------------ Accuracy: 57.7%\n",
            "Step: 2378 ------------ Loss: 8491.46 ------------ Accuracy: 57.7%\n",
            "Step: 2379 ------------ Loss: 8491.24 ------------ Accuracy: 57.8%\n",
            "Step: 2380 ------------ Loss: 8491.01 ------------ Accuracy: 57.7%\n",
            "Step: 2381 ------------ Loss: 8490.78 ------------ Accuracy: 57.7%\n",
            "Step: 2382 ------------ Loss: 8490.54 ------------ Accuracy: 57.7%\n",
            "Step: 2383 ------------ Loss: 8490.31 ------------ Accuracy: 57.7%\n",
            "Step: 2384 ------------ Loss: 8490.08 ------------ Accuracy: 57.7%\n",
            "Step: 2385 ------------ Loss: 8489.85 ------------ Accuracy: 57.7%\n",
            "Step: 2386 ------------ Loss: 8489.63 ------------ Accuracy: 57.8%\n",
            "Step: 2387 ------------ Loss: 8489.38 ------------ Accuracy: 57.7%\n",
            "Step: 2388 ------------ Loss: 8489.15 ------------ Accuracy: 57.7%\n",
            "Step: 2389 ------------ Loss: 8488.92 ------------ Accuracy: 57.7%\n",
            "Step: 2390 ------------ Loss: 8488.68 ------------ Accuracy: 57.7%\n",
            "Step: 2391 ------------ Loss: 8488.45 ------------ Accuracy: 57.7%\n",
            "Step: 2392 ------------ Loss: 8488.22 ------------ Accuracy: 57.7%\n",
            "Step: 2393 ------------ Loss: 8487.99 ------------ Accuracy: 57.7%\n",
            "Step: 2394 ------------ Loss: 8487.76 ------------ Accuracy: 57.7%\n",
            "Step: 2395 ------------ Loss: 8487.53 ------------ Accuracy: 57.7%\n",
            "Step: 2396 ------------ Loss: 8487.3 ------------ Accuracy: 57.7%\n",
            "Step: 2397 ------------ Loss: 8487.07 ------------ Accuracy: 57.7%\n",
            "Step: 2398 ------------ Loss: 8486.86 ------------ Accuracy: 57.8%\n",
            "Step: 2399 ------------ Loss: 8486.62 ------------ Accuracy: 57.7%\n",
            "Step: 2400 ------------ Loss: 8486.39 ------------ Accuracy: 57.7%\n",
            "Step: 2401 ------------ Loss: 8486.16 ------------ Accuracy: 57.7%\n",
            "Step: 2402 ------------ Loss: 8485.92 ------------ Accuracy: 57.7%\n",
            "Step: 2403 ------------ Loss: 8485.69 ------------ Accuracy: 57.7%\n",
            "Step: 2404 ------------ Loss: 8485.46 ------------ Accuracy: 57.7%\n",
            "Step: 2405 ------------ Loss: 8485.23 ------------ Accuracy: 57.7%\n",
            "Step: 2406 ------------ Loss: 8485.0 ------------ Accuracy: 57.7%\n",
            "Step: 2407 ------------ Loss: 8484.78 ------------ Accuracy: 57.7%\n",
            "Step: 2408 ------------ Loss: 8484.55 ------------ Accuracy: 57.7%\n",
            "Step: 2409 ------------ Loss: 8484.33 ------------ Accuracy: 57.8%\n",
            "Step: 2410 ------------ Loss: 8484.1 ------------ Accuracy: 57.8%\n",
            "Step: 2411 ------------ Loss: 8483.87 ------------ Accuracy: 57.7%\n",
            "Step: 2412 ------------ Loss: 8483.64 ------------ Accuracy: 57.8%\n",
            "Step: 2413 ------------ Loss: 8483.41 ------------ Accuracy: 57.7%\n",
            "Step: 2414 ------------ Loss: 8483.17 ------------ Accuracy: 57.8%\n",
            "Step: 2415 ------------ Loss: 8482.94 ------------ Accuracy: 57.7%\n",
            "Step: 2416 ------------ Loss: 8482.71 ------------ Accuracy: 57.7%\n",
            "Step: 2417 ------------ Loss: 8482.48 ------------ Accuracy: 57.7%\n",
            "Step: 2418 ------------ Loss: 8482.25 ------------ Accuracy: 57.7%\n",
            "Step: 2419 ------------ Loss: 8482.02 ------------ Accuracy: 57.7%\n",
            "Step: 2420 ------------ Loss: 8481.79 ------------ Accuracy: 57.7%\n",
            "Step: 2421 ------------ Loss: 8481.58 ------------ Accuracy: 57.8%\n",
            "Step: 2422 ------------ Loss: 8481.35 ------------ Accuracy: 57.7%\n",
            "Step: 2423 ------------ Loss: 8481.12 ------------ Accuracy: 57.7%\n",
            "Step: 2424 ------------ Loss: 8480.89 ------------ Accuracy: 57.7%\n",
            "Step: 2425 ------------ Loss: 8480.66 ------------ Accuracy: 57.7%\n",
            "Step: 2426 ------------ Loss: 8480.43 ------------ Accuracy: 57.8%\n",
            "Step: 2427 ------------ Loss: 8480.22 ------------ Accuracy: 57.7%\n",
            "Step: 2428 ------------ Loss: 8479.99 ------------ Accuracy: 57.7%\n",
            "Step: 2429 ------------ Loss: 8479.76 ------------ Accuracy: 57.7%\n",
            "Step: 2430 ------------ Loss: 8479.54 ------------ Accuracy: 57.6%\n",
            "Step: 2431 ------------ Loss: 8479.32 ------------ Accuracy: 57.7%\n",
            "Step: 2432 ------------ Loss: 8479.08 ------------ Accuracy: 57.7%\n",
            "Step: 2433 ------------ Loss: 8478.85 ------------ Accuracy: 57.7%\n",
            "Step: 2434 ------------ Loss: 8478.62 ------------ Accuracy: 57.7%\n",
            "Step: 2435 ------------ Loss: 8478.39 ------------ Accuracy: 57.7%\n",
            "Step: 2436 ------------ Loss: 8478.16 ------------ Accuracy: 57.7%\n",
            "Step: 2437 ------------ Loss: 8477.93 ------------ Accuracy: 57.7%\n",
            "Step: 2438 ------------ Loss: 8477.7 ------------ Accuracy: 57.7%\n",
            "Step: 2439 ------------ Loss: 8477.48 ------------ Accuracy: 57.7%\n",
            "Step: 2440 ------------ Loss: 8477.25 ------------ Accuracy: 57.7%\n",
            "Step: 2441 ------------ Loss: 8477.02 ------------ Accuracy: 57.7%\n",
            "Step: 2442 ------------ Loss: 8476.81 ------------ Accuracy: 57.7%\n",
            "Step: 2443 ------------ Loss: 8476.58 ------------ Accuracy: 57.7%\n",
            "Step: 2444 ------------ Loss: 8476.35 ------------ Accuracy: 57.7%\n",
            "Step: 2445 ------------ Loss: 8476.13 ------------ Accuracy: 57.7%\n",
            "Step: 2446 ------------ Loss: 8475.9 ------------ Accuracy: 57.7%\n",
            "Step: 2447 ------------ Loss: 8475.67 ------------ Accuracy: 57.7%\n",
            "Step: 2448 ------------ Loss: 8475.45 ------------ Accuracy: 57.7%\n",
            "Step: 2449 ------------ Loss: 8475.24 ------------ Accuracy: 57.8%\n",
            "Step: 2450 ------------ Loss: 8475.01 ------------ Accuracy: 57.7%\n",
            "Step: 2451 ------------ Loss: 8474.78 ------------ Accuracy: 57.7%\n",
            "Step: 2452 ------------ Loss: 8474.56 ------------ Accuracy: 57.7%\n",
            "Step: 2453 ------------ Loss: 8474.33 ------------ Accuracy: 57.7%\n",
            "Step: 2454 ------------ Loss: 8474.1 ------------ Accuracy: 57.7%\n",
            "Step: 2455 ------------ Loss: 8473.88 ------------ Accuracy: 57.7%\n",
            "Step: 2456 ------------ Loss: 8473.65 ------------ Accuracy: 57.7%\n",
            "Step: 2457 ------------ Loss: 8473.43 ------------ Accuracy: 57.7%\n",
            "Step: 2458 ------------ Loss: 8473.22 ------------ Accuracy: 57.8%\n",
            "Step: 2459 ------------ Loss: 8472.98 ------------ Accuracy: 57.8%\n",
            "Step: 2460 ------------ Loss: 8472.74 ------------ Accuracy: 57.8%\n",
            "Step: 2461 ------------ Loss: 8472.52 ------------ Accuracy: 57.7%\n",
            "Step: 2462 ------------ Loss: 8472.29 ------------ Accuracy: 57.7%\n",
            "Step: 2463 ------------ Loss: 8472.07 ------------ Accuracy: 57.8%\n",
            "Step: 2464 ------------ Loss: 8471.84 ------------ Accuracy: 57.7%\n",
            "Step: 2465 ------------ Loss: 8471.62 ------------ Accuracy: 57.7%\n",
            "Step: 2466 ------------ Loss: 8471.39 ------------ Accuracy: 57.7%\n",
            "Step: 2467 ------------ Loss: 8471.17 ------------ Accuracy: 57.7%\n",
            "Step: 2468 ------------ Loss: 8470.95 ------------ Accuracy: 57.7%\n",
            "Step: 2469 ------------ Loss: 8470.72 ------------ Accuracy: 57.8%\n",
            "Step: 2470 ------------ Loss: 8470.5 ------------ Accuracy: 57.8%\n",
            "Step: 2471 ------------ Loss: 8470.29 ------------ Accuracy: 57.8%\n",
            "Step: 2472 ------------ Loss: 8470.06 ------------ Accuracy: 57.7%\n",
            "Step: 2473 ------------ Loss: 8469.83 ------------ Accuracy: 57.8%\n",
            "Step: 2474 ------------ Loss: 8469.61 ------------ Accuracy: 57.7%\n",
            "Step: 2475 ------------ Loss: 8469.4 ------------ Accuracy: 57.8%\n",
            "Step: 2476 ------------ Loss: 8469.16 ------------ Accuracy: 57.8%\n",
            "Step: 2477 ------------ Loss: 8468.94 ------------ Accuracy: 57.8%\n",
            "Step: 2478 ------------ Loss: 8468.71 ------------ Accuracy: 57.8%\n",
            "Step: 2479 ------------ Loss: 8468.49 ------------ Accuracy: 57.7%\n",
            "Step: 2480 ------------ Loss: 8468.26 ------------ Accuracy: 57.8%\n",
            "Step: 2481 ------------ Loss: 8468.04 ------------ Accuracy: 57.8%\n",
            "Step: 2482 ------------ Loss: 8467.81 ------------ Accuracy: 57.8%\n",
            "Step: 2483 ------------ Loss: 8467.59 ------------ Accuracy: 57.8%\n",
            "Step: 2484 ------------ Loss: 8467.37 ------------ Accuracy: 57.8%\n",
            "Step: 2485 ------------ Loss: 8467.14 ------------ Accuracy: 57.8%\n",
            "Step: 2486 ------------ Loss: 8466.92 ------------ Accuracy: 57.8%\n",
            "Step: 2487 ------------ Loss: 8466.71 ------------ Accuracy: 57.9%\n",
            "Step: 2488 ------------ Loss: 8466.48 ------------ Accuracy: 57.9%\n",
            "Step: 2489 ------------ Loss: 8466.25 ------------ Accuracy: 57.8%\n",
            "Step: 2490 ------------ Loss: 8466.02 ------------ Accuracy: 57.9%\n",
            "Step: 2491 ------------ Loss: 8465.8 ------------ Accuracy: 57.8%\n",
            "Step: 2492 ------------ Loss: 8465.58 ------------ Accuracy: 57.9%\n",
            "Step: 2493 ------------ Loss: 8465.35 ------------ Accuracy: 57.9%\n",
            "Step: 2494 ------------ Loss: 8465.13 ------------ Accuracy: 57.9%\n",
            "Step: 2495 ------------ Loss: 8464.91 ------------ Accuracy: 57.8%\n",
            "Step: 2496 ------------ Loss: 8464.69 ------------ Accuracy: 57.8%\n",
            "Step: 2497 ------------ Loss: 8464.46 ------------ Accuracy: 57.9%\n",
            "Step: 2498 ------------ Loss: 8464.24 ------------ Accuracy: 57.9%\n",
            "Step: 2499 ------------ Loss: 8464.02 ------------ Accuracy: 57.9%\n",
            "Step: 2500 ------------ Loss: 8463.8 ------------ Accuracy: 57.9%\n",
            "Step: 2501 ------------ Loss: 8463.59 ------------ Accuracy: 57.9%\n",
            "Step: 2502 ------------ Loss: 8463.36 ------------ Accuracy: 57.9%\n",
            "Step: 2503 ------------ Loss: 8463.14 ------------ Accuracy: 57.9%\n",
            "Step: 2504 ------------ Loss: 8462.92 ------------ Accuracy: 57.9%\n",
            "Step: 2505 ------------ Loss: 8462.71 ------------ Accuracy: 57.9%\n",
            "Step: 2506 ------------ Loss: 8462.49 ------------ Accuracy: 57.9%\n",
            "Step: 2507 ------------ Loss: 8462.27 ------------ Accuracy: 57.9%\n",
            "Step: 2508 ------------ Loss: 8462.05 ------------ Accuracy: 57.9%\n",
            "Step: 2509 ------------ Loss: 8461.83 ------------ Accuracy: 57.9%\n",
            "Step: 2510 ------------ Loss: 8461.62 ------------ Accuracy: 57.9%\n",
            "Step: 2511 ------------ Loss: 8461.39 ------------ Accuracy: 57.9%\n",
            "Step: 2512 ------------ Loss: 8461.16 ------------ Accuracy: 57.9%\n",
            "Step: 2513 ------------ Loss: 8460.94 ------------ Accuracy: 57.9%\n",
            "Step: 2514 ------------ Loss: 8460.71 ------------ Accuracy: 57.9%\n",
            "Step: 2515 ------------ Loss: 8460.49 ------------ Accuracy: 57.9%\n",
            "Step: 2516 ------------ Loss: 8460.27 ------------ Accuracy: 57.9%\n",
            "Step: 2517 ------------ Loss: 8460.05 ------------ Accuracy: 57.9%\n",
            "Step: 2518 ------------ Loss: 8459.83 ------------ Accuracy: 57.9%\n",
            "Step: 2519 ------------ Loss: 8459.61 ------------ Accuracy: 57.9%\n",
            "Step: 2520 ------------ Loss: 8459.41 ------------ Accuracy: 57.9%\n",
            "Step: 2521 ------------ Loss: 8459.18 ------------ Accuracy: 57.9%\n",
            "Step: 2522 ------------ Loss: 8458.96 ------------ Accuracy: 57.9%\n",
            "Step: 2523 ------------ Loss: 8458.74 ------------ Accuracy: 57.9%\n",
            "Step: 2524 ------------ Loss: 8458.52 ------------ Accuracy: 57.9%\n",
            "Step: 2525 ------------ Loss: 8458.3 ------------ Accuracy: 57.9%\n",
            "Step: 2526 ------------ Loss: 8458.08 ------------ Accuracy: 57.9%\n",
            "Step: 2527 ------------ Loss: 8457.86 ------------ Accuracy: 57.9%\n",
            "Step: 2528 ------------ Loss: 8457.64 ------------ Accuracy: 57.9%\n",
            "Step: 2529 ------------ Loss: 8457.44 ------------ Accuracy: 57.9%\n",
            "Step: 2530 ------------ Loss: 8457.22 ------------ Accuracy: 57.9%\n",
            "Step: 2531 ------------ Loss: 8457.0 ------------ Accuracy: 57.9%\n",
            "Step: 2532 ------------ Loss: 8456.78 ------------ Accuracy: 57.9%\n",
            "Step: 2533 ------------ Loss: 8456.57 ------------ Accuracy: 57.9%\n",
            "Step: 2534 ------------ Loss: 8456.34 ------------ Accuracy: 57.9%\n",
            "Step: 2535 ------------ Loss: 8456.12 ------------ Accuracy: 57.9%\n",
            "Step: 2536 ------------ Loss: 8455.9 ------------ Accuracy: 57.9%\n",
            "Step: 2537 ------------ Loss: 8455.68 ------------ Accuracy: 57.9%\n",
            "Step: 2538 ------------ Loss: 8455.46 ------------ Accuracy: 57.9%\n",
            "Step: 2539 ------------ Loss: 8455.24 ------------ Accuracy: 57.9%\n",
            "Step: 2540 ------------ Loss: 8455.02 ------------ Accuracy: 57.9%\n",
            "Step: 2541 ------------ Loss: 8454.81 ------------ Accuracy: 57.9%\n",
            "Step: 2542 ------------ Loss: 8454.59 ------------ Accuracy: 57.9%\n",
            "Step: 2543 ------------ Loss: 8454.37 ------------ Accuracy: 57.9%\n",
            "Step: 2544 ------------ Loss: 8454.15 ------------ Accuracy: 57.9%\n",
            "Step: 2545 ------------ Loss: 8453.93 ------------ Accuracy: 57.9%\n",
            "Step: 2546 ------------ Loss: 8453.73 ------------ Accuracy: 57.9%\n",
            "Step: 2547 ------------ Loss: 8453.51 ------------ Accuracy: 57.9%\n",
            "Step: 2548 ------------ Loss: 8453.29 ------------ Accuracy: 57.9%\n",
            "Step: 2549 ------------ Loss: 8453.07 ------------ Accuracy: 57.9%\n",
            "Step: 2550 ------------ Loss: 8452.85 ------------ Accuracy: 57.9%\n",
            "Step: 2551 ------------ Loss: 8452.63 ------------ Accuracy: 57.9%\n",
            "Step: 2552 ------------ Loss: 8452.42 ------------ Accuracy: 57.9%\n",
            "Step: 2553 ------------ Loss: 8452.2 ------------ Accuracy: 57.9%\n",
            "Step: 2554 ------------ Loss: 8451.98 ------------ Accuracy: 57.9%\n",
            "Step: 2555 ------------ Loss: 8451.78 ------------ Accuracy: 57.9%\n",
            "Step: 2556 ------------ Loss: 8451.55 ------------ Accuracy: 57.9%\n",
            "Step: 2557 ------------ Loss: 8451.33 ------------ Accuracy: 57.9%\n",
            "Step: 2558 ------------ Loss: 8451.11 ------------ Accuracy: 57.9%\n",
            "Step: 2559 ------------ Loss: 8450.89 ------------ Accuracy: 57.9%\n",
            "Step: 2560 ------------ Loss: 8450.67 ------------ Accuracy: 57.9%\n",
            "Step: 2561 ------------ Loss: 8450.46 ------------ Accuracy: 57.9%\n",
            "Step: 2562 ------------ Loss: 8450.24 ------------ Accuracy: 57.9%\n",
            "Step: 2563 ------------ Loss: 8450.02 ------------ Accuracy: 57.9%\n",
            "Step: 2564 ------------ Loss: 8449.81 ------------ Accuracy: 57.9%\n",
            "Step: 2565 ------------ Loss: 8449.6 ------------ Accuracy: 57.9%\n",
            "Step: 2566 ------------ Loss: 8449.38 ------------ Accuracy: 57.9%\n",
            "Step: 2567 ------------ Loss: 8449.15 ------------ Accuracy: 57.9%\n",
            "Step: 2568 ------------ Loss: 8448.94 ------------ Accuracy: 57.9%\n",
            "Step: 2569 ------------ Loss: 8448.72 ------------ Accuracy: 57.8%\n",
            "Step: 2570 ------------ Loss: 8448.5 ------------ Accuracy: 57.8%\n",
            "Step: 2571 ------------ Loss: 8448.29 ------------ Accuracy: 57.9%\n",
            "Step: 2572 ------------ Loss: 8448.07 ------------ Accuracy: 57.9%\n",
            "Step: 2573 ------------ Loss: 8447.86 ------------ Accuracy: 57.9%\n",
            "Step: 2574 ------------ Loss: 8447.64 ------------ Accuracy: 57.9%\n",
            "Step: 2575 ------------ Loss: 8447.42 ------------ Accuracy: 57.9%\n",
            "Step: 2576 ------------ Loss: 8447.21 ------------ Accuracy: 57.9%\n",
            "Step: 2577 ------------ Loss: 8446.99 ------------ Accuracy: 57.9%\n",
            "Step: 2578 ------------ Loss: 8446.78 ------------ Accuracy: 57.9%\n",
            "Step: 2579 ------------ Loss: 8446.56 ------------ Accuracy: 57.8%\n",
            "Step: 2580 ------------ Loss: 8446.35 ------------ Accuracy: 57.8%\n",
            "Step: 2581 ------------ Loss: 8446.13 ------------ Accuracy: 57.8%\n",
            "Step: 2582 ------------ Loss: 8445.93 ------------ Accuracy: 57.9%\n",
            "Step: 2583 ------------ Loss: 8445.71 ------------ Accuracy: 57.8%\n",
            "Step: 2584 ------------ Loss: 8445.49 ------------ Accuracy: 57.8%\n",
            "Step: 2585 ------------ Loss: 8445.28 ------------ Accuracy: 57.8%\n",
            "Step: 2586 ------------ Loss: 8445.07 ------------ Accuracy: 57.9%\n",
            "Step: 2587 ------------ Loss: 8444.86 ------------ Accuracy: 57.8%\n",
            "Step: 2588 ------------ Loss: 8444.66 ------------ Accuracy: 57.9%\n",
            "Step: 2589 ------------ Loss: 8444.45 ------------ Accuracy: 57.9%\n",
            "Step: 2590 ------------ Loss: 8444.23 ------------ Accuracy: 57.9%\n",
            "Step: 2591 ------------ Loss: 8444.01 ------------ Accuracy: 57.9%\n",
            "Step: 2592 ------------ Loss: 8443.8 ------------ Accuracy: 57.9%\n",
            "Step: 2593 ------------ Loss: 8443.59 ------------ Accuracy: 57.9%\n",
            "Step: 2594 ------------ Loss: 8443.38 ------------ Accuracy: 57.9%\n",
            "Step: 2595 ------------ Loss: 8443.16 ------------ Accuracy: 57.9%\n",
            "Step: 2596 ------------ Loss: 8442.94 ------------ Accuracy: 58.0%\n",
            "Step: 2597 ------------ Loss: 8442.72 ------------ Accuracy: 58.0%\n",
            "Step: 2598 ------------ Loss: 8442.51 ------------ Accuracy: 58.0%\n",
            "Step: 2599 ------------ Loss: 8442.29 ------------ Accuracy: 57.9%\n",
            "Step: 2600 ------------ Loss: 8442.08 ------------ Accuracy: 57.9%\n",
            "Step: 2601 ------------ Loss: 8441.86 ------------ Accuracy: 57.9%\n",
            "Step: 2602 ------------ Loss: 8441.65 ------------ Accuracy: 57.9%\n",
            "Step: 2603 ------------ Loss: 8441.43 ------------ Accuracy: 57.9%\n",
            "Step: 2604 ------------ Loss: 8441.22 ------------ Accuracy: 57.9%\n",
            "Step: 2605 ------------ Loss: 8441.01 ------------ Accuracy: 57.9%\n",
            "Step: 2606 ------------ Loss: 8440.8 ------------ Accuracy: 57.9%\n",
            "Step: 2607 ------------ Loss: 8440.59 ------------ Accuracy: 57.9%\n",
            "Step: 2608 ------------ Loss: 8440.38 ------------ Accuracy: 57.9%\n",
            "Step: 2609 ------------ Loss: 8440.17 ------------ Accuracy: 57.9%\n",
            "Step: 2610 ------------ Loss: 8439.95 ------------ Accuracy: 57.9%\n",
            "Step: 2611 ------------ Loss: 8439.74 ------------ Accuracy: 57.9%\n",
            "Step: 2612 ------------ Loss: 8439.53 ------------ Accuracy: 57.9%\n",
            "Step: 2613 ------------ Loss: 8439.33 ------------ Accuracy: 57.9%\n",
            "Step: 2614 ------------ Loss: 8439.12 ------------ Accuracy: 57.7%\n",
            "Step: 2615 ------------ Loss: 8438.9 ------------ Accuracy: 57.7%\n",
            "Step: 2616 ------------ Loss: 8438.69 ------------ Accuracy: 57.9%\n",
            "Step: 2617 ------------ Loss: 8438.49 ------------ Accuracy: 57.8%\n",
            "Step: 2618 ------------ Loss: 8438.27 ------------ Accuracy: 57.9%\n",
            "Step: 2619 ------------ Loss: 8438.05 ------------ Accuracy: 57.9%\n",
            "Step: 2620 ------------ Loss: 8437.83 ------------ Accuracy: 57.9%\n",
            "Step: 2621 ------------ Loss: 8437.62 ------------ Accuracy: 57.9%\n",
            "Step: 2622 ------------ Loss: 8437.41 ------------ Accuracy: 57.9%\n",
            "Step: 2623 ------------ Loss: 8437.2 ------------ Accuracy: 57.9%\n",
            "Step: 2624 ------------ Loss: 8436.98 ------------ Accuracy: 57.9%\n",
            "Step: 2625 ------------ Loss: 8436.77 ------------ Accuracy: 57.9%\n",
            "Step: 2626 ------------ Loss: 8436.56 ------------ Accuracy: 57.9%\n",
            "Step: 2627 ------------ Loss: 8436.36 ------------ Accuracy: 57.9%\n",
            "Step: 2628 ------------ Loss: 8436.14 ------------ Accuracy: 57.9%\n",
            "Step: 2629 ------------ Loss: 8435.93 ------------ Accuracy: 57.7%\n",
            "Step: 2630 ------------ Loss: 8435.71 ------------ Accuracy: 57.7%\n",
            "Step: 2631 ------------ Loss: 8435.5 ------------ Accuracy: 57.7%\n",
            "Step: 2632 ------------ Loss: 8435.29 ------------ Accuracy: 57.7%\n",
            "Step: 2633 ------------ Loss: 8435.08 ------------ Accuracy: 57.7%\n",
            "Step: 2634 ------------ Loss: 8434.87 ------------ Accuracy: 57.7%\n",
            "Step: 2635 ------------ Loss: 8434.65 ------------ Accuracy: 57.7%\n",
            "Step: 2636 ------------ Loss: 8434.44 ------------ Accuracy: 57.7%\n",
            "Step: 2637 ------------ Loss: 8434.23 ------------ Accuracy: 57.7%\n",
            "Step: 2638 ------------ Loss: 8434.02 ------------ Accuracy: 57.7%\n",
            "Step: 2639 ------------ Loss: 8433.81 ------------ Accuracy: 57.7%\n",
            "Step: 2640 ------------ Loss: 8433.6 ------------ Accuracy: 57.7%\n",
            "Step: 2641 ------------ Loss: 8433.4 ------------ Accuracy: 57.8%\n",
            "Step: 2642 ------------ Loss: 8433.19 ------------ Accuracy: 57.7%\n",
            "Step: 2643 ------------ Loss: 8432.98 ------------ Accuracy: 57.7%\n",
            "Step: 2644 ------------ Loss: 8432.77 ------------ Accuracy: 57.7%\n",
            "Step: 2645 ------------ Loss: 8432.56 ------------ Accuracy: 57.9%\n",
            "Step: 2646 ------------ Loss: 8432.35 ------------ Accuracy: 57.9%\n",
            "Step: 2647 ------------ Loss: 8432.14 ------------ Accuracy: 57.9%\n",
            "Step: 2648 ------------ Loss: 8431.93 ------------ Accuracy: 57.9%\n",
            "Step: 2649 ------------ Loss: 8431.74 ------------ Accuracy: 57.9%\n",
            "Step: 2650 ------------ Loss: 8431.52 ------------ Accuracy: 57.9%\n",
            "Step: 2651 ------------ Loss: 8431.31 ------------ Accuracy: 57.9%\n",
            "Step: 2652 ------------ Loss: 8431.1 ------------ Accuracy: 57.9%\n",
            "Step: 2653 ------------ Loss: 8430.89 ------------ Accuracy: 57.9%\n",
            "Step: 2654 ------------ Loss: 8430.68 ------------ Accuracy: 57.9%\n",
            "Step: 2655 ------------ Loss: 8430.47 ------------ Accuracy: 57.9%\n",
            "Step: 2656 ------------ Loss: 8430.26 ------------ Accuracy: 57.9%\n",
            "Step: 2657 ------------ Loss: 8430.05 ------------ Accuracy: 57.9%\n",
            "Step: 2658 ------------ Loss: 8429.84 ------------ Accuracy: 57.9%\n",
            "Step: 2659 ------------ Loss: 8429.63 ------------ Accuracy: 57.9%\n",
            "Step: 2660 ------------ Loss: 8429.44 ------------ Accuracy: 57.8%\n",
            "Step: 2661 ------------ Loss: 8429.23 ------------ Accuracy: 57.8%\n",
            "Step: 2662 ------------ Loss: 8429.02 ------------ Accuracy: 57.8%\n",
            "Step: 2663 ------------ Loss: 8428.81 ------------ Accuracy: 57.8%\n",
            "Step: 2664 ------------ Loss: 8428.61 ------------ Accuracy: 57.8%\n",
            "Step: 2665 ------------ Loss: 8428.39 ------------ Accuracy: 57.9%\n",
            "Step: 2666 ------------ Loss: 8428.18 ------------ Accuracy: 57.8%\n",
            "Step: 2667 ------------ Loss: 8427.97 ------------ Accuracy: 57.8%\n",
            "Step: 2668 ------------ Loss: 8427.76 ------------ Accuracy: 57.8%\n",
            "Step: 2669 ------------ Loss: 8427.55 ------------ Accuracy: 57.8%\n",
            "Step: 2670 ------------ Loss: 8427.35 ------------ Accuracy: 57.8%\n",
            "Step: 2671 ------------ Loss: 8427.15 ------------ Accuracy: 57.8%\n",
            "Step: 2672 ------------ Loss: 8426.93 ------------ Accuracy: 57.9%\n",
            "Step: 2673 ------------ Loss: 8426.72 ------------ Accuracy: 57.9%\n",
            "Step: 2674 ------------ Loss: 8426.51 ------------ Accuracy: 57.9%\n",
            "Step: 2675 ------------ Loss: 8426.3 ------------ Accuracy: 57.9%\n",
            "Step: 2676 ------------ Loss: 8426.09 ------------ Accuracy: 57.9%\n",
            "Step: 2677 ------------ Loss: 8425.88 ------------ Accuracy: 57.9%\n",
            "Step: 2678 ------------ Loss: 8425.67 ------------ Accuracy: 57.9%\n",
            "Step: 2679 ------------ Loss: 8425.47 ------------ Accuracy: 57.9%\n",
            "Step: 2680 ------------ Loss: 8425.26 ------------ Accuracy: 57.9%\n",
            "Step: 2681 ------------ Loss: 8425.05 ------------ Accuracy: 57.9%\n",
            "Step: 2682 ------------ Loss: 8424.84 ------------ Accuracy: 57.8%\n",
            "Step: 2683 ------------ Loss: 8424.64 ------------ Accuracy: 57.8%\n",
            "Step: 2684 ------------ Loss: 8424.43 ------------ Accuracy: 57.8%\n",
            "Step: 2685 ------------ Loss: 8424.23 ------------ Accuracy: 57.9%\n",
            "Step: 2686 ------------ Loss: 8424.02 ------------ Accuracy: 57.8%\n",
            "Step: 2687 ------------ Loss: 8423.82 ------------ Accuracy: 57.8%\n",
            "Step: 2688 ------------ Loss: 8423.61 ------------ Accuracy: 57.8%\n",
            "Step: 2689 ------------ Loss: 8423.4 ------------ Accuracy: 57.8%\n",
            "Step: 2690 ------------ Loss: 8423.2 ------------ Accuracy: 57.8%\n",
            "Step: 2691 ------------ Loss: 8423.0 ------------ Accuracy: 57.9%\n",
            "Step: 2692 ------------ Loss: 8422.78 ------------ Accuracy: 57.9%\n",
            "Step: 2693 ------------ Loss: 8422.57 ------------ Accuracy: 57.9%\n",
            "Step: 2694 ------------ Loss: 8422.36 ------------ Accuracy: 57.9%\n",
            "Step: 2695 ------------ Loss: 8422.16 ------------ Accuracy: 57.9%\n",
            "Step: 2696 ------------ Loss: 8421.95 ------------ Accuracy: 57.9%\n",
            "Step: 2697 ------------ Loss: 8421.74 ------------ Accuracy: 57.9%\n",
            "Step: 2698 ------------ Loss: 8421.54 ------------ Accuracy: 57.9%\n",
            "Step: 2699 ------------ Loss: 8421.33 ------------ Accuracy: 57.9%\n",
            "Step: 2700 ------------ Loss: 8421.12 ------------ Accuracy: 57.9%\n",
            "Step: 2701 ------------ Loss: 8420.92 ------------ Accuracy: 57.9%\n",
            "Step: 2702 ------------ Loss: 8420.73 ------------ Accuracy: 57.9%\n",
            "Step: 2703 ------------ Loss: 8420.52 ------------ Accuracy: 57.9%\n",
            "Step: 2704 ------------ Loss: 8420.31 ------------ Accuracy: 57.9%\n",
            "Step: 2705 ------------ Loss: 8420.1 ------------ Accuracy: 57.9%\n",
            "Step: 2706 ------------ Loss: 8419.9 ------------ Accuracy: 57.9%\n",
            "Step: 2707 ------------ Loss: 8419.69 ------------ Accuracy: 57.9%\n",
            "Step: 2708 ------------ Loss: 8419.49 ------------ Accuracy: 57.9%\n",
            "Step: 2709 ------------ Loss: 8419.28 ------------ Accuracy: 57.9%\n",
            "Step: 2710 ------------ Loss: 8419.08 ------------ Accuracy: 57.9%\n",
            "Step: 2711 ------------ Loss: 8418.87 ------------ Accuracy: 57.9%\n",
            "Step: 2712 ------------ Loss: 8418.67 ------------ Accuracy: 57.9%\n",
            "Step: 2713 ------------ Loss: 8418.46 ------------ Accuracy: 57.9%\n",
            "Step: 2714 ------------ Loss: 8418.27 ------------ Accuracy: 57.9%\n",
            "Step: 2715 ------------ Loss: 8418.06 ------------ Accuracy: 57.9%\n",
            "Step: 2716 ------------ Loss: 8417.86 ------------ Accuracy: 57.9%\n",
            "Step: 2717 ------------ Loss: 8417.66 ------------ Accuracy: 57.9%\n",
            "Step: 2718 ------------ Loss: 8417.44 ------------ Accuracy: 57.9%\n",
            "Step: 2719 ------------ Loss: 8417.24 ------------ Accuracy: 57.9%\n",
            "Step: 2720 ------------ Loss: 8417.03 ------------ Accuracy: 57.9%\n",
            "Step: 2721 ------------ Loss: 8416.83 ------------ Accuracy: 57.9%\n",
            "Step: 2722 ------------ Loss: 8416.63 ------------ Accuracy: 57.9%\n",
            "Step: 2723 ------------ Loss: 8416.42 ------------ Accuracy: 57.9%\n",
            "Step: 2724 ------------ Loss: 8416.22 ------------ Accuracy: 57.9%\n",
            "Step: 2725 ------------ Loss: 8416.01 ------------ Accuracy: 57.9%\n",
            "Step: 2726 ------------ Loss: 8415.82 ------------ Accuracy: 58.0%\n",
            "Step: 2727 ------------ Loss: 8415.62 ------------ Accuracy: 57.9%\n",
            "Step: 2728 ------------ Loss: 8415.41 ------------ Accuracy: 57.9%\n",
            "Step: 2729 ------------ Loss: 8415.21 ------------ Accuracy: 57.9%\n",
            "Step: 2730 ------------ Loss: 8415.0 ------------ Accuracy: 57.9%\n",
            "Step: 2731 ------------ Loss: 8414.8 ------------ Accuracy: 57.9%\n",
            "Step: 2732 ------------ Loss: 8414.59 ------------ Accuracy: 57.9%\n",
            "Step: 2733 ------------ Loss: 8414.39 ------------ Accuracy: 57.9%\n",
            "Step: 2734 ------------ Loss: 8414.19 ------------ Accuracy: 57.9%\n",
            "Step: 2735 ------------ Loss: 8413.98 ------------ Accuracy: 57.9%\n",
            "Step: 2736 ------------ Loss: 8413.78 ------------ Accuracy: 57.9%\n",
            "Step: 2737 ------------ Loss: 8413.58 ------------ Accuracy: 57.9%\n",
            "Step: 2738 ------------ Loss: 8413.37 ------------ Accuracy: 57.9%\n",
            "Step: 2739 ------------ Loss: 8413.17 ------------ Accuracy: 57.9%\n",
            "Step: 2740 ------------ Loss: 8412.98 ------------ Accuracy: 58.0%\n",
            "Step: 2741 ------------ Loss: 8412.76 ------------ Accuracy: 58.0%\n",
            "Step: 2742 ------------ Loss: 8412.56 ------------ Accuracy: 57.9%\n",
            "Step: 2743 ------------ Loss: 8412.35 ------------ Accuracy: 57.9%\n",
            "Step: 2744 ------------ Loss: 8412.15 ------------ Accuracy: 57.9%\n",
            "Step: 2745 ------------ Loss: 8411.95 ------------ Accuracy: 57.9%\n",
            "Step: 2746 ------------ Loss: 8411.75 ------------ Accuracy: 57.9%\n",
            "Step: 2747 ------------ Loss: 8411.56 ------------ Accuracy: 58.0%\n",
            "Step: 2748 ------------ Loss: 8411.34 ------------ Accuracy: 58.0%\n",
            "Step: 2749 ------------ Loss: 8411.13 ------------ Accuracy: 58.0%\n",
            "Step: 2750 ------------ Loss: 8410.93 ------------ Accuracy: 58.0%\n",
            "Step: 2751 ------------ Loss: 8410.73 ------------ Accuracy: 58.0%\n",
            "Step: 2752 ------------ Loss: 8410.52 ------------ Accuracy: 58.0%\n",
            "Step: 2753 ------------ Loss: 8410.32 ------------ Accuracy: 58.0%\n",
            "Step: 2754 ------------ Loss: 8410.12 ------------ Accuracy: 58.0%\n",
            "Step: 2755 ------------ Loss: 8409.92 ------------ Accuracy: 58.0%\n",
            "Step: 2756 ------------ Loss: 8409.72 ------------ Accuracy: 58.0%\n",
            "Step: 2757 ------------ Loss: 8409.51 ------------ Accuracy: 58.0%\n",
            "Step: 2758 ------------ Loss: 8409.31 ------------ Accuracy: 58.0%\n",
            "Step: 2759 ------------ Loss: 8409.11 ------------ Accuracy: 58.0%\n",
            "Step: 2760 ------------ Loss: 8408.91 ------------ Accuracy: 58.0%\n",
            "Step: 2761 ------------ Loss: 8408.72 ------------ Accuracy: 57.9%\n",
            "Step: 2762 ------------ Loss: 8408.51 ------------ Accuracy: 58.0%\n",
            "Step: 2763 ------------ Loss: 8408.31 ------------ Accuracy: 58.0%\n",
            "Step: 2764 ------------ Loss: 8408.11 ------------ Accuracy: 58.0%\n",
            "Step: 2765 ------------ Loss: 8407.91 ------------ Accuracy: 58.0%\n",
            "Step: 2766 ------------ Loss: 8407.71 ------------ Accuracy: 58.0%\n",
            "Step: 2767 ------------ Loss: 8407.51 ------------ Accuracy: 58.0%\n",
            "Step: 2768 ------------ Loss: 8407.31 ------------ Accuracy: 58.0%\n",
            "Step: 2769 ------------ Loss: 8407.11 ------------ Accuracy: 58.0%\n",
            "Step: 2770 ------------ Loss: 8406.91 ------------ Accuracy: 58.0%\n",
            "Step: 2771 ------------ Loss: 8406.72 ------------ Accuracy: 57.9%\n",
            "Step: 2772 ------------ Loss: 8406.51 ------------ Accuracy: 58.0%\n",
            "Step: 2773 ------------ Loss: 8406.31 ------------ Accuracy: 58.0%\n",
            "Step: 2774 ------------ Loss: 8406.12 ------------ Accuracy: 57.9%\n",
            "Step: 2775 ------------ Loss: 8405.91 ------------ Accuracy: 57.9%\n",
            "Step: 2776 ------------ Loss: 8405.71 ------------ Accuracy: 57.9%\n",
            "Step: 2777 ------------ Loss: 8405.5 ------------ Accuracy: 58.0%\n",
            "Step: 2778 ------------ Loss: 8405.3 ------------ Accuracy: 58.0%\n",
            "Step: 2779 ------------ Loss: 8405.1 ------------ Accuracy: 58.0%\n",
            "Step: 2780 ------------ Loss: 8404.9 ------------ Accuracy: 58.0%\n",
            "Step: 2781 ------------ Loss: 8404.71 ------------ Accuracy: 57.9%\n",
            "Step: 2782 ------------ Loss: 8404.51 ------------ Accuracy: 57.9%\n",
            "Step: 2783 ------------ Loss: 8404.31 ------------ Accuracy: 57.9%\n",
            "Step: 2784 ------------ Loss: 8404.11 ------------ Accuracy: 57.9%\n",
            "Step: 2785 ------------ Loss: 8403.91 ------------ Accuracy: 57.9%\n",
            "Step: 2786 ------------ Loss: 8403.71 ------------ Accuracy: 57.9%\n",
            "Step: 2787 ------------ Loss: 8403.51 ------------ Accuracy: 57.9%\n",
            "Step: 2788 ------------ Loss: 8403.31 ------------ Accuracy: 57.9%\n",
            "Step: 2789 ------------ Loss: 8403.11 ------------ Accuracy: 57.9%\n",
            "Step: 2790 ------------ Loss: 8402.91 ------------ Accuracy: 58.0%\n",
            "Step: 2791 ------------ Loss: 8402.71 ------------ Accuracy: 58.0%\n",
            "Step: 2792 ------------ Loss: 8402.51 ------------ Accuracy: 58.0%\n",
            "Step: 2793 ------------ Loss: 8402.31 ------------ Accuracy: 58.0%\n",
            "Step: 2794 ------------ Loss: 8402.11 ------------ Accuracy: 58.0%\n",
            "Step: 2795 ------------ Loss: 8401.93 ------------ Accuracy: 57.9%\n",
            "Step: 2796 ------------ Loss: 8401.72 ------------ Accuracy: 57.9%\n",
            "Step: 2797 ------------ Loss: 8401.53 ------------ Accuracy: 57.9%\n",
            "Step: 2798 ------------ Loss: 8401.33 ------------ Accuracy: 57.9%\n",
            "Step: 2799 ------------ Loss: 8401.12 ------------ Accuracy: 57.9%\n",
            "Step: 2800 ------------ Loss: 8400.92 ------------ Accuracy: 58.0%\n",
            "Step: 2801 ------------ Loss: 8400.72 ------------ Accuracy: 58.0%\n",
            "Step: 2802 ------------ Loss: 8400.52 ------------ Accuracy: 58.0%\n",
            "Step: 2803 ------------ Loss: 8400.32 ------------ Accuracy: 58.0%\n",
            "Step: 2804 ------------ Loss: 8400.12 ------------ Accuracy: 58.0%\n",
            "Step: 2805 ------------ Loss: 8399.93 ------------ Accuracy: 58.0%\n",
            "Step: 2806 ------------ Loss: 8399.73 ------------ Accuracy: 58.0%\n",
            "Step: 2807 ------------ Loss: 8399.54 ------------ Accuracy: 57.9%\n",
            "Step: 2808 ------------ Loss: 8399.34 ------------ Accuracy: 58.0%\n",
            "Step: 2809 ------------ Loss: 8399.14 ------------ Accuracy: 58.0%\n",
            "Step: 2810 ------------ Loss: 8398.94 ------------ Accuracy: 58.0%\n",
            "Step: 2811 ------------ Loss: 8398.74 ------------ Accuracy: 58.0%\n",
            "Step: 2812 ------------ Loss: 8398.55 ------------ Accuracy: 57.9%\n",
            "Step: 2813 ------------ Loss: 8398.35 ------------ Accuracy: 57.9%\n",
            "Step: 2814 ------------ Loss: 8398.15 ------------ Accuracy: 57.9%\n",
            "Step: 2815 ------------ Loss: 8397.96 ------------ Accuracy: 58.0%\n",
            "Step: 2816 ------------ Loss: 8397.76 ------------ Accuracy: 58.0%\n",
            "Step: 2817 ------------ Loss: 8397.56 ------------ Accuracy: 58.0%\n",
            "Step: 2818 ------------ Loss: 8397.36 ------------ Accuracy: 58.0%\n",
            "Step: 2819 ------------ Loss: 8397.16 ------------ Accuracy: 58.0%\n",
            "Step: 2820 ------------ Loss: 8396.96 ------------ Accuracy: 57.9%\n",
            "Step: 2821 ------------ Loss: 8396.76 ------------ Accuracy: 57.9%\n",
            "Step: 2822 ------------ Loss: 8396.57 ------------ Accuracy: 57.9%\n",
            "Step: 2823 ------------ Loss: 8396.37 ------------ Accuracy: 57.9%\n",
            "Step: 2824 ------------ Loss: 8396.18 ------------ Accuracy: 58.0%\n",
            "Step: 2825 ------------ Loss: 8395.99 ------------ Accuracy: 57.9%\n",
            "Step: 2826 ------------ Loss: 8395.79 ------------ Accuracy: 58.0%\n",
            "Step: 2827 ------------ Loss: 8395.59 ------------ Accuracy: 58.0%\n",
            "Step: 2828 ------------ Loss: 8395.39 ------------ Accuracy: 58.0%\n",
            "Step: 2829 ------------ Loss: 8395.2 ------------ Accuracy: 58.0%\n",
            "Step: 2830 ------------ Loss: 8395.0 ------------ Accuracy: 57.9%\n",
            "Step: 2831 ------------ Loss: 8394.8 ------------ Accuracy: 57.9%\n",
            "Step: 2832 ------------ Loss: 8394.6 ------------ Accuracy: 57.9%\n",
            "Step: 2833 ------------ Loss: 8394.41 ------------ Accuracy: 57.9%\n",
            "Step: 2834 ------------ Loss: 8394.22 ------------ Accuracy: 57.9%\n",
            "Step: 2835 ------------ Loss: 8394.02 ------------ Accuracy: 57.9%\n",
            "Step: 2836 ------------ Loss: 8393.83 ------------ Accuracy: 57.9%\n",
            "Step: 2837 ------------ Loss: 8393.63 ------------ Accuracy: 57.9%\n",
            "Step: 2838 ------------ Loss: 8393.43 ------------ Accuracy: 57.9%\n",
            "Step: 2839 ------------ Loss: 8393.24 ------------ Accuracy: 57.9%\n",
            "Step: 2840 ------------ Loss: 8393.04 ------------ Accuracy: 57.9%\n",
            "Step: 2841 ------------ Loss: 8392.85 ------------ Accuracy: 58.0%\n",
            "Step: 2842 ------------ Loss: 8392.66 ------------ Accuracy: 57.9%\n",
            "Step: 2843 ------------ Loss: 8392.45 ------------ Accuracy: 57.9%\n",
            "Step: 2844 ------------ Loss: 8392.25 ------------ Accuracy: 57.9%\n",
            "Step: 2845 ------------ Loss: 8392.06 ------------ Accuracy: 57.9%\n",
            "Step: 2846 ------------ Loss: 8391.86 ------------ Accuracy: 57.9%\n",
            "Step: 2847 ------------ Loss: 8391.66 ------------ Accuracy: 57.9%\n",
            "Step: 2848 ------------ Loss: 8391.47 ------------ Accuracy: 57.9%\n",
            "Step: 2849 ------------ Loss: 8391.27 ------------ Accuracy: 57.9%\n",
            "Step: 2850 ------------ Loss: 8391.08 ------------ Accuracy: 57.9%\n",
            "Step: 2851 ------------ Loss: 8390.88 ------------ Accuracy: 57.9%\n",
            "Step: 2852 ------------ Loss: 8390.69 ------------ Accuracy: 57.9%\n",
            "Step: 2853 ------------ Loss: 8390.49 ------------ Accuracy: 57.9%\n",
            "Step: 2854 ------------ Loss: 8390.3 ------------ Accuracy: 57.9%\n",
            "Step: 2855 ------------ Loss: 8390.1 ------------ Accuracy: 57.9%\n",
            "Step: 2856 ------------ Loss: 8389.91 ------------ Accuracy: 57.9%\n",
            "Step: 2857 ------------ Loss: 8389.71 ------------ Accuracy: 57.9%\n",
            "Step: 2858 ------------ Loss: 8389.52 ------------ Accuracy: 57.9%\n",
            "Step: 2859 ------------ Loss: 8389.33 ------------ Accuracy: 57.8%\n",
            "Step: 2860 ------------ Loss: 8389.14 ------------ Accuracy: 57.8%\n",
            "Step: 2861 ------------ Loss: 8388.94 ------------ Accuracy: 57.8%\n",
            "Step: 2862 ------------ Loss: 8388.75 ------------ Accuracy: 57.8%\n",
            "Step: 2863 ------------ Loss: 8388.56 ------------ Accuracy: 57.8%\n",
            "Step: 2864 ------------ Loss: 8388.36 ------------ Accuracy: 57.8%\n",
            "Step: 2865 ------------ Loss: 8388.16 ------------ Accuracy: 57.8%\n",
            "Step: 2866 ------------ Loss: 8387.96 ------------ Accuracy: 57.8%\n",
            "Step: 2867 ------------ Loss: 8387.77 ------------ Accuracy: 57.8%\n",
            "Step: 2868 ------------ Loss: 8387.57 ------------ Accuracy: 57.8%\n",
            "Step: 2869 ------------ Loss: 8387.38 ------------ Accuracy: 57.8%\n",
            "Step: 2870 ------------ Loss: 8387.18 ------------ Accuracy: 57.8%\n",
            "Step: 2871 ------------ Loss: 8386.99 ------------ Accuracy: 57.8%\n",
            "Step: 2872 ------------ Loss: 8386.79 ------------ Accuracy: 57.8%\n",
            "Step: 2873 ------------ Loss: 8386.6 ------------ Accuracy: 57.8%\n",
            "Step: 2874 ------------ Loss: 8386.42 ------------ Accuracy: 57.8%\n",
            "Step: 2875 ------------ Loss: 8386.22 ------------ Accuracy: 57.8%\n",
            "Step: 2876 ------------ Loss: 8386.03 ------------ Accuracy: 57.8%\n",
            "Step: 2877 ------------ Loss: 8385.83 ------------ Accuracy: 57.8%\n",
            "Step: 2878 ------------ Loss: 8385.64 ------------ Accuracy: 57.8%\n",
            "Step: 2879 ------------ Loss: 8385.45 ------------ Accuracy: 57.8%\n",
            "Step: 2880 ------------ Loss: 8385.26 ------------ Accuracy: 57.8%\n",
            "Step: 2881 ------------ Loss: 8385.07 ------------ Accuracy: 57.8%\n",
            "Step: 2882 ------------ Loss: 8384.87 ------------ Accuracy: 57.8%\n",
            "Step: 2883 ------------ Loss: 8384.67 ------------ Accuracy: 57.9%\n",
            "Step: 2884 ------------ Loss: 8384.48 ------------ Accuracy: 57.9%\n",
            "Step: 2885 ------------ Loss: 8384.28 ------------ Accuracy: 57.9%\n",
            "Step: 2886 ------------ Loss: 8384.09 ------------ Accuracy: 57.9%\n",
            "Step: 2887 ------------ Loss: 8383.9 ------------ Accuracy: 57.9%\n",
            "Step: 2888 ------------ Loss: 8383.7 ------------ Accuracy: 57.9%\n",
            "Step: 2889 ------------ Loss: 8383.51 ------------ Accuracy: 57.9%\n",
            "Step: 2890 ------------ Loss: 8383.32 ------------ Accuracy: 57.9%\n",
            "Step: 2891 ------------ Loss: 8383.13 ------------ Accuracy: 57.9%\n",
            "Step: 2892 ------------ Loss: 8382.94 ------------ Accuracy: 57.9%\n",
            "Step: 2893 ------------ Loss: 8382.74 ------------ Accuracy: 57.8%\n",
            "Step: 2894 ------------ Loss: 8382.54 ------------ Accuracy: 57.8%\n",
            "Step: 2895 ------------ Loss: 8382.35 ------------ Accuracy: 57.8%\n",
            "Step: 2896 ------------ Loss: 8382.16 ------------ Accuracy: 57.8%\n",
            "Step: 2897 ------------ Loss: 8381.96 ------------ Accuracy: 57.8%\n",
            "Step: 2898 ------------ Loss: 8381.77 ------------ Accuracy: 57.9%\n",
            "Step: 2899 ------------ Loss: 8381.58 ------------ Accuracy: 57.9%\n",
            "Step: 2900 ------------ Loss: 8381.39 ------------ Accuracy: 57.9%\n",
            "Step: 2901 ------------ Loss: 8381.2 ------------ Accuracy: 57.9%\n",
            "Step: 2902 ------------ Loss: 8381.0 ------------ Accuracy: 58.4%\n",
            "Step: 2903 ------------ Loss: 8380.81 ------------ Accuracy: 57.8%\n",
            "Step: 2904 ------------ Loss: 8380.63 ------------ Accuracy: 57.9%\n",
            "Step: 2905 ------------ Loss: 8380.43 ------------ Accuracy: 57.9%\n",
            "Step: 2906 ------------ Loss: 8380.24 ------------ Accuracy: 57.9%\n",
            "Step: 2907 ------------ Loss: 8380.05 ------------ Accuracy: 57.9%\n",
            "Step: 2908 ------------ Loss: 8379.86 ------------ Accuracy: 57.9%\n",
            "Step: 2909 ------------ Loss: 8379.67 ------------ Accuracy: 57.9%\n",
            "Step: 2910 ------------ Loss: 8379.48 ------------ Accuracy: 57.9%\n",
            "Step: 2911 ------------ Loss: 8379.3 ------------ Accuracy: 58.4%\n",
            "Step: 2912 ------------ Loss: 8379.1 ------------ Accuracy: 57.9%\n",
            "Step: 2913 ------------ Loss: 8378.91 ------------ Accuracy: 58.4%\n",
            "Step: 2914 ------------ Loss: 8378.72 ------------ Accuracy: 58.5%\n",
            "Step: 2915 ------------ Loss: 8378.53 ------------ Accuracy: 58.5%\n",
            "Step: 2916 ------------ Loss: 8378.34 ------------ Accuracy: 58.5%\n",
            "Step: 2917 ------------ Loss: 8378.15 ------------ Accuracy: 58.4%\n",
            "Step: 2918 ------------ Loss: 8377.96 ------------ Accuracy: 57.9%\n",
            "Step: 2919 ------------ Loss: 8377.78 ------------ Accuracy: 58.4%\n",
            "Step: 2920 ------------ Loss: 8377.58 ------------ Accuracy: 57.9%\n",
            "Step: 2921 ------------ Loss: 8377.39 ------------ Accuracy: 57.9%\n",
            "Step: 2922 ------------ Loss: 8377.2 ------------ Accuracy: 58.4%\n",
            "Step: 2923 ------------ Loss: 8377.01 ------------ Accuracy: 58.5%\n",
            "Step: 2924 ------------ Loss: 8376.82 ------------ Accuracy: 58.5%\n",
            "Step: 2925 ------------ Loss: 8376.63 ------------ Accuracy: 58.5%\n",
            "Step: 2926 ------------ Loss: 8376.44 ------------ Accuracy: 58.5%\n",
            "Step: 2927 ------------ Loss: 8376.25 ------------ Accuracy: 58.5%\n",
            "Step: 2928 ------------ Loss: 8376.07 ------------ Accuracy: 58.4%\n",
            "Step: 2929 ------------ Loss: 8375.87 ------------ Accuracy: 58.5%\n",
            "Step: 2930 ------------ Loss: 8375.68 ------------ Accuracy: 58.5%\n",
            "Step: 2931 ------------ Loss: 8375.49 ------------ Accuracy: 58.5%\n",
            "Step: 2932 ------------ Loss: 8375.3 ------------ Accuracy: 58.5%\n",
            "Step: 2933 ------------ Loss: 8375.12 ------------ Accuracy: 58.5%\n",
            "Step: 2934 ------------ Loss: 8374.93 ------------ Accuracy: 58.4%\n",
            "Step: 2935 ------------ Loss: 8374.73 ------------ Accuracy: 58.4%\n",
            "Step: 2936 ------------ Loss: 8374.54 ------------ Accuracy: 58.4%\n",
            "Step: 2937 ------------ Loss: 8374.35 ------------ Accuracy: 58.5%\n",
            "Step: 2938 ------------ Loss: 8374.16 ------------ Accuracy: 58.5%\n",
            "Step: 2939 ------------ Loss: 8373.97 ------------ Accuracy: 58.5%\n",
            "Step: 2940 ------------ Loss: 8373.78 ------------ Accuracy: 58.5%\n",
            "Step: 2941 ------------ Loss: 8373.59 ------------ Accuracy: 58.5%\n",
            "Step: 2942 ------------ Loss: 8373.4 ------------ Accuracy: 58.5%\n",
            "Step: 2943 ------------ Loss: 8373.21 ------------ Accuracy: 58.5%\n",
            "Step: 2944 ------------ Loss: 8373.03 ------------ Accuracy: 58.4%\n",
            "Step: 2945 ------------ Loss: 8372.84 ------------ Accuracy: 58.5%\n",
            "Step: 2946 ------------ Loss: 8372.65 ------------ Accuracy: 58.5%\n",
            "Step: 2947 ------------ Loss: 8372.46 ------------ Accuracy: 58.5%\n",
            "Step: 2948 ------------ Loss: 8372.27 ------------ Accuracy: 58.5%\n",
            "Step: 2949 ------------ Loss: 8372.08 ------------ Accuracy: 58.5%\n",
            "Step: 2950 ------------ Loss: 8371.91 ------------ Accuracy: 58.4%\n",
            "Step: 2951 ------------ Loss: 8371.72 ------------ Accuracy: 58.5%\n",
            "Step: 2952 ------------ Loss: 8371.53 ------------ Accuracy: 58.5%\n",
            "Step: 2953 ------------ Loss: 8371.34 ------------ Accuracy: 58.5%\n",
            "Step: 2954 ------------ Loss: 8371.16 ------------ Accuracy: 58.4%\n",
            "Step: 2955 ------------ Loss: 8370.96 ------------ Accuracy: 58.4%\n",
            "Step: 2956 ------------ Loss: 8370.77 ------------ Accuracy: 58.4%\n",
            "Step: 2957 ------------ Loss: 8370.58 ------------ Accuracy: 58.4%\n",
            "Step: 2958 ------------ Loss: 8370.39 ------------ Accuracy: 58.5%\n",
            "Step: 2959 ------------ Loss: 8370.2 ------------ Accuracy: 58.4%\n",
            "Step: 2960 ------------ Loss: 8370.01 ------------ Accuracy: 58.5%\n",
            "Step: 2961 ------------ Loss: 8369.82 ------------ Accuracy: 58.4%\n",
            "Step: 2962 ------------ Loss: 8369.63 ------------ Accuracy: 58.5%\n",
            "Step: 2963 ------------ Loss: 8369.44 ------------ Accuracy: 58.5%\n",
            "Step: 2964 ------------ Loss: 8369.26 ------------ Accuracy: 58.5%\n",
            "Step: 2965 ------------ Loss: 8369.07 ------------ Accuracy: 58.5%\n",
            "Step: 2966 ------------ Loss: 8368.88 ------------ Accuracy: 58.5%\n",
            "Step: 2967 ------------ Loss: 8368.7 ------------ Accuracy: 58.5%\n",
            "Step: 2968 ------------ Loss: 8368.5 ------------ Accuracy: 58.5%\n",
            "Step: 2969 ------------ Loss: 8368.31 ------------ Accuracy: 58.5%\n",
            "Step: 2970 ------------ Loss: 8368.12 ------------ Accuracy: 58.5%\n",
            "Step: 2971 ------------ Loss: 8367.94 ------------ Accuracy: 58.6%\n",
            "Step: 2972 ------------ Loss: 8367.75 ------------ Accuracy: 58.5%\n",
            "Step: 2973 ------------ Loss: 8367.56 ------------ Accuracy: 58.6%\n",
            "Step: 2974 ------------ Loss: 8367.37 ------------ Accuracy: 58.6%\n",
            "Step: 2975 ------------ Loss: 8367.18 ------------ Accuracy: 58.6%\n",
            "Step: 2976 ------------ Loss: 8367.0 ------------ Accuracy: 58.6%\n",
            "Step: 2977 ------------ Loss: 8366.81 ------------ Accuracy: 58.6%\n",
            "Step: 2978 ------------ Loss: 8366.62 ------------ Accuracy: 58.6%\n",
            "Step: 2979 ------------ Loss: 8366.43 ------------ Accuracy: 58.6%\n",
            "Step: 2980 ------------ Loss: 8366.25 ------------ Accuracy: 58.6%\n",
            "Step: 2981 ------------ Loss: 8366.06 ------------ Accuracy: 58.6%\n",
            "Step: 2982 ------------ Loss: 8365.87 ------------ Accuracy: 58.6%\n",
            "Step: 2983 ------------ Loss: 8365.68 ------------ Accuracy: 58.6%\n",
            "Step: 2984 ------------ Loss: 8365.5 ------------ Accuracy: 58.6%\n",
            "Step: 2985 ------------ Loss: 8365.31 ------------ Accuracy: 58.6%\n",
            "Step: 2986 ------------ Loss: 8365.13 ------------ Accuracy: 58.6%\n",
            "Step: 2987 ------------ Loss: 8364.94 ------------ Accuracy: 58.6%\n",
            "Step: 2988 ------------ Loss: 8364.76 ------------ Accuracy: 58.6%\n",
            "Step: 2989 ------------ Loss: 8364.57 ------------ Accuracy: 58.6%\n",
            "Step: 2990 ------------ Loss: 8364.38 ------------ Accuracy: 58.6%\n",
            "Step: 2991 ------------ Loss: 8364.2 ------------ Accuracy: 58.6%\n",
            "Step: 2992 ------------ Loss: 8364.01 ------------ Accuracy: 58.6%\n",
            "Step: 2993 ------------ Loss: 8363.82 ------------ Accuracy: 58.6%\n",
            "Step: 2994 ------------ Loss: 8363.64 ------------ Accuracy: 58.7%\n",
            "Step: 2995 ------------ Loss: 8363.46 ------------ Accuracy: 58.6%\n",
            "Step: 2996 ------------ Loss: 8363.27 ------------ Accuracy: 58.6%\n",
            "Step: 2997 ------------ Loss: 8363.08 ------------ Accuracy: 58.6%\n",
            "Step: 2998 ------------ Loss: 8362.9 ------------ Accuracy: 58.6%\n",
            "Step: 2999 ------------ Loss: 8362.72 ------------ Accuracy: 58.7%\n",
            "Step: 3000 ------------ Loss: 8362.54 ------------ Accuracy: 58.7%\n",
            "Step: 3001 ------------ Loss: 8362.35 ------------ Accuracy: 58.7%\n",
            "Step: 3002 ------------ Loss: 8362.16 ------------ Accuracy: 58.7%\n",
            "Step: 3003 ------------ Loss: 8361.98 ------------ Accuracy: 58.7%\n",
            "Step: 3004 ------------ Loss: 8361.79 ------------ Accuracy: 58.7%\n",
            "Step: 3005 ------------ Loss: 8361.61 ------------ Accuracy: 58.7%\n",
            "Step: 3006 ------------ Loss: 8361.42 ------------ Accuracy: 58.7%\n",
            "Step: 3007 ------------ Loss: 8361.24 ------------ Accuracy: 58.7%\n",
            "Step: 3008 ------------ Loss: 8361.06 ------------ Accuracy: 58.7%\n",
            "Step: 3009 ------------ Loss: 8360.86 ------------ Accuracy: 58.7%\n",
            "Step: 3010 ------------ Loss: 8360.67 ------------ Accuracy: 58.7%\n",
            "Step: 3011 ------------ Loss: 8360.49 ------------ Accuracy: 58.7%\n",
            "Step: 3012 ------------ Loss: 8360.3 ------------ Accuracy: 58.7%\n",
            "Step: 3013 ------------ Loss: 8360.11 ------------ Accuracy: 58.7%\n",
            "Step: 3014 ------------ Loss: 8359.93 ------------ Accuracy: 58.7%\n",
            "Step: 3015 ------------ Loss: 8359.74 ------------ Accuracy: 58.7%\n",
            "Step: 3016 ------------ Loss: 8359.56 ------------ Accuracy: 58.7%\n",
            "Step: 3017 ------------ Loss: 8359.37 ------------ Accuracy: 58.7%\n",
            "Step: 3018 ------------ Loss: 8359.19 ------------ Accuracy: 58.7%\n",
            "Step: 3019 ------------ Loss: 8359.01 ------------ Accuracy: 58.7%\n",
            "Step: 3020 ------------ Loss: 8358.83 ------------ Accuracy: 58.7%\n",
            "Step: 3021 ------------ Loss: 8358.64 ------------ Accuracy: 58.7%\n",
            "Step: 3022 ------------ Loss: 8358.46 ------------ Accuracy: 58.7%\n",
            "Step: 3023 ------------ Loss: 8358.29 ------------ Accuracy: 58.8%\n",
            "Step: 3024 ------------ Loss: 8358.09 ------------ Accuracy: 58.7%\n",
            "Step: 3025 ------------ Loss: 8357.9 ------------ Accuracy: 58.7%\n",
            "Step: 3026 ------------ Loss: 8357.72 ------------ Accuracy: 58.7%\n",
            "Step: 3027 ------------ Loss: 8357.53 ------------ Accuracy: 58.7%\n",
            "Step: 3028 ------------ Loss: 8357.35 ------------ Accuracy: 58.7%\n",
            "Step: 3029 ------------ Loss: 8357.16 ------------ Accuracy: 58.7%\n",
            "Step: 3030 ------------ Loss: 8356.99 ------------ Accuracy: 58.8%\n",
            "Step: 3031 ------------ Loss: 8356.8 ------------ Accuracy: 58.8%\n",
            "Step: 3032 ------------ Loss: 8356.61 ------------ Accuracy: 58.7%\n",
            "Step: 3033 ------------ Loss: 8356.42 ------------ Accuracy: 58.7%\n",
            "Step: 3034 ------------ Loss: 8356.24 ------------ Accuracy: 58.7%\n",
            "Step: 3035 ------------ Loss: 8356.05 ------------ Accuracy: 58.7%\n",
            "Step: 3036 ------------ Loss: 8355.87 ------------ Accuracy: 58.7%\n",
            "Step: 3037 ------------ Loss: 8355.69 ------------ Accuracy: 58.7%\n",
            "Step: 3038 ------------ Loss: 8355.5 ------------ Accuracy: 58.7%\n",
            "Step: 3039 ------------ Loss: 8355.32 ------------ Accuracy: 58.7%\n",
            "Step: 3040 ------------ Loss: 8355.13 ------------ Accuracy: 58.7%\n",
            "Step: 3041 ------------ Loss: 8354.96 ------------ Accuracy: 58.8%\n",
            "Step: 3042 ------------ Loss: 8354.78 ------------ Accuracy: 58.7%\n",
            "Step: 3043 ------------ Loss: 8354.59 ------------ Accuracy: 58.7%\n",
            "Step: 3044 ------------ Loss: 8354.41 ------------ Accuracy: 58.7%\n",
            "Step: 3045 ------------ Loss: 8354.22 ------------ Accuracy: 58.7%\n",
            "Step: 3046 ------------ Loss: 8354.04 ------------ Accuracy: 58.7%\n",
            "Step: 3047 ------------ Loss: 8353.86 ------------ Accuracy: 58.8%\n",
            "Step: 3048 ------------ Loss: 8353.67 ------------ Accuracy: 58.7%\n",
            "Step: 3049 ------------ Loss: 8353.49 ------------ Accuracy: 58.7%\n",
            "Step: 3050 ------------ Loss: 8353.31 ------------ Accuracy: 58.7%\n",
            "Step: 3051 ------------ Loss: 8353.13 ------------ Accuracy: 58.7%\n",
            "Step: 3052 ------------ Loss: 8352.95 ------------ Accuracy: 58.7%\n",
            "Step: 3053 ------------ Loss: 8352.77 ------------ Accuracy: 58.8%\n",
            "Step: 3054 ------------ Loss: 8352.58 ------------ Accuracy: 58.8%\n",
            "Step: 3055 ------------ Loss: 8352.39 ------------ Accuracy: 58.8%\n",
            "Step: 3056 ------------ Loss: 8352.21 ------------ Accuracy: 58.8%\n",
            "Step: 3057 ------------ Loss: 8352.02 ------------ Accuracy: 58.8%\n",
            "Step: 3058 ------------ Loss: 8351.84 ------------ Accuracy: 58.8%\n",
            "Step: 3059 ------------ Loss: 8351.66 ------------ Accuracy: 58.7%\n",
            "Step: 3060 ------------ Loss: 8351.48 ------------ Accuracy: 58.7%\n",
            "Step: 3061 ------------ Loss: 8351.29 ------------ Accuracy: 58.8%\n",
            "Step: 3062 ------------ Loss: 8351.11 ------------ Accuracy: 58.7%\n",
            "Step: 3063 ------------ Loss: 8350.93 ------------ Accuracy: 58.8%\n",
            "Step: 3064 ------------ Loss: 8350.75 ------------ Accuracy: 58.8%\n",
            "Step: 3065 ------------ Loss: 8350.57 ------------ Accuracy: 58.8%\n",
            "Step: 3066 ------------ Loss: 8350.38 ------------ Accuracy: 58.8%\n",
            "Step: 3067 ------------ Loss: 8350.2 ------------ Accuracy: 58.8%\n",
            "Step: 3068 ------------ Loss: 8350.02 ------------ Accuracy: 58.8%\n",
            "Step: 3069 ------------ Loss: 8349.84 ------------ Accuracy: 58.7%\n",
            "Step: 3070 ------------ Loss: 8349.67 ------------ Accuracy: 58.8%\n",
            "Step: 3071 ------------ Loss: 8349.48 ------------ Accuracy: 58.8%\n",
            "Step: 3072 ------------ Loss: 8349.3 ------------ Accuracy: 58.8%\n",
            "Step: 3073 ------------ Loss: 8349.12 ------------ Accuracy: 58.8%\n",
            "Step: 3074 ------------ Loss: 8348.95 ------------ Accuracy: 58.8%\n",
            "Step: 3075 ------------ Loss: 8348.77 ------------ Accuracy: 58.8%\n",
            "Step: 3076 ------------ Loss: 8348.59 ------------ Accuracy: 58.8%\n",
            "Step: 3077 ------------ Loss: 8348.4 ------------ Accuracy: 58.8%\n",
            "Step: 3078 ------------ Loss: 8348.22 ------------ Accuracy: 58.8%\n",
            "Step: 3079 ------------ Loss: 8348.04 ------------ Accuracy: 58.8%\n",
            "Step: 3080 ------------ Loss: 8347.86 ------------ Accuracy: 58.8%\n",
            "Step: 3081 ------------ Loss: 8347.68 ------------ Accuracy: 58.8%\n",
            "Step: 3082 ------------ Loss: 8347.5 ------------ Accuracy: 58.8%\n",
            "Step: 3083 ------------ Loss: 8347.31 ------------ Accuracy: 58.8%\n",
            "Step: 3084 ------------ Loss: 8347.13 ------------ Accuracy: 58.8%\n",
            "Step: 3085 ------------ Loss: 8346.97 ------------ Accuracy: 58.8%\n",
            "Step: 3086 ------------ Loss: 8346.77 ------------ Accuracy: 58.8%\n",
            "Step: 3087 ------------ Loss: 8346.59 ------------ Accuracy: 58.8%\n",
            "Step: 3088 ------------ Loss: 8346.41 ------------ Accuracy: 58.8%\n",
            "Step: 3089 ------------ Loss: 8346.23 ------------ Accuracy: 58.8%\n",
            "Step: 3090 ------------ Loss: 8346.05 ------------ Accuracy: 58.8%\n",
            "Step: 3091 ------------ Loss: 8345.87 ------------ Accuracy: 58.8%\n",
            "Step: 3092 ------------ Loss: 8345.69 ------------ Accuracy: 58.8%\n",
            "Step: 3093 ------------ Loss: 8345.52 ------------ Accuracy: 58.8%\n",
            "Step: 3094 ------------ Loss: 8345.33 ------------ Accuracy: 58.8%\n",
            "Step: 3095 ------------ Loss: 8345.14 ------------ Accuracy: 58.8%\n",
            "Step: 3096 ------------ Loss: 8344.96 ------------ Accuracy: 58.8%\n",
            "Step: 3097 ------------ Loss: 8344.78 ------------ Accuracy: 58.8%\n",
            "Step: 3098 ------------ Loss: 8344.6 ------------ Accuracy: 58.8%\n",
            "Step: 3099 ------------ Loss: 8344.43 ------------ Accuracy: 58.8%\n",
            "Step: 3100 ------------ Loss: 8344.25 ------------ Accuracy: 58.8%\n",
            "Step: 3101 ------------ Loss: 8344.07 ------------ Accuracy: 58.8%\n",
            "Step: 3102 ------------ Loss: 8343.89 ------------ Accuracy: 58.8%\n",
            "Step: 3103 ------------ Loss: 8343.7 ------------ Accuracy: 58.8%\n",
            "Step: 3104 ------------ Loss: 8343.52 ------------ Accuracy: 58.8%\n",
            "Step: 3105 ------------ Loss: 8343.34 ------------ Accuracy: 58.8%\n",
            "Step: 3106 ------------ Loss: 8343.16 ------------ Accuracy: 58.8%\n",
            "Step: 3107 ------------ Loss: 8342.99 ------------ Accuracy: 58.8%\n",
            "Step: 3108 ------------ Loss: 8342.81 ------------ Accuracy: 58.8%\n",
            "Step: 3109 ------------ Loss: 8342.63 ------------ Accuracy: 58.8%\n",
            "Step: 3110 ------------ Loss: 8342.45 ------------ Accuracy: 58.8%\n",
            "Step: 3111 ------------ Loss: 8342.28 ------------ Accuracy: 58.8%\n",
            "Step: 3112 ------------ Loss: 8342.1 ------------ Accuracy: 58.8%\n",
            "Step: 3113 ------------ Loss: 8341.92 ------------ Accuracy: 58.8%\n",
            "Step: 3114 ------------ Loss: 8341.74 ------------ Accuracy: 58.8%\n",
            "Step: 3115 ------------ Loss: 8341.57 ------------ Accuracy: 58.9%\n",
            "Step: 3116 ------------ Loss: 8341.38 ------------ Accuracy: 58.8%\n",
            "Step: 3117 ------------ Loss: 8341.2 ------------ Accuracy: 58.8%\n",
            "Step: 3118 ------------ Loss: 8341.02 ------------ Accuracy: 58.8%\n",
            "Step: 3119 ------------ Loss: 8340.83 ------------ Accuracy: 58.8%\n",
            "Step: 3120 ------------ Loss: 8340.66 ------------ Accuracy: 58.9%\n",
            "Step: 3121 ------------ Loss: 8340.48 ------------ Accuracy: 58.9%\n",
            "Step: 3122 ------------ Loss: 8340.3 ------------ Accuracy: 58.9%\n",
            "Step: 3123 ------------ Loss: 8340.12 ------------ Accuracy: 58.9%\n",
            "Step: 3124 ------------ Loss: 8339.94 ------------ Accuracy: 58.8%\n",
            "Step: 3125 ------------ Loss: 8339.77 ------------ Accuracy: 58.9%\n",
            "Step: 3126 ------------ Loss: 8339.59 ------------ Accuracy: 59.0%\n",
            "Step: 3127 ------------ Loss: 8339.41 ------------ Accuracy: 59.0%\n",
            "Step: 3128 ------------ Loss: 8339.23 ------------ Accuracy: 59.0%\n",
            "Step: 3129 ------------ Loss: 8339.05 ------------ Accuracy: 59.0%\n",
            "Step: 3130 ------------ Loss: 8338.88 ------------ Accuracy: 59.0%\n",
            "Step: 3131 ------------ Loss: 8338.7 ------------ Accuracy: 59.0%\n",
            "Step: 3132 ------------ Loss: 8338.52 ------------ Accuracy: 59.0%\n",
            "Step: 3133 ------------ Loss: 8338.34 ------------ Accuracy: 59.0%\n",
            "Step: 3134 ------------ Loss: 8338.16 ------------ Accuracy: 59.0%\n",
            "Step: 3135 ------------ Loss: 8337.99 ------------ Accuracy: 59.0%\n",
            "Step: 3136 ------------ Loss: 8337.81 ------------ Accuracy: 59.0%\n",
            "Step: 3137 ------------ Loss: 8337.63 ------------ Accuracy: 59.0%\n",
            "Step: 3138 ------------ Loss: 8337.46 ------------ Accuracy: 59.0%\n",
            "Step: 3139 ------------ Loss: 8337.27 ------------ Accuracy: 58.9%\n",
            "Step: 3140 ------------ Loss: 8337.09 ------------ Accuracy: 58.9%\n",
            "Step: 3141 ------------ Loss: 8336.91 ------------ Accuracy: 59.0%\n",
            "Step: 3142 ------------ Loss: 8336.73 ------------ Accuracy: 59.0%\n",
            "Step: 3143 ------------ Loss: 8336.56 ------------ Accuracy: 59.0%\n",
            "Step: 3144 ------------ Loss: 8336.38 ------------ Accuracy: 59.0%\n",
            "Step: 3145 ------------ Loss: 8336.2 ------------ Accuracy: 59.0%\n",
            "Step: 3146 ------------ Loss: 8336.03 ------------ Accuracy: 59.0%\n",
            "Step: 3147 ------------ Loss: 8335.85 ------------ Accuracy: 59.0%\n",
            "Step: 3148 ------------ Loss: 8335.67 ------------ Accuracy: 59.0%\n",
            "Step: 3149 ------------ Loss: 8335.49 ------------ Accuracy: 59.0%\n",
            "Step: 3150 ------------ Loss: 8335.33 ------------ Accuracy: 59.0%\n",
            "Step: 3151 ------------ Loss: 8335.15 ------------ Accuracy: 59.0%\n",
            "Step: 3152 ------------ Loss: 8334.97 ------------ Accuracy: 58.9%\n",
            "Step: 3153 ------------ Loss: 8334.8 ------------ Accuracy: 58.9%\n",
            "Step: 3154 ------------ Loss: 8334.62 ------------ Accuracy: 58.9%\n",
            "Step: 3155 ------------ Loss: 8334.44 ------------ Accuracy: 59.0%\n",
            "Step: 3156 ------------ Loss: 8334.26 ------------ Accuracy: 59.0%\n",
            "Step: 3157 ------------ Loss: 8334.09 ------------ Accuracy: 59.0%\n",
            "Step: 3158 ------------ Loss: 8333.91 ------------ Accuracy: 59.0%\n",
            "Step: 3159 ------------ Loss: 8333.73 ------------ Accuracy: 59.0%\n",
            "Step: 3160 ------------ Loss: 8333.56 ------------ Accuracy: 59.0%\n",
            "Step: 3161 ------------ Loss: 8333.38 ------------ Accuracy: 59.0%\n",
            "Step: 3162 ------------ Loss: 8333.2 ------------ Accuracy: 59.0%\n",
            "Step: 3163 ------------ Loss: 8333.03 ------------ Accuracy: 59.0%\n",
            "Step: 3164 ------------ Loss: 8332.85 ------------ Accuracy: 59.0%\n",
            "Step: 3165 ------------ Loss: 8332.68 ------------ Accuracy: 59.0%\n",
            "Step: 3166 ------------ Loss: 8332.51 ------------ Accuracy: 59.0%\n",
            "Step: 3167 ------------ Loss: 8332.33 ------------ Accuracy: 59.0%\n",
            "Step: 3168 ------------ Loss: 8332.15 ------------ Accuracy: 59.0%\n",
            "Step: 3169 ------------ Loss: 8331.98 ------------ Accuracy: 59.0%\n",
            "Step: 3170 ------------ Loss: 8331.8 ------------ Accuracy: 59.0%\n",
            "Step: 3171 ------------ Loss: 8331.62 ------------ Accuracy: 59.0%\n",
            "Step: 3172 ------------ Loss: 8331.45 ------------ Accuracy: 59.0%\n",
            "Step: 3173 ------------ Loss: 8331.28 ------------ Accuracy: 59.0%\n",
            "Step: 3174 ------------ Loss: 8331.1 ------------ Accuracy: 59.0%\n",
            "Step: 3175 ------------ Loss: 8330.92 ------------ Accuracy: 59.0%\n",
            "Step: 3176 ------------ Loss: 8330.74 ------------ Accuracy: 59.0%\n",
            "Step: 3177 ------------ Loss: 8330.56 ------------ Accuracy: 59.0%\n",
            "Step: 3178 ------------ Loss: 8330.4 ------------ Accuracy: 59.0%\n",
            "Step: 3179 ------------ Loss: 8330.22 ------------ Accuracy: 59.0%\n",
            "Step: 3180 ------------ Loss: 8330.04 ------------ Accuracy: 59.0%\n",
            "Step: 3181 ------------ Loss: 8329.87 ------------ Accuracy: 59.0%\n",
            "Step: 3182 ------------ Loss: 8329.69 ------------ Accuracy: 59.0%\n",
            "Step: 3183 ------------ Loss: 8329.52 ------------ Accuracy: 59.0%\n",
            "Step: 3184 ------------ Loss: 8329.34 ------------ Accuracy: 59.0%\n",
            "Step: 3185 ------------ Loss: 8329.17 ------------ Accuracy: 59.0%\n",
            "Step: 3186 ------------ Loss: 8329.0 ------------ Accuracy: 59.0%\n",
            "Step: 3187 ------------ Loss: 8328.82 ------------ Accuracy: 59.0%\n",
            "Step: 3188 ------------ Loss: 8328.65 ------------ Accuracy: 59.0%\n",
            "Step: 3189 ------------ Loss: 8328.47 ------------ Accuracy: 59.0%\n",
            "Step: 3190 ------------ Loss: 8328.3 ------------ Accuracy: 59.0%\n",
            "Step: 3191 ------------ Loss: 8328.12 ------------ Accuracy: 59.0%\n",
            "Step: 3192 ------------ Loss: 8327.95 ------------ Accuracy: 59.0%\n",
            "Step: 3193 ------------ Loss: 8327.78 ------------ Accuracy: 59.0%\n",
            "Step: 3194 ------------ Loss: 8327.6 ------------ Accuracy: 59.0%\n",
            "Step: 3195 ------------ Loss: 8327.43 ------------ Accuracy: 59.0%\n",
            "Step: 3196 ------------ Loss: 8327.25 ------------ Accuracy: 59.0%\n",
            "Step: 3197 ------------ Loss: 8327.08 ------------ Accuracy: 59.0%\n",
            "Step: 3198 ------------ Loss: 8326.9 ------------ Accuracy: 59.0%\n",
            "Step: 3199 ------------ Loss: 8326.74 ------------ Accuracy: 58.9%\n",
            "Step: 3200 ------------ Loss: 8326.56 ------------ Accuracy: 58.9%\n",
            "Step: 3201 ------------ Loss: 8326.39 ------------ Accuracy: 59.0%\n",
            "Step: 3202 ------------ Loss: 8326.22 ------------ Accuracy: 59.0%\n",
            "Step: 3203 ------------ Loss: 8326.04 ------------ Accuracy: 59.0%\n",
            "Step: 3204 ------------ Loss: 8325.86 ------------ Accuracy: 59.0%\n",
            "Step: 3205 ------------ Loss: 8325.69 ------------ Accuracy: 59.0%\n",
            "Step: 3206 ------------ Loss: 8325.51 ------------ Accuracy: 59.0%\n",
            "Step: 3207 ------------ Loss: 8325.34 ------------ Accuracy: 59.0%\n",
            "Step: 3208 ------------ Loss: 8325.16 ------------ Accuracy: 59.0%\n",
            "Step: 3209 ------------ Loss: 8324.99 ------------ Accuracy: 59.0%\n",
            "Step: 3210 ------------ Loss: 8324.81 ------------ Accuracy: 59.0%\n",
            "Step: 3211 ------------ Loss: 8324.64 ------------ Accuracy: 59.0%\n",
            "Step: 3212 ------------ Loss: 8324.47 ------------ Accuracy: 59.0%\n",
            "Step: 3213 ------------ Loss: 8324.3 ------------ Accuracy: 59.0%\n",
            "Step: 3214 ------------ Loss: 8324.12 ------------ Accuracy: 59.0%\n",
            "Step: 3215 ------------ Loss: 8323.94 ------------ Accuracy: 59.0%\n",
            "Step: 3216 ------------ Loss: 8323.76 ------------ Accuracy: 59.0%\n",
            "Step: 3217 ------------ Loss: 8323.59 ------------ Accuracy: 59.0%\n",
            "Step: 3218 ------------ Loss: 8323.42 ------------ Accuracy: 59.0%\n",
            "Step: 3219 ------------ Loss: 8323.24 ------------ Accuracy: 59.0%\n",
            "Step: 3220 ------------ Loss: 8323.07 ------------ Accuracy: 59.0%\n",
            "Step: 3221 ------------ Loss: 8322.89 ------------ Accuracy: 59.0%\n",
            "Step: 3222 ------------ Loss: 8322.72 ------------ Accuracy: 59.0%\n",
            "Step: 3223 ------------ Loss: 8322.55 ------------ Accuracy: 59.0%\n",
            "Step: 3224 ------------ Loss: 8322.37 ------------ Accuracy: 59.0%\n",
            "Step: 3225 ------------ Loss: 8322.2 ------------ Accuracy: 59.0%\n",
            "Step: 3226 ------------ Loss: 8322.03 ------------ Accuracy: 59.0%\n",
            "Step: 3227 ------------ Loss: 8321.87 ------------ Accuracy: 59.0%\n",
            "Step: 3228 ------------ Loss: 8321.69 ------------ Accuracy: 59.0%\n",
            "Step: 3229 ------------ Loss: 8321.52 ------------ Accuracy: 59.0%\n",
            "Step: 3230 ------------ Loss: 8321.34 ------------ Accuracy: 59.0%\n",
            "Step: 3231 ------------ Loss: 8321.17 ------------ Accuracy: 59.0%\n",
            "Step: 3232 ------------ Loss: 8321.0 ------------ Accuracy: 59.0%\n",
            "Step: 3233 ------------ Loss: 8320.83 ------------ Accuracy: 58.9%\n",
            "Step: 3234 ------------ Loss: 8320.66 ------------ Accuracy: 59.0%\n",
            "Step: 3235 ------------ Loss: 8320.48 ------------ Accuracy: 59.0%\n",
            "Step: 3236 ------------ Loss: 8320.3 ------------ Accuracy: 59.0%\n",
            "Step: 3237 ------------ Loss: 8320.13 ------------ Accuracy: 59.0%\n",
            "Step: 3238 ------------ Loss: 8319.96 ------------ Accuracy: 59.0%\n",
            "Step: 3239 ------------ Loss: 8319.78 ------------ Accuracy: 59.0%\n",
            "Step: 3240 ------------ Loss: 8319.61 ------------ Accuracy: 59.0%\n",
            "Step: 3241 ------------ Loss: 8319.44 ------------ Accuracy: 59.0%\n",
            "Step: 3242 ------------ Loss: 8319.27 ------------ Accuracy: 59.0%\n",
            "Step: 3243 ------------ Loss: 8319.1 ------------ Accuracy: 59.0%\n",
            "Step: 3244 ------------ Loss: 8318.92 ------------ Accuracy: 59.0%\n",
            "Step: 3245 ------------ Loss: 8318.75 ------------ Accuracy: 59.0%\n",
            "Step: 3246 ------------ Loss: 8318.58 ------------ Accuracy: 59.0%\n",
            "Step: 3247 ------------ Loss: 8318.41 ------------ Accuracy: 59.0%\n",
            "Step: 3248 ------------ Loss: 8318.24 ------------ Accuracy: 59.0%\n",
            "Step: 3249 ------------ Loss: 8318.06 ------------ Accuracy: 59.0%\n",
            "Step: 3250 ------------ Loss: 8317.89 ------------ Accuracy: 59.0%\n",
            "Step: 3251 ------------ Loss: 8317.73 ------------ Accuracy: 59.1%\n",
            "Step: 3252 ------------ Loss: 8317.56 ------------ Accuracy: 59.0%\n",
            "Step: 3253 ------------ Loss: 8317.39 ------------ Accuracy: 59.0%\n",
            "Step: 3254 ------------ Loss: 8317.21 ------------ Accuracy: 58.9%\n",
            "Step: 3255 ------------ Loss: 8317.05 ------------ Accuracy: 59.1%\n",
            "Step: 3256 ------------ Loss: 8316.87 ------------ Accuracy: 59.1%\n",
            "Step: 3257 ------------ Loss: 8316.69 ------------ Accuracy: 59.0%\n",
            "Step: 3258 ------------ Loss: 8316.52 ------------ Accuracy: 59.0%\n",
            "Step: 3259 ------------ Loss: 8316.35 ------------ Accuracy: 59.0%\n",
            "Step: 3260 ------------ Loss: 8316.18 ------------ Accuracy: 59.0%\n",
            "Step: 3261 ------------ Loss: 8316.01 ------------ Accuracy: 59.0%\n",
            "Step: 3262 ------------ Loss: 8315.83 ------------ Accuracy: 59.0%\n",
            "Step: 3263 ------------ Loss: 8315.66 ------------ Accuracy: 59.0%\n",
            "Step: 3264 ------------ Loss: 8315.5 ------------ Accuracy: 59.0%\n",
            "Step: 3265 ------------ Loss: 8315.33 ------------ Accuracy: 58.9%\n",
            "Step: 3266 ------------ Loss: 8315.16 ------------ Accuracy: 59.0%\n",
            "Step: 3267 ------------ Loss: 8314.99 ------------ Accuracy: 58.9%\n",
            "Step: 3268 ------------ Loss: 8314.81 ------------ Accuracy: 59.0%\n",
            "Step: 3269 ------------ Loss: 8314.64 ------------ Accuracy: 59.0%\n",
            "Step: 3270 ------------ Loss: 8314.47 ------------ Accuracy: 59.0%\n",
            "Step: 3271 ------------ Loss: 8314.3 ------------ Accuracy: 59.0%\n",
            "Step: 3272 ------------ Loss: 8314.13 ------------ Accuracy: 59.1%\n",
            "Step: 3273 ------------ Loss: 8313.97 ------------ Accuracy: 59.1%\n",
            "Step: 3274 ------------ Loss: 8313.79 ------------ Accuracy: 59.1%\n",
            "Step: 3275 ------------ Loss: 8313.62 ------------ Accuracy: 59.1%\n",
            "Step: 3276 ------------ Loss: 8313.44 ------------ Accuracy: 59.0%\n",
            "Step: 3277 ------------ Loss: 8313.27 ------------ Accuracy: 59.0%\n",
            "Step: 3278 ------------ Loss: 8313.1 ------------ Accuracy: 59.0%\n",
            "Step: 3279 ------------ Loss: 8312.93 ------------ Accuracy: 59.0%\n",
            "Step: 3280 ------------ Loss: 8312.76 ------------ Accuracy: 59.0%\n",
            "Step: 3281 ------------ Loss: 8312.59 ------------ Accuracy: 59.0%\n",
            "Step: 3282 ------------ Loss: 8312.42 ------------ Accuracy: 59.0%\n",
            "Step: 3283 ------------ Loss: 8312.25 ------------ Accuracy: 59.0%\n",
            "Step: 3284 ------------ Loss: 8312.09 ------------ Accuracy: 59.0%\n",
            "Step: 3285 ------------ Loss: 8311.92 ------------ Accuracy: 59.0%\n",
            "Step: 3286 ------------ Loss: 8311.75 ------------ Accuracy: 59.0%\n",
            "Step: 3287 ------------ Loss: 8311.58 ------------ Accuracy: 59.0%\n",
            "Step: 3288 ------------ Loss: 8311.42 ------------ Accuracy: 59.1%\n",
            "Step: 3289 ------------ Loss: 8311.24 ------------ Accuracy: 59.1%\n",
            "Step: 3290 ------------ Loss: 8311.07 ------------ Accuracy: 59.1%\n",
            "Step: 3291 ------------ Loss: 8310.9 ------------ Accuracy: 59.1%\n",
            "Step: 3292 ------------ Loss: 8310.73 ------------ Accuracy: 59.1%\n",
            "Step: 3293 ------------ Loss: 8310.56 ------------ Accuracy: 59.1%\n",
            "Step: 3294 ------------ Loss: 8310.39 ------------ Accuracy: 59.0%\n",
            "Step: 3295 ------------ Loss: 8310.22 ------------ Accuracy: 59.0%\n",
            "Step: 3296 ------------ Loss: 8310.05 ------------ Accuracy: 59.0%\n",
            "Step: 3297 ------------ Loss: 8309.88 ------------ Accuracy: 59.0%\n",
            "Step: 3298 ------------ Loss: 8309.71 ------------ Accuracy: 59.0%\n",
            "Step: 3299 ------------ Loss: 8309.54 ------------ Accuracy: 59.0%\n",
            "Step: 3300 ------------ Loss: 8309.37 ------------ Accuracy: 59.0%\n",
            "Step: 3301 ------------ Loss: 8309.21 ------------ Accuracy: 59.0%\n",
            "Step: 3302 ------------ Loss: 8309.04 ------------ Accuracy: 59.0%\n",
            "Step: 3303 ------------ Loss: 8308.87 ------------ Accuracy: 59.0%\n",
            "Step: 3304 ------------ Loss: 8308.7 ------------ Accuracy: 59.0%\n",
            "Step: 3305 ------------ Loss: 8308.53 ------------ Accuracy: 59.0%\n",
            "Step: 3306 ------------ Loss: 8308.36 ------------ Accuracy: 59.0%\n",
            "Step: 3307 ------------ Loss: 8308.19 ------------ Accuracy: 59.0%\n",
            "Step: 3308 ------------ Loss: 8308.03 ------------ Accuracy: 59.0%\n",
            "Step: 3309 ------------ Loss: 8307.86 ------------ Accuracy: 59.0%\n",
            "Step: 3310 ------------ Loss: 8307.69 ------------ Accuracy: 59.0%\n",
            "Step: 3311 ------------ Loss: 8307.52 ------------ Accuracy: 59.0%\n",
            "Step: 3312 ------------ Loss: 8307.36 ------------ Accuracy: 59.0%\n",
            "Step: 3313 ------------ Loss: 8307.19 ------------ Accuracy: 59.0%\n",
            "Step: 3314 ------------ Loss: 8307.02 ------------ Accuracy: 59.0%\n",
            "Step: 3315 ------------ Loss: 8306.86 ------------ Accuracy: 59.0%\n",
            "Step: 3316 ------------ Loss: 8306.69 ------------ Accuracy: 59.0%\n",
            "Step: 3317 ------------ Loss: 8306.52 ------------ Accuracy: 59.0%\n",
            "Step: 3318 ------------ Loss: 8306.35 ------------ Accuracy: 59.1%\n",
            "Step: 3319 ------------ Loss: 8306.18 ------------ Accuracy: 59.0%\n",
            "Step: 3320 ------------ Loss: 8306.01 ------------ Accuracy: 59.0%\n",
            "Step: 3321 ------------ Loss: 8305.85 ------------ Accuracy: 59.1%\n",
            "Step: 3322 ------------ Loss: 8305.68 ------------ Accuracy: 59.0%\n",
            "Step: 3323 ------------ Loss: 8305.51 ------------ Accuracy: 59.0%\n",
            "Step: 3324 ------------ Loss: 8305.34 ------------ Accuracy: 59.0%\n",
            "Step: 3325 ------------ Loss: 8305.17 ------------ Accuracy: 59.0%\n",
            "Step: 3326 ------------ Loss: 8305.01 ------------ Accuracy: 59.0%\n",
            "Step: 3327 ------------ Loss: 8304.84 ------------ Accuracy: 59.0%\n",
            "Step: 3328 ------------ Loss: 8304.67 ------------ Accuracy: 59.0%\n",
            "Step: 3329 ------------ Loss: 8304.5 ------------ Accuracy: 59.0%\n",
            "Step: 3330 ------------ Loss: 8304.33 ------------ Accuracy: 59.0%\n",
            "Step: 3331 ------------ Loss: 8304.17 ------------ Accuracy: 59.0%\n",
            "Step: 3332 ------------ Loss: 8304.01 ------------ Accuracy: 59.1%\n",
            "Step: 3333 ------------ Loss: 8303.84 ------------ Accuracy: 59.0%\n",
            "Step: 3334 ------------ Loss: 8303.67 ------------ Accuracy: 59.0%\n",
            "Step: 3335 ------------ Loss: 8303.5 ------------ Accuracy: 59.0%\n",
            "Step: 3336 ------------ Loss: 8303.34 ------------ Accuracy: 59.1%\n",
            "Step: 3337 ------------ Loss: 8303.17 ------------ Accuracy: 59.1%\n",
            "Step: 3338 ------------ Loss: 8303.0 ------------ Accuracy: 59.0%\n",
            "Step: 3339 ------------ Loss: 8302.83 ------------ Accuracy: 59.1%\n",
            "Step: 3340 ------------ Loss: 8302.67 ------------ Accuracy: 59.1%\n",
            "Step: 3341 ------------ Loss: 8302.51 ------------ Accuracy: 59.1%\n",
            "Step: 3342 ------------ Loss: 8302.33 ------------ Accuracy: 59.1%\n",
            "Step: 3343 ------------ Loss: 8302.16 ------------ Accuracy: 59.1%\n",
            "Step: 3344 ------------ Loss: 8301.99 ------------ Accuracy: 59.1%\n",
            "Step: 3345 ------------ Loss: 8301.82 ------------ Accuracy: 59.1%\n",
            "Step: 3346 ------------ Loss: 8301.66 ------------ Accuracy: 59.1%\n",
            "Step: 3347 ------------ Loss: 8301.49 ------------ Accuracy: 59.1%\n",
            "Step: 3348 ------------ Loss: 8301.32 ------------ Accuracy: 59.1%\n",
            "Step: 3349 ------------ Loss: 8301.16 ------------ Accuracy: 59.0%\n",
            "Step: 3350 ------------ Loss: 8300.99 ------------ Accuracy: 59.0%\n",
            "Step: 3351 ------------ Loss: 8300.82 ------------ Accuracy: 59.0%\n",
            "Step: 3352 ------------ Loss: 8300.66 ------------ Accuracy: 59.1%\n",
            "Step: 3353 ------------ Loss: 8300.49 ------------ Accuracy: 59.1%\n",
            "Step: 3354 ------------ Loss: 8300.32 ------------ Accuracy: 59.1%\n",
            "Step: 3355 ------------ Loss: 8300.16 ------------ Accuracy: 59.1%\n",
            "Step: 3356 ------------ Loss: 8300.0 ------------ Accuracy: 59.1%\n",
            "Step: 3357 ------------ Loss: 8299.82 ------------ Accuracy: 59.1%\n",
            "Step: 3358 ------------ Loss: 8299.66 ------------ Accuracy: 59.1%\n",
            "Step: 3359 ------------ Loss: 8299.49 ------------ Accuracy: 59.1%\n",
            "Step: 3360 ------------ Loss: 8299.32 ------------ Accuracy: 59.1%\n",
            "Step: 3361 ------------ Loss: 8299.15 ------------ Accuracy: 59.1%\n",
            "Step: 3362 ------------ Loss: 8298.99 ------------ Accuracy: 59.1%\n",
            "Step: 3363 ------------ Loss: 8298.82 ------------ Accuracy: 59.1%\n",
            "Step: 3364 ------------ Loss: 8298.65 ------------ Accuracy: 59.1%\n",
            "Step: 3365 ------------ Loss: 8298.49 ------------ Accuracy: 59.1%\n",
            "Step: 3366 ------------ Loss: 8298.32 ------------ Accuracy: 59.1%\n",
            "Step: 3367 ------------ Loss: 8298.16 ------------ Accuracy: 59.1%\n",
            "Step: 3368 ------------ Loss: 8297.99 ------------ Accuracy: 59.1%\n",
            "Step: 3369 ------------ Loss: 8297.83 ------------ Accuracy: 59.1%\n",
            "Step: 3370 ------------ Loss: 8297.67 ------------ Accuracy: 59.1%\n",
            "Step: 3371 ------------ Loss: 8297.49 ------------ Accuracy: 59.1%\n",
            "Step: 3372 ------------ Loss: 8297.33 ------------ Accuracy: 59.1%\n",
            "Step: 3373 ------------ Loss: 8297.16 ------------ Accuracy: 59.1%\n",
            "Step: 3374 ------------ Loss: 8296.99 ------------ Accuracy: 59.1%\n",
            "Step: 3375 ------------ Loss: 8296.83 ------------ Accuracy: 59.1%\n",
            "Step: 3376 ------------ Loss: 8296.66 ------------ Accuracy: 59.1%\n",
            "Step: 3377 ------------ Loss: 8296.5 ------------ Accuracy: 59.1%\n",
            "Step: 3378 ------------ Loss: 8296.33 ------------ Accuracy: 59.1%\n",
            "Step: 3379 ------------ Loss: 8296.17 ------------ Accuracy: 59.1%\n",
            "Step: 3380 ------------ Loss: 8296.0 ------------ Accuracy: 59.1%\n",
            "Step: 3381 ------------ Loss: 8295.83 ------------ Accuracy: 59.1%\n",
            "Step: 3382 ------------ Loss: 8295.67 ------------ Accuracy: 59.1%\n",
            "Step: 3383 ------------ Loss: 8295.5 ------------ Accuracy: 59.1%\n",
            "Step: 3384 ------------ Loss: 8295.34 ------------ Accuracy: 59.1%\n",
            "Step: 3385 ------------ Loss: 8295.18 ------------ Accuracy: 59.1%\n",
            "Step: 3386 ------------ Loss: 8295.01 ------------ Accuracy: 59.1%\n",
            "Step: 3387 ------------ Loss: 8294.85 ------------ Accuracy: 59.1%\n",
            "Step: 3388 ------------ Loss: 8294.68 ------------ Accuracy: 59.1%\n",
            "Step: 3389 ------------ Loss: 8294.52 ------------ Accuracy: 59.1%\n",
            "Step: 3390 ------------ Loss: 8294.35 ------------ Accuracy: 59.1%\n",
            "Step: 3391 ------------ Loss: 8294.19 ------------ Accuracy: 59.1%\n",
            "Step: 3392 ------------ Loss: 8294.03 ------------ Accuracy: 59.1%\n",
            "Step: 3393 ------------ Loss: 8293.86 ------------ Accuracy: 59.1%\n",
            "Step: 3394 ------------ Loss: 8293.69 ------------ Accuracy: 59.1%\n",
            "Step: 3395 ------------ Loss: 8293.52 ------------ Accuracy: 59.1%\n",
            "Step: 3396 ------------ Loss: 8293.36 ------------ Accuracy: 59.1%\n",
            "Step: 3397 ------------ Loss: 8293.19 ------------ Accuracy: 59.1%\n",
            "Step: 3398 ------------ Loss: 8293.03 ------------ Accuracy: 59.1%\n",
            "Step: 3399 ------------ Loss: 8292.86 ------------ Accuracy: 59.1%\n",
            "Step: 3400 ------------ Loss: 8292.7 ------------ Accuracy: 59.1%\n",
            "Step: 3401 ------------ Loss: 8292.53 ------------ Accuracy: 59.1%\n",
            "Step: 3402 ------------ Loss: 8292.37 ------------ Accuracy: 59.1%\n",
            "Step: 3403 ------------ Loss: 8292.21 ------------ Accuracy: 59.1%\n",
            "Step: 3404 ------------ Loss: 8292.04 ------------ Accuracy: 59.1%\n",
            "Step: 3405 ------------ Loss: 8291.88 ------------ Accuracy: 59.1%\n",
            "Step: 3406 ------------ Loss: 8291.71 ------------ Accuracy: 59.1%\n",
            "Step: 3407 ------------ Loss: 8291.55 ------------ Accuracy: 59.1%\n",
            "Step: 3408 ------------ Loss: 8291.38 ------------ Accuracy: 59.1%\n",
            "Step: 3409 ------------ Loss: 8291.22 ------------ Accuracy: 59.1%\n",
            "Step: 3410 ------------ Loss: 8291.05 ------------ Accuracy: 59.1%\n",
            "Step: 3411 ------------ Loss: 8290.89 ------------ Accuracy: 59.1%\n",
            "Step: 3412 ------------ Loss: 8290.72 ------------ Accuracy: 59.1%\n",
            "Step: 3413 ------------ Loss: 8290.56 ------------ Accuracy: 59.1%\n",
            "Step: 3414 ------------ Loss: 8290.39 ------------ Accuracy: 59.1%\n",
            "Step: 3415 ------------ Loss: 8290.23 ------------ Accuracy: 59.1%\n",
            "Step: 3416 ------------ Loss: 8290.07 ------------ Accuracy: 59.1%\n",
            "Step: 3417 ------------ Loss: 8289.9 ------------ Accuracy: 59.1%\n",
            "Step: 3418 ------------ Loss: 8289.74 ------------ Accuracy: 59.1%\n",
            "Step: 3419 ------------ Loss: 8289.57 ------------ Accuracy: 59.1%\n",
            "Step: 3420 ------------ Loss: 8289.41 ------------ Accuracy: 59.1%\n",
            "Step: 3421 ------------ Loss: 8289.24 ------------ Accuracy: 59.1%\n",
            "Step: 3422 ------------ Loss: 8289.09 ------------ Accuracy: 59.6%\n",
            "Step: 3423 ------------ Loss: 8288.92 ------------ Accuracy: 59.1%\n",
            "Step: 3424 ------------ Loss: 8288.75 ------------ Accuracy: 59.1%\n",
            "Step: 3425 ------------ Loss: 8288.59 ------------ Accuracy: 59.1%\n",
            "Step: 3426 ------------ Loss: 8288.43 ------------ Accuracy: 59.1%\n",
            "Step: 3427 ------------ Loss: 8288.26 ------------ Accuracy: 59.1%\n",
            "Step: 3428 ------------ Loss: 8288.1 ------------ Accuracy: 59.1%\n",
            "Step: 3429 ------------ Loss: 8287.93 ------------ Accuracy: 59.1%\n",
            "Step: 3430 ------------ Loss: 8287.77 ------------ Accuracy: 59.1%\n",
            "Step: 3431 ------------ Loss: 8287.6 ------------ Accuracy: 59.1%\n",
            "Step: 3432 ------------ Loss: 8287.44 ------------ Accuracy: 59.1%\n",
            "Step: 3433 ------------ Loss: 8287.27 ------------ Accuracy: 59.1%\n",
            "Step: 3434 ------------ Loss: 8287.11 ------------ Accuracy: 59.1%\n",
            "Step: 3435 ------------ Loss: 8286.95 ------------ Accuracy: 59.1%\n",
            "Step: 3436 ------------ Loss: 8286.78 ------------ Accuracy: 59.1%\n",
            "Step: 3437 ------------ Loss: 8286.63 ------------ Accuracy: 59.6%\n",
            "Step: 3438 ------------ Loss: 8286.46 ------------ Accuracy: 59.1%\n",
            "Step: 3439 ------------ Loss: 8286.3 ------------ Accuracy: 59.1%\n",
            "Step: 3440 ------------ Loss: 8286.13 ------------ Accuracy: 59.1%\n",
            "Step: 3441 ------------ Loss: 8285.97 ------------ Accuracy: 59.1%\n",
            "Step: 3442 ------------ Loss: 8285.8 ------------ Accuracy: 59.1%\n",
            "Step: 3443 ------------ Loss: 8285.64 ------------ Accuracy: 59.6%\n",
            "Step: 3444 ------------ Loss: 8285.48 ------------ Accuracy: 59.6%\n",
            "Step: 3445 ------------ Loss: 8285.31 ------------ Accuracy: 59.1%\n",
            "Step: 3446 ------------ Loss: 8285.15 ------------ Accuracy: 59.1%\n",
            "Step: 3447 ------------ Loss: 8284.98 ------------ Accuracy: 59.1%\n",
            "Step: 3448 ------------ Loss: 8284.82 ------------ Accuracy: 59.1%\n",
            "Step: 3449 ------------ Loss: 8284.65 ------------ Accuracy: 59.6%\n",
            "Step: 3450 ------------ Loss: 8284.49 ------------ Accuracy: 59.1%\n",
            "Step: 3451 ------------ Loss: 8284.33 ------------ Accuracy: 59.1%\n",
            "Step: 3452 ------------ Loss: 8284.16 ------------ Accuracy: 59.1%\n",
            "Step: 3453 ------------ Loss: 8284.0 ------------ Accuracy: 59.1%\n",
            "Step: 3454 ------------ Loss: 8283.83 ------------ Accuracy: 59.1%\n",
            "Step: 3455 ------------ Loss: 8283.67 ------------ Accuracy: 59.1%\n",
            "Step: 3456 ------------ Loss: 8283.52 ------------ Accuracy: 59.7%\n",
            "Step: 3457 ------------ Loss: 8283.35 ------------ Accuracy: 59.3%\n",
            "Step: 3458 ------------ Loss: 8283.18 ------------ Accuracy: 59.1%\n",
            "Step: 3459 ------------ Loss: 8283.02 ------------ Accuracy: 59.3%\n",
            "Step: 3460 ------------ Loss: 8282.86 ------------ Accuracy: 59.7%\n",
            "Step: 3461 ------------ Loss: 8282.69 ------------ Accuracy: 59.7%\n",
            "Step: 3462 ------------ Loss: 8282.53 ------------ Accuracy: 59.7%\n",
            "Step: 3463 ------------ Loss: 8282.36 ------------ Accuracy: 59.7%\n",
            "Step: 3464 ------------ Loss: 8282.2 ------------ Accuracy: 59.8%\n",
            "Step: 3465 ------------ Loss: 8282.04 ------------ Accuracy: 59.8%\n",
            "Step: 3466 ------------ Loss: 8281.87 ------------ Accuracy: 59.8%\n",
            "Step: 3467 ------------ Loss: 8281.71 ------------ Accuracy: 59.8%\n",
            "Step: 3468 ------------ Loss: 8281.54 ------------ Accuracy: 59.8%\n",
            "Step: 3469 ------------ Loss: 8281.38 ------------ Accuracy: 59.8%\n",
            "Step: 3470 ------------ Loss: 8281.22 ------------ Accuracy: 59.8%\n",
            "Step: 3471 ------------ Loss: 8281.05 ------------ Accuracy: 59.8%\n",
            "Step: 3472 ------------ Loss: 8280.89 ------------ Accuracy: 59.8%\n",
            "Step: 3473 ------------ Loss: 8280.72 ------------ Accuracy: 59.9%\n",
            "Step: 3474 ------------ Loss: 8280.57 ------------ Accuracy: 59.8%\n",
            "Step: 3475 ------------ Loss: 8280.4 ------------ Accuracy: 59.7%\n",
            "Step: 3476 ------------ Loss: 8280.23 ------------ Accuracy: 59.7%\n",
            "Step: 3477 ------------ Loss: 8280.07 ------------ Accuracy: 59.7%\n",
            "Step: 3478 ------------ Loss: 8279.9 ------------ Accuracy: 59.7%\n",
            "Step: 3479 ------------ Loss: 8279.74 ------------ Accuracy: 59.7%\n",
            "Step: 3480 ------------ Loss: 8279.57 ------------ Accuracy: 59.7%\n",
            "Step: 3481 ------------ Loss: 8279.41 ------------ Accuracy: 59.7%\n",
            "Step: 3482 ------------ Loss: 8279.26 ------------ Accuracy: 59.7%\n",
            "Step: 3483 ------------ Loss: 8279.09 ------------ Accuracy: 59.8%\n",
            "Step: 3484 ------------ Loss: 8278.93 ------------ Accuracy: 59.8%\n",
            "Step: 3485 ------------ Loss: 8278.76 ------------ Accuracy: 59.8%\n",
            "Step: 3486 ------------ Loss: 8278.6 ------------ Accuracy: 59.2%\n",
            "Step: 3487 ------------ Loss: 8278.43 ------------ Accuracy: 59.8%\n",
            "Step: 3488 ------------ Loss: 8278.27 ------------ Accuracy: 59.8%\n",
            "Step: 3489 ------------ Loss: 8278.11 ------------ Accuracy: 59.9%\n",
            "Step: 3490 ------------ Loss: 8277.95 ------------ Accuracy: 59.8%\n",
            "Step: 3491 ------------ Loss: 8277.79 ------------ Accuracy: 59.3%\n",
            "Step: 3492 ------------ Loss: 8277.63 ------------ Accuracy: 59.9%\n",
            "Step: 3493 ------------ Loss: 8277.46 ------------ Accuracy: 59.9%\n",
            "Step: 3494 ------------ Loss: 8277.3 ------------ Accuracy: 59.9%\n",
            "Step: 3495 ------------ Loss: 8277.13 ------------ Accuracy: 59.9%\n",
            "Step: 3496 ------------ Loss: 8276.97 ------------ Accuracy: 59.9%\n",
            "Step: 3497 ------------ Loss: 8276.81 ------------ Accuracy: 59.9%\n",
            "Step: 3498 ------------ Loss: 8276.64 ------------ Accuracy: 59.9%\n",
            "Step: 3499 ------------ Loss: 8276.48 ------------ Accuracy: 59.9%\n",
            "Step: 3500 ------------ Loss: 8276.32 ------------ Accuracy: 59.9%\n",
            "Step: 3501 ------------ Loss: 8276.15 ------------ Accuracy: 59.9%\n",
            "Step: 3502 ------------ Loss: 8275.99 ------------ Accuracy: 59.9%\n",
            "Step: 3503 ------------ Loss: 8275.82 ------------ Accuracy: 59.9%\n",
            "Step: 3504 ------------ Loss: 8275.66 ------------ Accuracy: 59.9%\n",
            "Step: 3505 ------------ Loss: 8275.5 ------------ Accuracy: 59.9%\n",
            "Step: 3506 ------------ Loss: 8275.33 ------------ Accuracy: 59.9%\n",
            "Step: 3507 ------------ Loss: 8275.17 ------------ Accuracy: 59.9%\n",
            "Step: 3508 ------------ Loss: 8275.01 ------------ Accuracy: 59.9%\n",
            "Step: 3509 ------------ Loss: 8274.85 ------------ Accuracy: 59.9%\n",
            "Step: 3510 ------------ Loss: 8274.68 ------------ Accuracy: 59.9%\n",
            "Step: 3511 ------------ Loss: 8274.52 ------------ Accuracy: 59.9%\n",
            "Step: 3512 ------------ Loss: 8274.35 ------------ Accuracy: 59.9%\n",
            "Step: 3513 ------------ Loss: 8274.19 ------------ Accuracy: 59.9%\n",
            "Step: 3514 ------------ Loss: 8274.02 ------------ Accuracy: 59.9%\n",
            "Step: 3515 ------------ Loss: 8273.86 ------------ Accuracy: 59.9%\n",
            "Step: 3516 ------------ Loss: 8273.7 ------------ Accuracy: 59.9%\n",
            "Step: 3517 ------------ Loss: 8273.53 ------------ Accuracy: 59.9%\n",
            "Step: 3518 ------------ Loss: 8273.37 ------------ Accuracy: 59.9%\n",
            "Step: 3519 ------------ Loss: 8273.2 ------------ Accuracy: 59.9%\n",
            "Step: 3520 ------------ Loss: 8273.04 ------------ Accuracy: 59.9%\n",
            "Step: 3521 ------------ Loss: 8272.88 ------------ Accuracy: 59.9%\n",
            "Step: 3522 ------------ Loss: 8272.71 ------------ Accuracy: 59.9%\n",
            "Step: 3523 ------------ Loss: 8272.55 ------------ Accuracy: 59.9%\n",
            "Step: 3524 ------------ Loss: 8272.39 ------------ Accuracy: 59.9%\n",
            "Step: 3525 ------------ Loss: 8272.22 ------------ Accuracy: 59.9%\n",
            "Step: 3526 ------------ Loss: 8272.06 ------------ Accuracy: 59.9%\n",
            "Step: 3527 ------------ Loss: 8271.9 ------------ Accuracy: 59.9%\n",
            "Step: 3528 ------------ Loss: 8271.73 ------------ Accuracy: 59.9%\n",
            "Step: 3529 ------------ Loss: 8271.57 ------------ Accuracy: 59.9%\n",
            "Step: 3530 ------------ Loss: 8271.41 ------------ Accuracy: 59.9%\n",
            "Step: 3531 ------------ Loss: 8271.24 ------------ Accuracy: 59.9%\n",
            "Step: 3532 ------------ Loss: 8271.08 ------------ Accuracy: 59.9%\n",
            "Step: 3533 ------------ Loss: 8270.92 ------------ Accuracy: 59.9%\n",
            "Step: 3534 ------------ Loss: 8270.75 ------------ Accuracy: 59.9%\n",
            "Step: 3535 ------------ Loss: 8270.6 ------------ Accuracy: 59.9%\n",
            "Step: 3536 ------------ Loss: 8270.43 ------------ Accuracy: 59.9%\n",
            "Step: 3537 ------------ Loss: 8270.27 ------------ Accuracy: 59.9%\n",
            "Step: 3538 ------------ Loss: 8270.1 ------------ Accuracy: 59.9%\n",
            "Step: 3539 ------------ Loss: 8269.94 ------------ Accuracy: 59.9%\n",
            "Step: 3540 ------------ Loss: 8269.77 ------------ Accuracy: 59.9%\n",
            "Step: 3541 ------------ Loss: 8269.61 ------------ Accuracy: 59.9%\n",
            "Step: 3542 ------------ Loss: 8269.45 ------------ Accuracy: 59.9%\n",
            "Step: 3543 ------------ Loss: 8269.28 ------------ Accuracy: 59.9%\n",
            "Step: 3544 ------------ Loss: 8269.12 ------------ Accuracy: 59.9%\n",
            "Step: 3545 ------------ Loss: 8268.96 ------------ Accuracy: 59.9%\n",
            "Step: 3546 ------------ Loss: 8268.79 ------------ Accuracy: 59.9%\n",
            "Step: 3547 ------------ Loss: 8268.63 ------------ Accuracy: 59.9%\n",
            "Step: 3548 ------------ Loss: 8268.47 ------------ Accuracy: 59.9%\n",
            "Step: 3549 ------------ Loss: 8268.3 ------------ Accuracy: 59.9%\n",
            "Step: 3550 ------------ Loss: 8268.14 ------------ Accuracy: 59.9%\n",
            "Step: 3551 ------------ Loss: 8267.98 ------------ Accuracy: 59.9%\n",
            "Step: 3552 ------------ Loss: 8267.81 ------------ Accuracy: 59.9%\n",
            "Step: 3553 ------------ Loss: 8267.65 ------------ Accuracy: 59.9%\n",
            "Step: 3554 ------------ Loss: 8267.49 ------------ Accuracy: 59.9%\n",
            "Step: 3555 ------------ Loss: 8267.32 ------------ Accuracy: 59.9%\n",
            "Step: 3556 ------------ Loss: 8267.16 ------------ Accuracy: 59.9%\n",
            "Step: 3557 ------------ Loss: 8267.0 ------------ Accuracy: 59.9%\n",
            "Step: 3558 ------------ Loss: 8266.84 ------------ Accuracy: 59.9%\n",
            "Step: 3559 ------------ Loss: 8266.68 ------------ Accuracy: 59.9%\n",
            "Step: 3560 ------------ Loss: 8266.51 ------------ Accuracy: 59.9%\n",
            "Step: 3561 ------------ Loss: 8266.35 ------------ Accuracy: 59.9%\n",
            "Step: 3562 ------------ Loss: 8266.18 ------------ Accuracy: 59.9%\n",
            "Step: 3563 ------------ Loss: 8266.02 ------------ Accuracy: 59.9%\n",
            "Step: 3564 ------------ Loss: 8265.85 ------------ Accuracy: 59.9%\n",
            "Step: 3565 ------------ Loss: 8265.69 ------------ Accuracy: 59.9%\n",
            "Step: 3566 ------------ Loss: 8265.53 ------------ Accuracy: 59.9%\n",
            "Step: 3567 ------------ Loss: 8265.37 ------------ Accuracy: 59.9%\n",
            "Step: 3568 ------------ Loss: 8265.2 ------------ Accuracy: 59.9%\n",
            "Step: 3569 ------------ Loss: 8265.04 ------------ Accuracy: 59.9%\n",
            "Step: 3570 ------------ Loss: 8264.88 ------------ Accuracy: 59.9%\n",
            "Step: 3571 ------------ Loss: 8264.71 ------------ Accuracy: 59.9%\n",
            "Step: 3572 ------------ Loss: 8264.55 ------------ Accuracy: 59.9%\n",
            "Step: 3573 ------------ Loss: 8264.39 ------------ Accuracy: 59.9%\n",
            "Step: 3574 ------------ Loss: 8264.22 ------------ Accuracy: 59.9%\n",
            "Step: 3575 ------------ Loss: 8264.06 ------------ Accuracy: 59.9%\n",
            "Step: 3576 ------------ Loss: 8263.9 ------------ Accuracy: 59.9%\n",
            "Step: 3577 ------------ Loss: 8263.73 ------------ Accuracy: 59.9%\n",
            "Step: 3578 ------------ Loss: 8263.57 ------------ Accuracy: 59.9%\n",
            "Step: 3579 ------------ Loss: 8263.41 ------------ Accuracy: 59.9%\n",
            "Step: 3580 ------------ Loss: 8263.25 ------------ Accuracy: 59.9%\n",
            "Step: 3581 ------------ Loss: 8263.08 ------------ Accuracy: 59.9%\n",
            "Step: 3582 ------------ Loss: 8262.92 ------------ Accuracy: 59.9%\n",
            "Step: 3583 ------------ Loss: 8262.76 ------------ Accuracy: 59.9%\n",
            "Step: 3584 ------------ Loss: 8262.59 ------------ Accuracy: 59.9%\n",
            "Step: 3585 ------------ Loss: 8262.43 ------------ Accuracy: 59.9%\n",
            "Step: 3586 ------------ Loss: 8262.27 ------------ Accuracy: 59.9%\n",
            "Step: 3587 ------------ Loss: 8262.11 ------------ Accuracy: 59.9%\n",
            "Step: 3588 ------------ Loss: 8261.94 ------------ Accuracy: 59.9%\n",
            "Step: 3589 ------------ Loss: 8261.78 ------------ Accuracy: 59.9%\n",
            "Step: 3590 ------------ Loss: 8261.62 ------------ Accuracy: 59.9%\n",
            "Step: 3591 ------------ Loss: 8261.45 ------------ Accuracy: 59.9%\n",
            "Step: 3592 ------------ Loss: 8261.29 ------------ Accuracy: 59.9%\n",
            "Step: 3593 ------------ Loss: 8261.13 ------------ Accuracy: 59.9%\n",
            "Step: 3594 ------------ Loss: 8260.97 ------------ Accuracy: 59.9%\n",
            "Step: 3595 ------------ Loss: 8260.8 ------------ Accuracy: 59.9%\n",
            "Step: 3596 ------------ Loss: 8260.64 ------------ Accuracy: 59.9%\n",
            "Step: 3597 ------------ Loss: 8260.49 ------------ Accuracy: 59.9%\n",
            "Step: 3598 ------------ Loss: 8260.33 ------------ Accuracy: 59.9%\n",
            "Step: 3599 ------------ Loss: 8260.16 ------------ Accuracy: 59.9%\n",
            "Step: 3600 ------------ Loss: 8260.0 ------------ Accuracy: 59.9%\n",
            "Step: 3601 ------------ Loss: 8259.84 ------------ Accuracy: 59.9%\n",
            "Step: 3602 ------------ Loss: 8259.67 ------------ Accuracy: 59.9%\n",
            "Step: 3603 ------------ Loss: 8259.51 ------------ Accuracy: 59.9%\n",
            "Step: 3604 ------------ Loss: 8259.35 ------------ Accuracy: 59.9%\n",
            "Step: 3605 ------------ Loss: 8259.19 ------------ Accuracy: 59.9%\n",
            "Step: 3606 ------------ Loss: 8259.02 ------------ Accuracy: 59.9%\n",
            "Step: 3607 ------------ Loss: 8258.86 ------------ Accuracy: 59.9%\n",
            "Step: 3608 ------------ Loss: 8258.7 ------------ Accuracy: 59.9%\n",
            "Step: 3609 ------------ Loss: 8258.54 ------------ Accuracy: 59.9%\n",
            "Step: 3610 ------------ Loss: 8258.38 ------------ Accuracy: 59.9%\n",
            "Step: 3611 ------------ Loss: 8258.21 ------------ Accuracy: 59.9%\n",
            "Step: 3612 ------------ Loss: 8258.05 ------------ Accuracy: 59.9%\n",
            "Step: 3613 ------------ Loss: 8257.88 ------------ Accuracy: 59.9%\n",
            "Step: 3614 ------------ Loss: 8257.72 ------------ Accuracy: 59.9%\n",
            "Step: 3615 ------------ Loss: 8257.56 ------------ Accuracy: 59.9%\n",
            "Step: 3616 ------------ Loss: 8257.4 ------------ Accuracy: 59.9%\n",
            "Step: 3617 ------------ Loss: 8257.23 ------------ Accuracy: 59.9%\n",
            "Step: 3618 ------------ Loss: 8257.07 ------------ Accuracy: 59.9%\n",
            "Step: 3619 ------------ Loss: 8256.91 ------------ Accuracy: 59.9%\n",
            "Step: 3620 ------------ Loss: 8256.75 ------------ Accuracy: 59.9%\n",
            "Step: 3621 ------------ Loss: 8256.58 ------------ Accuracy: 59.9%\n",
            "Step: 3622 ------------ Loss: 8256.42 ------------ Accuracy: 59.9%\n",
            "Step: 3623 ------------ Loss: 8256.26 ------------ Accuracy: 59.9%\n",
            "Step: 3624 ------------ Loss: 8256.09 ------------ Accuracy: 59.9%\n",
            "Step: 3625 ------------ Loss: 8255.93 ------------ Accuracy: 59.9%\n",
            "Step: 3626 ------------ Loss: 8255.77 ------------ Accuracy: 59.9%\n",
            "Step: 3627 ------------ Loss: 8255.61 ------------ Accuracy: 59.9%\n",
            "Step: 3628 ------------ Loss: 8255.45 ------------ Accuracy: 59.9%\n",
            "Step: 3629 ------------ Loss: 8255.28 ------------ Accuracy: 59.9%\n",
            "Step: 3630 ------------ Loss: 8255.12 ------------ Accuracy: 59.9%\n",
            "Step: 3631 ------------ Loss: 8254.96 ------------ Accuracy: 59.9%\n",
            "Step: 3632 ------------ Loss: 8254.8 ------------ Accuracy: 59.9%\n",
            "Step: 3633 ------------ Loss: 8254.63 ------------ Accuracy: 59.9%\n",
            "Step: 3634 ------------ Loss: 8254.47 ------------ Accuracy: 59.9%\n",
            "Step: 3635 ------------ Loss: 8254.31 ------------ Accuracy: 59.9%\n",
            "Step: 3636 ------------ Loss: 8254.15 ------------ Accuracy: 59.9%\n",
            "Step: 3637 ------------ Loss: 8253.98 ------------ Accuracy: 59.9%\n",
            "Step: 3638 ------------ Loss: 8253.82 ------------ Accuracy: 59.9%\n",
            "Step: 3639 ------------ Loss: 8253.66 ------------ Accuracy: 59.9%\n",
            "Step: 3640 ------------ Loss: 8253.5 ------------ Accuracy: 59.9%\n",
            "Step: 3641 ------------ Loss: 8253.34 ------------ Accuracy: 59.9%\n",
            "Step: 3642 ------------ Loss: 8253.17 ------------ Accuracy: 59.9%\n",
            "Step: 3643 ------------ Loss: 8253.01 ------------ Accuracy: 59.9%\n",
            "Step: 3644 ------------ Loss: 8252.85 ------------ Accuracy: 59.9%\n",
            "Step: 3645 ------------ Loss: 8252.69 ------------ Accuracy: 59.9%\n",
            "Step: 3646 ------------ Loss: 8252.52 ------------ Accuracy: 59.9%\n",
            "Step: 3647 ------------ Loss: 8252.36 ------------ Accuracy: 60.0%\n",
            "Step: 3648 ------------ Loss: 8252.2 ------------ Accuracy: 60.0%\n",
            "Step: 3649 ------------ Loss: 8252.04 ------------ Accuracy: 60.0%\n",
            "Step: 3650 ------------ Loss: 8251.88 ------------ Accuracy: 60.0%\n",
            "Step: 3651 ------------ Loss: 8251.72 ------------ Accuracy: 60.0%\n",
            "Step: 3652 ------------ Loss: 8251.55 ------------ Accuracy: 60.0%\n",
            "Step: 3653 ------------ Loss: 8251.39 ------------ Accuracy: 60.0%\n",
            "Step: 3654 ------------ Loss: 8251.23 ------------ Accuracy: 60.0%\n",
            "Step: 3655 ------------ Loss: 8251.07 ------------ Accuracy: 60.0%\n",
            "Step: 3656 ------------ Loss: 8250.9 ------------ Accuracy: 60.0%\n",
            "Step: 3657 ------------ Loss: 8250.74 ------------ Accuracy: 60.0%\n",
            "Step: 3658 ------------ Loss: 8250.58 ------------ Accuracy: 60.0%\n",
            "Step: 3659 ------------ Loss: 8250.42 ------------ Accuracy: 60.0%\n",
            "Step: 3660 ------------ Loss: 8250.27 ------------ Accuracy: 60.0%\n",
            "Step: 3661 ------------ Loss: 8250.1 ------------ Accuracy: 60.0%\n",
            "Step: 3662 ------------ Loss: 8249.93 ------------ Accuracy: 59.9%\n",
            "Step: 3663 ------------ Loss: 8249.77 ------------ Accuracy: 59.9%\n",
            "Step: 3664 ------------ Loss: 8249.61 ------------ Accuracy: 59.9%\n",
            "Step: 3665 ------------ Loss: 8249.44 ------------ Accuracy: 59.9%\n",
            "Step: 3666 ------------ Loss: 8249.28 ------------ Accuracy: 60.0%\n",
            "Step: 3667 ------------ Loss: 8249.12 ------------ Accuracy: 60.0%\n",
            "Step: 3668 ------------ Loss: 8248.96 ------------ Accuracy: 60.0%\n",
            "Step: 3669 ------------ Loss: 8248.8 ------------ Accuracy: 60.0%\n",
            "Step: 3670 ------------ Loss: 8248.63 ------------ Accuracy: 60.0%\n",
            "Step: 3671 ------------ Loss: 8248.47 ------------ Accuracy: 60.0%\n",
            "Step: 3672 ------------ Loss: 8248.31 ------------ Accuracy: 60.0%\n",
            "Step: 3673 ------------ Loss: 8248.15 ------------ Accuracy: 60.0%\n",
            "Step: 3674 ------------ Loss: 8247.99 ------------ Accuracy: 60.0%\n",
            "Step: 3675 ------------ Loss: 8247.82 ------------ Accuracy: 60.0%\n",
            "Step: 3676 ------------ Loss: 8247.66 ------------ Accuracy: 60.0%\n",
            "Step: 3677 ------------ Loss: 8247.5 ------------ Accuracy: 60.0%\n",
            "Step: 3678 ------------ Loss: 8247.34 ------------ Accuracy: 60.0%\n",
            "Step: 3679 ------------ Loss: 8247.18 ------------ Accuracy: 60.0%\n",
            "Step: 3680 ------------ Loss: 8247.01 ------------ Accuracy: 60.0%\n",
            "Step: 3681 ------------ Loss: 8246.85 ------------ Accuracy: 60.0%\n",
            "Step: 3682 ------------ Loss: 8246.7 ------------ Accuracy: 60.0%\n",
            "Step: 3683 ------------ Loss: 8246.54 ------------ Accuracy: 60.0%\n",
            "Step: 3684 ------------ Loss: 8246.38 ------------ Accuracy: 60.0%\n",
            "Step: 3685 ------------ Loss: 8246.21 ------------ Accuracy: 60.0%\n",
            "Step: 3686 ------------ Loss: 8246.05 ------------ Accuracy: 60.0%\n",
            "Step: 3687 ------------ Loss: 8245.89 ------------ Accuracy: 60.0%\n",
            "Step: 3688 ------------ Loss: 8245.73 ------------ Accuracy: 60.0%\n",
            "Step: 3689 ------------ Loss: 8245.57 ------------ Accuracy: 60.0%\n",
            "Step: 3690 ------------ Loss: 8245.41 ------------ Accuracy: 60.0%\n",
            "Step: 3691 ------------ Loss: 8245.24 ------------ Accuracy: 60.0%\n",
            "Step: 3692 ------------ Loss: 8245.08 ------------ Accuracy: 60.0%\n",
            "Step: 3693 ------------ Loss: 8244.92 ------------ Accuracy: 60.0%\n",
            "Step: 3694 ------------ Loss: 8244.76 ------------ Accuracy: 60.0%\n",
            "Step: 3695 ------------ Loss: 8244.61 ------------ Accuracy: 60.0%\n",
            "Step: 3696 ------------ Loss: 8244.44 ------------ Accuracy: 60.0%\n",
            "Step: 3697 ------------ Loss: 8244.27 ------------ Accuracy: 60.0%\n",
            "Step: 3698 ------------ Loss: 8244.11 ------------ Accuracy: 60.0%\n",
            "Step: 3699 ------------ Loss: 8243.95 ------------ Accuracy: 60.0%\n",
            "Step: 3700 ------------ Loss: 8243.79 ------------ Accuracy: 60.0%\n",
            "Step: 3701 ------------ Loss: 8243.62 ------------ Accuracy: 60.0%\n",
            "Step: 3702 ------------ Loss: 8243.46 ------------ Accuracy: 60.0%\n",
            "Step: 3703 ------------ Loss: 8243.3 ------------ Accuracy: 60.0%\n",
            "Step: 3704 ------------ Loss: 8243.14 ------------ Accuracy: 60.0%\n",
            "Step: 3705 ------------ Loss: 8242.98 ------------ Accuracy: 60.0%\n",
            "Step: 3706 ------------ Loss: 8242.82 ------------ Accuracy: 60.0%\n",
            "Step: 3707 ------------ Loss: 8242.65 ------------ Accuracy: 60.0%\n",
            "Step: 3708 ------------ Loss: 8242.49 ------------ Accuracy: 60.0%\n",
            "Step: 3709 ------------ Loss: 8242.33 ------------ Accuracy: 60.0%\n",
            "Step: 3710 ------------ Loss: 8242.17 ------------ Accuracy: 60.0%\n",
            "Step: 3711 ------------ Loss: 8242.01 ------------ Accuracy: 60.0%\n",
            "Step: 3712 ------------ Loss: 8241.85 ------------ Accuracy: 60.0%\n",
            "Step: 3713 ------------ Loss: 8241.68 ------------ Accuracy: 60.0%\n",
            "Step: 3714 ------------ Loss: 8241.52 ------------ Accuracy: 60.0%\n",
            "Step: 3715 ------------ Loss: 8241.36 ------------ Accuracy: 60.0%\n",
            "Step: 3716 ------------ Loss: 8241.2 ------------ Accuracy: 60.0%\n",
            "Step: 3717 ------------ Loss: 8241.04 ------------ Accuracy: 60.0%\n",
            "Step: 3718 ------------ Loss: 8240.88 ------------ Accuracy: 60.0%\n",
            "Step: 3719 ------------ Loss: 8240.71 ------------ Accuracy: 60.0%\n",
            "Step: 3720 ------------ Loss: 8240.55 ------------ Accuracy: 60.0%\n",
            "Step: 3721 ------------ Loss: 8240.39 ------------ Accuracy: 60.0%\n",
            "Step: 3722 ------------ Loss: 8240.23 ------------ Accuracy: 60.0%\n",
            "Step: 3723 ------------ Loss: 8240.07 ------------ Accuracy: 60.0%\n",
            "Step: 3724 ------------ Loss: 8239.91 ------------ Accuracy: 60.0%\n",
            "Step: 3725 ------------ Loss: 8239.75 ------------ Accuracy: 60.0%\n",
            "Step: 3726 ------------ Loss: 8239.58 ------------ Accuracy: 60.0%\n",
            "Step: 3727 ------------ Loss: 8239.42 ------------ Accuracy: 60.0%\n",
            "Step: 3728 ------------ Loss: 8239.26 ------------ Accuracy: 60.0%\n",
            "Step: 3729 ------------ Loss: 8239.1 ------------ Accuracy: 60.0%\n",
            "Step: 3730 ------------ Loss: 8238.94 ------------ Accuracy: 60.0%\n",
            "Step: 3731 ------------ Loss: 8238.78 ------------ Accuracy: 60.0%\n",
            "Step: 3732 ------------ Loss: 8238.63 ------------ Accuracy: 60.1%\n",
            "Step: 3733 ------------ Loss: 8238.47 ------------ Accuracy: 60.0%\n",
            "Step: 3734 ------------ Loss: 8238.3 ------------ Accuracy: 60.0%\n",
            "Step: 3735 ------------ Loss: 8238.14 ------------ Accuracy: 60.0%\n",
            "Step: 3736 ------------ Loss: 8237.98 ------------ Accuracy: 60.0%\n",
            "Step: 3737 ------------ Loss: 8237.82 ------------ Accuracy: 60.0%\n",
            "Step: 3738 ------------ Loss: 8237.66 ------------ Accuracy: 60.0%\n",
            "Step: 3739 ------------ Loss: 8237.5 ------------ Accuracy: 60.0%\n",
            "Step: 3740 ------------ Loss: 8237.34 ------------ Accuracy: 60.0%\n",
            "Step: 3741 ------------ Loss: 8237.17 ------------ Accuracy: 60.0%\n",
            "Step: 3742 ------------ Loss: 8237.01 ------------ Accuracy: 60.0%\n",
            "Step: 3743 ------------ Loss: 8236.85 ------------ Accuracy: 60.0%\n",
            "Step: 3744 ------------ Loss: 8236.69 ------------ Accuracy: 60.0%\n",
            "Step: 3745 ------------ Loss: 8236.54 ------------ Accuracy: 60.1%\n",
            "Step: 3746 ------------ Loss: 8236.37 ------------ Accuracy: 60.1%\n",
            "Step: 3747 ------------ Loss: 8236.21 ------------ Accuracy: 60.1%\n",
            "Step: 3748 ------------ Loss: 8236.04 ------------ Accuracy: 60.1%\n",
            "Step: 3749 ------------ Loss: 8235.88 ------------ Accuracy: 60.1%\n",
            "Step: 3750 ------------ Loss: 8235.72 ------------ Accuracy: 60.1%\n",
            "Step: 3751 ------------ Loss: 8235.56 ------------ Accuracy: 60.1%\n",
            "Step: 3752 ------------ Loss: 8235.4 ------------ Accuracy: 60.0%\n",
            "Step: 3753 ------------ Loss: 8235.24 ------------ Accuracy: 60.0%\n",
            "Step: 3754 ------------ Loss: 8235.08 ------------ Accuracy: 60.0%\n",
            "Step: 3755 ------------ Loss: 8234.92 ------------ Accuracy: 60.0%\n",
            "Step: 3756 ------------ Loss: 8234.75 ------------ Accuracy: 60.0%\n",
            "Step: 3757 ------------ Loss: 8234.59 ------------ Accuracy: 60.0%\n",
            "Step: 3758 ------------ Loss: 8234.43 ------------ Accuracy: 60.0%\n",
            "Step: 3759 ------------ Loss: 8234.27 ------------ Accuracy: 60.0%\n",
            "Step: 3760 ------------ Loss: 8234.11 ------------ Accuracy: 60.0%\n",
            "Step: 3761 ------------ Loss: 8233.95 ------------ Accuracy: 60.0%\n",
            "Step: 3762 ------------ Loss: 8233.79 ------------ Accuracy: 60.0%\n",
            "Step: 3763 ------------ Loss: 8233.63 ------------ Accuracy: 60.0%\n",
            "Step: 3764 ------------ Loss: 8233.46 ------------ Accuracy: 60.0%\n",
            "Step: 3765 ------------ Loss: 8233.3 ------------ Accuracy: 60.0%\n",
            "Step: 3766 ------------ Loss: 8233.14 ------------ Accuracy: 60.0%\n",
            "Step: 3767 ------------ Loss: 8232.98 ------------ Accuracy: 60.0%\n",
            "Step: 3768 ------------ Loss: 8232.82 ------------ Accuracy: 60.0%\n",
            "Step: 3769 ------------ Loss: 8232.66 ------------ Accuracy: 60.0%\n",
            "Step: 3770 ------------ Loss: 8232.5 ------------ Accuracy: 60.0%\n",
            "Step: 3771 ------------ Loss: 8232.34 ------------ Accuracy: 60.0%\n",
            "Step: 3772 ------------ Loss: 8232.18 ------------ Accuracy: 60.0%\n",
            "Step: 3773 ------------ Loss: 8232.02 ------------ Accuracy: 60.0%\n",
            "Step: 3774 ------------ Loss: 8231.85 ------------ Accuracy: 60.0%\n",
            "Step: 3775 ------------ Loss: 8231.69 ------------ Accuracy: 60.0%\n",
            "Step: 3776 ------------ Loss: 8231.53 ------------ Accuracy: 60.0%\n",
            "Step: 3777 ------------ Loss: 8231.37 ------------ Accuracy: 60.0%\n",
            "Step: 3778 ------------ Loss: 8231.21 ------------ Accuracy: 60.0%\n",
            "Step: 3779 ------------ Loss: 8231.05 ------------ Accuracy: 60.0%\n",
            "Step: 3780 ------------ Loss: 8230.89 ------------ Accuracy: 60.0%\n",
            "Step: 3781 ------------ Loss: 8230.73 ------------ Accuracy: 60.0%\n",
            "Step: 3782 ------------ Loss: 8230.57 ------------ Accuracy: 60.0%\n",
            "Step: 3783 ------------ Loss: 8230.41 ------------ Accuracy: 60.1%\n",
            "Step: 3784 ------------ Loss: 8230.25 ------------ Accuracy: 60.1%\n",
            "Step: 3785 ------------ Loss: 8230.09 ------------ Accuracy: 60.1%\n",
            "Step: 3786 ------------ Loss: 8229.93 ------------ Accuracy: 60.1%\n",
            "Step: 3787 ------------ Loss: 8229.77 ------------ Accuracy: 60.1%\n",
            "Step: 3788 ------------ Loss: 8229.6 ------------ Accuracy: 60.1%\n",
            "Step: 3789 ------------ Loss: 8229.44 ------------ Accuracy: 60.1%\n",
            "Step: 3790 ------------ Loss: 8229.28 ------------ Accuracy: 60.1%\n",
            "Step: 3791 ------------ Loss: 8229.12 ------------ Accuracy: 60.1%\n",
            "Step: 3792 ------------ Loss: 8228.96 ------------ Accuracy: 60.1%\n",
            "Step: 3793 ------------ Loss: 8228.8 ------------ Accuracy: 60.1%\n",
            "Step: 3794 ------------ Loss: 8228.64 ------------ Accuracy: 60.1%\n",
            "Step: 3795 ------------ Loss: 8228.48 ------------ Accuracy: 60.1%\n",
            "Step: 3796 ------------ Loss: 8228.33 ------------ Accuracy: 60.1%\n",
            "Step: 3797 ------------ Loss: 8228.16 ------------ Accuracy: 60.1%\n",
            "Step: 3798 ------------ Loss: 8228.0 ------------ Accuracy: 60.1%\n",
            "Step: 3799 ------------ Loss: 8227.83 ------------ Accuracy: 60.1%\n",
            "Step: 3800 ------------ Loss: 8227.67 ------------ Accuracy: 60.1%\n",
            "Step: 3801 ------------ Loss: 8227.51 ------------ Accuracy: 60.1%\n",
            "Step: 3802 ------------ Loss: 8227.35 ------------ Accuracy: 60.1%\n",
            "Step: 3803 ------------ Loss: 8227.19 ------------ Accuracy: 60.1%\n",
            "Step: 3804 ------------ Loss: 8227.03 ------------ Accuracy: 60.1%\n",
            "Step: 3805 ------------ Loss: 8226.87 ------------ Accuracy: 60.1%\n",
            "Step: 3806 ------------ Loss: 8226.71 ------------ Accuracy: 60.1%\n",
            "Step: 3807 ------------ Loss: 8226.55 ------------ Accuracy: 60.1%\n",
            "Step: 3808 ------------ Loss: 8226.39 ------------ Accuracy: 60.1%\n",
            "Step: 3809 ------------ Loss: 8226.23 ------------ Accuracy: 60.1%\n",
            "Step: 3810 ------------ Loss: 8226.07 ------------ Accuracy: 60.1%\n",
            "Step: 3811 ------------ Loss: 8225.91 ------------ Accuracy: 60.1%\n",
            "Step: 3812 ------------ Loss: 8225.75 ------------ Accuracy: 60.1%\n",
            "Step: 3813 ------------ Loss: 8225.6 ------------ Accuracy: 60.2%\n",
            "Step: 3814 ------------ Loss: 8225.44 ------------ Accuracy: 60.1%\n",
            "Step: 3815 ------------ Loss: 8225.27 ------------ Accuracy: 60.2%\n",
            "Step: 3816 ------------ Loss: 8225.11 ------------ Accuracy: 60.1%\n",
            "Step: 3817 ------------ Loss: 8224.95 ------------ Accuracy: 60.1%\n",
            "Step: 3818 ------------ Loss: 8224.79 ------------ Accuracy: 60.1%\n",
            "Step: 3819 ------------ Loss: 8224.63 ------------ Accuracy: 60.2%\n",
            "Step: 3820 ------------ Loss: 8224.47 ------------ Accuracy: 60.1%\n",
            "Step: 3821 ------------ Loss: 8224.31 ------------ Accuracy: 60.1%\n",
            "Step: 3822 ------------ Loss: 8224.15 ------------ Accuracy: 60.1%\n",
            "Step: 3823 ------------ Loss: 8223.99 ------------ Accuracy: 60.1%\n",
            "Step: 3824 ------------ Loss: 8223.83 ------------ Accuracy: 60.1%\n",
            "Step: 3825 ------------ Loss: 8223.67 ------------ Accuracy: 60.2%\n",
            "Step: 3826 ------------ Loss: 8223.51 ------------ Accuracy: 60.1%\n",
            "Step: 3827 ------------ Loss: 8223.35 ------------ Accuracy: 60.1%\n",
            "Step: 3828 ------------ Loss: 8223.19 ------------ Accuracy: 60.1%\n",
            "Step: 3829 ------------ Loss: 8223.03 ------------ Accuracy: 60.1%\n",
            "Step: 3830 ------------ Loss: 8222.87 ------------ Accuracy: 60.1%\n",
            "Step: 3831 ------------ Loss: 8222.71 ------------ Accuracy: 60.1%\n",
            "Step: 3832 ------------ Loss: 8222.55 ------------ Accuracy: 60.1%\n",
            "Step: 3833 ------------ Loss: 8222.39 ------------ Accuracy: 60.1%\n",
            "Step: 3834 ------------ Loss: 8222.23 ------------ Accuracy: 60.1%\n",
            "Step: 3835 ------------ Loss: 8222.07 ------------ Accuracy: 60.1%\n",
            "Step: 3836 ------------ Loss: 8221.91 ------------ Accuracy: 60.1%\n",
            "Step: 3837 ------------ Loss: 8221.75 ------------ Accuracy: 60.1%\n",
            "Step: 3838 ------------ Loss: 8221.59 ------------ Accuracy: 60.1%\n",
            "Step: 3839 ------------ Loss: 8221.43 ------------ Accuracy: 60.1%\n",
            "Step: 3840 ------------ Loss: 8221.27 ------------ Accuracy: 60.1%\n",
            "Step: 3841 ------------ Loss: 8221.12 ------------ Accuracy: 60.2%\n",
            "Step: 3842 ------------ Loss: 8220.95 ------------ Accuracy: 60.1%\n",
            "Step: 3843 ------------ Loss: 8220.79 ------------ Accuracy: 60.1%\n",
            "Step: 3844 ------------ Loss: 8220.62 ------------ Accuracy: 60.1%\n",
            "Step: 3845 ------------ Loss: 8220.46 ------------ Accuracy: 60.1%\n",
            "Step: 3846 ------------ Loss: 8220.3 ------------ Accuracy: 60.1%\n",
            "Step: 3847 ------------ Loss: 8220.14 ------------ Accuracy: 60.1%\n",
            "Step: 3848 ------------ Loss: 8219.98 ------------ Accuracy: 60.1%\n",
            "Step: 3849 ------------ Loss: 8219.82 ------------ Accuracy: 60.1%\n",
            "Step: 3850 ------------ Loss: 8219.66 ------------ Accuracy: 60.1%\n",
            "Step: 3851 ------------ Loss: 8219.5 ------------ Accuracy: 60.1%\n",
            "Step: 3852 ------------ Loss: 8219.34 ------------ Accuracy: 60.1%\n",
            "Step: 3853 ------------ Loss: 8219.18 ------------ Accuracy: 60.1%\n",
            "Step: 3854 ------------ Loss: 8219.02 ------------ Accuracy: 60.1%\n",
            "Step: 3855 ------------ Loss: 8218.86 ------------ Accuracy: 60.1%\n",
            "Step: 3856 ------------ Loss: 8218.7 ------------ Accuracy: 60.1%\n",
            "Step: 3857 ------------ Loss: 8218.54 ------------ Accuracy: 60.1%\n",
            "Step: 3858 ------------ Loss: 8218.38 ------------ Accuracy: 60.1%\n",
            "Step: 3859 ------------ Loss: 8218.22 ------------ Accuracy: 60.1%\n",
            "Step: 3860 ------------ Loss: 8218.06 ------------ Accuracy: 60.1%\n",
            "Step: 3861 ------------ Loss: 8217.9 ------------ Accuracy: 60.1%\n",
            "Step: 3862 ------------ Loss: 8217.74 ------------ Accuracy: 60.1%\n",
            "Step: 3863 ------------ Loss: 8217.58 ------------ Accuracy: 60.1%\n",
            "Step: 3864 ------------ Loss: 8217.42 ------------ Accuracy: 60.1%\n",
            "Step: 3865 ------------ Loss: 8217.26 ------------ Accuracy: 60.1%\n",
            "Step: 3866 ------------ Loss: 8217.1 ------------ Accuracy: 60.1%\n",
            "Step: 3867 ------------ Loss: 8216.94 ------------ Accuracy: 60.1%\n",
            "Step: 3868 ------------ Loss: 8216.78 ------------ Accuracy: 60.1%\n",
            "Step: 3869 ------------ Loss: 8216.62 ------------ Accuracy: 60.1%\n",
            "Step: 3870 ------------ Loss: 8216.46 ------------ Accuracy: 60.1%\n",
            "Step: 3871 ------------ Loss: 8216.3 ------------ Accuracy: 60.1%\n",
            "Step: 3872 ------------ Loss: 8216.14 ------------ Accuracy: 60.1%\n",
            "Step: 3873 ------------ Loss: 8215.98 ------------ Accuracy: 60.1%\n",
            "Step: 3874 ------------ Loss: 8215.82 ------------ Accuracy: 60.1%\n",
            "Step: 3875 ------------ Loss: 8215.66 ------------ Accuracy: 60.1%\n",
            "Step: 3876 ------------ Loss: 8215.5 ------------ Accuracy: 60.1%\n",
            "Step: 3877 ------------ Loss: 8215.34 ------------ Accuracy: 60.1%\n",
            "Step: 3878 ------------ Loss: 8215.18 ------------ Accuracy: 60.1%\n",
            "Step: 3879 ------------ Loss: 8215.03 ------------ Accuracy: 60.2%\n",
            "Step: 3880 ------------ Loss: 8214.87 ------------ Accuracy: 60.2%\n",
            "Step: 3881 ------------ Loss: 8214.71 ------------ Accuracy: 60.2%\n",
            "Step: 3882 ------------ Loss: 8214.55 ------------ Accuracy: 60.2%\n",
            "Step: 3883 ------------ Loss: 8214.39 ------------ Accuracy: 60.2%\n",
            "Step: 3884 ------------ Loss: 8214.23 ------------ Accuracy: 60.2%\n",
            "Step: 3885 ------------ Loss: 8214.07 ------------ Accuracy: 60.2%\n",
            "Step: 3886 ------------ Loss: 8213.91 ------------ Accuracy: 60.2%\n",
            "Step: 3887 ------------ Loss: 8213.75 ------------ Accuracy: 60.2%\n",
            "Step: 3888 ------------ Loss: 8213.59 ------------ Accuracy: 60.2%\n",
            "Step: 3889 ------------ Loss: 8213.43 ------------ Accuracy: 60.2%\n",
            "Step: 3890 ------------ Loss: 8213.27 ------------ Accuracy: 60.2%\n",
            "Step: 3891 ------------ Loss: 8213.11 ------------ Accuracy: 60.2%\n",
            "Step: 3892 ------------ Loss: 8212.95 ------------ Accuracy: 60.2%\n",
            "Step: 3893 ------------ Loss: 8212.79 ------------ Accuracy: 60.2%\n",
            "Step: 3894 ------------ Loss: 8212.63 ------------ Accuracy: 60.2%\n",
            "Step: 3895 ------------ Loss: 8212.47 ------------ Accuracy: 60.2%\n",
            "Step: 3896 ------------ Loss: 8212.31 ------------ Accuracy: 60.2%\n",
            "Step: 3897 ------------ Loss: 8212.15 ------------ Accuracy: 60.2%\n",
            "Step: 3898 ------------ Loss: 8212.0 ------------ Accuracy: 60.2%\n",
            "Step: 3899 ------------ Loss: 8211.83 ------------ Accuracy: 60.2%\n",
            "Step: 3900 ------------ Loss: 8211.67 ------------ Accuracy: 60.2%\n",
            "Step: 3901 ------------ Loss: 8211.51 ------------ Accuracy: 60.2%\n",
            "Step: 3902 ------------ Loss: 8211.35 ------------ Accuracy: 60.2%\n",
            "Step: 3903 ------------ Loss: 8211.19 ------------ Accuracy: 60.2%\n",
            "Step: 3904 ------------ Loss: 8211.03 ------------ Accuracy: 60.2%\n",
            "Step: 3905 ------------ Loss: 8210.87 ------------ Accuracy: 60.2%\n",
            "Step: 3906 ------------ Loss: 8210.71 ------------ Accuracy: 60.2%\n",
            "Step: 3907 ------------ Loss: 8210.55 ------------ Accuracy: 60.2%\n",
            "Step: 3908 ------------ Loss: 8210.39 ------------ Accuracy: 60.2%\n",
            "Step: 3909 ------------ Loss: 8210.23 ------------ Accuracy: 60.2%\n",
            "Step: 3910 ------------ Loss: 8210.07 ------------ Accuracy: 60.2%\n",
            "Step: 3911 ------------ Loss: 8209.91 ------------ Accuracy: 60.2%\n",
            "Step: 3912 ------------ Loss: 8209.75 ------------ Accuracy: 60.2%\n",
            "Step: 3913 ------------ Loss: 8209.59 ------------ Accuracy: 60.2%\n",
            "Step: 3914 ------------ Loss: 8209.43 ------------ Accuracy: 60.2%\n",
            "Step: 3915 ------------ Loss: 8209.27 ------------ Accuracy: 60.2%\n",
            "Step: 3916 ------------ Loss: 8209.11 ------------ Accuracy: 60.2%\n",
            "Step: 3917 ------------ Loss: 8208.95 ------------ Accuracy: 60.2%\n",
            "Step: 3918 ------------ Loss: 8208.79 ------------ Accuracy: 60.2%\n",
            "Step: 3919 ------------ Loss: 8208.63 ------------ Accuracy: 60.2%\n",
            "Step: 3920 ------------ Loss: 8208.47 ------------ Accuracy: 60.2%\n",
            "Step: 3921 ------------ Loss: 8208.31 ------------ Accuracy: 60.2%\n",
            "Step: 3922 ------------ Loss: 8208.15 ------------ Accuracy: 60.2%\n",
            "Step: 3923 ------------ Loss: 8208.0 ------------ Accuracy: 60.2%\n",
            "Step: 3924 ------------ Loss: 8207.84 ------------ Accuracy: 60.2%\n",
            "Step: 3925 ------------ Loss: 8207.68 ------------ Accuracy: 60.2%\n",
            "Step: 3926 ------------ Loss: 8207.52 ------------ Accuracy: 60.2%\n",
            "Step: 3927 ------------ Loss: 8207.36 ------------ Accuracy: 60.2%\n",
            "Step: 3928 ------------ Loss: 8207.2 ------------ Accuracy: 60.2%\n",
            "Step: 3929 ------------ Loss: 8207.04 ------------ Accuracy: 60.2%\n",
            "Step: 3930 ------------ Loss: 8206.88 ------------ Accuracy: 60.2%\n",
            "Step: 3931 ------------ Loss: 8206.72 ------------ Accuracy: 60.2%\n",
            "Step: 3932 ------------ Loss: 8206.56 ------------ Accuracy: 60.2%\n",
            "Step: 3933 ------------ Loss: 8206.4 ------------ Accuracy: 60.2%\n",
            "Step: 3934 ------------ Loss: 8206.24 ------------ Accuracy: 60.2%\n",
            "Step: 3935 ------------ Loss: 8206.08 ------------ Accuracy: 60.3%\n",
            "Step: 3936 ------------ Loss: 8205.93 ------------ Accuracy: 60.2%\n",
            "Step: 3937 ------------ Loss: 8205.77 ------------ Accuracy: 60.4%\n",
            "Step: 3938 ------------ Loss: 8205.61 ------------ Accuracy: 60.4%\n",
            "Step: 3939 ------------ Loss: 8205.45 ------------ Accuracy: 60.4%\n",
            "Step: 3940 ------------ Loss: 8205.29 ------------ Accuracy: 60.4%\n",
            "Step: 3941 ------------ Loss: 8205.14 ------------ Accuracy: 60.4%\n",
            "Step: 3942 ------------ Loss: 8204.98 ------------ Accuracy: 60.4%\n",
            "Step: 3943 ------------ Loss: 8204.82 ------------ Accuracy: 60.4%\n",
            "Step: 3944 ------------ Loss: 8204.66 ------------ Accuracy: 60.4%\n",
            "Step: 3945 ------------ Loss: 8204.5 ------------ Accuracy: 60.4%\n",
            "Step: 3946 ------------ Loss: 8204.34 ------------ Accuracy: 60.4%\n",
            "Step: 3947 ------------ Loss: 8204.18 ------------ Accuracy: 60.4%\n",
            "Step: 3948 ------------ Loss: 8204.02 ------------ Accuracy: 60.4%\n",
            "Step: 3949 ------------ Loss: 8203.86 ------------ Accuracy: 60.4%\n",
            "Step: 3950 ------------ Loss: 8203.7 ------------ Accuracy: 60.4%\n",
            "Step: 3951 ------------ Loss: 8203.54 ------------ Accuracy: 60.4%\n",
            "Step: 3952 ------------ Loss: 8203.38 ------------ Accuracy: 60.4%\n",
            "Step: 3953 ------------ Loss: 8203.22 ------------ Accuracy: 60.4%\n",
            "Step: 3954 ------------ Loss: 8203.07 ------------ Accuracy: 60.4%\n",
            "Step: 3955 ------------ Loss: 8202.91 ------------ Accuracy: 60.4%\n",
            "Step: 3956 ------------ Loss: 8202.75 ------------ Accuracy: 60.4%\n",
            "Step: 3957 ------------ Loss: 8202.59 ------------ Accuracy: 60.4%\n",
            "Step: 3958 ------------ Loss: 8202.44 ------------ Accuracy: 60.4%\n",
            "Step: 3959 ------------ Loss: 8202.27 ------------ Accuracy: 60.4%\n",
            "Step: 3960 ------------ Loss: 8202.11 ------------ Accuracy: 60.4%\n",
            "Step: 3961 ------------ Loss: 8201.95 ------------ Accuracy: 60.4%\n",
            "Step: 3962 ------------ Loss: 8201.79 ------------ Accuracy: 60.4%\n",
            "Step: 3963 ------------ Loss: 8201.63 ------------ Accuracy: 60.4%\n",
            "Step: 3964 ------------ Loss: 8201.47 ------------ Accuracy: 60.4%\n",
            "Step: 3965 ------------ Loss: 8201.31 ------------ Accuracy: 60.4%\n",
            "Step: 3966 ------------ Loss: 8201.15 ------------ Accuracy: 60.4%\n",
            "Step: 3967 ------------ Loss: 8200.99 ------------ Accuracy: 60.4%\n",
            "Step: 3968 ------------ Loss: 8200.83 ------------ Accuracy: 60.4%\n",
            "Step: 3969 ------------ Loss: 8200.67 ------------ Accuracy: 60.4%\n",
            "Step: 3970 ------------ Loss: 8200.52 ------------ Accuracy: 60.3%\n",
            "Step: 3971 ------------ Loss: 8200.36 ------------ Accuracy: 60.3%\n",
            "Step: 3972 ------------ Loss: 8200.2 ------------ Accuracy: 60.3%\n",
            "Step: 3973 ------------ Loss: 8200.04 ------------ Accuracy: 60.3%\n",
            "Step: 3974 ------------ Loss: 8199.88 ------------ Accuracy: 60.3%\n",
            "Step: 3975 ------------ Loss: 8199.72 ------------ Accuracy: 60.3%\n",
            "Step: 3976 ------------ Loss: 8199.56 ------------ Accuracy: 60.4%\n",
            "Step: 3977 ------------ Loss: 8199.4 ------------ Accuracy: 60.4%\n",
            "Step: 3978 ------------ Loss: 8199.24 ------------ Accuracy: 60.4%\n",
            "Step: 3979 ------------ Loss: 8199.08 ------------ Accuracy: 60.4%\n",
            "Step: 3980 ------------ Loss: 8198.93 ------------ Accuracy: 60.4%\n",
            "Step: 3981 ------------ Loss: 8198.77 ------------ Accuracy: 60.4%\n",
            "Step: 3982 ------------ Loss: 8198.61 ------------ Accuracy: 60.4%\n",
            "Step: 3983 ------------ Loss: 8198.45 ------------ Accuracy: 60.4%\n",
            "Step: 3984 ------------ Loss: 8198.3 ------------ Accuracy: 60.4%\n",
            "Step: 3985 ------------ Loss: 8198.14 ------------ Accuracy: 60.4%\n",
            "Step: 3986 ------------ Loss: 8197.97 ------------ Accuracy: 60.4%\n",
            "Step: 3987 ------------ Loss: 8197.81 ------------ Accuracy: 60.4%\n",
            "Step: 3988 ------------ Loss: 8197.65 ------------ Accuracy: 60.4%\n",
            "Step: 3989 ------------ Loss: 8197.5 ------------ Accuracy: 60.4%\n",
            "Step: 3990 ------------ Loss: 8197.34 ------------ Accuracy: 60.4%\n",
            "Step: 3991 ------------ Loss: 8197.18 ------------ Accuracy: 60.4%\n",
            "Step: 3992 ------------ Loss: 8197.02 ------------ Accuracy: 60.4%\n",
            "Step: 3993 ------------ Loss: 8196.86 ------------ Accuracy: 60.4%\n",
            "Step: 3994 ------------ Loss: 8196.7 ------------ Accuracy: 60.4%\n",
            "Step: 3995 ------------ Loss: 8196.54 ------------ Accuracy: 60.4%\n",
            "Step: 3996 ------------ Loss: 8196.38 ------------ Accuracy: 60.4%\n",
            "Step: 3997 ------------ Loss: 8196.22 ------------ Accuracy: 60.4%\n",
            "Step: 3998 ------------ Loss: 8196.07 ------------ Accuracy: 60.4%\n",
            "Step: 3999 ------------ Loss: 8195.91 ------------ Accuracy: 60.4%\n",
            "Step: 4000 ------------ Loss: 8195.75 ------------ Accuracy: 60.4%\n",
            "Step: 4001 ------------ Loss: 8195.59 ------------ Accuracy: 60.4%\n",
            "Step: 4002 ------------ Loss: 8195.43 ------------ Accuracy: 60.4%\n",
            "Step: 4003 ------------ Loss: 8195.27 ------------ Accuracy: 60.4%\n",
            "Step: 4004 ------------ Loss: 8195.11 ------------ Accuracy: 60.4%\n",
            "Step: 4005 ------------ Loss: 8194.95 ------------ Accuracy: 60.4%\n",
            "Step: 4006 ------------ Loss: 8194.8 ------------ Accuracy: 60.4%\n",
            "Step: 4007 ------------ Loss: 8194.64 ------------ Accuracy: 60.4%\n",
            "Step: 4008 ------------ Loss: 8194.48 ------------ Accuracy: 60.4%\n",
            "Step: 4009 ------------ Loss: 8194.32 ------------ Accuracy: 60.4%\n",
            "Step: 4010 ------------ Loss: 8194.16 ------------ Accuracy: 60.4%\n",
            "Step: 4011 ------------ Loss: 8194.0 ------------ Accuracy: 60.4%\n",
            "Step: 4012 ------------ Loss: 8193.84 ------------ Accuracy: 60.4%\n",
            "Step: 4013 ------------ Loss: 8193.68 ------------ Accuracy: 60.4%\n",
            "Step: 4014 ------------ Loss: 8193.53 ------------ Accuracy: 60.4%\n",
            "Step: 4015 ------------ Loss: 8193.37 ------------ Accuracy: 60.4%\n",
            "Step: 4016 ------------ Loss: 8193.21 ------------ Accuracy: 60.4%\n",
            "Step: 4017 ------------ Loss: 8193.05 ------------ Accuracy: 60.4%\n",
            "Step: 4018 ------------ Loss: 8192.89 ------------ Accuracy: 60.4%\n",
            "Step: 4019 ------------ Loss: 8192.73 ------------ Accuracy: 60.4%\n",
            "Step: 4020 ------------ Loss: 8192.57 ------------ Accuracy: 60.4%\n",
            "Step: 4021 ------------ Loss: 8192.42 ------------ Accuracy: 60.4%\n",
            "Step: 4022 ------------ Loss: 8192.26 ------------ Accuracy: 60.4%\n",
            "Step: 4023 ------------ Loss: 8192.1 ------------ Accuracy: 60.4%\n",
            "Step: 4024 ------------ Loss: 8191.94 ------------ Accuracy: 60.4%\n",
            "Step: 4025 ------------ Loss: 8191.79 ------------ Accuracy: 60.5%\n",
            "Step: 4026 ------------ Loss: 8191.63 ------------ Accuracy: 60.4%\n",
            "Step: 4027 ------------ Loss: 8191.47 ------------ Accuracy: 60.4%\n",
            "Step: 4028 ------------ Loss: 8191.32 ------------ Accuracy: 60.4%\n",
            "Step: 4029 ------------ Loss: 8191.16 ------------ Accuracy: 60.4%\n",
            "Step: 4030 ------------ Loss: 8191.0 ------------ Accuracy: 60.4%\n",
            "Step: 4031 ------------ Loss: 8190.84 ------------ Accuracy: 60.4%\n",
            "Step: 4032 ------------ Loss: 8190.68 ------------ Accuracy: 60.4%\n",
            "Step: 4033 ------------ Loss: 8190.52 ------------ Accuracy: 60.4%\n",
            "Step: 4034 ------------ Loss: 8190.37 ------------ Accuracy: 60.4%\n",
            "Step: 4035 ------------ Loss: 8190.21 ------------ Accuracy: 60.4%\n",
            "Step: 4036 ------------ Loss: 8190.05 ------------ Accuracy: 60.4%\n",
            "Step: 4037 ------------ Loss: 8189.89 ------------ Accuracy: 60.4%\n",
            "Step: 4038 ------------ Loss: 8189.74 ------------ Accuracy: 60.5%\n",
            "Step: 4039 ------------ Loss: 8189.58 ------------ Accuracy: 60.5%\n",
            "Step: 4040 ------------ Loss: 8189.41 ------------ Accuracy: 60.4%\n",
            "Step: 4041 ------------ Loss: 8189.25 ------------ Accuracy: 60.4%\n",
            "Step: 4042 ------------ Loss: 8189.1 ------------ Accuracy: 60.4%\n",
            "Step: 4043 ------------ Loss: 8188.94 ------------ Accuracy: 60.4%\n",
            "Step: 4044 ------------ Loss: 8188.78 ------------ Accuracy: 60.4%\n",
            "Step: 4045 ------------ Loss: 8188.62 ------------ Accuracy: 60.4%\n",
            "Step: 4046 ------------ Loss: 8188.46 ------------ Accuracy: 60.4%\n",
            "Step: 4047 ------------ Loss: 8188.3 ------------ Accuracy: 60.4%\n",
            "Step: 4048 ------------ Loss: 8188.14 ------------ Accuracy: 60.4%\n",
            "Step: 4049 ------------ Loss: 8187.99 ------------ Accuracy: 60.4%\n",
            "Step: 4050 ------------ Loss: 8187.83 ------------ Accuracy: 60.4%\n",
            "Step: 4051 ------------ Loss: 8187.67 ------------ Accuracy: 60.4%\n",
            "Step: 4052 ------------ Loss: 8187.51 ------------ Accuracy: 60.4%\n",
            "Step: 4053 ------------ Loss: 8187.35 ------------ Accuracy: 60.4%\n",
            "Step: 4054 ------------ Loss: 8187.2 ------------ Accuracy: 60.4%\n",
            "Step: 4055 ------------ Loss: 8187.04 ------------ Accuracy: 60.4%\n",
            "Step: 4056 ------------ Loss: 8186.88 ------------ Accuracy: 60.4%\n",
            "Step: 4057 ------------ Loss: 8186.72 ------------ Accuracy: 60.4%\n",
            "Step: 4058 ------------ Loss: 8186.56 ------------ Accuracy: 60.4%\n",
            "Step: 4059 ------------ Loss: 8186.4 ------------ Accuracy: 60.4%\n",
            "Step: 4060 ------------ Loss: 8186.25 ------------ Accuracy: 60.4%\n",
            "Step: 4061 ------------ Loss: 8186.09 ------------ Accuracy: 60.4%\n",
            "Step: 4062 ------------ Loss: 8185.93 ------------ Accuracy: 60.4%\n",
            "Step: 4063 ------------ Loss: 8185.77 ------------ Accuracy: 60.4%\n",
            "Step: 4064 ------------ Loss: 8185.61 ------------ Accuracy: 60.4%\n",
            "Step: 4065 ------------ Loss: 8185.45 ------------ Accuracy: 60.4%\n",
            "Step: 4066 ------------ Loss: 8185.3 ------------ Accuracy: 60.4%\n",
            "Step: 4067 ------------ Loss: 8185.14 ------------ Accuracy: 60.4%\n",
            "Step: 4068 ------------ Loss: 8184.98 ------------ Accuracy: 60.4%\n",
            "Step: 4069 ------------ Loss: 8184.82 ------------ Accuracy: 60.4%\n",
            "Step: 4070 ------------ Loss: 8184.67 ------------ Accuracy: 60.4%\n",
            "Step: 4071 ------------ Loss: 8184.51 ------------ Accuracy: 60.4%\n",
            "Step: 4072 ------------ Loss: 8184.35 ------------ Accuracy: 60.4%\n",
            "Step: 4073 ------------ Loss: 8184.19 ------------ Accuracy: 60.4%\n",
            "Step: 4074 ------------ Loss: 8184.03 ------------ Accuracy: 60.4%\n",
            "Step: 4075 ------------ Loss: 8183.88 ------------ Accuracy: 60.4%\n",
            "Step: 4076 ------------ Loss: 8183.72 ------------ Accuracy: 60.4%\n",
            "Step: 4077 ------------ Loss: 8183.56 ------------ Accuracy: 60.4%\n",
            "Step: 4078 ------------ Loss: 8183.4 ------------ Accuracy: 60.4%\n",
            "Step: 4079 ------------ Loss: 8183.24 ------------ Accuracy: 60.4%\n",
            "Step: 4080 ------------ Loss: 8183.09 ------------ Accuracy: 60.4%\n",
            "Step: 4081 ------------ Loss: 8182.93 ------------ Accuracy: 60.4%\n",
            "Step: 4082 ------------ Loss: 8182.77 ------------ Accuracy: 60.4%\n",
            "Step: 4083 ------------ Loss: 8182.61 ------------ Accuracy: 60.4%\n",
            "Step: 4084 ------------ Loss: 8182.46 ------------ Accuracy: 60.5%\n",
            "Step: 4085 ------------ Loss: 8182.3 ------------ Accuracy: 60.5%\n",
            "Step: 4086 ------------ Loss: 8182.14 ------------ Accuracy: 60.4%\n",
            "Step: 4087 ------------ Loss: 8181.98 ------------ Accuracy: 60.4%\n",
            "Step: 4088 ------------ Loss: 8181.82 ------------ Accuracy: 60.4%\n",
            "Step: 4089 ------------ Loss: 8181.66 ------------ Accuracy: 60.4%\n",
            "Step: 4090 ------------ Loss: 8181.5 ------------ Accuracy: 60.4%\n",
            "Step: 4091 ------------ Loss: 8181.35 ------------ Accuracy: 60.4%\n",
            "Step: 4092 ------------ Loss: 8181.19 ------------ Accuracy: 60.4%\n",
            "Step: 4093 ------------ Loss: 8181.03 ------------ Accuracy: 60.4%\n",
            "Step: 4094 ------------ Loss: 8180.87 ------------ Accuracy: 60.4%\n",
            "Step: 4095 ------------ Loss: 8180.71 ------------ Accuracy: 60.4%\n",
            "Step: 4096 ------------ Loss: 8180.56 ------------ Accuracy: 60.4%\n",
            "Step: 4097 ------------ Loss: 8180.4 ------------ Accuracy: 60.4%\n",
            "Step: 4098 ------------ Loss: 8180.24 ------------ Accuracy: 60.4%\n",
            "Step: 4099 ------------ Loss: 8180.08 ------------ Accuracy: 60.4%\n",
            "Step: 4100 ------------ Loss: 8179.92 ------------ Accuracy: 60.4%\n",
            "Step: 4101 ------------ Loss: 8179.77 ------------ Accuracy: 60.4%\n",
            "Step: 4102 ------------ Loss: 8179.61 ------------ Accuracy: 60.4%\n",
            "Step: 4103 ------------ Loss: 8179.45 ------------ Accuracy: 60.4%\n",
            "Step: 4104 ------------ Loss: 8179.29 ------------ Accuracy: 60.4%\n",
            "Step: 4105 ------------ Loss: 8179.14 ------------ Accuracy: 60.4%\n",
            "Step: 4106 ------------ Loss: 8178.98 ------------ Accuracy: 60.4%\n",
            "Step: 4107 ------------ Loss: 8178.82 ------------ Accuracy: 60.4%\n",
            "Step: 4108 ------------ Loss: 8178.66 ------------ Accuracy: 60.4%\n",
            "Step: 4109 ------------ Loss: 8178.5 ------------ Accuracy: 60.4%\n",
            "Step: 4110 ------------ Loss: 8178.35 ------------ Accuracy: 60.4%\n",
            "Step: 4111 ------------ Loss: 8178.19 ------------ Accuracy: 60.4%\n",
            "Step: 4112 ------------ Loss: 8178.03 ------------ Accuracy: 60.4%\n",
            "Step: 4113 ------------ Loss: 8177.87 ------------ Accuracy: 60.4%\n",
            "Step: 4114 ------------ Loss: 8177.72 ------------ Accuracy: 60.4%\n",
            "Step: 4115 ------------ Loss: 8177.56 ------------ Accuracy: 60.4%\n",
            "Step: 4116 ------------ Loss: 8177.4 ------------ Accuracy: 60.4%\n",
            "Step: 4117 ------------ Loss: 8177.24 ------------ Accuracy: 60.4%\n",
            "Step: 4118 ------------ Loss: 8177.09 ------------ Accuracy: 60.4%\n",
            "Step: 4119 ------------ Loss: 8176.93 ------------ Accuracy: 60.4%\n",
            "Step: 4120 ------------ Loss: 8176.77 ------------ Accuracy: 60.4%\n",
            "Step: 4121 ------------ Loss: 8176.62 ------------ Accuracy: 60.4%\n",
            "Step: 4122 ------------ Loss: 8176.46 ------------ Accuracy: 60.4%\n",
            "Step: 4123 ------------ Loss: 8176.31 ------------ Accuracy: 60.4%\n",
            "Step: 4124 ------------ Loss: 8176.15 ------------ Accuracy: 60.4%\n",
            "Step: 4125 ------------ Loss: 8175.99 ------------ Accuracy: 60.4%\n",
            "Step: 4126 ------------ Loss: 8175.83 ------------ Accuracy: 60.4%\n",
            "Step: 4127 ------------ Loss: 8175.68 ------------ Accuracy: 60.4%\n",
            "Step: 4128 ------------ Loss: 8175.52 ------------ Accuracy: 60.4%\n",
            "Step: 4129 ------------ Loss: 8175.36 ------------ Accuracy: 60.4%\n",
            "Step: 4130 ------------ Loss: 8175.2 ------------ Accuracy: 60.4%\n",
            "Step: 4131 ------------ Loss: 8175.05 ------------ Accuracy: 60.4%\n",
            "Step: 4132 ------------ Loss: 8174.89 ------------ Accuracy: 60.4%\n",
            "Step: 4133 ------------ Loss: 8174.73 ------------ Accuracy: 60.4%\n",
            "Step: 4134 ------------ Loss: 8174.57 ------------ Accuracy: 60.4%\n",
            "Step: 4135 ------------ Loss: 8174.42 ------------ Accuracy: 60.4%\n",
            "Step: 4136 ------------ Loss: 8174.26 ------------ Accuracy: 60.4%\n",
            "Step: 4137 ------------ Loss: 8174.1 ------------ Accuracy: 60.4%\n",
            "Step: 4138 ------------ Loss: 8173.95 ------------ Accuracy: 60.4%\n",
            "Step: 4139 ------------ Loss: 8173.8 ------------ Accuracy: 60.4%\n",
            "Step: 4140 ------------ Loss: 8173.63 ------------ Accuracy: 60.4%\n",
            "Step: 4141 ------------ Loss: 8173.47 ------------ Accuracy: 60.4%\n",
            "Step: 4142 ------------ Loss: 8173.32 ------------ Accuracy: 60.4%\n",
            "Step: 4143 ------------ Loss: 8173.16 ------------ Accuracy: 60.4%\n",
            "Step: 4144 ------------ Loss: 8173.0 ------------ Accuracy: 60.4%\n",
            "Step: 4145 ------------ Loss: 8172.84 ------------ Accuracy: 60.4%\n",
            "Step: 4146 ------------ Loss: 8172.69 ------------ Accuracy: 60.4%\n",
            "Step: 4147 ------------ Loss: 8172.53 ------------ Accuracy: 60.4%\n",
            "Step: 4148 ------------ Loss: 8172.37 ------------ Accuracy: 60.4%\n",
            "Step: 4149 ------------ Loss: 8172.21 ------------ Accuracy: 60.4%\n",
            "Step: 4150 ------------ Loss: 8172.06 ------------ Accuracy: 60.4%\n",
            "Step: 4151 ------------ Loss: 8171.9 ------------ Accuracy: 60.4%\n",
            "Step: 4152 ------------ Loss: 8171.74 ------------ Accuracy: 60.4%\n",
            "Step: 4153 ------------ Loss: 8171.59 ------------ Accuracy: 60.4%\n",
            "Step: 4154 ------------ Loss: 8171.43 ------------ Accuracy: 60.4%\n",
            "Step: 4155 ------------ Loss: 8171.27 ------------ Accuracy: 60.4%\n",
            "Step: 4156 ------------ Loss: 8171.11 ------------ Accuracy: 60.4%\n",
            "Step: 4157 ------------ Loss: 8170.96 ------------ Accuracy: 60.4%\n",
            "Step: 4158 ------------ Loss: 8170.8 ------------ Accuracy: 60.4%\n",
            "Step: 4159 ------------ Loss: 8170.64 ------------ Accuracy: 60.4%\n",
            "Step: 4160 ------------ Loss: 8170.48 ------------ Accuracy: 60.4%\n",
            "Step: 4161 ------------ Loss: 8170.33 ------------ Accuracy: 60.4%\n",
            "Step: 4162 ------------ Loss: 8170.17 ------------ Accuracy: 60.4%\n",
            "Step: 4163 ------------ Loss: 8170.01 ------------ Accuracy: 60.4%\n",
            "Step: 4164 ------------ Loss: 8169.86 ------------ Accuracy: 60.4%\n",
            "Step: 4165 ------------ Loss: 8169.7 ------------ Accuracy: 60.4%\n",
            "Step: 4166 ------------ Loss: 8169.54 ------------ Accuracy: 60.4%\n",
            "Step: 4167 ------------ Loss: 8169.38 ------------ Accuracy: 60.4%\n",
            "Step: 4168 ------------ Loss: 8169.23 ------------ Accuracy: 60.4%\n",
            "Step: 4169 ------------ Loss: 8169.08 ------------ Accuracy: 60.4%\n",
            "Step: 4170 ------------ Loss: 8168.92 ------------ Accuracy: 60.4%\n",
            "Step: 4171 ------------ Loss: 8168.76 ------------ Accuracy: 60.4%\n",
            "Step: 4172 ------------ Loss: 8168.6 ------------ Accuracy: 60.4%\n",
            "Step: 4173 ------------ Loss: 8168.44 ------------ Accuracy: 60.4%\n",
            "Step: 4174 ------------ Loss: 8168.28 ------------ Accuracy: 60.4%\n",
            "Step: 4175 ------------ Loss: 8168.12 ------------ Accuracy: 60.4%\n",
            "Step: 4176 ------------ Loss: 8167.97 ------------ Accuracy: 60.4%\n",
            "Step: 4177 ------------ Loss: 8167.81 ------------ Accuracy: 60.4%\n",
            "Step: 4178 ------------ Loss: 8167.65 ------------ Accuracy: 60.4%\n",
            "Step: 4179 ------------ Loss: 8167.5 ------------ Accuracy: 60.4%\n",
            "Step: 4180 ------------ Loss: 8167.34 ------------ Accuracy: 60.4%\n",
            "Step: 4181 ------------ Loss: 8167.18 ------------ Accuracy: 60.4%\n",
            "Step: 4182 ------------ Loss: 8167.02 ------------ Accuracy: 60.4%\n",
            "Step: 4183 ------------ Loss: 8166.87 ------------ Accuracy: 60.4%\n",
            "Step: 4184 ------------ Loss: 8166.71 ------------ Accuracy: 60.4%\n",
            "Step: 4185 ------------ Loss: 8166.55 ------------ Accuracy: 60.4%\n",
            "Step: 4186 ------------ Loss: 8166.4 ------------ Accuracy: 60.4%\n",
            "Step: 4187 ------------ Loss: 8166.24 ------------ Accuracy: 60.4%\n",
            "Step: 4188 ------------ Loss: 8166.08 ------------ Accuracy: 60.4%\n",
            "Step: 4189 ------------ Loss: 8165.93 ------------ Accuracy: 60.4%\n",
            "Step: 4190 ------------ Loss: 8165.77 ------------ Accuracy: 60.4%\n",
            "Step: 4191 ------------ Loss: 8165.61 ------------ Accuracy: 60.4%\n",
            "Step: 4192 ------------ Loss: 8165.46 ------------ Accuracy: 60.4%\n",
            "Step: 4193 ------------ Loss: 8165.3 ------------ Accuracy: 60.4%\n",
            "Step: 4194 ------------ Loss: 8165.14 ------------ Accuracy: 60.4%\n",
            "Step: 4195 ------------ Loss: 8164.99 ------------ Accuracy: 60.4%\n",
            "Step: 4196 ------------ Loss: 8164.83 ------------ Accuracy: 60.4%\n",
            "Step: 4197 ------------ Loss: 8164.67 ------------ Accuracy: 60.4%\n",
            "Step: 4198 ------------ Loss: 8164.51 ------------ Accuracy: 60.4%\n",
            "Step: 4199 ------------ Loss: 8164.36 ------------ Accuracy: 60.4%\n",
            "Step: 4200 ------------ Loss: 8164.2 ------------ Accuracy: 60.4%\n",
            "Step: 4201 ------------ Loss: 8164.06 ------------ Accuracy: 60.4%\n",
            "Step: 4202 ------------ Loss: 8163.9 ------------ Accuracy: 60.4%\n",
            "Step: 4203 ------------ Loss: 8163.74 ------------ Accuracy: 60.4%\n",
            "Step: 4204 ------------ Loss: 8163.58 ------------ Accuracy: 60.4%\n",
            "Step: 4205 ------------ Loss: 8163.43 ------------ Accuracy: 60.4%\n",
            "Step: 4206 ------------ Loss: 8163.27 ------------ Accuracy: 60.4%\n",
            "Step: 4207 ------------ Loss: 8163.11 ------------ Accuracy: 60.4%\n",
            "Step: 4208 ------------ Loss: 8162.96 ------------ Accuracy: 60.4%\n",
            "Step: 4209 ------------ Loss: 8162.8 ------------ Accuracy: 60.4%\n",
            "Step: 4210 ------------ Loss: 8162.64 ------------ Accuracy: 60.4%\n",
            "Step: 4211 ------------ Loss: 8162.49 ------------ Accuracy: 60.4%\n",
            "Step: 4212 ------------ Loss: 8162.33 ------------ Accuracy: 60.4%\n",
            "Step: 4213 ------------ Loss: 8162.17 ------------ Accuracy: 60.4%\n",
            "Step: 4214 ------------ Loss: 8162.02 ------------ Accuracy: 60.4%\n",
            "Step: 4215 ------------ Loss: 8161.86 ------------ Accuracy: 60.4%\n",
            "Step: 4216 ------------ Loss: 8161.7 ------------ Accuracy: 60.4%\n",
            "Step: 4217 ------------ Loss: 8161.55 ------------ Accuracy: 60.4%\n",
            "Step: 4218 ------------ Loss: 8161.39 ------------ Accuracy: 60.4%\n",
            "Step: 4219 ------------ Loss: 8161.24 ------------ Accuracy: 60.4%\n",
            "Step: 4220 ------------ Loss: 8161.08 ------------ Accuracy: 60.4%\n",
            "Step: 4221 ------------ Loss: 8160.92 ------------ Accuracy: 60.4%\n",
            "Step: 4222 ------------ Loss: 8160.76 ------------ Accuracy: 60.4%\n",
            "Step: 4223 ------------ Loss: 8160.6 ------------ Accuracy: 60.4%\n",
            "Step: 4224 ------------ Loss: 8160.45 ------------ Accuracy: 60.4%\n",
            "Step: 4225 ------------ Loss: 8160.29 ------------ Accuracy: 60.4%\n",
            "Step: 4226 ------------ Loss: 8160.13 ------------ Accuracy: 60.4%\n",
            "Step: 4227 ------------ Loss: 8159.98 ------------ Accuracy: 60.4%\n",
            "Step: 4228 ------------ Loss: 8159.82 ------------ Accuracy: 60.4%\n",
            "Step: 4229 ------------ Loss: 8159.66 ------------ Accuracy: 60.4%\n",
            "Step: 4230 ------------ Loss: 8159.51 ------------ Accuracy: 60.4%\n",
            "Step: 4231 ------------ Loss: 8159.35 ------------ Accuracy: 60.4%\n",
            "Step: 4232 ------------ Loss: 8159.2 ------------ Accuracy: 60.4%\n",
            "Step: 4233 ------------ Loss: 8159.04 ------------ Accuracy: 60.4%\n",
            "Step: 4234 ------------ Loss: 8158.88 ------------ Accuracy: 60.4%\n",
            "Step: 4235 ------------ Loss: 8158.73 ------------ Accuracy: 60.4%\n",
            "Step: 4236 ------------ Loss: 8158.57 ------------ Accuracy: 60.4%\n",
            "Step: 4237 ------------ Loss: 8158.41 ------------ Accuracy: 60.4%\n",
            "Step: 4238 ------------ Loss: 8158.26 ------------ Accuracy: 60.4%\n",
            "Step: 4239 ------------ Loss: 8158.1 ------------ Accuracy: 60.4%\n",
            "Step: 4240 ------------ Loss: 8157.94 ------------ Accuracy: 60.4%\n",
            "Step: 4241 ------------ Loss: 8157.79 ------------ Accuracy: 60.4%\n",
            "Step: 4242 ------------ Loss: 8157.63 ------------ Accuracy: 60.4%\n",
            "Step: 4243 ------------ Loss: 8157.47 ------------ Accuracy: 60.4%\n",
            "Step: 4244 ------------ Loss: 8157.32 ------------ Accuracy: 60.4%\n",
            "Step: 4245 ------------ Loss: 8157.16 ------------ Accuracy: 60.4%\n",
            "Step: 4246 ------------ Loss: 8157.01 ------------ Accuracy: 60.4%\n",
            "Step: 4247 ------------ Loss: 8156.85 ------------ Accuracy: 60.4%\n",
            "Step: 4248 ------------ Loss: 8156.69 ------------ Accuracy: 60.4%\n",
            "Step: 4249 ------------ Loss: 8156.54 ------------ Accuracy: 60.4%\n",
            "Step: 4250 ------------ Loss: 8156.38 ------------ Accuracy: 60.4%\n",
            "Step: 4251 ------------ Loss: 8156.22 ------------ Accuracy: 60.4%\n",
            "Step: 4252 ------------ Loss: 8156.07 ------------ Accuracy: 60.4%\n",
            "Step: 4253 ------------ Loss: 8155.91 ------------ Accuracy: 60.4%\n",
            "Step: 4254 ------------ Loss: 8155.76 ------------ Accuracy: 60.4%\n",
            "Step: 4255 ------------ Loss: 8155.6 ------------ Accuracy: 60.4%\n",
            "Step: 4256 ------------ Loss: 8155.46 ------------ Accuracy: 60.4%\n",
            "Step: 4257 ------------ Loss: 8155.3 ------------ Accuracy: 60.4%\n",
            "Step: 4258 ------------ Loss: 8155.14 ------------ Accuracy: 60.4%\n",
            "Step: 4259 ------------ Loss: 8154.98 ------------ Accuracy: 60.4%\n",
            "Step: 4260 ------------ Loss: 8154.83 ------------ Accuracy: 60.4%\n",
            "Step: 4261 ------------ Loss: 8154.67 ------------ Accuracy: 60.4%\n",
            "Step: 4262 ------------ Loss: 8154.52 ------------ Accuracy: 60.4%\n",
            "Step: 4263 ------------ Loss: 8154.36 ------------ Accuracy: 60.4%\n",
            "Step: 4264 ------------ Loss: 8154.21 ------------ Accuracy: 60.4%\n",
            "Step: 4265 ------------ Loss: 8154.05 ------------ Accuracy: 60.4%\n",
            "Step: 4266 ------------ Loss: 8153.89 ------------ Accuracy: 60.4%\n",
            "Step: 4267 ------------ Loss: 8153.74 ------------ Accuracy: 60.4%\n",
            "Step: 4268 ------------ Loss: 8153.58 ------------ Accuracy: 60.4%\n",
            "Step: 4269 ------------ Loss: 8153.43 ------------ Accuracy: 60.4%\n",
            "Step: 4270 ------------ Loss: 8153.27 ------------ Accuracy: 60.4%\n",
            "Step: 4271 ------------ Loss: 8153.11 ------------ Accuracy: 60.4%\n",
            "Step: 4272 ------------ Loss: 8152.96 ------------ Accuracy: 60.4%\n",
            "Step: 4273 ------------ Loss: 8152.81 ------------ Accuracy: 60.4%\n",
            "Step: 4274 ------------ Loss: 8152.65 ------------ Accuracy: 60.4%\n",
            "Step: 4275 ------------ Loss: 8152.49 ------------ Accuracy: 60.4%\n",
            "Step: 4276 ------------ Loss: 8152.33 ------------ Accuracy: 60.4%\n",
            "Step: 4277 ------------ Loss: 8152.18 ------------ Accuracy: 60.4%\n",
            "Step: 4278 ------------ Loss: 8152.02 ------------ Accuracy: 60.4%\n",
            "Step: 4279 ------------ Loss: 8151.87 ------------ Accuracy: 60.4%\n",
            "Step: 4280 ------------ Loss: 8151.71 ------------ Accuracy: 60.4%\n",
            "Step: 4281 ------------ Loss: 8151.55 ------------ Accuracy: 60.4%\n",
            "Step: 4282 ------------ Loss: 8151.4 ------------ Accuracy: 60.4%\n",
            "Step: 4283 ------------ Loss: 8151.24 ------------ Accuracy: 60.4%\n",
            "Step: 4284 ------------ Loss: 8151.09 ------------ Accuracy: 60.4%\n",
            "Step: 4285 ------------ Loss: 8150.93 ------------ Accuracy: 60.4%\n",
            "Step: 4286 ------------ Loss: 8150.77 ------------ Accuracy: 60.4%\n",
            "Step: 4287 ------------ Loss: 8150.62 ------------ Accuracy: 60.4%\n",
            "Step: 4288 ------------ Loss: 8150.46 ------------ Accuracy: 60.4%\n",
            "Step: 4289 ------------ Loss: 8150.31 ------------ Accuracy: 60.4%\n",
            "Step: 4290 ------------ Loss: 8150.15 ------------ Accuracy: 60.4%\n",
            "Step: 4291 ------------ Loss: 8149.99 ------------ Accuracy: 60.4%\n",
            "Step: 4292 ------------ Loss: 8149.84 ------------ Accuracy: 60.4%\n",
            "Step: 4293 ------------ Loss: 8149.68 ------------ Accuracy: 60.4%\n",
            "Step: 4294 ------------ Loss: 8149.53 ------------ Accuracy: 60.4%\n",
            "Step: 4295 ------------ Loss: 8149.37 ------------ Accuracy: 60.4%\n",
            "Step: 4296 ------------ Loss: 8149.22 ------------ Accuracy: 60.4%\n",
            "Step: 4297 ------------ Loss: 8149.06 ------------ Accuracy: 60.4%\n",
            "Step: 4298 ------------ Loss: 8148.9 ------------ Accuracy: 60.4%\n",
            "Step: 4299 ------------ Loss: 8148.75 ------------ Accuracy: 60.4%\n",
            "Step: 4300 ------------ Loss: 8148.59 ------------ Accuracy: 60.4%\n",
            "Step: 4301 ------------ Loss: 8148.44 ------------ Accuracy: 60.4%\n",
            "Step: 4302 ------------ Loss: 8148.28 ------------ Accuracy: 60.4%\n",
            "Step: 4303 ------------ Loss: 8148.13 ------------ Accuracy: 60.4%\n",
            "Step: 4304 ------------ Loss: 8147.97 ------------ Accuracy: 60.4%\n",
            "Step: 4305 ------------ Loss: 8147.82 ------------ Accuracy: 60.4%\n",
            "Step: 4306 ------------ Loss: 8147.66 ------------ Accuracy: 60.4%\n",
            "Step: 4307 ------------ Loss: 8147.5 ------------ Accuracy: 60.4%\n",
            "Step: 4308 ------------ Loss: 8147.36 ------------ Accuracy: 60.5%\n",
            "Step: 4309 ------------ Loss: 8147.2 ------------ Accuracy: 60.4%\n",
            "Step: 4310 ------------ Loss: 8147.05 ------------ Accuracy: 60.4%\n",
            "Step: 4311 ------------ Loss: 8146.89 ------------ Accuracy: 60.4%\n",
            "Step: 4312 ------------ Loss: 8146.74 ------------ Accuracy: 60.4%\n",
            "Step: 4313 ------------ Loss: 8146.58 ------------ Accuracy: 60.4%\n",
            "Step: 4314 ------------ Loss: 8146.42 ------------ Accuracy: 60.4%\n",
            "Step: 4315 ------------ Loss: 8146.27 ------------ Accuracy: 60.4%\n",
            "Step: 4316 ------------ Loss: 8146.11 ------------ Accuracy: 60.4%\n",
            "Step: 4317 ------------ Loss: 8145.96 ------------ Accuracy: 60.4%\n",
            "Step: 4318 ------------ Loss: 8145.8 ------------ Accuracy: 60.4%\n",
            "Step: 4319 ------------ Loss: 8145.65 ------------ Accuracy: 60.4%\n",
            "Step: 4320 ------------ Loss: 8145.49 ------------ Accuracy: 60.4%\n",
            "Step: 4321 ------------ Loss: 8145.33 ------------ Accuracy: 60.4%\n",
            "Step: 4322 ------------ Loss: 8145.18 ------------ Accuracy: 60.4%\n",
            "Step: 4323 ------------ Loss: 8145.02 ------------ Accuracy: 60.4%\n",
            "Step: 4324 ------------ Loss: 8144.87 ------------ Accuracy: 60.4%\n",
            "Step: 4325 ------------ Loss: 8144.71 ------------ Accuracy: 60.4%\n",
            "Step: 4326 ------------ Loss: 8144.56 ------------ Accuracy: 60.4%\n",
            "Step: 4327 ------------ Loss: 8144.41 ------------ Accuracy: 60.5%\n",
            "Step: 4328 ------------ Loss: 8144.25 ------------ Accuracy: 60.5%\n",
            "Step: 4329 ------------ Loss: 8144.09 ------------ Accuracy: 60.5%\n",
            "Step: 4330 ------------ Loss: 8143.93 ------------ Accuracy: 60.5%\n",
            "Step: 4331 ------------ Loss: 8143.78 ------------ Accuracy: 60.5%\n",
            "Step: 4332 ------------ Loss: 8143.62 ------------ Accuracy: 60.5%\n",
            "Step: 4333 ------------ Loss: 8143.47 ------------ Accuracy: 60.5%\n",
            "Step: 4334 ------------ Loss: 8143.31 ------------ Accuracy: 60.5%\n",
            "Step: 4335 ------------ Loss: 8143.15 ------------ Accuracy: 60.5%\n",
            "Step: 4336 ------------ Loss: 8143.0 ------------ Accuracy: 60.5%\n",
            "Step: 4337 ------------ Loss: 8142.84 ------------ Accuracy: 60.5%\n",
            "Step: 4338 ------------ Loss: 8142.69 ------------ Accuracy: 60.5%\n",
            "Step: 4339 ------------ Loss: 8142.53 ------------ Accuracy: 60.5%\n",
            "Step: 4340 ------------ Loss: 8142.38 ------------ Accuracy: 60.5%\n",
            "Step: 4341 ------------ Loss: 8142.22 ------------ Accuracy: 60.5%\n",
            "Step: 4342 ------------ Loss: 8142.07 ------------ Accuracy: 60.5%\n",
            "Step: 4343 ------------ Loss: 8141.91 ------------ Accuracy: 60.5%\n",
            "Step: 4344 ------------ Loss: 8141.75 ------------ Accuracy: 60.5%\n",
            "Step: 4345 ------------ Loss: 8141.6 ------------ Accuracy: 60.5%\n",
            "Step: 4346 ------------ Loss: 8141.44 ------------ Accuracy: 60.5%\n",
            "Step: 4347 ------------ Loss: 8141.29 ------------ Accuracy: 60.5%\n",
            "Step: 4348 ------------ Loss: 8141.13 ------------ Accuracy: 60.5%\n",
            "Step: 4349 ------------ Loss: 8140.98 ------------ Accuracy: 60.5%\n",
            "Step: 4350 ------------ Loss: 8140.82 ------------ Accuracy: 60.5%\n",
            "Step: 4351 ------------ Loss: 8140.67 ------------ Accuracy: 60.5%\n",
            "Step: 4352 ------------ Loss: 8140.51 ------------ Accuracy: 60.5%\n",
            "Step: 4353 ------------ Loss: 8140.36 ------------ Accuracy: 60.5%\n",
            "Step: 4354 ------------ Loss: 8140.2 ------------ Accuracy: 60.5%\n",
            "Step: 4355 ------------ Loss: 8140.05 ------------ Accuracy: 60.5%\n",
            "Step: 4356 ------------ Loss: 8139.89 ------------ Accuracy: 60.5%\n",
            "Step: 4357 ------------ Loss: 8139.74 ------------ Accuracy: 60.5%\n",
            "Step: 4358 ------------ Loss: 8139.58 ------------ Accuracy: 60.5%\n",
            "Step: 4359 ------------ Loss: 8139.43 ------------ Accuracy: 60.5%\n",
            "Step: 4360 ------------ Loss: 8139.27 ------------ Accuracy: 60.5%\n",
            "Step: 4361 ------------ Loss: 8139.12 ------------ Accuracy: 60.5%\n",
            "Step: 4362 ------------ Loss: 8138.96 ------------ Accuracy: 60.5%\n",
            "Step: 4363 ------------ Loss: 8138.82 ------------ Accuracy: 60.5%\n",
            "Step: 4364 ------------ Loss: 8138.66 ------------ Accuracy: 60.5%\n",
            "Step: 4365 ------------ Loss: 8138.51 ------------ Accuracy: 60.5%\n",
            "Step: 4366 ------------ Loss: 8138.35 ------------ Accuracy: 60.5%\n",
            "Step: 4367 ------------ Loss: 8138.19 ------------ Accuracy: 60.5%\n",
            "Step: 4368 ------------ Loss: 8138.04 ------------ Accuracy: 60.5%\n",
            "Step: 4369 ------------ Loss: 8137.88 ------------ Accuracy: 60.5%\n",
            "Step: 4370 ------------ Loss: 8137.73 ------------ Accuracy: 60.5%\n",
            "Step: 4371 ------------ Loss: 8137.57 ------------ Accuracy: 60.5%\n",
            "Step: 4372 ------------ Loss: 8137.42 ------------ Accuracy: 60.5%\n",
            "Step: 4373 ------------ Loss: 8137.26 ------------ Accuracy: 60.5%\n",
            "Step: 4374 ------------ Loss: 8137.11 ------------ Accuracy: 60.5%\n",
            "Step: 4375 ------------ Loss: 8136.96 ------------ Accuracy: 60.5%\n",
            "Step: 4376 ------------ Loss: 8136.8 ------------ Accuracy: 60.5%\n",
            "Step: 4377 ------------ Loss: 8136.65 ------------ Accuracy: 60.5%\n",
            "Step: 4378 ------------ Loss: 8136.49 ------------ Accuracy: 60.5%\n",
            "Step: 4379 ------------ Loss: 8136.34 ------------ Accuracy: 60.5%\n",
            "Step: 4380 ------------ Loss: 8136.19 ------------ Accuracy: 60.5%\n",
            "Step: 4381 ------------ Loss: 8136.03 ------------ Accuracy: 60.5%\n",
            "Step: 4382 ------------ Loss: 8135.87 ------------ Accuracy: 60.5%\n",
            "Step: 4383 ------------ Loss: 8135.71 ------------ Accuracy: 60.5%\n",
            "Step: 4384 ------------ Loss: 8135.56 ------------ Accuracy: 60.5%\n",
            "Step: 4385 ------------ Loss: 8135.4 ------------ Accuracy: 60.5%\n",
            "Step: 4386 ------------ Loss: 8135.25 ------------ Accuracy: 60.5%\n",
            "Step: 4387 ------------ Loss: 8135.09 ------------ Accuracy: 60.5%\n",
            "Step: 4388 ------------ Loss: 8134.94 ------------ Accuracy: 60.5%\n",
            "Step: 4389 ------------ Loss: 8134.78 ------------ Accuracy: 60.5%\n",
            "Step: 4390 ------------ Loss: 8134.63 ------------ Accuracy: 60.5%\n",
            "Step: 4391 ------------ Loss: 8134.47 ------------ Accuracy: 60.5%\n",
            "Step: 4392 ------------ Loss: 8134.32 ------------ Accuracy: 60.5%\n",
            "Step: 4393 ------------ Loss: 8134.16 ------------ Accuracy: 60.5%\n",
            "Step: 4394 ------------ Loss: 8134.01 ------------ Accuracy: 60.5%\n",
            "Step: 4395 ------------ Loss: 8133.85 ------------ Accuracy: 60.5%\n",
            "Step: 4396 ------------ Loss: 8133.7 ------------ Accuracy: 60.5%\n",
            "Step: 4397 ------------ Loss: 8133.54 ------------ Accuracy: 60.5%\n",
            "Step: 4398 ------------ Loss: 8133.39 ------------ Accuracy: 60.5%\n",
            "Step: 4399 ------------ Loss: 8133.23 ------------ Accuracy: 60.5%\n",
            "Step: 4400 ------------ Loss: 8133.08 ------------ Accuracy: 60.5%\n",
            "Step: 4401 ------------ Loss: 8132.92 ------------ Accuracy: 60.5%\n",
            "Step: 4402 ------------ Loss: 8132.77 ------------ Accuracy: 60.5%\n",
            "Step: 4403 ------------ Loss: 8132.61 ------------ Accuracy: 60.5%\n",
            "Step: 4404 ------------ Loss: 8132.46 ------------ Accuracy: 60.5%\n",
            "Step: 4405 ------------ Loss: 8132.31 ------------ Accuracy: 60.5%\n",
            "Step: 4406 ------------ Loss: 8132.15 ------------ Accuracy: 60.5%\n",
            "Step: 4407 ------------ Loss: 8132.0 ------------ Accuracy: 60.5%\n",
            "Step: 4408 ------------ Loss: 8131.84 ------------ Accuracy: 60.5%\n",
            "Step: 4409 ------------ Loss: 8131.69 ------------ Accuracy: 60.5%\n",
            "Step: 4410 ------------ Loss: 8131.53 ------------ Accuracy: 60.5%\n",
            "Step: 4411 ------------ Loss: 8131.38 ------------ Accuracy: 60.5%\n",
            "Step: 4412 ------------ Loss: 8131.22 ------------ Accuracy: 60.5%\n",
            "Step: 4413 ------------ Loss: 8131.07 ------------ Accuracy: 60.5%\n",
            "Step: 4414 ------------ Loss: 8130.91 ------------ Accuracy: 60.5%\n",
            "Step: 4415 ------------ Loss: 8130.76 ------------ Accuracy: 60.5%\n",
            "Step: 4416 ------------ Loss: 8130.61 ------------ Accuracy: 60.5%\n",
            "Step: 4417 ------------ Loss: 8130.45 ------------ Accuracy: 60.5%\n",
            "Step: 4418 ------------ Loss: 8130.31 ------------ Accuracy: 60.5%\n",
            "Step: 4419 ------------ Loss: 8130.14 ------------ Accuracy: 60.5%\n",
            "Step: 4420 ------------ Loss: 8129.99 ------------ Accuracy: 60.5%\n",
            "Step: 4421 ------------ Loss: 8129.83 ------------ Accuracy: 60.5%\n",
            "Step: 4422 ------------ Loss: 8129.68 ------------ Accuracy: 60.5%\n",
            "Step: 4423 ------------ Loss: 8129.52 ------------ Accuracy: 60.5%\n",
            "Step: 4424 ------------ Loss: 8129.37 ------------ Accuracy: 60.5%\n",
            "Step: 4425 ------------ Loss: 8129.21 ------------ Accuracy: 60.5%\n",
            "Step: 4426 ------------ Loss: 8129.06 ------------ Accuracy: 60.5%\n",
            "Step: 4427 ------------ Loss: 8128.9 ------------ Accuracy: 60.5%\n",
            "Step: 4428 ------------ Loss: 8128.75 ------------ Accuracy: 60.5%\n",
            "Step: 4429 ------------ Loss: 8128.59 ------------ Accuracy: 60.5%\n",
            "Step: 4430 ------------ Loss: 8128.44 ------------ Accuracy: 60.5%\n",
            "Step: 4431 ------------ Loss: 8128.29 ------------ Accuracy: 60.5%\n",
            "Step: 4432 ------------ Loss: 8128.13 ------------ Accuracy: 60.5%\n",
            "Step: 4433 ------------ Loss: 8127.98 ------------ Accuracy: 60.5%\n",
            "Step: 4434 ------------ Loss: 8127.82 ------------ Accuracy: 60.5%\n",
            "Step: 4435 ------------ Loss: 8127.67 ------------ Accuracy: 60.5%\n",
            "Step: 4436 ------------ Loss: 8127.51 ------------ Accuracy: 60.5%\n",
            "Step: 4437 ------------ Loss: 8127.36 ------------ Accuracy: 60.5%\n",
            "Step: 4438 ------------ Loss: 8127.21 ------------ Accuracy: 60.5%\n",
            "Step: 4439 ------------ Loss: 8127.05 ------------ Accuracy: 60.5%\n",
            "Step: 4440 ------------ Loss: 8126.9 ------------ Accuracy: 60.5%\n",
            "Step: 4441 ------------ Loss: 8126.74 ------------ Accuracy: 60.5%\n",
            "Step: 4442 ------------ Loss: 8126.59 ------------ Accuracy: 60.5%\n",
            "Step: 4443 ------------ Loss: 8126.43 ------------ Accuracy: 60.5%\n",
            "Step: 4444 ------------ Loss: 8126.28 ------------ Accuracy: 60.5%\n",
            "Step: 4445 ------------ Loss: 8126.13 ------------ Accuracy: 60.5%\n",
            "Step: 4446 ------------ Loss: 8125.97 ------------ Accuracy: 60.5%\n",
            "Step: 4447 ------------ Loss: 8125.82 ------------ Accuracy: 60.5%\n",
            "Step: 4448 ------------ Loss: 8125.66 ------------ Accuracy: 60.5%\n",
            "Step: 4449 ------------ Loss: 8125.52 ------------ Accuracy: 60.4%\n",
            "Step: 4450 ------------ Loss: 8125.36 ------------ Accuracy: 60.5%\n",
            "Step: 4451 ------------ Loss: 8125.21 ------------ Accuracy: 60.5%\n",
            "Step: 4452 ------------ Loss: 8125.05 ------------ Accuracy: 60.5%\n",
            "Step: 4453 ------------ Loss: 8124.9 ------------ Accuracy: 60.5%\n",
            "Step: 4454 ------------ Loss: 8124.75 ------------ Accuracy: 60.5%\n",
            "Step: 4455 ------------ Loss: 8124.59 ------------ Accuracy: 60.5%\n",
            "Step: 4456 ------------ Loss: 8124.44 ------------ Accuracy: 60.5%\n",
            "Step: 4457 ------------ Loss: 8124.28 ------------ Accuracy: 60.5%\n",
            "Step: 4458 ------------ Loss: 8124.13 ------------ Accuracy: 60.5%\n",
            "Step: 4459 ------------ Loss: 8123.98 ------------ Accuracy: 60.5%\n",
            "Step: 4460 ------------ Loss: 8123.82 ------------ Accuracy: 60.5%\n",
            "Step: 4461 ------------ Loss: 8123.67 ------------ Accuracy: 60.5%\n",
            "Step: 4462 ------------ Loss: 8123.51 ------------ Accuracy: 60.5%\n",
            "Step: 4463 ------------ Loss: 8123.36 ------------ Accuracy: 60.5%\n",
            "Step: 4464 ------------ Loss: 8123.21 ------------ Accuracy: 60.5%\n",
            "Step: 4465 ------------ Loss: 8123.05 ------------ Accuracy: 60.5%\n",
            "Step: 4466 ------------ Loss: 8122.9 ------------ Accuracy: 60.5%\n",
            "Step: 4467 ------------ Loss: 8122.75 ------------ Accuracy: 60.5%\n",
            "Step: 4468 ------------ Loss: 8122.59 ------------ Accuracy: 60.5%\n",
            "Step: 4469 ------------ Loss: 8122.44 ------------ Accuracy: 60.5%\n",
            "Step: 4470 ------------ Loss: 8122.28 ------------ Accuracy: 60.5%\n",
            "Step: 4471 ------------ Loss: 8122.13 ------------ Accuracy: 60.5%\n",
            "Step: 4472 ------------ Loss: 8121.99 ------------ Accuracy: 60.5%\n",
            "Step: 4473 ------------ Loss: 8121.82 ------------ Accuracy: 60.6%\n",
            "Step: 4474 ------------ Loss: 8121.67 ------------ Accuracy: 60.4%\n",
            "Step: 4475 ------------ Loss: 8121.51 ------------ Accuracy: 60.5%\n",
            "Step: 4476 ------------ Loss: 8121.36 ------------ Accuracy: 60.5%\n",
            "Step: 4477 ------------ Loss: 8121.2 ------------ Accuracy: 60.5%\n",
            "Step: 4478 ------------ Loss: 8121.05 ------------ Accuracy: 60.5%\n",
            "Step: 4479 ------------ Loss: 8120.89 ------------ Accuracy: 60.5%\n",
            "Step: 4480 ------------ Loss: 8120.74 ------------ Accuracy: 60.5%\n",
            "Step: 4481 ------------ Loss: 8120.59 ------------ Accuracy: 60.5%\n",
            "Step: 4482 ------------ Loss: 8120.43 ------------ Accuracy: 60.5%\n",
            "Step: 4483 ------------ Loss: 8120.28 ------------ Accuracy: 60.5%\n",
            "Step: 4484 ------------ Loss: 8120.13 ------------ Accuracy: 60.4%\n",
            "Step: 4485 ------------ Loss: 8119.98 ------------ Accuracy: 60.5%\n",
            "Step: 4486 ------------ Loss: 8119.83 ------------ Accuracy: 60.6%\n",
            "Step: 4487 ------------ Loss: 8119.67 ------------ Accuracy: 60.6%\n",
            "Step: 4488 ------------ Loss: 8119.51 ------------ Accuracy: 60.6%\n",
            "Step: 4489 ------------ Loss: 8119.36 ------------ Accuracy: 60.6%\n",
            "Step: 4490 ------------ Loss: 8119.2 ------------ Accuracy: 60.6%\n",
            "Step: 4491 ------------ Loss: 8119.05 ------------ Accuracy: 60.6%\n",
            "Step: 4492 ------------ Loss: 8118.9 ------------ Accuracy: 60.6%\n",
            "Step: 4493 ------------ Loss: 8118.74 ------------ Accuracy: 60.6%\n",
            "Step: 4494 ------------ Loss: 8118.59 ------------ Accuracy: 60.6%\n",
            "Step: 4495 ------------ Loss: 8118.43 ------------ Accuracy: 60.6%\n",
            "Step: 4496 ------------ Loss: 8118.28 ------------ Accuracy: 60.6%\n",
            "Step: 4497 ------------ Loss: 8118.13 ------------ Accuracy: 60.6%\n",
            "Step: 4498 ------------ Loss: 8117.97 ------------ Accuracy: 60.6%\n",
            "Step: 4499 ------------ Loss: 8117.82 ------------ Accuracy: 60.6%\n",
            "Step: 4500 ------------ Loss: 8117.67 ------------ Accuracy: 60.6%\n",
            "Step: 4501 ------------ Loss: 8117.51 ------------ Accuracy: 60.6%\n",
            "Step: 4502 ------------ Loss: 8117.36 ------------ Accuracy: 60.6%\n",
            "Step: 4503 ------------ Loss: 8117.2 ------------ Accuracy: 60.6%\n",
            "Step: 4504 ------------ Loss: 8117.05 ------------ Accuracy: 60.6%\n",
            "Step: 4505 ------------ Loss: 8116.9 ------------ Accuracy: 60.6%\n",
            "Step: 4506 ------------ Loss: 8116.74 ------------ Accuracy: 60.6%\n",
            "Step: 4507 ------------ Loss: 8116.59 ------------ Accuracy: 60.6%\n",
            "Step: 4508 ------------ Loss: 8116.44 ------------ Accuracy: 60.6%\n",
            "Step: 4509 ------------ Loss: 8116.28 ------------ Accuracy: 60.6%\n",
            "Step: 4510 ------------ Loss: 8116.13 ------------ Accuracy: 60.6%\n",
            "Step: 4511 ------------ Loss: 8115.98 ------------ Accuracy: 60.6%\n",
            "Step: 4512 ------------ Loss: 8115.82 ------------ Accuracy: 60.6%\n",
            "Step: 4513 ------------ Loss: 8115.67 ------------ Accuracy: 60.6%\n",
            "Step: 4514 ------------ Loss: 8115.52 ------------ Accuracy: 60.6%\n",
            "Step: 4515 ------------ Loss: 8115.36 ------------ Accuracy: 60.6%\n",
            "Step: 4516 ------------ Loss: 8115.21 ------------ Accuracy: 60.6%\n",
            "Step: 4517 ------------ Loss: 8115.06 ------------ Accuracy: 60.6%\n",
            "Step: 4518 ------------ Loss: 8114.9 ------------ Accuracy: 60.6%\n",
            "Step: 4519 ------------ Loss: 8114.75 ------------ Accuracy: 60.6%\n",
            "Step: 4520 ------------ Loss: 8114.6 ------------ Accuracy: 60.6%\n",
            "Step: 4521 ------------ Loss: 8114.44 ------------ Accuracy: 60.6%\n",
            "Step: 4522 ------------ Loss: 8114.29 ------------ Accuracy: 60.6%\n",
            "Step: 4523 ------------ Loss: 8114.14 ------------ Accuracy: 60.6%\n",
            "Step: 4524 ------------ Loss: 8113.98 ------------ Accuracy: 60.6%\n",
            "Step: 4525 ------------ Loss: 8113.83 ------------ Accuracy: 60.6%\n",
            "Step: 4526 ------------ Loss: 8113.68 ------------ Accuracy: 60.6%\n",
            "Step: 4527 ------------ Loss: 8113.52 ------------ Accuracy: 60.6%\n",
            "Step: 4528 ------------ Loss: 8113.37 ------------ Accuracy: 60.6%\n",
            "Step: 4529 ------------ Loss: 8113.22 ------------ Accuracy: 60.6%\n",
            "Step: 4530 ------------ Loss: 8113.06 ------------ Accuracy: 60.6%\n",
            "Step: 4531 ------------ Loss: 8112.91 ------------ Accuracy: 60.6%\n",
            "Step: 4532 ------------ Loss: 8112.77 ------------ Accuracy: 60.6%\n",
            "Step: 4533 ------------ Loss: 8112.61 ------------ Accuracy: 60.7%\n",
            "Step: 4534 ------------ Loss: 8112.46 ------------ Accuracy: 60.6%\n",
            "Step: 4535 ------------ Loss: 8112.3 ------------ Accuracy: 60.6%\n",
            "Step: 4536 ------------ Loss: 8112.15 ------------ Accuracy: 60.6%\n",
            "Step: 4537 ------------ Loss: 8112.0 ------------ Accuracy: 60.6%\n",
            "Step: 4538 ------------ Loss: 8111.85 ------------ Accuracy: 60.6%\n",
            "Step: 4539 ------------ Loss: 8111.69 ------------ Accuracy: 60.6%\n",
            "Step: 4540 ------------ Loss: 8111.54 ------------ Accuracy: 60.6%\n",
            "Step: 4541 ------------ Loss: 8111.39 ------------ Accuracy: 60.6%\n",
            "Step: 4542 ------------ Loss: 8111.23 ------------ Accuracy: 60.6%\n",
            "Step: 4543 ------------ Loss: 8111.08 ------------ Accuracy: 60.6%\n",
            "Step: 4544 ------------ Loss: 8110.93 ------------ Accuracy: 60.6%\n",
            "Step: 4545 ------------ Loss: 8110.77 ------------ Accuracy: 60.6%\n",
            "Step: 4546 ------------ Loss: 8110.62 ------------ Accuracy: 60.6%\n",
            "Step: 4547 ------------ Loss: 8110.47 ------------ Accuracy: 60.6%\n",
            "Step: 4548 ------------ Loss: 8110.32 ------------ Accuracy: 60.5%\n",
            "Step: 4549 ------------ Loss: 8110.16 ------------ Accuracy: 60.5%\n",
            "Step: 4550 ------------ Loss: 8110.01 ------------ Accuracy: 60.5%\n",
            "Step: 4551 ------------ Loss: 8109.85 ------------ Accuracy: 60.6%\n",
            "Step: 4552 ------------ Loss: 8109.7 ------------ Accuracy: 60.6%\n",
            "Step: 4553 ------------ Loss: 8109.55 ------------ Accuracy: 60.6%\n",
            "Step: 4554 ------------ Loss: 8109.39 ------------ Accuracy: 60.6%\n",
            "Step: 4555 ------------ Loss: 8109.24 ------------ Accuracy: 60.6%\n",
            "Step: 4556 ------------ Loss: 8109.09 ------------ Accuracy: 60.6%\n",
            "Step: 4557 ------------ Loss: 8108.93 ------------ Accuracy: 60.6%\n",
            "Step: 4558 ------------ Loss: 8108.78 ------------ Accuracy: 60.6%\n",
            "Step: 4559 ------------ Loss: 8108.63 ------------ Accuracy: 60.6%\n",
            "Step: 4560 ------------ Loss: 8108.48 ------------ Accuracy: 60.6%\n",
            "Step: 4561 ------------ Loss: 8108.32 ------------ Accuracy: 60.6%\n",
            "Step: 4562 ------------ Loss: 8108.17 ------------ Accuracy: 60.6%\n",
            "Step: 4563 ------------ Loss: 8108.02 ------------ Accuracy: 60.6%\n",
            "Step: 4564 ------------ Loss: 8107.86 ------------ Accuracy: 60.6%\n",
            "Step: 4565 ------------ Loss: 8107.71 ------------ Accuracy: 60.6%\n",
            "Step: 4566 ------------ Loss: 8107.56 ------------ Accuracy: 60.6%\n",
            "Step: 4567 ------------ Loss: 8107.4 ------------ Accuracy: 60.6%\n",
            "Step: 4568 ------------ Loss: 8107.25 ------------ Accuracy: 60.6%\n",
            "Step: 4569 ------------ Loss: 8107.1 ------------ Accuracy: 60.6%\n",
            "Step: 4570 ------------ Loss: 8106.95 ------------ Accuracy: 60.6%\n",
            "Step: 4571 ------------ Loss: 8106.79 ------------ Accuracy: 60.6%\n",
            "Step: 4572 ------------ Loss: 8106.64 ------------ Accuracy: 60.6%\n",
            "Step: 4573 ------------ Loss: 8106.49 ------------ Accuracy: 60.6%\n",
            "Step: 4574 ------------ Loss: 8106.34 ------------ Accuracy: 60.6%\n",
            "Step: 4575 ------------ Loss: 8106.18 ------------ Accuracy: 60.6%\n",
            "Step: 4576 ------------ Loss: 8106.03 ------------ Accuracy: 60.6%\n",
            "Step: 4577 ------------ Loss: 8105.89 ------------ Accuracy: 60.6%\n",
            "Step: 4578 ------------ Loss: 8105.73 ------------ Accuracy: 60.6%\n",
            "Step: 4579 ------------ Loss: 8105.57 ------------ Accuracy: 60.6%\n",
            "Step: 4580 ------------ Loss: 8105.42 ------------ Accuracy: 60.6%\n",
            "Step: 4581 ------------ Loss: 8105.27 ------------ Accuracy: 60.7%\n",
            "Step: 4582 ------------ Loss: 8105.11 ------------ Accuracy: 60.7%\n",
            "Step: 4583 ------------ Loss: 8104.96 ------------ Accuracy: 60.7%\n",
            "Step: 4584 ------------ Loss: 8104.81 ------------ Accuracy: 60.7%\n",
            "Step: 4585 ------------ Loss: 8104.66 ------------ Accuracy: 60.7%\n",
            "Step: 4586 ------------ Loss: 8104.5 ------------ Accuracy: 60.7%\n",
            "Step: 4587 ------------ Loss: 8104.35 ------------ Accuracy: 60.7%\n",
            "Step: 4588 ------------ Loss: 8104.2 ------------ Accuracy: 60.7%\n",
            "Step: 4589 ------------ Loss: 8104.04 ------------ Accuracy: 60.7%\n",
            "Step: 4590 ------------ Loss: 8103.89 ------------ Accuracy: 60.7%\n",
            "Step: 4591 ------------ Loss: 8103.74 ------------ Accuracy: 60.7%\n",
            "Step: 4592 ------------ Loss: 8103.59 ------------ Accuracy: 60.7%\n",
            "Step: 4593 ------------ Loss: 8103.43 ------------ Accuracy: 60.7%\n",
            "Step: 4594 ------------ Loss: 8103.28 ------------ Accuracy: 60.7%\n",
            "Step: 4595 ------------ Loss: 8103.13 ------------ Accuracy: 60.7%\n",
            "Step: 4596 ------------ Loss: 8102.98 ------------ Accuracy: 60.7%\n",
            "Step: 4597 ------------ Loss: 8102.82 ------------ Accuracy: 60.7%\n",
            "Step: 4598 ------------ Loss: 8102.67 ------------ Accuracy: 60.7%\n",
            "Step: 4599 ------------ Loss: 8102.52 ------------ Accuracy: 60.7%\n",
            "Step: 4600 ------------ Loss: 8102.37 ------------ Accuracy: 60.7%\n",
            "Step: 4601 ------------ Loss: 8102.21 ------------ Accuracy: 60.7%\n",
            "Step: 4602 ------------ Loss: 8102.06 ------------ Accuracy: 60.7%\n",
            "Step: 4603 ------------ Loss: 8101.91 ------------ Accuracy: 60.7%\n",
            "Step: 4604 ------------ Loss: 8101.76 ------------ Accuracy: 60.7%\n",
            "Step: 4605 ------------ Loss: 8101.6 ------------ Accuracy: 60.7%\n",
            "Step: 4606 ------------ Loss: 8101.45 ------------ Accuracy: 60.6%\n",
            "Step: 4607 ------------ Loss: 8101.3 ------------ Accuracy: 60.6%\n",
            "Step: 4608 ------------ Loss: 8101.16 ------------ Accuracy: 60.6%\n",
            "Step: 4609 ------------ Loss: 8101.0 ------------ Accuracy: 60.6%\n",
            "Step: 4610 ------------ Loss: 8100.85 ------------ Accuracy: 60.6%\n",
            "Step: 4611 ------------ Loss: 8100.7 ------------ Accuracy: 60.6%\n",
            "Step: 4612 ------------ Loss: 8100.55 ------------ Accuracy: 60.6%\n",
            "Step: 4613 ------------ Loss: 8100.39 ------------ Accuracy: 60.6%\n",
            "Step: 4614 ------------ Loss: 8100.24 ------------ Accuracy: 60.6%\n",
            "Step: 4615 ------------ Loss: 8100.09 ------------ Accuracy: 60.6%\n",
            "Step: 4616 ------------ Loss: 8099.94 ------------ Accuracy: 60.6%\n",
            "Step: 4617 ------------ Loss: 8099.78 ------------ Accuracy: 60.6%\n",
            "Step: 4618 ------------ Loss: 8099.63 ------------ Accuracy: 60.6%\n",
            "Step: 4619 ------------ Loss: 8099.48 ------------ Accuracy: 60.6%\n",
            "Step: 4620 ------------ Loss: 8099.33 ------------ Accuracy: 60.6%\n",
            "Step: 4621 ------------ Loss: 8099.17 ------------ Accuracy: 60.6%\n",
            "Step: 4622 ------------ Loss: 8099.02 ------------ Accuracy: 60.6%\n",
            "Step: 4623 ------------ Loss: 8098.87 ------------ Accuracy: 60.6%\n",
            "Step: 4624 ------------ Loss: 8098.72 ------------ Accuracy: 60.6%\n",
            "Step: 4625 ------------ Loss: 8098.57 ------------ Accuracy: 60.6%\n",
            "Step: 4626 ------------ Loss: 8098.42 ------------ Accuracy: 60.6%\n",
            "Step: 4627 ------------ Loss: 8098.28 ------------ Accuracy: 60.6%\n",
            "Step: 4628 ------------ Loss: 8098.12 ------------ Accuracy: 60.6%\n",
            "Step: 4629 ------------ Loss: 8097.97 ------------ Accuracy: 60.6%\n",
            "Step: 4630 ------------ Loss: 8097.82 ------------ Accuracy: 60.6%\n",
            "Step: 4631 ------------ Loss: 8097.66 ------------ Accuracy: 60.6%\n",
            "Step: 4632 ------------ Loss: 8097.51 ------------ Accuracy: 60.6%\n",
            "Step: 4633 ------------ Loss: 8097.36 ------------ Accuracy: 60.6%\n",
            "Step: 4634 ------------ Loss: 8097.21 ------------ Accuracy: 60.6%\n",
            "Step: 4635 ------------ Loss: 8097.06 ------------ Accuracy: 60.6%\n",
            "Step: 4636 ------------ Loss: 8096.9 ------------ Accuracy: 60.6%\n",
            "Step: 4637 ------------ Loss: 8096.75 ------------ Accuracy: 60.6%\n",
            "Step: 4638 ------------ Loss: 8096.6 ------------ Accuracy: 60.6%\n",
            "Step: 4639 ------------ Loss: 8096.45 ------------ Accuracy: 60.6%\n",
            "Step: 4640 ------------ Loss: 8096.3 ------------ Accuracy: 60.6%\n",
            "Step: 4641 ------------ Loss: 8096.14 ------------ Accuracy: 60.6%\n",
            "Step: 4642 ------------ Loss: 8095.99 ------------ Accuracy: 60.6%\n",
            "Step: 4643 ------------ Loss: 8095.84 ------------ Accuracy: 60.6%\n",
            "Step: 4644 ------------ Loss: 8095.69 ------------ Accuracy: 60.6%\n",
            "Step: 4645 ------------ Loss: 8095.54 ------------ Accuracy: 60.6%\n",
            "Step: 4646 ------------ Loss: 8095.38 ------------ Accuracy: 60.6%\n",
            "Step: 4647 ------------ Loss: 8095.23 ------------ Accuracy: 60.6%\n",
            "Step: 4648 ------------ Loss: 8095.08 ------------ Accuracy: 60.6%\n",
            "Step: 4649 ------------ Loss: 8094.94 ------------ Accuracy: 60.6%\n",
            "Step: 4650 ------------ Loss: 8094.78 ------------ Accuracy: 60.6%\n",
            "Step: 4651 ------------ Loss: 8094.62 ------------ Accuracy: 60.6%\n",
            "Step: 4652 ------------ Loss: 8094.47 ------------ Accuracy: 60.6%\n",
            "Step: 4653 ------------ Loss: 8094.32 ------------ Accuracy: 60.6%\n",
            "Step: 4654 ------------ Loss: 8094.17 ------------ Accuracy: 60.6%\n",
            "Step: 4655 ------------ Loss: 8094.01 ------------ Accuracy: 60.6%\n",
            "Step: 4656 ------------ Loss: 8093.86 ------------ Accuracy: 60.6%\n",
            "Step: 4657 ------------ Loss: 8093.71 ------------ Accuracy: 60.6%\n",
            "Step: 4658 ------------ Loss: 8093.56 ------------ Accuracy: 60.6%\n",
            "Step: 4659 ------------ Loss: 8093.41 ------------ Accuracy: 60.6%\n",
            "Step: 4660 ------------ Loss: 8093.25 ------------ Accuracy: 60.6%\n",
            "Step: 4661 ------------ Loss: 8093.1 ------------ Accuracy: 60.6%\n",
            "Step: 4662 ------------ Loss: 8092.95 ------------ Accuracy: 60.6%\n",
            "Step: 4663 ------------ Loss: 8092.8 ------------ Accuracy: 60.6%\n",
            "Step: 4664 ------------ Loss: 8092.65 ------------ Accuracy: 60.6%\n",
            "Step: 4665 ------------ Loss: 8092.5 ------------ Accuracy: 60.6%\n",
            "Step: 4666 ------------ Loss: 8092.35 ------------ Accuracy: 60.6%\n",
            "Step: 4667 ------------ Loss: 8092.2 ------------ Accuracy: 60.6%\n",
            "Step: 4668 ------------ Loss: 8092.04 ------------ Accuracy: 60.6%\n",
            "Step: 4669 ------------ Loss: 8091.89 ------------ Accuracy: 60.6%\n",
            "Step: 4670 ------------ Loss: 8091.74 ------------ Accuracy: 60.6%\n",
            "Step: 4671 ------------ Loss: 8091.59 ------------ Accuracy: 60.6%\n",
            "Step: 4672 ------------ Loss: 8091.44 ------------ Accuracy: 60.6%\n",
            "Step: 4673 ------------ Loss: 8091.3 ------------ Accuracy: 60.6%\n",
            "Step: 4674 ------------ Loss: 8091.14 ------------ Accuracy: 60.6%\n",
            "Step: 4675 ------------ Loss: 8090.98 ------------ Accuracy: 60.6%\n",
            "Step: 4676 ------------ Loss: 8090.83 ------------ Accuracy: 60.6%\n",
            "Step: 4677 ------------ Loss: 8090.68 ------------ Accuracy: 60.6%\n",
            "Step: 4678 ------------ Loss: 8090.53 ------------ Accuracy: 60.6%\n",
            "Step: 4679 ------------ Loss: 8090.37 ------------ Accuracy: 60.6%\n",
            "Step: 4680 ------------ Loss: 8090.22 ------------ Accuracy: 60.6%\n",
            "Step: 4681 ------------ Loss: 8090.07 ------------ Accuracy: 60.6%\n",
            "Step: 4682 ------------ Loss: 8089.92 ------------ Accuracy: 60.6%\n",
            "Step: 4683 ------------ Loss: 8089.77 ------------ Accuracy: 60.6%\n",
            "Step: 4684 ------------ Loss: 8089.62 ------------ Accuracy: 60.6%\n",
            "Step: 4685 ------------ Loss: 8089.46 ------------ Accuracy: 60.6%\n",
            "Step: 4686 ------------ Loss: 8089.31 ------------ Accuracy: 60.6%\n",
            "Step: 4687 ------------ Loss: 8089.16 ------------ Accuracy: 60.6%\n",
            "Step: 4688 ------------ Loss: 8089.01 ------------ Accuracy: 60.6%\n",
            "Step: 4689 ------------ Loss: 8088.86 ------------ Accuracy: 60.6%\n",
            "Step: 4690 ------------ Loss: 8088.71 ------------ Accuracy: 60.6%\n",
            "Step: 4691 ------------ Loss: 8088.55 ------------ Accuracy: 60.6%\n",
            "Step: 4692 ------------ Loss: 8088.4 ------------ Accuracy: 60.6%\n",
            "Step: 4693 ------------ Loss: 8088.25 ------------ Accuracy: 60.6%\n",
            "Step: 4694 ------------ Loss: 8088.1 ------------ Accuracy: 60.6%\n",
            "Step: 4695 ------------ Loss: 8087.95 ------------ Accuracy: 60.6%\n",
            "Step: 4696 ------------ Loss: 8087.8 ------------ Accuracy: 60.6%\n",
            "Step: 4697 ------------ Loss: 8087.65 ------------ Accuracy: 60.6%\n",
            "Step: 4698 ------------ Loss: 8087.49 ------------ Accuracy: 60.6%\n",
            "Step: 4699 ------------ Loss: 8087.34 ------------ Accuracy: 60.6%\n",
            "Step: 4700 ------------ Loss: 8087.19 ------------ Accuracy: 60.6%\n",
            "Step: 4701 ------------ Loss: 8087.04 ------------ Accuracy: 60.6%\n",
            "Step: 4702 ------------ Loss: 8086.89 ------------ Accuracy: 60.6%\n",
            "Step: 4703 ------------ Loss: 8086.74 ------------ Accuracy: 60.6%\n",
            "Step: 4704 ------------ Loss: 8086.59 ------------ Accuracy: 60.6%\n",
            "Step: 4705 ------------ Loss: 8086.44 ------------ Accuracy: 60.6%\n",
            "Step: 4706 ------------ Loss: 8086.28 ------------ Accuracy: 60.6%\n",
            "Step: 4707 ------------ Loss: 8086.13 ------------ Accuracy: 60.6%\n",
            "Step: 4708 ------------ Loss: 8085.98 ------------ Accuracy: 60.6%\n",
            "Step: 4709 ------------ Loss: 8085.84 ------------ Accuracy: 60.6%\n",
            "Step: 4710 ------------ Loss: 8085.69 ------------ Accuracy: 60.6%\n",
            "Step: 4711 ------------ Loss: 8085.54 ------------ Accuracy: 60.6%\n",
            "Step: 4712 ------------ Loss: 8085.38 ------------ Accuracy: 60.6%\n",
            "Step: 4713 ------------ Loss: 8085.23 ------------ Accuracy: 60.6%\n",
            "Step: 4714 ------------ Loss: 8085.08 ------------ Accuracy: 60.6%\n",
            "Step: 4715 ------------ Loss: 8084.93 ------------ Accuracy: 60.6%\n",
            "Step: 4716 ------------ Loss: 8084.78 ------------ Accuracy: 60.6%\n",
            "Step: 4717 ------------ Loss: 8084.63 ------------ Accuracy: 60.6%\n",
            "Step: 4718 ------------ Loss: 8084.48 ------------ Accuracy: 60.6%\n",
            "Step: 4719 ------------ Loss: 8084.33 ------------ Accuracy: 60.6%\n",
            "Step: 4720 ------------ Loss: 8084.18 ------------ Accuracy: 60.6%\n",
            "Step: 4721 ------------ Loss: 8084.02 ------------ Accuracy: 60.6%\n",
            "Step: 4722 ------------ Loss: 8083.87 ------------ Accuracy: 60.6%\n",
            "Step: 4723 ------------ Loss: 8083.72 ------------ Accuracy: 60.6%\n",
            "Step: 4724 ------------ Loss: 8083.57 ------------ Accuracy: 60.6%\n",
            "Step: 4725 ------------ Loss: 8083.42 ------------ Accuracy: 60.6%\n",
            "Step: 4726 ------------ Loss: 8083.28 ------------ Accuracy: 60.7%\n",
            "Step: 4727 ------------ Loss: 8083.12 ------------ Accuracy: 60.6%\n",
            "Step: 4728 ------------ Loss: 8082.97 ------------ Accuracy: 60.6%\n",
            "Step: 4729 ------------ Loss: 8082.82 ------------ Accuracy: 60.7%\n",
            "Step: 4730 ------------ Loss: 8082.66 ------------ Accuracy: 60.7%\n",
            "Step: 4731 ------------ Loss: 8082.51 ------------ Accuracy: 60.7%\n",
            "Step: 4732 ------------ Loss: 8082.36 ------------ Accuracy: 60.7%\n",
            "Step: 4733 ------------ Loss: 8082.21 ------------ Accuracy: 60.7%\n",
            "Step: 4734 ------------ Loss: 8082.06 ------------ Accuracy: 60.7%\n",
            "Step: 4735 ------------ Loss: 8081.91 ------------ Accuracy: 60.7%\n",
            "Step: 4736 ------------ Loss: 8081.76 ------------ Accuracy: 60.7%\n",
            "Step: 4737 ------------ Loss: 8081.61 ------------ Accuracy: 60.7%\n",
            "Step: 4738 ------------ Loss: 8081.46 ------------ Accuracy: 60.7%\n",
            "Step: 4739 ------------ Loss: 8081.3 ------------ Accuracy: 60.7%\n",
            "Step: 4740 ------------ Loss: 8081.15 ------------ Accuracy: 60.7%\n",
            "Step: 4741 ------------ Loss: 8081.0 ------------ Accuracy: 60.7%\n",
            "Step: 4742 ------------ Loss: 8080.85 ------------ Accuracy: 60.7%\n",
            "Step: 4743 ------------ Loss: 8080.7 ------------ Accuracy: 60.7%\n",
            "Step: 4744 ------------ Loss: 8080.55 ------------ Accuracy: 60.7%\n",
            "Step: 4745 ------------ Loss: 8080.4 ------------ Accuracy: 60.7%\n",
            "Step: 4746 ------------ Loss: 8080.25 ------------ Accuracy: 60.7%\n",
            "Step: 4747 ------------ Loss: 8080.1 ------------ Accuracy: 60.7%\n",
            "Step: 4748 ------------ Loss: 8079.95 ------------ Accuracy: 60.7%\n",
            "Step: 4749 ------------ Loss: 8079.8 ------------ Accuracy: 60.7%\n",
            "Step: 4750 ------------ Loss: 8079.65 ------------ Accuracy: 60.7%\n",
            "Step: 4751 ------------ Loss: 8079.5 ------------ Accuracy: 60.7%\n",
            "Step: 4752 ------------ Loss: 8079.35 ------------ Accuracy: 60.7%\n",
            "Step: 4753 ------------ Loss: 8079.2 ------------ Accuracy: 60.7%\n",
            "Step: 4754 ------------ Loss: 8079.05 ------------ Accuracy: 60.7%\n",
            "Step: 4755 ------------ Loss: 8078.89 ------------ Accuracy: 60.7%\n",
            "Step: 4756 ------------ Loss: 8078.74 ------------ Accuracy: 60.7%\n",
            "Step: 4757 ------------ Loss: 8078.59 ------------ Accuracy: 60.7%\n",
            "Step: 4758 ------------ Loss: 8078.44 ------------ Accuracy: 60.7%\n",
            "Step: 4759 ------------ Loss: 8078.29 ------------ Accuracy: 60.7%\n",
            "Step: 4760 ------------ Loss: 8078.14 ------------ Accuracy: 60.7%\n",
            "Step: 4761 ------------ Loss: 8077.99 ------------ Accuracy: 60.7%\n",
            "Step: 4762 ------------ Loss: 8077.84 ------------ Accuracy: 60.7%\n",
            "Step: 4763 ------------ Loss: 8077.69 ------------ Accuracy: 60.7%\n",
            "Step: 4764 ------------ Loss: 8077.54 ------------ Accuracy: 60.7%\n",
            "Step: 4765 ------------ Loss: 8077.39 ------------ Accuracy: 60.7%\n",
            "Step: 4766 ------------ Loss: 8077.24 ------------ Accuracy: 60.7%\n",
            "Step: 4767 ------------ Loss: 8077.09 ------------ Accuracy: 60.7%\n",
            "Step: 4768 ------------ Loss: 8076.94 ------------ Accuracy: 60.7%\n",
            "Step: 4769 ------------ Loss: 8076.79 ------------ Accuracy: 60.7%\n",
            "Step: 4770 ------------ Loss: 8076.65 ------------ Accuracy: 60.7%\n",
            "Step: 4771 ------------ Loss: 8076.49 ------------ Accuracy: 60.7%\n",
            "Step: 4772 ------------ Loss: 8076.33 ------------ Accuracy: 60.7%\n",
            "Step: 4773 ------------ Loss: 8076.18 ------------ Accuracy: 60.7%\n",
            "Step: 4774 ------------ Loss: 8076.03 ------------ Accuracy: 60.7%\n",
            "Step: 4775 ------------ Loss: 8075.88 ------------ Accuracy: 60.7%\n",
            "Step: 4776 ------------ Loss: 8075.73 ------------ Accuracy: 60.7%\n",
            "Step: 4777 ------------ Loss: 8075.58 ------------ Accuracy: 60.7%\n",
            "Step: 4778 ------------ Loss: 8075.43 ------------ Accuracy: 60.7%\n",
            "Step: 4779 ------------ Loss: 8075.28 ------------ Accuracy: 60.7%\n",
            "Step: 4780 ------------ Loss: 8075.13 ------------ Accuracy: 60.7%\n",
            "Step: 4781 ------------ Loss: 8074.98 ------------ Accuracy: 60.7%\n",
            "Step: 4782 ------------ Loss: 8074.83 ------------ Accuracy: 60.7%\n",
            "Step: 4783 ------------ Loss: 8074.68 ------------ Accuracy: 60.7%\n",
            "Step: 4784 ------------ Loss: 8074.53 ------------ Accuracy: 60.7%\n",
            "Step: 4785 ------------ Loss: 8074.38 ------------ Accuracy: 60.7%\n",
            "Step: 4786 ------------ Loss: 8074.23 ------------ Accuracy: 60.7%\n",
            "Step: 4787 ------------ Loss: 8074.08 ------------ Accuracy: 60.7%\n",
            "Step: 4788 ------------ Loss: 8073.93 ------------ Accuracy: 60.7%\n",
            "Step: 4789 ------------ Loss: 8073.79 ------------ Accuracy: 60.7%\n",
            "Step: 4790 ------------ Loss: 8073.64 ------------ Accuracy: 60.7%\n",
            "Step: 4791 ------------ Loss: 8073.48 ------------ Accuracy: 60.7%\n",
            "Step: 4792 ------------ Loss: 8073.33 ------------ Accuracy: 60.7%\n",
            "Step: 4793 ------------ Loss: 8073.18 ------------ Accuracy: 60.7%\n",
            "Step: 4794 ------------ Loss: 8073.03 ------------ Accuracy: 60.7%\n",
            "Step: 4795 ------------ Loss: 8072.88 ------------ Accuracy: 60.7%\n",
            "Step: 4796 ------------ Loss: 8072.73 ------------ Accuracy: 60.7%\n",
            "Step: 4797 ------------ Loss: 8072.58 ------------ Accuracy: 60.7%\n",
            "Step: 4798 ------------ Loss: 8072.43 ------------ Accuracy: 60.7%\n",
            "Step: 4799 ------------ Loss: 8072.28 ------------ Accuracy: 60.7%\n",
            "Step: 4800 ------------ Loss: 8072.13 ------------ Accuracy: 60.7%\n",
            "Step: 4801 ------------ Loss: 8071.98 ------------ Accuracy: 60.7%\n",
            "Step: 4802 ------------ Loss: 8071.83 ------------ Accuracy: 60.7%\n",
            "Step: 4803 ------------ Loss: 8071.68 ------------ Accuracy: 60.7%\n",
            "Step: 4804 ------------ Loss: 8071.53 ------------ Accuracy: 60.7%\n",
            "Step: 4805 ------------ Loss: 8071.39 ------------ Accuracy: 60.7%\n",
            "Step: 4806 ------------ Loss: 8071.24 ------------ Accuracy: 60.7%\n",
            "Step: 4807 ------------ Loss: 8071.08 ------------ Accuracy: 60.7%\n",
            "Step: 4808 ------------ Loss: 8070.93 ------------ Accuracy: 60.7%\n",
            "Step: 4809 ------------ Loss: 8070.78 ------------ Accuracy: 60.7%\n",
            "Step: 4810 ------------ Loss: 8070.63 ------------ Accuracy: 60.7%\n",
            "Step: 4811 ------------ Loss: 8070.48 ------------ Accuracy: 60.7%\n",
            "Step: 4812 ------------ Loss: 8070.33 ------------ Accuracy: 60.7%\n",
            "Step: 4813 ------------ Loss: 8070.18 ------------ Accuracy: 60.7%\n",
            "Step: 4814 ------------ Loss: 8070.03 ------------ Accuracy: 60.7%\n",
            "Step: 4815 ------------ Loss: 8069.88 ------------ Accuracy: 60.7%\n",
            "Step: 4816 ------------ Loss: 8069.73 ------------ Accuracy: 60.7%\n",
            "Step: 4817 ------------ Loss: 8069.58 ------------ Accuracy: 60.7%\n",
            "Step: 4818 ------------ Loss: 8069.43 ------------ Accuracy: 60.7%\n",
            "Step: 4819 ------------ Loss: 8069.28 ------------ Accuracy: 60.7%\n",
            "Step: 4820 ------------ Loss: 8069.13 ------------ Accuracy: 60.7%\n",
            "Step: 4821 ------------ Loss: 8068.98 ------------ Accuracy: 60.7%\n",
            "Step: 4822 ------------ Loss: 8068.83 ------------ Accuracy: 60.7%\n",
            "Step: 4823 ------------ Loss: 8068.68 ------------ Accuracy: 60.7%\n",
            "Step: 4824 ------------ Loss: 8068.53 ------------ Accuracy: 60.7%\n",
            "Step: 4825 ------------ Loss: 8068.38 ------------ Accuracy: 60.7%\n",
            "Step: 4826 ------------ Loss: 8068.23 ------------ Accuracy: 60.7%\n",
            "Step: 4827 ------------ Loss: 8068.08 ------------ Accuracy: 60.7%\n",
            "Step: 4828 ------------ Loss: 8067.93 ------------ Accuracy: 60.7%\n",
            "Step: 4829 ------------ Loss: 8067.78 ------------ Accuracy: 60.7%\n",
            "Step: 4830 ------------ Loss: 8067.63 ------------ Accuracy: 60.7%\n",
            "Step: 4831 ------------ Loss: 8067.48 ------------ Accuracy: 60.7%\n",
            "Step: 4832 ------------ Loss: 8067.33 ------------ Accuracy: 60.7%\n",
            "Step: 4833 ------------ Loss: 8067.18 ------------ Accuracy: 60.7%\n",
            "Step: 4834 ------------ Loss: 8067.03 ------------ Accuracy: 60.7%\n",
            "Step: 4835 ------------ Loss: 8066.89 ------------ Accuracy: 60.7%\n",
            "Step: 4836 ------------ Loss: 8066.75 ------------ Accuracy: 60.7%\n",
            "Step: 4837 ------------ Loss: 8066.59 ------------ Accuracy: 60.7%\n",
            "Step: 4838 ------------ Loss: 8066.44 ------------ Accuracy: 60.7%\n",
            "Step: 4839 ------------ Loss: 8066.29 ------------ Accuracy: 60.7%\n",
            "Step: 4840 ------------ Loss: 8066.14 ------------ Accuracy: 60.7%\n",
            "Step: 4841 ------------ Loss: 8065.99 ------------ Accuracy: 60.7%\n",
            "Step: 4842 ------------ Loss: 8065.85 ------------ Accuracy: 60.7%\n",
            "Step: 4843 ------------ Loss: 8065.7 ------------ Accuracy: 60.7%\n",
            "Step: 4844 ------------ Loss: 8065.55 ------------ Accuracy: 60.7%\n",
            "Step: 4845 ------------ Loss: 8065.4 ------------ Accuracy: 60.7%\n",
            "Step: 4846 ------------ Loss: 8065.25 ------------ Accuracy: 60.7%\n",
            "Step: 4847 ------------ Loss: 8065.1 ------------ Accuracy: 60.7%\n",
            "Step: 4848 ------------ Loss: 8064.95 ------------ Accuracy: 60.7%\n",
            "Step: 4849 ------------ Loss: 8064.8 ------------ Accuracy: 60.7%\n",
            "Step: 4850 ------------ Loss: 8064.65 ------------ Accuracy: 60.7%\n",
            "Step: 4851 ------------ Loss: 8064.5 ------------ Accuracy: 60.7%\n",
            "Step: 4852 ------------ Loss: 8064.35 ------------ Accuracy: 60.7%\n",
            "Step: 4853 ------------ Loss: 8064.2 ------------ Accuracy: 60.7%\n",
            "Step: 4854 ------------ Loss: 8064.05 ------------ Accuracy: 60.7%\n",
            "Step: 4855 ------------ Loss: 8063.9 ------------ Accuracy: 60.7%\n",
            "Step: 4856 ------------ Loss: 8063.75 ------------ Accuracy: 60.7%\n",
            "Step: 4857 ------------ Loss: 8063.6 ------------ Accuracy: 60.7%\n",
            "Step: 4858 ------------ Loss: 8063.46 ------------ Accuracy: 60.8%\n",
            "Step: 4859 ------------ Loss: 8063.31 ------------ Accuracy: 60.7%\n",
            "Step: 4860 ------------ Loss: 8063.15 ------------ Accuracy: 60.6%\n",
            "Step: 4861 ------------ Loss: 8063.0 ------------ Accuracy: 60.7%\n",
            "Step: 4862 ------------ Loss: 8062.85 ------------ Accuracy: 60.7%\n",
            "Step: 4863 ------------ Loss: 8062.7 ------------ Accuracy: 60.7%\n",
            "Step: 4864 ------------ Loss: 8062.55 ------------ Accuracy: 60.7%\n",
            "Step: 4865 ------------ Loss: 8062.41 ------------ Accuracy: 60.7%\n",
            "Step: 4866 ------------ Loss: 8062.26 ------------ Accuracy: 60.7%\n",
            "Step: 4867 ------------ Loss: 8062.11 ------------ Accuracy: 60.7%\n",
            "Step: 4868 ------------ Loss: 8061.96 ------------ Accuracy: 60.7%\n",
            "Step: 4869 ------------ Loss: 8061.81 ------------ Accuracy: 60.7%\n",
            "Step: 4870 ------------ Loss: 8061.66 ------------ Accuracy: 60.7%\n",
            "Step: 4871 ------------ Loss: 8061.51 ------------ Accuracy: 60.7%\n",
            "Step: 4872 ------------ Loss: 8061.36 ------------ Accuracy: 60.7%\n",
            "Step: 4873 ------------ Loss: 8061.21 ------------ Accuracy: 60.7%\n",
            "Step: 4874 ------------ Loss: 8061.06 ------------ Accuracy: 60.7%\n",
            "Step: 4875 ------------ Loss: 8060.92 ------------ Accuracy: 60.7%\n",
            "Step: 4876 ------------ Loss: 8060.77 ------------ Accuracy: 60.7%\n",
            "Step: 4877 ------------ Loss: 8060.62 ------------ Accuracy: 60.7%\n",
            "Step: 4878 ------------ Loss: 8060.47 ------------ Accuracy: 60.7%\n",
            "Step: 4879 ------------ Loss: 8060.32 ------------ Accuracy: 60.7%\n",
            "Step: 4880 ------------ Loss: 8060.18 ------------ Accuracy: 60.7%\n",
            "Step: 4881 ------------ Loss: 8060.02 ------------ Accuracy: 60.7%\n",
            "Step: 4882 ------------ Loss: 8059.87 ------------ Accuracy: 60.7%\n",
            "Step: 4883 ------------ Loss: 8059.72 ------------ Accuracy: 60.7%\n",
            "Step: 4884 ------------ Loss: 8059.57 ------------ Accuracy: 60.7%\n",
            "Step: 4885 ------------ Loss: 8059.42 ------------ Accuracy: 60.7%\n",
            "Step: 4886 ------------ Loss: 8059.27 ------------ Accuracy: 60.7%\n",
            "Step: 4887 ------------ Loss: 8059.12 ------------ Accuracy: 60.7%\n",
            "Step: 4888 ------------ Loss: 8058.97 ------------ Accuracy: 60.7%\n",
            "Step: 4889 ------------ Loss: 8058.83 ------------ Accuracy: 60.7%\n",
            "Step: 4890 ------------ Loss: 8058.68 ------------ Accuracy: 60.7%\n",
            "Step: 4891 ------------ Loss: 8058.53 ------------ Accuracy: 60.7%\n",
            "Step: 4892 ------------ Loss: 8058.38 ------------ Accuracy: 60.7%\n",
            "Step: 4893 ------------ Loss: 8058.23 ------------ Accuracy: 60.7%\n",
            "Step: 4894 ------------ Loss: 8058.08 ------------ Accuracy: 60.7%\n",
            "Step: 4895 ------------ Loss: 8057.93 ------------ Accuracy: 60.7%\n",
            "Step: 4896 ------------ Loss: 8057.78 ------------ Accuracy: 60.7%\n",
            "Step: 4897 ------------ Loss: 8057.63 ------------ Accuracy: 60.7%\n",
            "Step: 4898 ------------ Loss: 8057.48 ------------ Accuracy: 60.7%\n",
            "Step: 4899 ------------ Loss: 8057.34 ------------ Accuracy: 60.7%\n",
            "Step: 4900 ------------ Loss: 8057.19 ------------ Accuracy: 60.7%\n",
            "Step: 4901 ------------ Loss: 8057.04 ------------ Accuracy: 60.7%\n",
            "Step: 4902 ------------ Loss: 8056.89 ------------ Accuracy: 60.7%\n",
            "Step: 4903 ------------ Loss: 8056.74 ------------ Accuracy: 60.7%\n",
            "Step: 4904 ------------ Loss: 8056.59 ------------ Accuracy: 60.7%\n",
            "Step: 4905 ------------ Loss: 8056.44 ------------ Accuracy: 60.7%\n",
            "Step: 4906 ------------ Loss: 8056.29 ------------ Accuracy: 60.7%\n",
            "Step: 4907 ------------ Loss: 8056.15 ------------ Accuracy: 60.7%\n",
            "Step: 4908 ------------ Loss: 8056.0 ------------ Accuracy: 60.7%\n",
            "Step: 4909 ------------ Loss: 8055.85 ------------ Accuracy: 60.7%\n",
            "Step: 4910 ------------ Loss: 8055.7 ------------ Accuracy: 60.7%\n",
            "Step: 4911 ------------ Loss: 8055.55 ------------ Accuracy: 60.7%\n",
            "Step: 4912 ------------ Loss: 8055.4 ------------ Accuracy: 60.7%\n",
            "Step: 4913 ------------ Loss: 8055.25 ------------ Accuracy: 60.7%\n",
            "Step: 4914 ------------ Loss: 8055.11 ------------ Accuracy: 60.7%\n",
            "Step: 4915 ------------ Loss: 8054.97 ------------ Accuracy: 60.8%\n",
            "Step: 4916 ------------ Loss: 8054.82 ------------ Accuracy: 60.7%\n",
            "Step: 4917 ------------ Loss: 8054.67 ------------ Accuracy: 60.7%\n",
            "Step: 4918 ------------ Loss: 8054.52 ------------ Accuracy: 60.7%\n",
            "Step: 4919 ------------ Loss: 8054.37 ------------ Accuracy: 60.7%\n",
            "Step: 4920 ------------ Loss: 8054.22 ------------ Accuracy: 60.7%\n",
            "Step: 4921 ------------ Loss: 8054.07 ------------ Accuracy: 60.7%\n",
            "Step: 4922 ------------ Loss: 8053.93 ------------ Accuracy: 60.7%\n",
            "Step: 4923 ------------ Loss: 8053.78 ------------ Accuracy: 60.7%\n",
            "Step: 4924 ------------ Loss: 8053.63 ------------ Accuracy: 60.7%\n",
            "Step: 4925 ------------ Loss: 8053.48 ------------ Accuracy: 60.7%\n",
            "Step: 4926 ------------ Loss: 8053.33 ------------ Accuracy: 60.7%\n",
            "Step: 4927 ------------ Loss: 8053.18 ------------ Accuracy: 60.7%\n",
            "Step: 4928 ------------ Loss: 8053.04 ------------ Accuracy: 60.7%\n",
            "Step: 4929 ------------ Loss: 8052.9 ------------ Accuracy: 60.8%\n",
            "Step: 4930 ------------ Loss: 8052.75 ------------ Accuracy: 60.7%\n",
            "Step: 4931 ------------ Loss: 8052.6 ------------ Accuracy: 60.7%\n",
            "Step: 4932 ------------ Loss: 8052.45 ------------ Accuracy: 60.7%\n",
            "Step: 4933 ------------ Loss: 8052.3 ------------ Accuracy: 60.7%\n",
            "Step: 4934 ------------ Loss: 8052.15 ------------ Accuracy: 60.7%\n",
            "Step: 4935 ------------ Loss: 8052.0 ------------ Accuracy: 60.7%\n",
            "Step: 4936 ------------ Loss: 8051.85 ------------ Accuracy: 60.7%\n",
            "Step: 4937 ------------ Loss: 8051.71 ------------ Accuracy: 60.7%\n",
            "Step: 4938 ------------ Loss: 8051.56 ------------ Accuracy: 60.7%\n",
            "Step: 4939 ------------ Loss: 8051.41 ------------ Accuracy: 60.7%\n",
            "Step: 4940 ------------ Loss: 8051.26 ------------ Accuracy: 60.7%\n",
            "Step: 4941 ------------ Loss: 8051.11 ------------ Accuracy: 60.7%\n",
            "Step: 4942 ------------ Loss: 8050.96 ------------ Accuracy: 60.7%\n",
            "Step: 4943 ------------ Loss: 8050.82 ------------ Accuracy: 60.7%\n",
            "Step: 4944 ------------ Loss: 8050.67 ------------ Accuracy: 60.7%\n",
            "Step: 4945 ------------ Loss: 8050.53 ------------ Accuracy: 60.8%\n",
            "Step: 4946 ------------ Loss: 8050.37 ------------ Accuracy: 60.7%\n",
            "Step: 4947 ------------ Loss: 8050.22 ------------ Accuracy: 60.7%\n",
            "Step: 4948 ------------ Loss: 8050.07 ------------ Accuracy: 60.7%\n",
            "Step: 4949 ------------ Loss: 8049.92 ------------ Accuracy: 60.7%\n",
            "Step: 4950 ------------ Loss: 8049.78 ------------ Accuracy: 60.7%\n",
            "Step: 4951 ------------ Loss: 8049.63 ------------ Accuracy: 60.7%\n",
            "Step: 4952 ------------ Loss: 8049.48 ------------ Accuracy: 60.7%\n",
            "Step: 4953 ------------ Loss: 8049.33 ------------ Accuracy: 60.7%\n",
            "Step: 4954 ------------ Loss: 8049.18 ------------ Accuracy: 60.7%\n",
            "Step: 4955 ------------ Loss: 8049.03 ------------ Accuracy: 60.7%\n",
            "Step: 4956 ------------ Loss: 8048.89 ------------ Accuracy: 60.7%\n",
            "Step: 4957 ------------ Loss: 8048.74 ------------ Accuracy: 60.7%\n",
            "Step: 4958 ------------ Loss: 8048.59 ------------ Accuracy: 60.7%\n",
            "Step: 4959 ------------ Loss: 8048.44 ------------ Accuracy: 60.7%\n",
            "Step: 4960 ------------ Loss: 8048.29 ------------ Accuracy: 60.7%\n",
            "Step: 4961 ------------ Loss: 8048.15 ------------ Accuracy: 60.7%\n",
            "Step: 4962 ------------ Loss: 8048.0 ------------ Accuracy: 60.7%\n",
            "Step: 4963 ------------ Loss: 8047.85 ------------ Accuracy: 60.7%\n",
            "Step: 4964 ------------ Loss: 8047.7 ------------ Accuracy: 60.7%\n",
            "Step: 4965 ------------ Loss: 8047.56 ------------ Accuracy: 60.7%\n",
            "Step: 4966 ------------ Loss: 8047.41 ------------ Accuracy: 60.7%\n",
            "Step: 4967 ------------ Loss: 8047.26 ------------ Accuracy: 60.7%\n",
            "Step: 4968 ------------ Loss: 8047.11 ------------ Accuracy: 60.7%\n",
            "Step: 4969 ------------ Loss: 8046.96 ------------ Accuracy: 60.7%\n",
            "Step: 4970 ------------ Loss: 8046.82 ------------ Accuracy: 60.7%\n",
            "Step: 4971 ------------ Loss: 8046.67 ------------ Accuracy: 60.7%\n",
            "Step: 4972 ------------ Loss: 8046.52 ------------ Accuracy: 60.7%\n",
            "Step: 4973 ------------ Loss: 8046.38 ------------ Accuracy: 60.8%\n",
            "Step: 4974 ------------ Loss: 8046.23 ------------ Accuracy: 60.8%\n",
            "Step: 4975 ------------ Loss: 8046.08 ------------ Accuracy: 60.8%\n",
            "Step: 4976 ------------ Loss: 8045.93 ------------ Accuracy: 60.8%\n",
            "Step: 4977 ------------ Loss: 8045.78 ------------ Accuracy: 60.8%\n",
            "Step: 4978 ------------ Loss: 8045.63 ------------ Accuracy: 60.8%\n",
            "Step: 4979 ------------ Loss: 8045.48 ------------ Accuracy: 60.8%\n",
            "Step: 4980 ------------ Loss: 8045.33 ------------ Accuracy: 60.8%\n",
            "Step: 4981 ------------ Loss: 8045.19 ------------ Accuracy: 60.8%\n",
            "Step: 4982 ------------ Loss: 8045.04 ------------ Accuracy: 60.8%\n",
            "Step: 4983 ------------ Loss: 8044.89 ------------ Accuracy: 60.8%\n",
            "Step: 4984 ------------ Loss: 8044.74 ------------ Accuracy: 60.8%\n",
            "Step: 4985 ------------ Loss: 8044.59 ------------ Accuracy: 60.7%\n",
            "Step: 4986 ------------ Loss: 8044.45 ------------ Accuracy: 60.8%\n",
            "Step: 4987 ------------ Loss: 8044.3 ------------ Accuracy: 60.8%\n",
            "Step: 4988 ------------ Loss: 8044.15 ------------ Accuracy: 60.8%\n",
            "Step: 4989 ------------ Loss: 8044.0 ------------ Accuracy: 60.7%\n",
            "Step: 4990 ------------ Loss: 8043.86 ------------ Accuracy: 60.7%\n",
            "Step: 4991 ------------ Loss: 8043.71 ------------ Accuracy: 60.7%\n",
            "Step: 4992 ------------ Loss: 8043.56 ------------ Accuracy: 60.8%\n",
            "Step: 4993 ------------ Loss: 8043.41 ------------ Accuracy: 60.8%\n",
            "Step: 4994 ------------ Loss: 8043.26 ------------ Accuracy: 60.7%\n",
            "Step: 4995 ------------ Loss: 8043.12 ------------ Accuracy: 60.8%\n",
            "Step: 4996 ------------ Loss: 8042.97 ------------ Accuracy: 60.8%\n",
            "Step: 4997 ------------ Loss: 8042.82 ------------ Accuracy: 60.8%\n",
            "Step: 4998 ------------ Loss: 8042.67 ------------ Accuracy: 60.7%\n",
            "Step: 4999 ------------ Loss: 8042.53 ------------ Accuracy: 60.7%\n",
            "Step: 5000 ------------ Loss: 8042.38 ------------ Accuracy: 60.7%\n",
            "\n",
            " Time taken: 3039.19 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "# fit model\n",
        "model.fit(X_train, Y_train, type=\"BCGD_GS\", alpha=0.0001, max_iter=5000, threshold=100)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"\\n Time taken: {np.round(end_time - start_time,2)} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6_E7-OqjDoU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "73a05ca1-70fe-4b7e-f548-cb41b771d87b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAHHCAYAAACle7JuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABM9klEQVR4nO3dd3hUVf7H8c+kEiAFkpCCISR0KVJEiAjSFBApgiDIiiLCqohgW4RVAXdXlP2tBVRWXQXdDaAoWFZB6ejSO4hGCCAgvaRAIAnJ+f0xZmBIAgkzyc2Q9+t55pmZe8/c+c41ej+ee+65NmOMEQAAgAfysroAAACAq0WQAQAAHosgAwAAPBZBBgAAeCyCDAAA8FgEGQAA4LEIMgAAwGMRZAAAgMciyAAAAI9FkAEgSWrfvr3at29vdRkAUCwEGaCEJCcn649//KPi4+NVoUIFBQUFqU2bNnrjjTd09uxZR7uaNWvKZrM5HtWqVVPbtm01b948p+3VrFlTd955Z4HftX79etlsNs2YMeOyNe3YsUMTJkzQ3r17Xf15Japnz56qWLGi0tPTC20zaNAg+fn56cSJE5Kk06dPa/z48WrUqJEqVaqk0NBQNW3aVKNGjdLBgweL/N3ffPONbDaboqOjlZub6/JvAVCyCDJACfj666/VuHFjffLJJ+rRo4emTp2qSZMmqUaNGnrmmWc0atQop/ZNmzbVv//9b/373//W008/rYMHD6pPnz765z//6da6duzYoYkTJxYYZL777jt99913bv2+qzVo0CCdPXs2X5jLk5GRoS+++EJdu3ZVaGiosrOz1a5dO/39739X27Zt9eqrr2rcuHFq3ry5Zs6cqV9++aXI352YmKiaNWvq0KFDWrJkibt+EoAS4mN1AcC1Zs+ePRowYIBiY2O1ZMkSRUVFOdaNGDFCu3bt0tdff+30merVq+sPf/iD4/3gwYNVu3Ztvfbaa3r44YdLpW4/P79S+Z6i6NmzpwIDAzVz5kwNHjw43/ovvvhCZ86c0aBBgyRJn3/+uTZt2qTExETde++9Tm3PnTunrKysIn3vmTNn9MUXX2jSpEmaPn26EhMT1blzZ9d/UAk4c+aMKlWqZHUZgOXokQHcbPLkyTp9+rTef/99pxCTp3bt2vl6ZC4VGRmpBg0aaM+ePW6ra8aMGerXr58kqUOHDo5TWcuWLZOUf4zMsmXLZLPZ9Mknn2jixImqXr26AgMDdffddys1NVWZmZkaPXq0qlWrpsqVK2vIkCHKzMzM973/+c9/1KJFCwUEBKhq1aoaMGCA9u/ff9laAwIC1KdPHy1evFhHjx7Nt37mzJkKDAxUz549JdlP40lSmzZt8rXNO61XFPPmzdPZs2fVr18/DRgwQHPnztW5c+fytTt37pwmTJigunXrqkKFCoqKilKfPn0cdUhSbm6u3njjDTVu3FgVKlRQeHi4unbtqvXr10uS9u7dW+jpQJvNpgkTJjjeT5gwQTabTTt27NC9996rKlWq6JZbbpEkbd26VQ888IDjFGZkZKQefPBBxym3i/32228aOnSooqOj5e/vr7i4OD3yyCPKysrS7t27ZbPZ9Nprr+X73MqVK2Wz2TRr1qwi7UegNNEjA7jZV199pfj4eN18881XvY3s7Gzt379foaGhbqurXbt2evzxxzVlyhSNGzdODRo0kCTHc2EmTZqkgIAAPfvss9q1a5emTp0qX19feXl56dSpU5owYYJWr16tGTNmKC4uTi+88ILjs3/729/0/PPPq3///nrooYd07NgxTZ06Ve3atdOmTZsUEhJS6PcOGjRIH374oT755BM99thjjuUnT57Ut99+q4EDByogIECSFBsbK0n66KOP9Nxzz8lms13VPkpMTFSHDh0UGRmpAQMG6Nlnn9VXX33lCICSlJOTozvvvFOLFy/WgAEDNGrUKKWnp2vhwoXavn27atWqJUkaOnSoZsyYoW7duumhhx7S+fPn9f3332v16tW68cYbr6q+fv36qU6dOnrppZdkjJEkLVy4ULt379aQIUMUGRmpH3/8Ue+++65+/PFHrV692rEvDh48qJtuukkpKSkaPny46tevr99++02ffvqpMjIyFB8frzZt2igxMVFPPPFEvv0SGBioXr16XVXdQIkyANwmNTXVSDK9evUq8mdiY2PN7bffbo4dO2aOHTtmtmzZYgYMGGAkmZEjRzq16969e4HbWLdunZFkpk+fftnvmjNnjpFkli5dmm/drbfeam699VbH+6VLlxpJplGjRiYrK8uxfODAgcZms5lu3bo5fT4hIcHExsY63u/du9d4e3ubv/3tb07ttm3bZnx8fPItv9T58+dNVFSUSUhIcFr+z3/+00gy3377rWNZRkaGqVevnpFkYmNjzQMPPGDef/99c+TIkct+x8WOHDlifHx8zHvvvedYdvPNN+f7Z/nBBx8YSebVV1/Nt43c3FxjjDFLliwxkszjjz9eaJs9e/YU+s9Mkhk/frzj/fjx440kM3DgwHxtMzIy8i2bNWuWkWRWrFjhWDZ48GDj5eVl1q1bV2hN77zzjpFkfvrpJ8e6rKwsExYWZu6///58nwPKAk4tAW6UlpYmSQoMDCzW57777juFh4crPDxcN9xwg+bMmaP77rtPr7zySkmUWSyDBw+Wr6+v432rVq1kjNGDDz7o1K5Vq1bav3+/zp8/L0maO3eucnNz1b9/fx0/ftzxiIyMVJ06dbR06dLLfq+3t7cGDBigVatWOQ1OnjlzpiIiItSpUyfHsoCAAK1Zs0bPPPOMJPtptKFDhyoqKkojR44s8JTXpWbPni0vLy/17dvXsWzgwIGaP3++Tp065Vj22WefKSwsTCNHjsy3jbzej88++0w2m03jx48vtM3VKGi8VF6vlGQ/5XX8+HG1bt1akrRx40ZJ9tNcn3/+uXr06FFgb1BeTf3791eFChWUmJjoWPftt9/q+PHjTmO4gLKEIAO4Ud5YjMtdNlyQVq1aaeHChVq0aJFWrlyp48eP66OPPnI6SBWFKwfJwtSoUcPpfXBwsCQpJiYm3/Lc3FylpqZKknbu3CljjOrUqeMIaXmPn376qcCxL5fKG8w7c+ZMSdKBAwf0/fffa8CAAfL29s73/ZMnT9bevXu1d+9evf/++6pXr57efPNN/eUvf7nid/3nP//RTTfdpBMnTmjXrl3atWuXmjVrpqysLM2ZM8fRLjk5WfXq1ZOPT+Fn5pOTkxUdHa2qVate8XuLIy4uLt+ykydPatSoUYqIiFBAQIDCw8Md7fL+WRw7dkxpaWlq1KjRZbcfEhKiHj16OPa3ZD+tVL16dXXs2NGNvwRwH8bIAG4UFBSk6Ohobd++vVifCwsLu+LVMRUqVHCaf+ZiGRkZjjbudmlguNJy8/vYjdzcXNlsNs2fP7/AtpUrV77id7do0UL169fXrFmzNG7cOM2aNUvGGEfAKUxsbKwefPBB3XXXXYqPj1diYqL++te/Ftp+586dWrdunSSpTp06+dYnJiZq+PDhV6y3OAoLnTk5OYV+pqBg279/f61cuVLPPPOMmjZtqsqVKys3N1ddu3a9qnlwBg8erDlz5mjlypVq3LixvvzySz366KPy8uL/e1E2EWQAN7vzzjv17rvvatWqVUpISHDbdmNjY7Vjx44C1yUlJTnaXE5J9NgUplatWjLGKC4uTnXr1r3q7QwaNEjPP/+8tm7dqpkzZ6pOnTpq2bJlkT5bpUoV1apV64rBMjExUb6+vvr3v/+dL3T98MMPmjJlivbt26caNWqoVq1aWrNmjbKzs51OuV2sVq1a+vbbb3Xy5MlCe2WqVKkiSUpJSXFa/uuvvxbpt0nSqVOntHjxYk2cONFpkPXOnTud2oWHhysoKKhIAbtr164KDw9XYmKiWrVqpYyMDN13331FrgkobURswM3+9Kc/qVKlSnrooYd05MiRfOuTk5P1xhtvFHu7d9xxhw4cOKDPP//caXlmZqb+9a9/qVq1amrevPllt5E378ilB8+S0KdPH3l7e2vixImOXpo8xpgCLw8uSF7vywsvvKDNmzcX2BuzZcsWHT9+PN/yX3/9VTt27FC9evUu+x2JiYlq27at7rnnHt19991Oj7xxN3mXHvft21fHjx/Xm2++mW87eb+zb9++MsZo4sSJhbYJCgpSWFiYVqxY4bT+7bffvmytF8sLXZfu39dff93pvZeXl3r37q2vvvrKcfl3QTVJko+PjwYOHKhPPvlEM2bMUOPGjdWkSZMi1wSUNnpkADerVauWZs6cqXvuuUcNGjTQ4MGD1ahRI2VlZWnlypWaM2eOHnjggWJvd/jw4frggw/Ur18/Pfjgg2rWrJlOnDihjz/+WNu3b9dHH310xUntmjZtKm9vb73yyitKTU2Vv7+/OnbsqGrVql3lry1crVq19Ne//lVjx47V3r171bt3bwUGBmrPnj2aN2+ehg8frqeffvqK24mLi9PNN9+sL774QpIKDDILFy7U+PHj1bNnT7Vu3VqVK1fW7t279cEHHygzM9NpTpZLrVmzRrt27XK6xPti1atXV/PmzZWYmKgxY8Zo8ODB+uijj/Tkk09q7dq1atu2rc6cOaNFixbp0UcfVa9evdShQwfdd999mjJlinbu3Ok4zfP999+rQ4cOju966KGH9PLLL+uhhx7SjTfeqBUrVhRrFuKgoCC1a9dOkydPVnZ2tqpXr67vvvuuwPmHXnrpJX333Xe69dZbNXz4cDVo0ECHDh3SnDlz9MMPPzhdCj948GBNmTJFS5cuLRMDzoHLsuZiKeDa98svv5hhw4aZmjVrGj8/PxMYGGjatGljpk6das6dO+dod7nLqi916tQp88QTT5i4uDjj6+trgoKCTIcOHcz8+fOLXNd7771n4uPjjbe3t9Ol2IVdfj1nzhynz0+fPt1IyncZb94lwseOHXNa/tlnn5lbbrnFVKpUyVSqVMnUr1/fjBgxwiQlJRW55rfeestIMjfddFOB63fv3m1eeOEF07p1a1OtWjXj4+NjwsPDTffu3c2SJUsuu+2RI0caSSY5ObnQNhMmTDCSzJYtW4wx9kue//znPzv+OURGRpq7777baRvnz583f//73039+vWNn5+fCQ8PN926dTMbNmxwtMnIyDBDhw41wcHBJjAw0PTv398cPXq00MuvL923xhhz4MABc9ddd5mQkBATHBxs+vXrZw4ePJhvG8YY8+uvv5rBgweb8PBw4+/vb+Lj482IESNMZmZmvu02bNjQeHl5mQMHDlx2/wFWsxlzSZ8kAKDca9asmapWrarFixdbXQpwWYyRAQA4Wb9+vTZv3lzgfa6AsoYeGQCAJGn79u3asGGD/vGPf+j48ePavXt3iVzSD7gTPTIAAEnSp59+qiFDhig7O1uzZs0ixMAj0CMDAAA8Fj0yAADAYxFkAACAx7rmJ8TLzc3VwYMHFRgYWKrTswMAgKtnjFF6erqio6Mve6+vaz7IHDx4MN9degEAgGfYv3+/rrvuukLXX/NBJjAwUJJ9RwQFBVlcDQAAKIq0tDTFxMQ4juOFueaDTN7ppKCgIIIMAAAe5krDQhjsCwAAPBZBBgAAeCyCDAAA8FgEGQAA4LEIMgAAwGMRZAAAgMciyAAAAI9FkAEAAB6LIAMAADwWQQYAAHgsggwAAPBYBBkAAOCxrvmbRgIAgCLIOSd5+Um2S/o4zmfYl9l8pdxMyaeiZHKljP2SzUfyC5F8KllSskSQAQAA2WnSl7WlKs2kjt9eWL5/nvR9nwvvbd5Sh2+lX6ZKB764sPzuU/ZAYwGCDAAAZc3Pr0lHlkm3fCx5V5AOL5E2PinlnpMq15Ju+VTyCSj88zmZ0scV7K+D6l35+9KS7M+Hv5O+qifZbM7L85gcaUnn/J/fPFa6adqVv6cEEGQAALDSsVXS3kR7YDHn7cuS3rA/fxwgxT8o7f7gQvu0JOmbJlL17oVv89ePndsXR/ovxWsvSVWaFv8zbkKQAQBc286fldJ+knKz7Qdcb3/78tN77KdD/Kq453vOHZXOn7a/Lkp4yE63t18z9PLtLg4xeU7vuhB2ruSWT6QKEVdut+hW+3Orf0mBdS4sP3vYPgbG5i2dT7+wLf9q0vGVkn+4FHpj0WopAQQZAIDnM0aS+f2N7aLXkv43QPrtS/vruiOlFq9L6Tul/9a3B5uuG9xTw+cxUm6Wa9uIGyxVvE4686u9lyZPw3FSpTgpupuU/IH9FNOVHF0uVe8l1ehXtO/utEzKPCbVuLvo9QbXL3rbEmIzxpgrN/NcaWlpCg4OVmpqqoKCgqwuBwDgbueOSwtaSBn7rK7EWdUWha8zRjq1Mf/y7juk4Ab21+m7pPUjpXqjpOiuJVNjGVbU4zc9MgAAz7b/07IXYuo+Jt049fJtlnaT0n6Wou+Qdr4t+QQ6n9IJrC11mF+ydV4DLA8yv/32m8aMGaP58+crIyNDtWvX1vTp03XjjfbzbcYYjR8/Xu+9955SUlLUpk0bTZs2TXXq1LnClgEAHssY+9UxR5baL/c9f1qKuUvKPCn9OkvKOXuh7aZnLrxO+I+06g/2171/uzAexuYlyWa/6iaPzefC4Fq3sdmv+CnKuJv239jr8fKRmr9mH4Pi5e3meq59lgaZU6dOqU2bNurQoYPmz5+v8PBw7dy5U1WqXPgDmDx5sqZMmaIPP/xQcXFxev7559WlSxft2LFDFSpUsLB6AIDLzh2zH8hzz0sVwqWcLCk9SfrlbenIEnubpbfbn5u+Ih1eJB1eWPj2at4rBURIAddJFaNLvn5X2Gz2MCVJ3n7W1uLBLB0j8+yzz+p///ufvv/++wLXG2MUHR2tp556Sk8//bQkKTU1VREREZoxY4YGDBhwxe9gjAwAlFH750rf97W/9vKV7kySVj8gHV1RtM/HDbY/Z6dJBz6XOnwnRd1WEpXCAh4xRubLL79Uly5d1K9fPy1fvlzVq1fXo48+qmHDhkmS9uzZo8OHD6tz5wuT7wQHB6tVq1ZatWpVgUEmMzNTmZmZjvdpaWkl/0MAAPnlnpeW97T3oJjzUoXICxOtSdLZQxe1zZa+jL/89vyq2KfQr1BNavelVLlmiZQNz2JpkNm9e7emTZumJ598UuPGjdO6dev0+OOPy8/PT/fff78OHz4sSYqIcL7+PSIiwrHuUpMmTdLEiRNLvHYAKBeSpkhn9kk//0Oq0d9+n52iOrXZ/shzruD/bucT3Ei6Y6tz6AEKYWmQyc3N1Y033qiXXnpJktSsWTNt375d//znP3X//fdf1TbHjh2rJ5980vE+LS1NMTExbqkXAMqVI0ulDaMuvN/3iWvbq9bePofLxbLTf79Hj+3CwNvAuoQYFJmlQSYqKkrXX3+907IGDRros88+kyRFRkZKko4cOaKoqChHmyNHjqhp06YFbtPf31/+/v4lUzAAlCf/K2AcYtNXircNm5dUOd4+O2zNQZJfsHtqA35naZBp06aNkpKcp3H+5ZdfFBsbK0mKi4tTZGSkFi9e7AguaWlpWrNmjR555JHSLhcAyo8NT9qn3L/U9X8q/VqAy7A0yDzxxBO6+eab9dJLL6l///5au3at3n33Xb377ruSJJvNptGjR+uvf/2r6tSp47j8Ojo6Wr1797aydAC49hz9QdoxSTr4jdWVAEVmaZBp2bKl5s2bp7Fjx+rFF19UXFycXn/9dQ0aNMjR5k9/+pPOnDmj4cOHKyUlRbfccosWLFjAHDIA4G6L2lpdAVBs3GsJAGA3swgDbO+9pg8ZKEOKevz2KsWaAAAA3IogAwAAPBZBBgBQNDUHXbkNUMosv/s1AMDNUrZJuz+UruspZR6Xsk9LUbdLez6SUndI6b/YJ50LSyjedm94qWTqBVxAkAEAT3H2sJRzzj7rrdN1GkbS7wN1zXnpmyb21z//o/BtHV8l7fmwaN/b/Scp66RUqcbVVA2UKIIMAHiCX96S1j/m/u1e1/vC63NH7AHnYnf+LAXVc//3Am5CkAGAsm73RwWHGO8AKefs1W+30zIp4tar/zxQBhBkAMBKOZnSjpelYz9Ip7ZImcfsy/2qSjX/YH/9y5T8n4vsLHVcaL+x4+KOUo1+UkB1Kel153YVr5N67y/RnwBYiQnxAMAK6cnS8dXSzrfyn865nJvekyI6SAFRkk9F+7LTu6WKMZLN2/66Uk3p9B7pzB574LFxgSo8T1GP3/TIAEBpMkY6f0b6qvaV20Z1k6o2lzIO2AfmNnhaqv1Q/naV4y+8Dvx9u0F17A/gGkeQAYDSkp0uzSliz3CV5lL7r+1XKElSwowSKwvwZAQZACgJGQelpbdLqT9evh1XBQEuIcgAgLvlZktf1bLP+VKYvscln8qSt3/p1QVcgwgyAOBuO165fIjpslbyDy29eoBrGEPZAcDdDnxZ+LraD0uhLUuvFuAaR48MALjdJbNa+AZJ/VKtKQW4xtEjAwBud0mQMbnWlAGUA/TIACgfjJGOLpeCG0oVwi/fNjfbPtNuwHXSwa/t748ul0JvkgKipbMHpZPrJZ9A+4y6VZpKlWte5rsJMkBJIcgA8HzGSNlpkskpeL3NSzo4X1p5r31+lk5L7LPiGiPlnLFfPXT+jOTlb7930bYJ0i9T82/n4Nf5l/060/7cL13yrWwPPVkplzQiyAAlhSADwPPNKsZZ8lMbpU9Dfn9jU77TQFdrTqDUYor002T7TLxOOIsPlBSCDICya0+itOoP+ZffnGi/xDllq4tf4OZbzW14vODlXda493sAOBBkAFgjLUma39Q+34pPoFQhQjq9y77Oy1eqECllFHLX5pWDCt/ugGzZe1p+910r6eSGotfV+EWp4bgL751uuJgXfC7avsmVTqyVFt5c8PYG5l64zQAAtyPIAHC/82elfZ/YD/JevpI5L4XdLAXVlc4dlTJ+kxY0v6h9unQ6/cL73OzCQ8zl9P5N8rrkP2udltoH7h5ZIjWeKH1SKf/nWky133gx56x0XU/Jy7uQLyggkNi8pfAEqetG6ewh+/sK4VLqT1JMb0IMUMJsxhg3962WLUW9DTgAN5pZyMG7+4/S1w1L4Att9in//ateuemhhfZQc/agtO9Tqdtm7hINlEFFPX4TZABcvT3/kVbdV3Lbr9ZOajvXeTr/zWPtPToJH9LbAVzDinr85tQSgKI5d0yaW+3C+4iO9p4NV128nfgh0u7pUsdFUmSngts3neT6dwK4ZhBkAFzemf3SD3fbB7Re7HIh5oaXpC2/D5hN+LcUdbt0/rTslyFfNGA2IFLy8pNyMu3LfSpKN06VfAoYxwIABSDIALi8L2pcuc11vSTfECmonhRUX6reU4obLKX+KEXe9vspoGqFf94n4KLXhBgARUeQAVC4/XMLXl57uFT3MWnnNOn6sVKlmPxtKla3PwCgBBFkAOSXsk36pknB61p/KMUPtr9u+Xbp1QQABWDebAD5Levu/L7DdxcmhqvRt/TrAYBC0CMDIL+LJ6O7fZUU1lrqe1LKzWIMC4AyhSAD4PKCG9mf/YKtrQMACsCpJQCXd+mU/wBQhhBkAFyejSADoOwiyAC4PFthN1AEAOsRZAA4yzzp/J77GQEowwgyAC44e1j6LPTK7QCgjODkN1Ce5WRJH/tbXQUAXDV6ZIDyavWDVw4xvkGlUwsAXCV6ZIBrjcmVdk+3T17n+/vcLyfWSsdWShWjJe+K0qFvpayTBX++y1rJy1ey+UqBdUqvbgC4CgQZwJMYI5nzUs5Z+2svHyknU5K50Gb3h9Kmpwr+fCHZxeG63lJoSzcVCwAljyADeJK1f5SS3yt6+4gO0pGlV25XKVY686vU5uOrrw0ALECQAcqKtF+k/9aTYvpIlWtLP02+sK5qC/vzyQ1F355PJanTEun0HunL+ILb9D8j+VS8+poBwGIEGZRP2aelOYH2MSSdl0s7/ynt+qcU0kTyriDd+rVUIcz5M7/9V1reQ2r2f1KDQk7dXCrjgPR5jP21f6h0/qwUWFsKbmgfh3L+jJSVIoW1kn58yd5u/9z827lSgGkzW6rRz3lZ3t2qK8dJA3ML/hxzxADwcDZjjLlyM8+Vlpam4OBgpaamKiiIKzAgKeec9HHAlds1fVmKHyJVqGZ/P/Oig36H76Tzp+3birpdyk63D54NrGsfZJv+iz18rH/MPTW3/+b32jOl07ulU5sl5Up+oVLMXVK1WwklAK4pRT1+0yOD8md5j6K12/ys/XGvsZ/2udjS2wv+TNjN0vGVxa+p7mOSyZF2TpMqxUkVq0vHfrCvu/W/UnS34m8TAMoBemRw7UrbKf23rv31wFx7UJgTaO9FKUtCGkt3bLW6CgAoU+iRAfJCjCQtbGO/KufiEFOjv3RLAVfpmFxplhtvlHj3Kckv5ML71UOl3R/YX7f8p1Tnj+77LgAoZ+iRwbXl0HfST3+X0pKkjP2Ft7v+WemGlwofV5KTJWWdsI9JubhNQHUpO9U+PsbkSLnnJS8/+8BaLz8pN9M+v4uMfZl/mP3qoYsZ83ugMlwxBACFoEcGnsfk2ntN/KpKfsH51+dkSWcPSN6VJL8qUuYx+2f8QiTvAOnsIWlpl/yfi+pqHxArSak/2wfv1h99+cGx3n5SQFTB6/xD7Y+rZbNJPkUYbAwAuCKCDMqOi0/n3JkkBV10asjkXv6+QH5VpKxTBa9rPV0KiHRPjQCAMoUgg7Lh9B7n9/+td+F1x0X2+V0up7AQE32nVCHCtdoAAGWWpXe/njBhgmw2m9Ojfv36jvXt27fPt/7hhx+2sGKUCGMKn3lWkpZ0tp9GKq7KtaT2XzG/CgBcwyzvkWnYsKEWLVrkeO/j41zSsGHD9OKLLzreV6zI4MhrSnaatPFJ52VVmks3TpEW3nJh2f8GXngdO1D6dVbB27tju30OlowD9hl0AQDXNMuDjI+PjyIjCx+/ULFixcuuh4ebGyXlZFx4H9paum2Fffr+i6VcNM/KzYlS5G1S6E3SiTXSz69JEe2l2HulkIb2Nhdf7gwAuGZZempJknbu3Kno6GjFx8dr0KBB2rdvn9P6xMREhYWFqVGjRho7dqwyMjIK2ZJdZmam0tLSnB4oo75p6hxiOnwrdVl1IcSEti74czabVGuIPbTUelDqvk26caoUnlDiJQMAyhZLe2RatWqlGTNmqF69ejp06JAmTpyotm3bavv27QoMDNS9996r2NhYRUdHa+vWrRozZoySkpI0d24BN9X73aRJkzRx4sRS/BW4Kp8ESefTL7xv8hf7PYsudvtKaVFb6dj/LixrMbV06gMAeIQyNSFeSkqKYmNj9eqrr2ro0KH51i9ZskSdOnXSrl27VKtWrQK3kZmZqczMTMf7tLQ0xcTEMCFeWZDxm7T2j5JvUP4xLv3SJN/A/J8xv9+1Ofe8ZPOWvNw44y4AoMzyyAnxQkJCVLduXe3atavA9a1atZKkywYZf39/+ftfZr4RlL6M3+yXVy9qW/D6W78qOMRI9tlxJfsEdQAAXMLyMTIXO336tJKTkxUVVfCMqps3b5akQtejDDq+Wvr8usJDTJ1HpOp3lm5NAIBrhqU9Mk8//bR69Oih2NhYHTx4UOPHj5e3t7cGDhyo5ORkzZw5U3fccYdCQ0O1detWPfHEE2rXrp2aNLnC5Giw1t5Z0sp7L9/GN0SqPUxqNrlUSgIAXJssDTIHDhzQwIEDdeLECYWHh+uWW27R6tWrFR4ernPnzmnRokV6/fXXdebMGcXExKhv37567rnnrCwZRXG5EHNzolTzCiEHAIAiKlODfUsCd78uRbnZ0vd9pd++yr+u3mipwTNSxehSLwsA4Hk8crAvPFTOOSk3S9r8rHOICblBCqpvv5N181e5VQAAwO0IMnDNqgekPR8WvO6OzaVZCQCgHCLI4Oot7igdWVrwuobjSrcWAEC5RJBBfjnnpC9rSWcP2t8HN5JSt19YX2+01GRi4SFmYM6F+V8AAChBBBk4O7lR2v7ihRAjOYcYSUp63f64VI9dkk8lQgwAoNQQZHDB4cXSks7F/9x1vaWWb0sBTFQIAChdBBlckPRG8T8TfafUbp77awEAoAgIMuXVqa3S/BsuvI+8TTq80LlNs39IDZ688P74aum7hAvvu22WqtwgAACsQpApj06sl75t6bzs0hDT94TkX9V5WVhrqf8Z+2Bg7wqST8WSrRMAgCsgyJQ3uTn5Q0yem96VTm2W4ofkDzF5fCoSYAAAZQZBprxZ0qng5d13SMENSrcWAABcRJApL9YMk5L/5bzsurukdnOtqQcAADcgyFyL9s6WVg+WqveU9n+Wf31AtNTrV8mLf/wAAM/GkczTZKVIa4ZKueftE89ViJSibpNsvhfarBxofy4oxPhVlbpvJ8QAAK4JHM08gTGSyZVkpE+r5F+/659F245/uNQjSfIrYBsAAHgggkxZl3VK+rSQK4guFtrqwusTa+zPradLq4fYX/uHS32OSDab+2sEAMAiBJmybu3DV25T/ymp+f8VvC7+AbeWAwBAWUKQKSuyUqQNo6U9H9rf1/yDlHVSOviNc7uqLaVOSyRvf8nkSDZvycv30q0BAFAuEGTKgtwcaV6UfcbcPHv/k79d3P1Sy2mST8DvCwgwAIDyjSBTFsy+zD8GL38pN1MKamAf88IYFwAAHAgyVrrSQN7qPaW2cyUv79KrCQAAD0KQKQ0zL+lF6bZFOvi1tGVcwe1bTpPqFGGQLwAA5RxBxp3OHZd+ekVqMEaqEGaf/2X1A/nbzb+h8G3cPEuqOaDESgQA4FpCkHGnueH255/+T7rXSL+8Je35qHjbqHid++sCAOAa5WV1AdesHydJG0YW7zORt0nhbUqmHgAArkH0yLjL2cPO7wsa/9Lkr1KjP0ubx0q/zpa6rJEqVCud+gAAuAbRI+MuG0ZduU1MH/tz00lSrz2EGAAAXESPjLukbCl4eVQXyb+aVPshKbhB6dYEAMA1jiDjLrZCdmWHBaVbBwAA5QinltwlN+vC6xZv2J8r1bSkFAAAygt6ZNwlfeeF1/Uetz8AAECJokcGAAB4LIIMAADwWAQZdwmqb39uPMHSMgAAKE8IMu4SEG1/DqxnbR0AAJQjBBl3ObLE/uzF+GkAAEoLQcbdTq63ugIAAMoNgoy7nd5jdQUAAJQbBBl3M7lWVwAAQLlBkHGH3JwLr+s/YV0dAACUMwQZd9j/2YXXFa+zrg4AAMoZgow7ZJ288NrmbV0dAACUMwQZd7j4ztcEGQAASg1Bxh0unjvGxi4FAKC0cNR1i4t2Y+5568oAAKCcIci4g5ffhde+la2rAwCAcoYg405efpJvkNVVAABQbhBk3MFk25+r3WptHQAAlDMEGXc48fv9lVJ3WFsHAADlDEHGHX6ZYn8++5u1dQAAUM4QZAAAgMciyAAAAI9FkAEAAB7L0iAzYcIE2Ww2p0f9+vUd68+dO6cRI0YoNDRUlStXVt++fXXkyBELKy5E5Xj7s08la+sAAKCcsbxHpmHDhjp06JDj8cMPPzjWPfHEE/rqq680Z84cLV++XAcPHlSfPn0srLYQ0d3tz/VGW1oGAADljc+Vm5RwAT4+ioyMzLc8NTVV77//vmbOnKmOHTtKkqZPn64GDRpo9erVat26dWmXehnm92ebpVUAAFDeWN4js3PnTkVHRys+Pl6DBg3Svn37JEkbNmxQdna2Onfu7Ghbv3591ahRQ6tWrSp0e5mZmUpLS3N6lDjze5CxEWQAAChNlgaZVq1aacaMGVqwYIGmTZumPXv2qG3btkpPT9fhw4fl5+enkJAQp89ERETo8OHDhW5z0qRJCg4OdjxiYmJK+FdIUu7vzwQZAABKU7GDTM2aNfXiiy86ek5c0a1bN/Xr109NmjRRly5d9M033yglJUWffPLJVW9z7NixSk1NdTz279/vcp1XZDi1BACAFYodZEaPHq25c+cqPj5et912m2bPnq3MzEy3FBMSEqK6detq165dioyMVFZWllJSUpzaHDlypMAxNXn8/f0VFBTk9Ch5eaeWLD9TBwBAuXJVQWbz5s1au3atGjRooJEjRyoqKkqPPfaYNm7c6FIxp0+fVnJysqKiotSiRQv5+vpq8eLFjvVJSUnat2+fEhISXPoe96NHBgAAK1x1F0Lz5s01ZcoUHTx4UOPHj9e//vUvtWzZUk2bNtUHH3wg4zjdUrinn35ay5cv1969e7Vy5Urddddd8vb21sCBAxUcHKyhQ4fqySef1NKlS7VhwwYNGTJECQkJZeyKJTHYFwAAi1z15dfZ2dmaN2+epk+froULF6p169YaOnSoDhw4oHHjxmnRokWaOXPmZbdx4MABDRw4UCdOnFB4eLhuueUWrV69WuHh4ZKk1157TV5eXurbt68yMzPVpUsXvf3221dbcgmiRwYAACvYTFG6Ti6yceNGTZ8+XbNmzZKXl5cGDx6shx56yGlG3u3bt6tly5Y6e/as2wsurrS0NAUHBys1NbXkxsusHirt/kC64SWp4diS+Q4AAMqRoh6/i90j07JlS912222aNm2aevfuLV9f33xt4uLiNGDAgOJu2oPRIwMAgBWKHWR2796t2NjYy7apVKmSpk+fftVFeR7GyAAAYIViD/Y9evSo1qxZk2/5mjVrtH79ercU5XF2z7A/Zxy0tAwAAMqbYgeZESNGFDjJ3G+//aYRI0a4pSiP9csUqysAAKBcKXaQ2bFjh5o3b55vebNmzbRjxw63FAUAAFAUxQ4y/v7+OnLkSL7lhw4dko+P5TfTBgAA5Uixg8ztt9/uuJ9RnpSUFI0bN0633XabW4vzGF7+9ueWZXGOGwAArl3F7kL5v//7P7Vr106xsbFq1qyZJGnz5s2KiIjQv//9b7cX6BGqNJVOrJECrrO6EgAAypViB5nq1atr69atSkxM1JYtWxQQEKAhQ4Zo4MCBBc4pUy6YHPszN40EAKBUXdWglkqVKmn48OHursVzOYKMt7V1AABQzlz16NwdO3Zo3759ysrKclres2dPl4vyOCbX/kyQAQCgVF3VzL533XWXtm3bJpvN5rjLte33WW1zcnLcW6En4NQSAACWKPaRd9SoUYqLi9PRo0dVsWJF/fjjj1qxYoVuvPFGLVu2rARK9ACcWgIAwBLF7pFZtWqVlixZorCwMHl5ecnLy0u33HKLJk2apMcff1ybNm0qiTrLOE4tAQBghWL3yOTk5CgwMFCSFBYWpoMH7fcXio2NVVJSknur8xS5nFoCAMAKxe6RadSokbZs2aK4uDi1atVKkydPlp+fn959913Fx8eXRI1lH6eWAACwRLGDzHPPPaczZ85Ikl588UXdeeedatu2rUJDQ/Xxxx+7vUDPwKklAACsUOwg06VLF8fr2rVr6+eff9bJkydVpUoVx5VL5Q5XLQEAYIliHXmzs7Pl4+Oj7du3Oy2vWrVq+Q0xEqeWAACwSLGCjK+vr2rUqFE+54q5HCbEAwDAEsU+F/LnP/9Z48aN08mTJ0uiHs+U1yNT/N0JAABcUOwxMm+++aZ27dql6OhoxcbGqlKlSk7rN27c6LbiPEbmcfszPTIAAJSqYgeZ3r17l0AZHuzsoQuvTbZ1dQAAUA4VO8iMHz++JOrwXLkXhRfD2CEAAEoTgzpcZbsoC+YN+gUAAKWi2D0yXl5el73Uutxd0XTx3DH0yAAAUKqKHWTmzZvn9D47O1ubNm3Shx9+qIkTJ7qtMM9hLrwMbmhdGQAAlEPFDjK9evXKt+zuu+9Ww4YN9fHHH2vo0KFuKcxjXHw6yaeidXUAAFAOuW2MTOvWrbV48WJ3bc5z5AUZLz9r6wAAoBxyS5A5e/aspkyZourVq7tjcx4mr0emHN+iAQAAixT71NKlN4c0xig9PV0VK1bUf/7zH7cW5xHM72NkuGEkAAClrthB5rXXXnMKMl5eXgoPD1erVq1UpUoVtxbnGfLus0SQAQCgtBU7yDzwwAMlUIYHcwz2JcgAAFDain30nT59uubMmZNv+Zw5c/Thhx+6pSiPYuiRAQDAKsU++k6aNElhYWH5llerVk0vvfSSW4ryKIbBvgAAWKXYQWbfvn2Ki4vLtzw2Nlb79u1zS1GehcG+AABYpdhH32rVqmnr1q35lm/ZskWhoaFuKcqjcGoJAADLFPvoO3DgQD3++ONaunSpcnJylJOToyVLlmjUqFEaMGBASdRYxhFkAACwSrGvWvrLX/6ivXv3qlOnTvLxsX88NzdXgwcPLudjZAgyAACUtmIHGT8/P3388cf661//qs2bNysgIECNGzdWbGxsSdRX9jlOLTHYFwCA0lbsIJOnTp06qlOnjjtr8VD0yAAAYJViH3379u2rV155Jd/yyZMnq1+/fm4pyqNwiwIAACxT7KPvihUrdMcdd+Rb3q1bN61YscItRXkUrloCAMAyxT76nj59Wn5+fvmW+/r6Ki0tzS1FeRZOLQEAYJViH30bN26sjz/+ON/y2bNn6/rrr3dLUR6FHhkAACxT7MG+zz//vPr06aPk5GR17NhRkrR48WLNnDlTn376qdsLLPO4RQEAAJYpdpDp0aOHPv/8c7300kv69NNPFRAQoBtuuEFLlixR1apVS6LGMo7BvgAAWOWqLr/u3r27unfvLklKS0vTrFmz9PTTT2vDhg3Kyclxa4FlHqeWAACwzFUffVesWKH7779f0dHR+sc//qGOHTtq9erV7qzNQxBkAACwSrF6ZA4fPqwZM2bo/fffV1pamvr376/MzEx9/vnn5XOgr8QtCgAAsFCRj749evRQvXr1tHXrVr3++us6ePCgpk6dWpK1eQZuUQAAgGWK3CMzf/58Pf7443rkkUe4NYGT3wf70iMDAECpK/LR94cfflB6erpatGihVq1a6c0339Tx48fdVsjLL78sm82m0aNHO5a1b99eNpvN6fHwww+77Tvd4vjv44JStlhbBwAA5VCRg0zr1q313nvv6dChQ/rjH/+o2bNnKzo6Wrm5uVq4cKHS09Ovuoh169bpnXfeUZMmTfKtGzZsmA4dOuR4TJ48+aq/p0RsG291BQAAlFvFPh9SqVIlPfjgg/rhhx+0bds2PfXUU3r55ZdVrVo19ezZs9gFnD59WoMGDdJ7772nKlWq5FtfsWJFRUZGOh5BQUHF/g4AAHBtcmlgR7169TR58mQdOHBAs2bNuqptjBgxQt27d1fnzp0LXJ+YmKiwsDA1atRIY8eOVUZGhislu19I/l4kAABQOq5qQrxLeXt7q3fv3urdu3exPjd79mxt3LhR69atK3D9vffeq9jYWEVHR2vr1q0aM2aMkpKSNHfu3EK3mZmZqczMTMf7Er+RZa2HpA2PS0H1SvZ7AABAPm4JMldj//79GjVqlBYuXKgKFSoU2Gb48OGO140bN1ZUVJQ6deqk5ORk1apVq8DPTJo0SRMnTiyRmgv2+2XX9MwAAFDqLLtmeMOGDTp69KiaN28uHx8f+fj4aPny5ZoyZYp8fHwKvNVBq1atJEm7du0qdLtjx45Vamqq47F///4S+w123DQSAACrWNYj06lTJ23bts1p2ZAhQ1S/fn2NGTNG3t7e+T6zefNmSVJUVFSh2/X395e/v79ba70skzePDEEGAIDSZlmQCQwMVKNGjZyWVapUSaGhoWrUqJGSk5M1c+ZM3XHHHQoNDdXWrVv1xBNPqF27dgVepm0d7n4NAIBVLAsyV+Ln56dFixbp9ddf15kzZxQTE6O+ffvqueees7o0Z4ZTSwAAWKVMBZlly5Y5XsfExGj58uXWFVNk9MgAAGAVjr4uY4wMAABWIci4irtfAwBgGYKMyzi1BACAVTj6uorBvgAAWIYg4zLGyAAAYBWCjKsMp5YAALAKR19XcWoJAADLEGRcRo8MAABW4ejrKnpkAACwDEHGZXk9MgQZAABKG0HGZXlXLbErAQAobRx9XcXMvgAAWIYg4zJ6ZAAAsApHX1fRIwMAgGUIMi5jZl8AAKxCkHEVM/sCAGAZjr4uYx4ZAACsQpBxFT0yAABYhqOvyxgjAwCAVQgyruKqJQAALEOQcRnzyAAAYBWOvq6iRwYAAMsQZFxGjwwAAFbh6Osqw92vAQCwCkHGZcwjAwCAVQgyrmIeGQAALMPR12X0yAAAYBWCjKvokQEAwDIcfV3GzL4AAFiFIOMq5pEBAMAyBBmXMY8MAABW4ejrKnpkAACwDEHGZfTIAABgFY6+rmJmXwAALEOQcRnzyAAAYBWCjKuYRwYAAMtw9HUZ88gAAGAVgoyrHFctsSsBAChtHH1dRo8MAABWIci4yjDYFwAAqxBkXMZgXwAArMLR12XMIwMAgFUIMq5ynFpiVwIAUNo4+rqMHhkAAKxCkHEVg30BALAMQcZVzOwLAIBlOPq6jHlkAACwCkHGVZxaAgDAMgQZl3FqCQAAq3D0dRU9MgAAWIYg4zJ6ZAAAsApHX5cx2BcAAKsQZFyVd2qJCfEAACh1ZSbIvPzyy7LZbBo9erRj2blz5zRixAiFhoaqcuXK6tu3r44cOWJdkQXK65EpM7sSAIByo0wcfdetW6d33nlHTZo0cVr+xBNP6KuvvtKcOXO0fPlyHTx4UH369LGoykIYblEAAIBVLA8yp0+f1qBBg/Tee++pSpUqjuWpqal6//339eqrr6pjx45q0aKFpk+frpUrV2r16tUWVnypvFNLlu9KAADKHcuPviNGjFD37t3VuXNnp+UbNmxQdna20/L69eurRo0aWrVqVWmXWTjDYF8AAKziY+WXz549Wxs3btS6devyrTt8+LD8/PwUEhLitDwiIkKHDx8udJuZmZnKzMx0vE9LS3NbvQVjHhkAAKxiWY/M/v37NWrUKCUmJqpChQpu2+6kSZMUHBzseMTExLht2wXippEAAFjGsqPvhg0bdPToUTVv3lw+Pj7y8fHR8uXLNWXKFPn4+CgiIkJZWVlKSUlx+tyRI0cUGRlZ6HbHjh2r1NRUx2P//v0l/Es4tQQAgFUsO7XUqVMnbdu2zWnZkCFDVL9+fY0ZM0YxMTHy9fXV4sWL1bdvX0lSUlKS9u3bp4SEhEK36+/vL39//xKt3YlhsC8AAFaxLMgEBgaqUaNGTssqVaqk0NBQx/KhQ4fqySefVNWqVRUUFKSRI0cqISFBrVu3tqLkQtAjAwCAVSwd7Hslr732mry8vNS3b19lZmaqS5cuevvtt60uyxkz+wIAYBmbMY7rh69JaWlpCg4OVmpqqoKCgtz/BQtulE5ukG79Wqp+h/u3DwBAOVTU4zcDO1zFzL4AAFiGIOOyvHlk2JUAAJQ2jr6uokcGAADLEGRcxsy+AABYhSDjKmb2BQDAMhx9XcY8MgAAWIUg4ypm9gUAwDIcfV1GjwwAAFYhyLiMq5YAALAKQcZVhnlkAACwCkdfVzGPDAAAliHIuIweGQAArMLR11X0yAAAYBmCjMu4agkAAKsQZFzFPDIAAFiGo6/L6JEBAMAqBBlX0SMDAIBlOPq6jB4ZAACsQpBxGVctAQBgFYKMq5jZFwAAy3D0dRk9MgAAWIUg4yp6ZAAAsAxHX5fRIwMAgFUIMq4yXLUEAIBVCDKuYh4ZAAAsw9HXZfTIAABgFYKMywgyAABYhSDjKk4tAQBgGY6+LuOqJQAArEKQcRXzyAAAYBmOvi6jRwYAAKsQZFzFPDIAAFiGIOMyBvsCAGAVjr6uokcGAADLEGRcRo8MAABW4ejrKnpkAACwDEHGZQQZAACsQpBxhaM3RpxaAgDAAhx9XXJRkKFHBgCAUkeQcYVjVl/RIwMAgAU4+rrk4lNL9MgAAFDaCDKuMJxaAgDASgQZl3BqCQAAK3H0dQU9MgAAWIog4xIuvwYAwEocfV1x8VVL9MgAAFDqCDIu4dQSAABWIsi4gnlkAACwFEdfl9AjAwCAlQgyLmGwLwAAVuLo6woG+wIAYCmCjCsMtygAAMBKBBmX0CMDAICVLA0y06ZNU5MmTRQUFKSgoCAlJCRo/vz5jvXt27eXzWZzejz88MMWVnwJemQAALCUj5Vfft111+nll19WnTp1ZIzRhx9+qF69emnTpk1q2LChJGnYsGF68cUXHZ+pWLGiVeUW4Pcgw0BfAAAsYWmQ6dGjh9P7v/3tb5o2bZpWr17tCDIVK1ZUZGSkFeVdmWOwL70xAABYocx0JeTk5Gj27Nk6c+aMEhISHMsTExMVFhamRo0aaezYscrIyLCwykvlnVoiyAAAYAVLe2Qkadu2bUpISNC5c+dUuXJlzZs3T9dff70k6d5771VsbKyio6O1detWjRkzRklJSZo7d26h28vMzFRmZqbjfVpaWskVn9cjw6klAAAsYXmQqVevnjZv3qzU1FR9+umnuv/++7V8+XJdf/31Gj58uKNd48aNFRUVpU6dOik5OVm1atUqcHuTJk3SxIkTS6l6emQAALCSzZiLL72xXufOnVWrVi298847+dadOXNGlStX1oIFC9SlS5cCP19Qj0xMTIxSU1MVFBTk3mLP/Cp9UVPyDpDuKUunvAAA8GxpaWkKDg6+4vHb8h6ZS+Xm5joFkYtt3rxZkhQVFVXo5/39/eXv718SpeXHYF8AACxlaZAZO3asunXrpho1aig9PV0zZ87UsmXL9O233yo5OVkzZ87UHXfcodDQUG3dulVPPPGE2rVrpyZNmlhZ9gW5WfZnrzKXBwEAKBcsPQIfPXpUgwcP1qFDhxQcHKwmTZro22+/1W233ab9+/dr0aJFev3113XmzBnFxMSob9++eu6556ws+YLME9LJjfbX/mHW1gIAQDlV5sbIuFtRz7EV29qHpV2/j+MJbSV1We2+bQMAUM557BgZj+HlK3lXkGw+UuxAq6sBAKBcIshcrRun2h8AAMAyzOQGAAA8FkEGAAB4LIIMAADwWAQZAADgsQgyAADAYxFkAACAxyLIAAAAj0WQAQAAHosgAwAAPBZBBgAAeCyCDAAA8FgEGQAA4LEIMgAAwGMRZAAAgMfysbqAkmaMkSSlpaVZXAkAACiqvON23nG8MNd8kElPT5ckxcTEWFwJAAAorvT0dAUHBxe63mauFHU8XG5urg4ePKjAwEDZbDa3bTctLU0xMTHav3+/goKC3LbdaxH7qmjYT0XDfioa9lPRsJ+KrrT3lTFG6enpio6OlpdX4SNhrvkeGS8vL1133XUltv2goCD++IuIfVU07KeiYT8VDfupaNhPRVea++pyPTF5GOwLAAA8FkEGAAB4LILMVfL399f48ePl7+9vdSllHvuqaNhPRcN+Khr2U9Gwn4qurO6ra36wLwAAuHbRIwMAADwWQQYAAHgsggwAAPBYBBkAAOCxCDJX6a233lLNmjVVoUIFtWrVSmvXrrW6pFIzYcIE2Ww2p0f9+vUd68+dO6cRI0YoNDRUlStXVt++fXXkyBGnbezbt0/du3dXxYoVVa1aNT3zzDM6f/58af8Ut1uxYoV69Oih6Oho2Ww2ff75507rjTF64YUXFBUVpYCAAHXu3Fk7d+50anPy5EkNGjRIQUFBCgkJ0dChQ3X69GmnNlu3blXbtm1VoUIFxcTEaPLkySX909zqSvvpgQceyPc31rVrV6c25WE/TZo0SS1btlRgYKCqVaum3r17KykpyamNu/59W7ZsmZo3by5/f3/Vrl1bM2bMKOmf5zZF2U/t27fP9zf18MMPO7W51vfTtGnT1KRJE8eEdgkJCZo/f75jvcf+LRkU2+zZs42fn5/54IMPzI8//miGDRtmQkJCzJEjR6wurVSMHz/eNGzY0Bw6dMjxOHbsmGP9ww8/bGJiYszixYvN+vXrTevWrc3NN9/sWH/+/HnTqFEj07lzZ7Np0ybzzTffmLCwMDN27Fgrfo5bffPNN+bPf/6zmTt3rpFk5s2b57T+5ZdfNsHBwebzzz83W7ZsMT179jRxcXHm7NmzjjZdu3Y1N9xwg1m9erX5/vvvTe3atc3AgQMd61NTU01ERIQZNGiQ2b59u5k1a5YJCAgw77zzTmn9TJddaT/df//9pmvXrk5/YydPnnRqUx72U5cuXcz06dPN9u3bzebNm80dd9xhatSoYU6fPu1o445/33bv3m0qVqxonnzySbNjxw4zdepU4+3tbRYsWFCqv/dqFWU/3XrrrWbYsGFOf1OpqamO9eVhP3355Zfm66+/Nr/88otJSkoy48aNM76+vmb79u3GGM/9WyLIXIWbbrrJjBgxwvE+JyfHREdHm0mTJllYVekZP368ueGGGwpcl5KSYnx9fc2cOXMcy3766ScjyaxatcoYYz+IeXl5mcOHDzvaTJs2zQQFBZnMzMwSrb00XXqAzs3NNZGRkebvf/+7Y1lKSorx9/c3s2bNMsYYs2PHDiPJrFu3ztFm/vz5xmazmd9++80YY8zbb79tqlSp4rSvxowZY+rVq1fCv6hkFBZkevXqVehnyuN+MsaYo0ePGklm+fLlxhj3/fv2pz/9yTRs2NDpu+655x7TpUuXkv5JJeLS/WSMPciMGjWq0M+Ux/1kjDFVqlQx//rXvzz6b4lTS8WUlZWlDRs2qHPnzo5lXl5e6ty5s1atWmVhZaVr586dio6OVnx8vAYNGqR9+/ZJkjZs2KDs7Gyn/VO/fn3VqFHDsX9WrVqlxo0bKyIiwtGmS5cuSktL048//li6P6QU7dmzR4cPH3baN8HBwWrVqpXTvgkJCdGNN97oaNO5c2d5eXlpzZo1jjbt2rWTn5+fo02XLl2UlJSkU6dOldKvKXnLli1TtWrVVK9ePT3yyCM6ceKEY1153U+pqamSpKpVq0py379vq1atctpGXhtP/W/apfspT2JiosLCwtSoUSONHTtWGRkZjnXlbT/l5ORo9uzZOnPmjBISEjz6b+mav2mkux0/flw5OTlO/yAlKSIiQj///LNFVZWuVq1aacaMGapXr54OHTqkiRMnqm3bttq+fbsOHz4sPz8/hYSEOH0mIiJChw8fliQdPny4wP2Xt+5alffbCvrtF++batWqOa338fFR1apVndrExcXl20beuipVqpRI/aWpa9eu6tOnj+Li4pScnKxx48apW7duWrVqlby9vcvlfsrNzdXo0aPVpk0bNWrUSJLc9u9bYW3S0tJ09uxZBQQElMRPKhEF7SdJuvfeexUbG6vo6Ght3bpVY8aMUVJSkubOnSup/Oynbdu2KSEhQefOnVPlypU1b948XX/99dq8ebPH/i0RZFBs3bp1c7xu0qSJWrVqpdjYWH3yySce8S8yyr4BAwY4Xjdu3FhNmjRRrVq1tGzZMnXq1MnCyqwzYsQIbd++XT/88IPVpZRphe2n4cOHO143btxYUVFR6tSpk5KTk1WrVq3SLtMy9erV0+bNm5WamqpPP/1U999/v5YvX251WS7h1FIxhYWFydvbO99I7iNHjigyMtKiqqwVEhKiunXrateuXYqMjFRWVpZSUlKc2ly8fyIjIwvcf3nrrlV5v+1yfzuRkZE6evSo0/rz58/r5MmT5Xr/xcfHKywsTLt27ZJU/vbTY489pv/+979aunSprrvuOsdyd/37VliboKAgj/qfk8L2U0FatWolSU5/U+VhP/n5+al27dpq0aKFJk2apBtuuEFvvPGGR/8tEWSKyc/PTy1atNDixYsdy3Jzc7V48WIlJCRYWJl1Tp8+reTkZEVFRalFixby9fV12j9JSUnat2+fY/8kJCRo27ZtTgeihQsXKigoSNdff32p119a4uLiFBkZ6bRv0tLStGbNGqd9k5KSog0bNjjaLFmyRLm5uY7/8CYkJGjFihXKzs52tFm4cKHq1avncadLiurAgQM6ceKEoqKiJJWf/WSM0WOPPaZ58+ZpyZIl+U6Vuevft4SEBKdt5LXxlP+mXWk/FWTz5s2S5PQ3da3vp4Lk5uYqMzPTs/+WSmwY8TVs9uzZxt/f38yYMcPs2LHDDB8+3ISEhDiN5L6WPfXUU2bZsmVmz5495n//+5/p3LmzCQsLM0ePHjXG2C/hq1GjhlmyZIlZv369SUhIMAkJCY7P513Cd/vtt5vNmzebBQsWmPDw8Gvi8uv09HSzadMms2nTJiPJvPrqq2bTpk3m119/NcbYL78OCQkxX3zxhdm6davp1atXgZdfN2vWzKxZs8b88MMPpk6dOk6XFaekpJiIiAhz3333me3bt5vZs2ebihUretRlxZfbT+np6ebpp582q1atMnv27DGLFi0yzZs3N3Xq1DHnzp1zbKM87KdHHnnEBAcHm2XLljldNpyRkeFo445/3/IumX3mmWfMTz/9ZN566y2Puqz4Svtp165d5sUXXzTr1683e/bsMV988YWJj4837dq1c2yjPOynZ5991ixfvtzs2bPHbN261Tz77LPGZrOZ7777zhjjuX9LBJmrNHXqVFOjRg3j5+dnbrrpJrN69WqrSyo199xzj4mKijJ+fn6mevXq5p577jG7du1yrD979qx59NFHTZUqVUzFihXNXXfdZQ4dOuS0jb1795pu3bqZgIAAExYWZp566imTnZ1d2j/F7ZYuXWok5Xvcf//9xhj7JdjPP/+8iYiIMP7+/qZTp04mKSnJaRsnTpwwAwcONJUrVzZBQUFmyJAhJj093anNli1bzC233GL8/f1N9erVzcsvv1xaP9EtLrefMjIyzO23327Cw8ONr6+viY2NNcOGDcv3PwrlYT8VtI8kmenTpzvauOvft6VLl5qmTZsaPz8/Ex8f7/QdZd2V9tO+fftMu3btTNWqVY2/v7+pXbu2eeaZZ5zmkTHm2t9PDz74oImNjTV+fn4mPDzcdOrUyRFijPHcvyWbMcaUXH8PAABAyWGMDAAA8FgEGQAA4LEIMgAAwGMRZAAAgMciyAAAAI9FkAEAAB6LIAMAADwWQQbANeuBBx5Q7969rS4DQAkiyABwi8OHD2vkyJGKj4+Xv7+/YmJi1KNHD6f7rtSsWVM2m002m02VKlVS8+bNNWfOHMf6woLHsmXLZLPZ8t3QLs/evXtls9kc98/J88Ybb2jGjBlu+HUAyiqCDACX7d27Vy1atNCSJUv097//Xdu2bdOCBQvUoUMHjRgxwqntiy++qEOHDmnTpk1q2bKl7rnnHq1cubJE6goODlZISEiJbBtA2UCQAeCyRx99VDabTWvXrlXfvn1Vt25dNWzYUE8++aRWr17t1DYwMFCRkZGqW7eu3nrrLQUEBOirr75y6fvz7nbcrFkz2Ww2tW/fXlL+Hp727dtr5MiRGj16tKpUqaKIiAi99957OnPmjIYMGaLAwEDVrl1b8+fPd9r+9u3b1a1bN1WuXFkRERG67777dPz4cZdqBuAeBBkALjl58qQWLFigESNGqFKlSvnWX65HxMfHR76+vsrKynKphrVr10qSFi1apEOHDmnu3LmFtv3www8VFhamtWvXauTIkXrkkUfUr18/3Xzzzdq4caNuv/123XfffcrIyJAkpaSkqGPHjmrWrJnWr1+vBQsW6MiRI+rfv79LNQNwD4IMAJfs2rVLxhjVr1+/WJ/LysrSpEmTlJqaqo4dO7pUQ3h4uCQpNDRUkZGRqlq1aqFtb7jhBj333HOqU6eOxo4dqwoVKigsLEzDhg1TnTp19MILL+jEiRPaunWrJOnNN99Us2bN9NJLL6l+/fpq1qyZPvjgAy1dulS//PKLS3UDcJ2P1QUA8GzGmGK1HzNmjJ577jmdO3dOlStX1ssvv6zu3buXUHX5NWnSxPHa29tboaGhaty4sWNZRESEJOno0aOSpC1btmjp0qWqXLlyvm0lJyerbt26JVwxgMshyABwSZ06dWSz2fTzzz8Xqf0zzzyjBx54wDHexGazOdYFBQXp119/zfeZlJQUeXt7F3jqqrh8fX2d3ttsNqdlefXk5uZKkk6fPq0ePXrolVdeybetqKgol+sB4BpOLQFwSdWqVdWlSxe99dZbOnPmTL71l14yHRYWptq1aysyMtIpxEhSvXr19OOPPyozM9Np+caNGxUXF5cvhOTx8/OTJOXk5LjwSwrWvHlz/fjjj6pZs6Zq167t9HBHsALgGoIMAJe99dZbysnJ0U033aTPPvtMO3fu1E8//aQpU6YoISGhyNsZNGiQbDabBg8erA0bNmjXrl364IMP9Prrr+upp54q9HPVqlVTQECAYyBuamqqO36WJGnEiBE6efKkBg4cqHXr1ik5OVnffvuthgwZUiLBCUDxEGQAuCw+Pl4bN25Uhw4d9NRTT6lRo0a67bbbtHjxYk2bNq3I2wkJCdH333+v7Oxs9ezZU02bNtWUKVP06quv6o9//GOhn/Px8dGUKVP0zjvvKDo6Wr169XLHz5IkRUdH63//+59ycnJ0++23q3Hjxho9erRCQkLk5cV/QgGr2UxxR+oBAACUEfzvBAAA8FgEGQAA4LEIMgAAwGMRZAAAgMciyAAAAI9FkAEAAB6LIAMAADwWQQYAAHgsggwAAPBYBBkAAOCxCDIAAMBjEWQAAIDH+n8b2ySu41baigAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Produce plots\n",
        "args = [\"Loss\", \"Accuracy\", \"CPU\"]\n",
        "for a in args: model.plot(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpPQytRQjDhv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6099bb8e-a2e8-43cf-fe08-64ab3d290879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score on test set: 57.84\n"
          ]
        }
      ],
      "source": [
        "# check accuracy on test set\n",
        "print(f\"Accuracy score on test set: {np.round(np.sum(model.predict(X_test) == Y_test) / X_test.shape[0] * 100,2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "js6Zasee3C98"
      },
      "outputs": [],
      "source": [
        "# save the data for later comparison\n",
        "df_gs = model.backup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8EyXR7J25Ez"
      },
      "source": [
        "## 5) Final Comparision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSWSq46r27iU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "bca19803-8b3f-46d7-902d-5dcb53cbb163"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.plot(df_gd['step'], df_gd['loss'], label='Classic GD')\n",
        "plt.plot(df_random['step'], df_random['loss'], label='BCGD Randomized')\n",
        "plt.plot(df_gs['step'], df_gs['loss'], label='BCGD GS')\n",
        "\n",
        "plt.title('Loss comparison ')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "K42SP5Fiv5f8",
        "VLKgOJrhvx8S",
        "3hoWc2wju4aP",
        "o8ByFRyYaV6A",
        "my-QT4EOi4Ty"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}